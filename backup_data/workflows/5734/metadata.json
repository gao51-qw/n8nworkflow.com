{
  "id": 5734,
  "slug": "5734",
  "title": "Build a PDF-based RAG system with OpenAI, Pinecone and Cohere reranking",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\nThis workflow provides a complete, ready-to-use template for a **Retrieval-Augmented Generation (RAG)** system. It allows you to build a powerful AI chatbot that can answer questions based on the content of PDF documents you provide, using a modern and powerful stack for optimal performance.\n\n### Good to know\n* **Costs:** This workflow uses paid services (OpenAI, Pinecone, Cohere). Costs will be incurred based on your usage. Please review the pricing pages for each service to understand the potential expenses.\n* **Video Tutorial (Bahasa Indonesia):** For a step-by-step guide on how this workflow functions, you can watch the accompanying video tutorial here: [N8N Tutorial: Membangun Chatbot RAG dengan Pinecone, OpenAI, & Cohere](https://www.youtube.com/watch?v=pmp96hT8604&t=2s)\n\n### How it works\nThis workflow operates in two distinct stages:\n\n**1. Data Ingestion & Indexing:**\n* It begins when a **.pdf** file is uploaded via the n8n **Form Trigger**.\n* The **Default Data Loader** node processes the PDF, and the **Recursive Character Text Splitter** breaks down the content into smaller, manageable chunks.\n* The **Embeddings OpenAI** node converts these text chunks into vector embeddings (numerical representations).\n* Finally, the **Pinecone Vector Store** node takes these embeddings and stores (upserts) them into your specified Pinecone index, creating a searchable knowledge base.\n\n**2. Conversational AI Agent:**\n* A user sends a message through the **Chat Trigger**.\n* The **AI Agent** receives the message and uses its **VectorDB** tool to search the Pinecone index for relevant information.\n* The **Reranker Cohere** node refines these search results, ensuring only the most relevant context is selected.\n* The user's original question and the refined context are sent to the **OpenAI Chat Model** (`gpt-4.1`), which generates a helpful, context-aware answer.\n* The **Simple Memory** node maintains conversation history, allowing for natural, multi-turn dialogues.\n\n### How to use\nUsing this workflow is a two-step process:\n\n1.  **Populate the Knowledge Base:** First, you need to add documents. Trigger the workflow by using the **Form Trigger** and uploading a PDF file. Wait for the execution to complete. You can do this for multiple documents.\n2.  **Start Chatting:** Once your data has been ingested, open the **Chat Trigger**'s interface and start asking questions related to the content of your uploaded documents.\n\nThe Form Trigger is just an example. Feel free to replace it with other triggers, such as a node that watches a Google Drive or Dropbox folder for new files.\n\n### Requirements\nTo run this workflow, you will need active accounts and API keys for the following services.\n\n* **OpenAI Account & API Key:**\n    * **Function:** Powers text embedding and the final chat generation. Required for the `Embeddings OpenAI` and `OpenAI Chat Model` nodes.\n* **Pinecone Account & API Key:**\n    * **Function:** Used to store and retrieve your vector knowledge base. Required for the `Pinecone Vector Store` and `VectorDB` nodes. You also need to provide your Pinecone **Environment**.\n* **Cohere Account & API Key:**\n    * **Function:** Improves the accuracy of your chatbot by re-ranking search results for relevance. Required for the `Reranker Cohere` node.\n\n### Customising this workflow\nThis template is a great starting point. Here are a few ways you can customize it:\n\n* **Change the AI Personality:** Edit the **System Message** in the `AI Agent` node to change the bot's behavior, tone, or instructions.\n* **Use Different Models:** You can easily swap the OpenAI model for another one (e.g., `gpt-3.5-turbo` for lower costs) in the `OpenAI Chat Model` node.\n* **Adjust Retrieval:** In the `VectorDB` tool node, you can modify the `Top K` parameter to retrieve more or fewer document chunks to use as context.\n* **Automate Ingestion:** Replace the manual `Form Trigger` with an automated one, like a node that triggers whenever a new file is added to a specific cloud storage folder.",
  "featuredImage": "/data/workflows/5734/5734.webp",
  "author": {
    "id": 101,
    "slug": "jipraks",
    "name": "Aji Prakoso",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 8071,
  "downloads": 807,
  "createdAt": "2025-07-07T04:35:30.589Z",
  "updatedAt": "2026-01-16T08:41:09.033Z",
  "publishedAt": "2025-07-07T04:35:30.589Z",
  "nodes": 14,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5734"
}