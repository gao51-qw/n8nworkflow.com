{
  "workflow": {
    "id": 5816,
    "name": "Discord AI chatbot with GPT-4o-mini & Redis memory persistence",
    "views": 1757,
    "recentViews": 1,
    "totalViews": 1757,
    "createdAt": "2025-07-09T10:01:50.431Z",
    "description": "**Description:**\nThis n8n workflow automates a Discord bot to fetch messages from a specified channel and send AI-generated responses in threads. It ensures smooth message processing and interaction, making it ideal for managing community discussions, customer support, or AI-based engagement. This workflow leverages Redis for memory persistence, ensuring that conversation history is maintained even if the workflow restarts, providing a seamless user experience.\n\n## How It Works\n\n- The bot listens for new messages in a specified Discord channel.\n- It sends the messages to an AI model for response generation.\n- The AI-generated reply is posted as a thread under the original message.\n- The bot runs on an Ubuntu server and is managed using PM2 for uptime stability.\n- The Discord bot (Python script) acts as the bridge, capturing messages from Discord and sending them to the n8n webhook. The n8n workflow then processes these messages, interacts with the AI model, and sends the AI's response back to Discord via the bot.\n\n## Prerequisites to host Bot\n- Sign up on [Pella](https://www.pella.app/), which is a managed hosting service for Discord Bots. (Easy Setup)\n- A Redis instance for memory persistence. Redis is an in-memory data structure store, used here to store and retrieve conversation history, ensuring that the AI can maintain context across multiple interactions. This is crucial for coherent and continuous conversations.\n\n## Set Up Steps\n\n### **1Ô∏è‚É£ Create a Discord Bot**\n\n1. Go to the [Discord Developer Portal](https://discord.com/developers/applications).\n2. Click **‚ÄúNew Application‚Äù**, enter a name, and create it.\n3. Navigate to **Bot** &gt; **Reset Token**, then copy the **Bot Token**.\n4. Enable **Privileged Gateway Intents** (Presence, Server Members, Message Content).\n5. Under **OAuth2 &gt; URL Generator**, select **bot** scope and required permissions.\n6. Copy the generated URL, open it in a browser, select your server, and click **Authorize**.\n\n### **2Ô∏è‚É£ Deploy the Bot on Pella**\n\n1. Create a new folder `discord-bot` and navigate into it:\n\n2. Create and configure an `.env` file to store your bot token:\n\n3. Copy the code to .env: (You can copy the webhook URL from the n8n workflow)\n    ```bash\n    TOKEN=your-bot-token-here\n    WEBHOOK_URL=[https://your-domain.tld/webhook/getmessage](https://your-domain.tld/webhook/getmessage) \n    ```\n4. Create file `main.py` copy the below code and save it:\n\n5. Copy this Bot script to `main.py`:\n    ```py\n    import discord\n    import requests\n    import json\n    import os\n    from dotenv import load_dotenv\n    \n    # Load environment variables from .env file\n    load_dotenv()\n    TOKEN = os.getenv(\"TOKEN\")\n    WEBHOOK_URL = os.getenv(\"WEBHOOK_URL\")\n    \n    # Bot Configuration\n    LISTEN_CHANNELS = [\"YOUR_CHANNEL_ID_1\", \"YOUR_CHANNEL_ID_2\"]  # Replace with your target channel IDs\n    \n    # Intents setup\n    intents = discord.Intents.default()\n    intents.messages = True  # Enable message event\n    intents.guilds = True\n    intents.message_content = True  # Required to read messages\n    \n    client = discord.Client(intents=intents)\n\n    @client.event\n    async def on_ready():\n        print(f'Logged in as {client.user}')\n    \n    @client.event\n    async def on_message(message):\n        if message.author == client.user:\n            return  # Ignore bot's own messages\n    \n        if str(message.channel.id) in LISTEN_CHANNELS:\n            try:\n                fetched_message = await message.channel.fetch_message(message.id)  # Ensure correct fetching\n                payload = {\n                    \"channel_id\": str(fetched_message.channel.id),  # Ensure it's string\n                    \"chat_message\": fetched_message.content,\n                    \"timestamp\": str(fetched_message.created_at),  # Ensure proper formatting\n                    \"message_id\": str(fetched_message.id),  # Ensure ID is a string\n                    \"user_id\": str(fetched_message.author.id)  # Ensure user ID is also string\n                }\n    \n                headers = {'Content-Type': 'application/json'}\n                response = requests.post(WEBHOOK_URL, data=json.dumps(payload), headers=headers)\n    \n                if response.status_code == 200:\n                    print(f\"Message sent successfully: {payload}\")\n                else:\n                    print(f\"Failed to send message: {response.status_code}, Response: {response.text}\")\n            except Exception as e:\n                print(f\"Error fetching message: {e}\")\n    \n    client.run(TOKEN)\n    ```\n\n6. Create `requirements.txt` and copy:\n    ```bash\n    discord\n    python-dotenv\n    ```\n### **3Ô∏è‚É£ Follow the video to set up the bot which will run 24/7**\n\n1. Tutorial - https://www.youtube.com/watch?v=rNnK3XlUtYU\n\nNote: Free Plan will expire after 24 hours, so please opt for the Paid Plan in Pella to keep your bot running.\n\n### **4Ô∏è‚É£ n8n Workflow Configuration**\n\nThe n8n workflow consists of the following nodes:\n\n-   **Get Discord Messages (Webhook):** This node acts as the entry point for messages from the Discord bot. It receives the `channel_id`, `chat_message`, `timestamp`, `message_id`, and `user_id` from Discord when a new message is posted in the configured channel. Its webhook path is `/getmessage` and it expects a POST request.\n-   **Chat Agent (Langchain Agent):** This node processes the incoming Discord message (`chat_message`). It is configured as a conversational agent, integrating the language model and memory to generate an appropriate response. It also has a prompt to keep the reply concise, under 1800 characters.\n-   **OpenAI -4o-mini (Langchain Language Model):** This node connects to the OpenAI API and uses the `gpt-4o-mini-2024-07-18` model for generating AI responses. It is the core AI component of the workflow.\n-   **Message History (Redis Chat Memory):** This node manages the conversation history using Redis. It stores and retrieves chat messages, ensuring the `Chat Agent` maintains context for each user based on their `user_id`. This is critical for coherent multi-turn conversations.\n-   **Calculator (Langchain Tool):** This node provides a calculator tool that the AI agent can utilize if a mathematical calculation is required within the conversation. This expands the capabilities of the AI beyond just text generation.\n-   **Response fromAI (Discord):** This node sends the AI-generated response back to the Discord channel. It uses the Discord Bot API credentials and replies in a thread under the original message (`message_id`) in the specified `channel_id`.\n-   **Sticky Note1, Sticky Note2, Sticky Note3, Sticky Note4, Sticky Note5, Sticky Note:** These are informational nodes within the workflow providing instructions, code snippets for the Discord bot, and setup guidance for the user. These notes guide the user on setting up the `.env` file, `requirements.txt`, the Python bot code, and general recommendations for channel configuration and adding tools.\n\n### **5Ô∏è‚É£ Setting up Redis**\n\n1.  **Choose a Redis Hosting Provider:** You can use a cloud provider like Redis Labs, Aiven, or set up your own Redis instance on a VPS.\n2.  **Obtain Redis Connection Details:** Once your Redis instance is set up, you will need the host, port, and password (if applicable).\n3.  **Configure n8n Redis Nodes:** In your n8n workflow, configure the \"Message History\" node with your Redis connection details. Ensure the Redis credential `‚úÖ redis-for-n8n` is properly set up with your Redis instance details (host, port, password).\n\n### **6Ô∏è‚É£ Customizing the Template**\n\n-   **AI Model:** You can easily swap out the \"OpenAI -4o-mini\" node with any other AI service supported by n8n (e.g., Cohere, Hugging Face) to use a different language model. Ensure the new language model node is connected to the `ai_languageModel` input of the \"Chat Agent\" node.\n-   **Agent Prompt:** Modify the `text` parameter in the \"Chat Agent\" node to change the AI's persona, provide specific instructions, or adjust the response length.\n-   **Additional Tools:** The \"Calculator\" node is an example of an AI tool. You can add more Langchain tool nodes (e.g., search, data lookup) and connect them to the `ai_tool` input of the \"Chat Agent\" node to extend the AI's capabilities. Refer to the \"Sticky Note5\" in the workflow for a reminder.\n-   **Channel Filtering:** Adjust the `LISTEN_CHANNELS` list in the `main.py` file of your Discord bot to include or exclude specific Discord channel IDs where the bot should listen for messages.\n-   **Thread Management:** The \"Response fromAI\" node can be modified to change how threads are created or managed, or to send responses directly to the channel instead of a thread. The current setup links the response to the original message ID (`message_reference`).\n\n### **7Ô∏è‚É£ Testing Instructions**\n\n1.  **Start the Discord Bot:** Ensure your `main.py` script is running on Pella.\n2.  **Activate the n8n Workflow:** Make sure your n8n workflow is active and listening for webhooks.\n3.  **Send a Message in Discord:** Go to one of the `LISTEN_CHANNELS` in your Discord server and send a message.\n4.  **Verify Response:** The bot should capture the message, send it to n8n, receive an AI-generated response, and post it as a thread under your original message.\n5.  **Check Redis:** Verify that the conversation history is being stored and updated correctly in your Redis instance. Look for keys related to user IDs.\n\n‚úÖ **Now your bot is running in the background!** üöÄ",
    "workflow": {
      "meta": {
        "instanceId": "88bf9d043fa4afdfb9ba1170aff0be979b18f135494b39a8b59f9dbeb5bf011c",
        "templateCredsSetupCompleted": true
      },
      "nodes": [
        {
          "id": "1a8503cb-7d8f-4160-b9aa-bfe5c75f02e0",
          "name": "Calculator",
          "type": "@n8n/n8n-nodes-langchain.toolCalculator",
          "position": [
            1000,
            520
          ],
          "parameters": {},
          "typeVersion": 1
        },
        {
          "id": "8dab1d16-0d0d-47fe-9675-017827a0188c",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -640,
            40
          ],
          "parameters": {
            "width": 953.4544277976706,
            "content": "## .env for Discord bot\n```md\nTOKEN=your-bot-token-here\nWEBHOOK_URL=https://your-domain.tld/webhook/getmessage\n```"
          },
          "typeVersion": 1
        },
        {
          "id": "b83c3a70-fe5e-4f90-8177-e6fbefc1af2a",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -640,
            1220
          ],
          "parameters": {
            "width": 949,
            "height": 100,
            "content": "## requirements.txt,txt\ndiscord\npython-dotenv"
          },
          "typeVersion": 1
        },
        {
          "id": "8c4b3445-005e-4418-9ad0-e89c53b077b4",
          "name": "Sticky Note3",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -640,
            220
          ],
          "parameters": {
            "width": 953.7499545009089,
            "height": 974.8320906053484,
            "content": "## Discord Bot Code\n\n```py\nimport discord\nimport requests\nimport json\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\nTOKEN = os.getenv(\"TOKEN\")\nWEBHOOK_URL = os.getenv(\"WEBHOOK_URL\")\n\n# Bot Configuration\nLISTEN_CHANNELS = [123456789012345678]  # Replace with your target channel IDs\n\n# Intents setup\nintents = discord.Intents.default()\nintents.messages = True  # Enable message event\nintents.guilds = True\nintents.message_content = True  # Required to read messages\n\nclient = discord.Client(intents=intents)\n\n@client.event\nasync def on_ready():\n    print(f'Logged in as {client.user}')\n\n@client.event\nasync def on_message(message):\n    if message.author == client.user:\n        return  # Ignore bot's own messages\n    \n    if message.channel.id in LISTEN_CHANNELS:\n        try:\n            fetched_message = await message.channel.fetch_message(message.id)  # Ensure correct fetching\n            payload = {\n                \"channel_id\": str(fetched_message.channel.id),  # Ensure it's string\n                \"chat_message\": fetched_message.content,\n                \"timestamp\": str(fetched_message.created_at),  # Ensure proper formatting\n                \"message_id\": str(fetched_message.id),  # Ensure ID is a string\n                \"user_id\": str(fetched_message.author.id)  # Ensure user ID is also string\n            }\n            \n            headers = {'Content-Type': 'application/json'}\n            response = requests.post(WEBHOOK_URL, data=json.dumps(payload), headers=headers)\n            \n            if response.status_code == 200:\n                print(f\"Message sent successfully: {payload}\")\n            else:\n                print(f\"Failed to send message: {response.status_code}, Response: {response.text}\")\n        except Exception as e:\n            print(f\"Error fetching message: {e}\")\n\nclient.run(TOKEN)\n\n```"
          },
          "typeVersion": 1
        },
        {
          "id": "1187dd59-d4d9-4916-8b91-49e5e0756cc1",
          "name": "Response fromAI",
          "type": "n8n-nodes-base.discord",
          "position": [
            1120,
            220
          ],
          "webhookId": "735bc71f-14ae-48ff-b145-f2620466a3d0",
          "parameters": {
            "content": "={{ $json.output }}",
            "guildId": {
              "__rl": true,
              "mode": "list",
              "value": "697416344865472593",
              "cachedResultUrl": "https://discord.com/channels/697416344865472593",
              "cachedResultName": "server"
            },
            "options": {
              "message_reference": "={{ $('Get Discord Messages').item.json.body.message_id }}"
            },
            "resource": "message",
            "channelId": {
              "__rl": true,
              "mode": "list",
              "value": "1336754177824653423",
              "cachedResultUrl": "https://discord.com/channels/697416344865472593/1336754177824653423",
              "cachedResultName": "assistant"
            }
          },
          "credentials": {
            "discordBotApi": {
              "id": "credential-id",
              "name": "discordBotApi Credential"
            }
          },
          "typeVersion": 2
        },
        {
          "id": "51199d60-0549-43a6-affd-e0056fba36f5",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            420,
            120
          ],
          "parameters": {
            "color": 4,
            "width": 220,
            "height": 260,
            "content": "Get the Production Webhook URL for .env"
          },
          "typeVersion": 1
        },
        {
          "id": "af7b7213-e586-4ca0-9caf-38ba91a74092",
          "name": "OpenAI -4o-mini ",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            640,
            520
          ],
          "parameters": {
            "model": "gpt-4o-mini-2024-07-18",
            "options": {
              "maxTokens": 2000
            }
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "0788c61b-ae58-446a-a5fe-06bf15b2c2f3",
          "name": "Sticky Note4",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1020,
            120
          ],
          "parameters": {
            "color": 6,
            "width": 300,
            "height": 260,
            "content": "Change the Channel According to you. \n( Recommend to make it Private if you are using it for personal Chat )"
          },
          "typeVersion": 1
        },
        {
          "id": "6c2cc2e2-0123-45ac-ae8c-2f6f2d294c14",
          "name": "Get Discord Messages",
          "type": "n8n-nodes-base.webhook",
          "position": [
            480,
            220
          ],
          "webhookId": "4c80241d-69ca-4394-8e09-d1f72cd0878f",
          "parameters": {
            "path": "getmessage",
            "options": {},
            "httpMethod": "POST"
          },
          "typeVersion": 2
        },
        {
          "id": "874ba5fd-2d34-4621-a147-0a3f161fb9a1",
          "name": "Message History",
          "type": "@n8n/n8n-nodes-langchain.memoryRedisChat",
          "position": [
            800,
            520
          ],
          "parameters": {
            "sessionKey": "={{ $('Get Discord Messages').item.json.body.user_id}}",
            "sessionIdType": "customKey"
          },
          "credentials": {
            "redis": {
              "id": "credential-id",
              "name": "redis Credential"
            }
          },
          "typeVersion": 1.4
        },
        {
          "id": "2f228d84-3ee6-4050-a7f3-3d0e6a70c4fc",
          "name": "Sticky Note5",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            940,
            480
          ],
          "parameters": {
            "width": 280,
            "height": 220,
            "content": "\n\n\n\n\n\n\n\n\n\n\n\nAdd additional necessary Tools based on you requirements."
          },
          "typeVersion": 1
        },
        {
          "id": "b2dd03bf-e52e-4046-a94b-1020ccc3709d",
          "name": "Chat Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            700,
            220
          ],
          "parameters": {
            "text": "={{ $json.body.chat_message }} \n\nKeep the Reply Max and under 1800 characters.",
            "agent": "conversationalAgent",
            "options": {},
            "promptType": "define"
          },
          "typeVersion": 1.6
        }
      ],
      "pinData": {},
      "connections": {
        "Calculator": {
          "ai_tool": [
            [
              {
                "node": "Chat Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Chat Agent": {
          "main": [
            [
              {
                "node": "Response fromAI",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Message History": {
          "ai_memory": [
            [
              {
                "node": "Chat Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "OpenAI -4o-mini ": {
          "ai_languageModel": [
            [
              {
                "node": "Chat Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Get Discord Messages": {
          "main": [
            [
              {
                "node": "Chat Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 12,
      "nodeTypes": {
        "n8n-nodes-base.discord": {
          "count": 1
        },
        "n8n-nodes-base.webhook": {
          "count": 1
        },
        "n8n-nodes-base.stickyNote": {
          "count": 6
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.toolCalculator": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.memoryRedisChat": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Dhruv Dalsaniya",
      "username": "ddm21",
      "bio": "IT Professional & Freelance Automation Consultant specializing in AI-driven automation and business process optimization",
      "verified": true,
      "links": [
        "https://in.linkedin.com/in/dhruvdalsaniya21"
      ],
      "avatar": "https://gravatar.com/avatar/367111bb2fd90204e1ce6f05ef666d8e9e6b73829748584483278f1843c02060?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 47,
        "icon": "file:webhook.svg",
        "name": "n8n-nodes-base.webhook",
        "codex": {
          "data": {
            "alias": [
              "HTTP",
              "API",
              "Build",
              "WH"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/learn-how-to-automatically-cross-post-your-content-with-n8n/",
                  "icon": "‚úçÔ∏è",
                  "label": "Learn how to automatically cross-post your content with n8n"
                },
                {
                  "url": "https://n8n.io/blog/running-n8n-on-ships-an-interview-with-maranics/",
                  "icon": "üõ≥",
                  "label": "Running n8n on ships: An interview with Maranics"
                },
                {
                  "url": "https://n8n.io/blog/how-to-build-a-low-code-self-hosted-url-shortener/",
                  "icon": "üîó",
                  "label": "How to build a low-code, self-hosted URL shortener in 3 steps"
                },
                {
                  "url": "https://n8n.io/blog/what-are-apis-how-to-use-them-with-no-code/",
                  "icon": " ü™¢",
                  "label": "What are APIs and how to use them with no code"
                },
                {
                  "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                  "icon": "‚ö°Ô∏è",
                  "label": "5 tasks you can automate with the new Notion API "
                },
                {
                  "url": "https://n8n.io/blog/how-a-digital-strategist-uses-n8n-for-online-marketing/",
                  "icon": "üíª",
                  "label": "How a digital strategist uses n8n for online marketing"
                },
                {
                  "url": "https://n8n.io/blog/the-ultimate-guide-to-automate-your-video-collaboration-with-whereby-mattermost-and-n8n/",
                  "icon": "üìπ",
                  "label": "The ultimate guide to automate your video collaboration with Whereby, Mattermost, and n8n"
                },
                {
                  "url": "https://n8n.io/blog/how-to-automatically-give-kudos-to-contributors-with-github-slack-and-n8n/",
                  "icon": "üëè",
                  "label": "How to automatically give kudos to contributors with GitHub, Slack, and n8n"
                },
                {
                  "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                  "icon": "ü§ñ",
                  "label": "5 workflow automations for Mattermost that we love at n8n"
                },
                {
                  "url": "https://n8n.io/blog/why-this-product-manager-loves-workflow-automation-with-n8n/",
                  "icon": "üß†",
                  "label": "Why this Product Manager loves workflow automation with n8n"
                },
                {
                  "url": "https://n8n.io/blog/creating-custom-incident-response-workflows-with-n8n/",
                  "label": "How to automate every step of an incident response workflow"
                },
                {
                  "url": "https://n8n.io/blog/learn-to-build-powerful-api-endpoints-using-webhooks/",
                  "icon": "üß∞",
                  "label": "Learn to Build Powerful API Endpoints Using Webhooks"
                },
                {
                  "url": "https://n8n.io/blog/learn-how-to-use-webhooks-with-mattermost-slash-commands/",
                  "icon": "ü¶Ñ",
                  "label": "Learn how to use webhooks with Mattermost slash commands"
                },
                {
                  "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                  "icon": "üõµ",
                  "label": "How Goomer automated their operations with over 200 n8n workflows"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/"
                }
              ]
            },
            "categories": [
              "Development",
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "Webhook"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCI+PHBhdGggZmlsbD0iIzM3NDc0ZiIgZD0iTTM1IDM3Yy0yLjIgMC00LTEuOC00LTRzMS44LTQgNC00IDQgMS44IDQgNC0xLjggNC00IDQiLz48cGF0aCBmaWxsPSIjMzc0NzRmIiBkPSJNMzUgNDNjLTMgMC01LjktMS40LTcuOC0zLjdsMy4xLTIuNWMxLjEgMS40IDIuOSAyLjMgNC43IDIuMyAzLjMgMCA2LTIuNyA2LTZzLTIuNy02LTYtNmMtMSAwLTIgLjMtMi45LjdsLTEuNyAxTDIzLjMgMTZsMy41LTEuOSA1LjMgOS40YzEtLjMgMi0uNSAzLS41IDUuNSAwIDEwIDQuNSAxMCAxMFM0MC41IDQzIDM1IDQzIi8+PHBhdGggZmlsbD0iIzM3NDc0ZiIgZD0iTTE0IDQzQzguNSA0MyA0IDM4LjUgNCAzM2MwLTQuNiAzLjEtOC41IDcuNS05LjdsMSAzLjlDOS45IDI3LjkgOCAzMC4zIDggMzNjMCAzLjMgMi43IDYgNiA2czYtMi43IDYtNnYtMmgxNXY0SDIzLjhjLS45IDQuNi01IDgtOS44IDgiLz48cGF0aCBmaWxsPSIjZTkxZTYzIiBkPSJNMTQgMzdjLTIuMiAwLTQtMS44LTQtNHMxLjgtNCA0LTQgNCAxLjggNCA0LTEuOCA0LTQgNCIvPjxwYXRoIGZpbGw9IiMzNzQ3NGYiIGQ9Ik0yNSAxOWMtMi4yIDAtNC0xLjgtNC00czEuOC00IDQtNCA0IDEuOCA0IDQtMS44IDQtNCA0Ii8+PHBhdGggZmlsbD0iI2U5MWU2MyIgZD0ibTE1LjcgMzQtMy40LTIgNS45LTkuN2MtMi0xLjktMy4yLTQuNS0zLjItNy4zIDAtNS41IDQuNS0xMCAxMC0xMHMxMCA0LjUgMTAgMTBjMCAuOS0uMSAxLjctLjMgMi41bC0zLjktMWMuMS0uNS4yLTEgLjItMS41IDAtMy4zLTIuNy02LTYtNnMtNiAyLjctNiA2YzAgMi4xIDEuMSA0IDIuOSA1LjFsMS43IDF6Ii8+PC9zdmc+"
        },
        "displayName": "Webhook",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 5,
            "name": "Development"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 60,
        "icon": "file:discord.svg",
        "name": "n8n-nodes-base.discord",
        "codex": {
          "data": {
            "alias": [
              "human",
              "form",
              "wait",
              "hitl",
              "approval"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.discord/"
                }
              ],
              "credentialDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/credentials/discord/"
                }
              ]
            },
            "categories": [
              "Communication",
              "HITL"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "HITL": [
                "Human in the Loop"
              ]
            }
          }
        },
        "group": "[\"output\"]",
        "defaults": {
          "name": "Discord"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNTYiIGhlaWdodD0iMTk5IiBwcmVzZXJ2ZUFzcGVjdFJhdGlvPSJ4TWlkWU1pZCI+PHBhdGggZmlsbD0iIzU4NjVGMiIgZD0iTTIxNi44NTYgMTYuNTk3QTIwOC41IDIwOC41IDAgMCAwIDE2NC4wNDIgMGMtMi4yNzUgNC4xMTMtNC45MzMgOS42NDUtNi43NjYgMTQuMDQ2cS0yOS41MzgtNC40NDItNTguNTMzIDBjLTEuODMyLTQuNC00LjU1LTkuOTMzLTYuODQ2LTE0LjA0NmEyMDcuOCAyMDcuOCAwIDAgMC01Mi44NTUgMTYuNjM4QzUuNjE4IDY3LjE0Ny0zLjQ0MyAxMTYuNCAxLjA4NyAxNjQuOTU2YzIyLjE2OSAxNi41NTUgNDMuNjUzIDI2LjYxMiA2NC43NzUgMzMuMTkzQTE2MSAxNjEgMCAwIDAgNzkuNzM1IDE3NS4zYTEzNi40IDEzNi40IDAgMCAxLTIxLjg0Ni0xMC42MzIgMTA5IDEwOSAwIDAgMCA1LjM1Ni00LjIzN2M0Mi4xMjIgMTkuNzAyIDg3Ljg5IDE5LjcwMiAxMjkuNTEgMGExMzIgMTMyIDAgMCAwIDUuMzU1IDQuMjM3IDEzNiAxMzYgMCAwIDEtMjEuODg2IDEwLjY1M2M0LjAwNiA4LjAyIDguNjM4IDE1LjY3IDEzLjg3MyAyMi44NDggMjEuMTQyLTYuNTggNDIuNjQ2LTE2LjYzNyA2NC44MTUtMzMuMjEzIDUuMzE2LTU2LjI4OC05LjA4LTEwNS4wOS0zOC4wNTYtMTQ4LjM2TTg1LjQ3NCAxMzUuMDk1Yy0xMi42NDUgMC0yMy4wMTUtMTEuODA1LTIzLjAxNS0yNi4xOHMxMC4xNDktMjYuMiAyMy4wMTUtMjYuMiAyMy4yMzYgMTEuODA0IDIzLjAxNSAyNi4yYy4wMiAxNC4zNzUtMTAuMTQ4IDI2LjE4LTIzLjAxNSAyNi4xOG04NS4wNTEgMGMtMTIuNjQ1IDAtMjMuMDE0LTExLjgwNS0yMy4wMTQtMjYuMThzMTAuMTQ4LTI2LjIgMjMuMDE0LTI2LjJjMTIuODY3IDAgMjMuMjM2IDExLjgwNCAyMy4wMTUgMjYuMiAwIDE0LjM3NS0xMC4xNDggMjYuMTgtMjMuMDE1IDI2LjE4Ii8+PC9zdmc+"
        },
        "displayName": "Discord",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 6,
            "name": "Communication"
          },
          {
            "id": 28,
            "name": "HITL"
          }
        ]
      },
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTM2Ljg2NzEgMTYuMzcxOEMzNy43NzQ2IDEzLjY0OCAzNy40NjIxIDEwLjY2NDIgMzYuMDEwOCA4LjE4NjYxQzMzLjgyODIgNC4zODY1MyAyOS40NDA3IDIuNDMxNDkgMjUuMTU1NiAzLjM1MTUxQzIzLjI0OTMgMS4yMDM5NiAyMC41MTA1IC0wLjAxNzMxNDggMTcuNjM5MiAwLjAwMDE4NTUzM0MxMy4yNTkxIC0wLjAwOTgxNDY4IDkuMzcyNzMgMi44MTAyNSA4LjAyNTIgNi45Nzc4M0M1LjIxMTM5IDcuNTU0MSAyLjc4MjU4IDkuMzE1MzggMS4zNjEzIDExLjgxMTdDLTAuODM3NDkzIDE1LjYwMTggLTAuMzM2MjMyIDIwLjM3OTQgMi42MDEzMyAyMy42Mjk0QzEuNjkzODEgMjYuMzUzMiAyLjAwNjMyIDI5LjMzNzEgMy40NTc2IDMxLjgxNDZDNS42NDAxNSAzNS42MTQ3IDEwLjAyNzcgMzcuNTY5NyAxNC4zMTI4IDM2LjY0OTdDMTYuMjE3OSAzOC43OTczIDE4Ljk1NzkgNDAuMDE4NSAyMS44MjkyIDM5Ljk5OThDMjYuMjExOCA0MC4wMTEgMzAuMDk5NCAzNy4xODg1IDMxLjQ0NjkgMzMuMDE3MUMzNC4yNjA4IDMyLjQ0MDkgMzYuNjg5NiAzMC42Nzk2IDM4LjExMDggMjguMTgzM0M0MC4zMDcxIDI0LjM5MzIgMzkuODA0NiAxOS42MTk0IDM2Ljg2ODMgMTYuMzY5M0wzNi44NjcxIDE2LjM3MThaTTIxLjgzMTcgMzcuMzg2QzIwLjA3OCAzNy4zODg1IDE4LjM3OTIgMzYuNzc0NyAxNy4wMzI5IDM1LjY1MDlDMTcuMDk0MSAzNS42MTg0IDE3LjIwMDQgMzUuNTU5NyAxNy4yNjkxIDM1LjUxNzJMMjUuMjM0MyAzMC45MTcxQzI1LjY0MTggMzAuNjg1OCAyNS44OTE4IDMwLjI1MjEgMjUuODg5MyAyOS43ODMzVjE4LjU1NDNMMjkuMjU1NyAyMC40OTgxQzI5LjI5MTkgMjAuNTE1NiAyOS4zMTU3IDIwLjU1MDYgMjkuMzIwNyAyMC41OTA2VjI5Ljg4OTZDMjkuMzE1NyAzNC4wMjQ3IDI1Ljk2NjggMzcuMzc3MiAyMS44MzE3IDM3LjM4NlpNNS43MjY0IDMwLjUwNzFDNC44NDc2MyAyOC45ODk2IDQuNTMxMzcgMjcuMjEwOCA0LjgzMjYzIDI1LjQ4NDVDNC44OTEzOCAyNS41MTk1IDQuOTk1MTMgMjUuNTgzMiA1LjA2ODg4IDI1LjYyNTdMMTMuMDM0MSAzMC4yMjU4QzEzLjQzNzggMzAuNDYyMSAxMy45Mzc4IDMwLjQ2MjEgMTQuMzQyOCAzMC4yMjU4TDI0LjA2NjggMjQuNjEwN1YyOC40OTgzQzI0LjA2OTMgMjguNTM4MyAyNC4wNTA1IDI4LjU3NyAyNC4wMTkzIDI4LjYwMkwxNS45Njc5IDMzLjI1MDlDMTIuMzgxNSAzNS4zMTU5IDcuODAxNDQgMzQuMDg4NCA1LjcyNzY1IDMwLjUwNzFINS43MjY0Wk0zLjYzMDEgMTMuMTIwNUM0LjUwNTEyIDExLjYwMDQgNS44ODY0IDEwLjQzNzkgNy41MzE0NCA5LjgzNDE1QzcuNTMxNDQgOS45MDI5IDcuNTI3NjkgMTAuMDI0MiA3LjUyNzY5IDEwLjEwOTJWMTkuMzEwNkM3LjUyNTE5IDE5Ljc3ODEgNy43NzUxOSAyMC4yMTE5IDguMTgxNDUgMjAuNDQzMUwxNy45MDU0IDI2LjA1N0wxNC41MzkxIDI4LjAwMDhDMTQuNTA1MyAyOC4wMjMzIDE0LjQ2MjggMjguMDI3IDE0LjQyNTMgMjguMDEwOEw2LjM3MjY2IDIzLjM1ODJDMi43OTM4MyAyMS4yODU2IDEuNTY2MzEgMTYuNzA2OCAzLjYyODg1IDEzLjEyMTdMMy42MzAxIDEzLjEyMDVaTTMxLjI4ODIgMTkuNTU2OUwyMS41NjQyIDEzLjk0MTdMMjQuOTMwNiAxMS45OTkyQzI0Ljk2NDMgMTEuOTc2NyAyNS4wMDY4IDExLjk3MjkgMjUuMDQ0MyAxMS45ODkyTDMzLjA5NyAxNi42MzhDMzYuNjgyMSAxOC43MDkzIDM3LjkxMDggMjMuMjk1NyAzNS44Mzk1IDI2Ljg4MDhDMzQuOTYzMyAyOC4zOTgzIDMzLjU4MzIgMjkuNTYwOCAzMS45Mzk1IDMwLjE2NThWMjAuNjg5NEMzMS45NDMyIDIwLjIyMTkgMzEuNjk0NSAxOS43ODk0IDMxLjI4OTQgMTkuNTU2OUgzMS4yODgyWk0zNC42MzgzIDE0LjUxNDJDMzQuNTc5NSAxNC40NzggMzQuNDc1OCAxNC40MTU1IDM0LjQwMiAxNC4zNzNMMjYuNDM2OCA5Ljc3Mjg5QzI2LjAzMzEgOS41MzY2NCAyNS41MzMxIDkuNTM2NjQgMjUuMTI4MSA5Ljc3Mjg5TDE1LjQwNDEgMTUuMzg4VjExLjUwMDRDMTUuNDAxNiAxMS40NjA0IDE1LjQyMDQgMTEuNDIxNyAxNS40NTE2IDExLjM5NjdMMjMuNTAzIDYuNzUxNThDMjcuMDg5NCA0LjY4Mjc5IDMxLjY3NDUgNS45MTQwNiAzMy43NDIgOS41MDE2NEMzNC42MTU4IDExLjAxNjcgMzQuOTMyIDEyLjc5MDUgMzQuNjM1OCAxNC41MTQySDM0LjYzODNaTTEzLjU3NDEgMjEuNDQzMUwxMC4yMDY1IDE5LjQ5OTRDMTAuMTcwMiAxOS40ODE5IDEwLjE0NjUgMTkuNDQ2OCAxMC4xNDE1IDE5LjQwNjhWMTAuMTA3OUMxMC4xNDQgNS45Njc4MSAxMy41MDI4IDIuNjEyNzQgMTcuNjQyOSAyLjYxNTI0QzE5LjM5NDIgMi42MTUyNCAyMS4wODkyIDMuMjMwMjUgMjIuNDM1NSA0LjM1MDI4QzIyLjM3NDMgNC4zODI3OCAyMi4yNjkzIDQuNDQxNTMgMjIuMTk5MiA0LjQ4NDAzTDE0LjIzNDEgOS4wODQxM0MxMy44MjY2IDkuMzE1MzggMTMuNTc2NiA5Ljc0Nzg5IDEzLjU3OTEgMTAuMjE2N0wxMy41NzQxIDIxLjQ0MDZWMjEuNDQzMVpNMTUuNDAyOSAxNy41MDA2TDE5LjczNDIgMTQuOTk5M0wyNC4wNjU1IDE3LjQ5OTNWMjIuNTAwN0wxOS43MzQyIDI1LjAwMDdMMTUuNDAyOSAyMi41MDA3VjE3LjUwMDZaIiBmaWxsPSIjN0Q3RDg3Ii8+Cjwvc3ZnPgo="
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1167,
        "icon": "file:redis.svg",
        "name": "@n8n/n8n-nodes-langchain.memoryRedisChat",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryredischat/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "Other memories"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Redis Chat Memory"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "Redis Chat Memory",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1195,
        "icon": "fa:calculator",
        "name": "@n8n/n8n-nodes-langchain.toolCalculator",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolcalculator/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Tools"
              ],
              "Tools": [
                "Other Tools"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Calculator"
        },
        "iconData": {
          "icon": "calculator",
          "type": "icon"
        },
        "displayName": "Calculator",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 40,
        "name": "Support Chatbot"
      },
      {
        "id": 47,
        "name": "AI Chatbot"
      }
    ],
    "image": []
  }
}