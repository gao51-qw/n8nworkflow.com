{
  "workflow": {
    "id": 7679,
    "name": "Email drafting & news research assistant with OpenAI, Gmail, Tavily & Perplexity",
    "views": 395,
    "recentViews": 0,
    "totalViews": 395,
    "createdAt": "2025-08-21T04:32:11.779Z",
    "description": "AI Agent MCP for Email & News Research\n\nBuild a chat-first MCP-powered research and outreach agent. This workflow lets you ask questions in an n8n chat, then the agent researches news (via Tavily + Perplexity through an MCP server) and drafts emails (via Gmail through a separate MCP server). It uses OpenAI for reasoning and short-term memory for coherent, multi‑turn conversations.\n\nWatch build along videos for workflows like these on: www.youtube.com/@automatewithmarc\n\nWhat this template does\n\nChat-native trigger: Start a conversation and ask for research or an email draft.\n\nMCP client tools: The agent talks to two MCP servers — one for Email work, one for News research.\n\nNews research stack: Uses Tavily (search) and Perplexity (LLM retrieval/answers) behind a News MCP server.\n\nEmail stack: Uses Gmail Tool to generate and send messages via an Email MCP server.\n\nReasoning + memory: OpenAI Chat Model + Simple Memory for context-aware, multi-step outputs.\n\nHow it works (node map)\n\nWhen chat message received → collects your prompt and routes it to the agent.\n\nAI Agent (system prompt = “helpful email assistant”) → orchestrates tools via MCP Clients.\n\nOpenAI Chat Model → reasoning/planning for research or email drafting.\n\nSimple Memory → keeps recent chat context for follow-ups.\n\nNews MCP Server exposes:\n\nTavily Tool (Search) and Perplexity Tool (Ask) for up-to-date findings.\n\nEmail MCP Server exposes:\n\nGmail Tool (To, Subject, Message via AI fields) to send or draft emails.\n\nThe MCP Clients (News/Email) plug into the Agent, so your single chat prompt can research and then draft/send emails in one flow.\n\nRequirements\n\nn8n (Cloud or self‑hosted)\n\nOpenAI API key for the Chat Model (set on the node)\n\nTavily, Perplexity, and Gmail credentials (connected on their respective tool nodes)\n\nPublicly reachable MCP Server endpoints (provided in the MCP Client nodes)\n\nSetup (quick start)\n\nImport the template and open it in the editor.\n\nConnect credentials on: OpenAI, Tavily, Perplexity, and Gmail tool nodes.\n\nConfirm MCP endpoints in both MCP Client nodes (News/Email) and leave transport as httpStreamable unless you have special requirements.\n\nRun the workflow. In chat, try:\n\n“Find today’s top stories on Kubernetes security and draft an intro email to Acme.”\n\n“Summarize the latest AI infra trends and email a 3‑bullet update to my team.”\n\nInputs & outputs\n\nInput: Natural-language prompt via chat trigger.\n\nTools used: News MCP (Tavily + Perplexity), Email MCP (Gmail).\n\nOutput: A researched summary and/or a drafted/sent email, returned in the chat and executed via Gmail when requested.\n\nWhy teams will love it\n\nOne prompt → research + outreach: No tab‑hopping between tools.\n\nUp-to-date answers: Pulls current info through Tavily/Perplexity.\n\nEmail finalization: Converts findings into send-ready drafts via Gmail.\n\nContext-aware: Memory keeps threads coherent across follow-ups.\n\nPro tips\n\nUse clear verbs in your prompt: “Research X, then email Y with Z takeaways.”\n\nFor safer runs, point Gmail to a test inbox first (or disable send and only draft).\n\nAdd guardrails in the Agent’s system message to match your voice/tone.",
    "workflow": {
      "id": "TgpCq3JAieEaFdGJ",
      "meta": {
        "templateCredsSetupCompleted": true
      },
      "name": "Email News MCP Template",
      "tags": [],
      "nodes": [
        {
          "id": "0606f766-255e-469c-8e6c-5751537ed3ab",
          "name": "AI Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            192,
            -160
          ],
          "parameters": {
            "options": {
              "systemMessage": "You are a helpful email assistant.\n\n##Tool\nUse attached Email MCP Tool for emails when asked\n\nUse attached Email MCP Tool for "
            }
          },
          "typeVersion": 2.2
        },
        {
          "id": "225b0350-6eae-45fc-a158-da9961b8aafe",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            0,
            -160
          ],
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.3
        },
        {
          "id": "80fcfcad-1310-4cf2-a4df-bf6746339cfd",
          "name": "OpenAI Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            48,
            48
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4.1-mini"
            },
            "options": {}
          },
          "typeVersion": 1.2
        },
        {
          "id": "7e3db391-7ede-4e92-9593-7a1288938d80",
          "name": "Simple Memory",
          "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
          "position": [
            224,
            48
          ],
          "parameters": {},
          "typeVersion": 1.3
        },
        {
          "id": "1b9a577c-3401-4081-be39-d5051922df38",
          "name": "Send a message in Gmail",
          "type": "n8n-nodes-base.gmailTool",
          "position": [
            -144,
            480
          ],
          "parameters": {
            "sendTo": "<<<REPLACE_WITH_EMAIL>>>",
            "message": "<<<REPLACE_WITH_MESSAGE>>>",
            "options": {},
            "subject": "<<<REPLACE_WITH_SUBJECT>>>"
          },
          "typeVersion": 2.1
        },
        {
          "id": "fa6ae7d8-3d4d-4bd0-a4f9-d1d295f5f14b",
          "name": "Send a message in Gmail1",
          "type": "n8n-nodes-base.gmailTool",
          "position": [
            64,
            480
          ],
          "parameters": {
            "sendTo": "<<<REPLACE_WITH_EMAIL>>>",
            "message": "<<<REPLACE_WITH_MESSAGE>>>",
            "options": {},
            "subject": "<<<REPLACE_WITH_SUBJECT>>>"
          },
          "typeVersion": 2.1
        },
        {
          "id": "252988a9-b546-4e1a-9d6f-338618b5781b",
          "name": "Send a message in Gmail2",
          "type": "n8n-nodes-base.gmailTool",
          "position": [
            256,
            480
          ],
          "parameters": {
            "sendTo": "<<<REPLACE_WITH_EMAIL>>>",
            "message": "<<<REPLACE_WITH_MESSAGE>>>",
            "options": {},
            "subject": "<<<REPLACE_WITH_SUBJECT>>>"
          },
          "typeVersion": 2.1
        },
        {
          "id": "722718e7-8a84-44b4-98e3-a6eb53902a7c",
          "name": "Search in Tavily",
          "type": "@tavily/n8n-nodes-tavily.tavilyTool",
          "position": [
            512,
            480
          ],
          "parameters": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Query', ``, 'string') }}",
            "options": {}
          },
          "typeVersion": 1
        },
        {
          "id": "0bba3a97-e1ee-46f5-abec-7713d6ff2948",
          "name": "Message a model in Perplexity",
          "type": "n8n-nodes-base.perplexityTool",
          "position": [
            688,
            480
          ],
          "parameters": {
            "options": {},
            "messages": {
              "message": [
                {
                  "content": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('message0_Text', ``, 'string') }}"
                }
              ]
            },
            "simplify": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Simplify_Output', ``, 'boolean') }}",
            "requestOptions": {}
          },
          "typeVersion": 1
        },
        {
          "id": "60b275c9-9e2f-4e3c-bc11-2477fe0bc951",
          "name": "News MCP Server",
          "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
          "position": [
            544,
            256
          ],
          "parameters": {
            "path": "<<<REPLACE_WITH_PATH>>>"
          },
          "typeVersion": 2
        },
        {
          "id": "946b0a9d-590f-4633-ac98-ce983bbb205f",
          "name": "Email MCP Server",
          "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
          "position": [
            -96,
            256
          ],
          "parameters": {
            "path": "<<<REPLACE_WITH_PATH>>>"
          },
          "typeVersion": 2
        },
        {
          "id": "34bff09d-95d1-446f-88cb-1c664d1ad754",
          "name": "Email MCP Client",
          "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
          "position": [
            544,
            48
          ],
          "parameters": {
            "endpointUrl": "<<<REPLACE_WITH_ENDPOINT_URL>>>",
            "serverTransport": "httpStreamable"
          },
          "typeVersion": 1.1
        },
        {
          "id": "57587695-df6b-461d-8596-6561ce295f79",
          "name": "News MCP Client",
          "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
          "position": [
            384,
            48
          ],
          "parameters": {
            "endpointUrl": "<<<REPLACE_WITH_ENDPOINT_URL>>>",
            "serverTransport": "httpStreamable"
          },
          "typeVersion": 1.1
        },
        {
          "id": "2e931983-39af-4b1d-9a16-e30cd536ff0b",
          "name": "Search in Tavily1",
          "type": "@tavily/n8n-nodes-tavily.tavilyTool",
          "position": [
            848,
            480
          ],
          "parameters": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Query', ``, 'string') }}",
            "options": {}
          },
          "typeVersion": 1
        },
        {
          "id": "c8fc2868-c029-454f-b47c-6cf2a4f2fb7c",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -1024,
            -432
          ],
          "parameters": {
            "width": 736,
            "height": 1808,
            "content": "AI Agent MCP for Email & News Research \n\nBuild a chat-first MCP-powered research and outreach agent. This workflow lets you ask questions in an n8n chat, then the agent researches news (via Tavily + Perplexity through an MCP server) and drafts emails (via Gmail through a separate MCP server). It uses OpenAI for reasoning and short-term memory for coherent, multi‑turn conversations.\n\nWatch build along videos for workflows like these on: www.youtube.com/@automatewithmarc\n\nWhat this template does\n\nChat-native trigger: Start a conversation and ask for research or an email draft.\n\nMCP client tools: The agent talks to two MCP servers — one for Email work, one for News research.\n\nNews research stack: Uses Tavily (search) and Perplexity (LLM retrieval/answers) behind a News MCP server.\n\nEmail stack: Uses Gmail Tool to generate and send messages via an Email MCP server.\n\nReasoning + memory: OpenAI Chat Model + Simple Memory for context-aware, multi-step outputs.\n\nHow it works (node map)\n\nWhen chat message received → collects your prompt and routes it to the agent.\n\nAI Agent (system prompt = “helpful email assistant”) → orchestrates tools via MCP Clients.\n\nOpenAI Chat Model → reasoning/planning for research or email drafting.\n\nSimple Memory → keeps recent chat context for follow-ups.\n\nNews MCP Server exposes:\n\nTavily Tool (Search) and Perplexity Tool (Ask) for up-to-date findings.\n\nEmail MCP Server exposes:\n\nGmail Tool (To, Subject, Message via AI fields) to send or draft emails.\n\nThe MCP Clients (News/Email) plug into the Agent, so your single chat prompt can research and then draft/send emails in one flow.\n\nRequirements\n\nn8n (Cloud or self‑hosted)\n\nOpenAI API key for the Chat Model (set on the node)\n\nTavily, Perplexity, and Gmail credentials (connected on their respective tool nodes)\n\nPublicly reachable MCP Server endpoints (provided in the MCP Client nodes)\n\nSetup (quick start)\n\nImport the template and open it in the editor.\n\nConnect credentials on: OpenAI, Tavily, Perplexity, and Gmail tool nodes.\n\nConfirm MCP endpoints in both MCP Client nodes (News/Email) and leave transport as httpStreamable unless you have special requirements.\n\nRun the workflow. In chat, try:\n\n“Find today’s top stories on Kubernetes security and draft an intro email to Acme.”\n\n“Summarize the latest AI infra trends and email a 3‑bullet update to my team.”\n\nInputs & outputs\n\nInput: Natural-language prompt via chat trigger.\n\nTools used: News MCP (Tavily + Perplexity), Email MCP (Gmail).\n\nOutput: A researched summary and/or a drafted/sent email, returned in the chat and executed via Gmail when requested.\n\nWhy teams will love it\n\nOne prompt → research + outreach: No tab‑hopping between tools.\n\nUp-to-date answers: Pulls current info through Tavily/Perplexity.\n\nEmail finalization: Converts findings into send-ready drafts via Gmail.\n\nContext-aware: Memory keeps threads coherent across follow-ups.\n\nPro tips\n\nUse clear verbs in your prompt: “Research X, then email Y with Z takeaways.”\n\nFor safer runs, point Gmail to a test inbox first (or disable send and only draft).\n\nAdd guardrails in the Agent’s system message to match your voice/tone."
          },
          "typeVersion": 1
        },
        {
          "id": "226bc7c3-d026-4dea-adec-1d8fc5a5481b",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -144,
            -304
          ],
          "parameters": {
            "color": 5,
            "width": 928,
            "height": 512,
            "content": "Agent & MCP Client"
          },
          "typeVersion": 1
        },
        {
          "id": "4d9280da-af9b-4eab-be1a-9c25a6258022",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -256,
            224
          ],
          "parameters": {
            "color": 6,
            "width": 672,
            "height": 512,
            "content": "Email MCP Server"
          },
          "typeVersion": 1
        },
        {
          "id": "f55f5515-090b-4c3d-9e60-49e0588292a4",
          "name": "Sticky Note3",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            432,
            224
          ],
          "parameters": {
            "color": 7,
            "width": 672,
            "height": 512,
            "content": "News Research MCP Server"
          },
          "typeVersion": 1
        }
      ],
      "active": false,
      "pinData": {},
      "settings": {
        "executionOrder": "v1"
      },
      "connections": {
        "Simple Memory": {
          "ai_memory": [
            [
              {
                "node": "AI Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "News MCP Client": {
          "ai_tool": [
            [
              {
                "node": "AI Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Email MCP Client": {
          "ai_tool": [
            [
              {
                "node": "AI Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Search in Tavily": {
          "ai_tool": [
            [
              {
                "node": "News MCP Server",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "OpenAI Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "AI Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Search in Tavily1": {
          "ai_tool": [
            [
              {
                "node": "News MCP Server",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Send a message in Gmail": {
          "ai_tool": [
            [
              {
                "node": "Email MCP Server",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Send a message in Gmail1": {
          "ai_tool": [
            [
              {
                "node": "Email MCP Server",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Send a message in Gmail2": {
          "ai_tool": [
            [
              {
                "node": "Email MCP Server",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "AI Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Message a model in Perplexity": {
          "ai_tool": [
            [
              {
                "node": "News MCP Server",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 18,
      "nodeTypes": {
        "n8n-nodes-base.gmailTool": {
          "count": 3
        },
        "n8n-nodes-base.stickyNote": {
          "count": 4
        },
        "n8n-nodes-base.perplexityTool": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.mcpTrigger": {
          "count": 2
        },
        "@tavily/n8n-nodes-tavily.tavilyTool": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.mcpClientTool": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Automate With Marc",
      "username": "marconi",
      "bio": "Automating Start-Up and Business processes. \nHelping non-techies understand and leverage Agentic AI with easy to understand step-by-step tutorials.\nCheck out my educational content:\nhttps://www.youtube.com/@Automatewithmarc\n",
      "verified": true,
      "links": [
        "https://www.youtube.com/@Automatewithmarc"
      ],
      "avatar": "https://gravatar.com/avatar/b9654a0dd147e6f3fa7e6eb601b6572b8051c8ab4cb693774451adf9a6294798?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1163,
        "icon": "fa:database",
        "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "For beginners"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Simple Memory"
        },
        "iconData": {
          "icon": "database",
          "type": "icon"
        },
        "displayName": "Simple Memory",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1292,
        "icon": "file:../mcp.svg",
        "name": "@n8n/n8n-nodes-langchain.mcpClientTool",
        "codex": {
          "data": {
            "alias": [
              "Model Context Protocol",
              "MCP Client"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolmcp/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Model Context Protocol",
                "Tools"
              ]
            }
          }
        },
        "group": "[\"output\"]",
        "defaults": {
          "name": "MCP Client"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTgwIiBoZWlnaHQ9IjE4MCIgdmlld0JveD0iMCAwIDE5NSAxOTUiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+Cgk8ZyBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMTIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+CgkJPHBhdGggZD0iTTI1IDk3Ljg1MjhMOTIuODgyMyAyOS45NzA2QzEwMi4yNTUgMjAuNTk4IDExNy40NTEgMjAuNTk4IDEyNi44MjMgMjkuOTcwNlYyOS45NzA2QzEzNi4xOTYgMzkuMzQzMSAxMzYuMTk2IDU0LjUzOTEgMTI2LjgyMyA2My45MTE3TDc1LjU1ODEgMTE1LjE3NyIvPgoJCTxwYXRoIGQ9Ik03Ni4yNjUzIDExNC40N0wxMjYuODIzIDYzLjkxMTdDMTM2LjE5NiA1NC41MzkxIDE1MS4zOTIgNTQuNTM5MSAxNjAuNzY1IDYzLjkxMTdMMTYxLjExOCA2NC4yNjUyQzE3MC40OTEgNzMuNjM3OCAxNzAuNDkxIDg4LjgzMzggMTYxLjExOCA5OC4yMDYzTDk5LjcyNDggMTU5LjZDOTYuNjAwNiAxNjIuNzI0IDk2LjYwMDYgMTY3Ljc4OSA5OS43MjQ4IDE3MC45MTNMMTEyLjMzMSAxODMuNTIiLz4KCQk8cGF0aCBkPSJNMTA5Ljg1MyA0Ni45NDExTDU5LjY0ODIgOTcuMTQ1N0M1MC4yNzU3IDEwNi41MTggNTAuMjc1NyAxMjEuNzE0IDU5LjY0ODIgMTMxLjA4N1YxMzEuMDg3QzY5LjAyMDggMTQwLjQ1OSA4NC4yMTY4IDE0MC40NTkgOTMuNTg5NCAxMzEuMDg3TDE0My43OTQgODAuODgyMiIvPgoJPC9nPgo8L3N2Zz4K"
        },
        "displayName": "MCP Client Tool",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1293,
        "icon": "file:../mcp.svg",
        "name": "@n8n/n8n-nodes-langchain.mcpTrigger",
        "codex": {
          "data": {
            "alias": [
              "Model Context Protocol",
              "MCP Server"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.mcptrigger/"
                }
              ]
            },
            "categories": [
              "AI",
              "Core Nodes",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Root Nodes",
                "Model Context Protocol"
              ],
              "Core Nodes": [
                "Other Trigger Nodes"
              ]
            }
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "MCP Server Trigger"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTgwIiBoZWlnaHQ9IjE4MCIgdmlld0JveD0iMCAwIDE5NSAxOTUiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+Cgk8ZyBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMTIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+CgkJPHBhdGggZD0iTTI1IDk3Ljg1MjhMOTIuODgyMyAyOS45NzA2QzEwMi4yNTUgMjAuNTk4IDExNy40NTEgMjAuNTk4IDEyNi44MjMgMjkuOTcwNlYyOS45NzA2QzEzNi4xOTYgMzkuMzQzMSAxMzYuMTk2IDU0LjUzOTEgMTI2LjgyMyA2My45MTE3TDc1LjU1ODEgMTE1LjE3NyIvPgoJCTxwYXRoIGQ9Ik03Ni4yNjUzIDExNC40N0wxMjYuODIzIDYzLjkxMTdDMTM2LjE5NiA1NC41MzkxIDE1MS4zOTIgNTQuNTM5MSAxNjAuNzY1IDYzLjkxMTdMMTYxLjExOCA2NC4yNjUyQzE3MC40OTEgNzMuNjM3OCAxNzAuNDkxIDg4LjgzMzggMTYxLjExOCA5OC4yMDYzTDk5LjcyNDggMTU5LjZDOTYuNjAwNiAxNjIuNzI0IDk2LjYwMDYgMTY3Ljc4OSA5OS43MjQ4IDE3MC45MTNMMTEyLjMzMSAxODMuNTIiLz4KCQk8cGF0aCBkPSJNMTA5Ljg1MyA0Ni45NDExTDU5LjY0ODIgOTcuMTQ1N0M1MC4yNzU3IDEwNi41MTggNTAuMjc1NyAxMjEuNzE0IDU5LjY0ODIgMTMxLjA4N1YxMzEuMDg3QzY5LjAyMDggMTQwLjQ1OSA4NC4yMTY4IDE0MC40NTkgOTMuNTg5NCAxMzEuMDg3TDE0My43OTQgODAuODgyMiIvPgoJPC9nPgo8L3N2Zz4K"
        },
        "displayName": "MCP Server Trigger",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 47,
        "name": "AI Chatbot"
      },
      {
        "id": 51,
        "name": "Multimodal AI"
      }
    ],
    "image": []
  }
}