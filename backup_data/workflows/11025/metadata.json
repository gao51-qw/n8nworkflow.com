{
  "id": 11025,
  "slug": "11025",
  "title": "n8n enterprise AI security firewall ‚Äî guardrails for secure agents",
  "description": "# üõ°Ô∏è n8n Guardrails: Risk Ranking\n\nThis workflow provides a complete testing rig for evaluating text against **seven essential AI guardrails** used in production systems.  \nIt helps you detect jailbreak attempts, PII exposure, NSFW content, secret key leaks, malicious URLs, topical misalignment, and keyword violations.  \nUse the included **Google Sheet or CSV** to batch-test multiple inputs instantly.\n\n---\n\n## ## How It Works (Internal Workflow Overview)\n\n### **1. Load Input Rows**\nThe workflow reads each test entry (Guardrail_Type + Input_Text) from a Google Sheet or CSV.\n\n### **2. Route to the Correct Guardrail**\nA Switch node sends the text to the appropriate guardrail:\n- Jailbreak  \n- PII  \n- Secret Keys  \n- NSFW  \n- URLs  \n- Topical Alignment  \n- Keywords  \n\n### **3. AI Guardrail Evaluation**\nEach guardrail uses **Google Gemini** to return:\n- Pass / Fail  \n- Confidence score  \n- Reasoning  \n- Extracted PII, URLs, or entities (when relevant)\n\n### **4. Optional Sanitization Layer**\nThree sanitizers demonstrate how to *clean* unsafe text:\n- PII Sanitization  \n- Secret Key Sanitization  \n- URL Sanitization  \n\n### **5. Review Results**\nEach guardrail node outputs clean JSON, making debugging fast and transparent.\n\n---\n\n## ## How to Set Up\n\n### **1. Load the Test Dataset**\nUse either:\n- The included CSV file  \n- The linked Google Sheet  \n\nUpdate only:\n- **Document ID**  \n- **Sheet name**\n\n---\n\n### **2. Add Google Sheets Credentials**\nCreate an OAuth2 credential ‚Üí paste the Google JSON ‚Üí connect your account.\n\n---\n\n### **3. Add Google Gemini Credential**\nGo to **Credentials ‚Üí Google Gemini (PaLM API)** ‚Üí  \nPaste your API key ‚Üí attach it to all Guardrail nodes.\n\n---\n\n### **4. Review Sticky Notes**\nThey visually explain:\n- What each guardrail checks  \n- Why the check is important  \n- Risk scoring and impact  \n\n---\n\n### **5. Run the Workflow**\nClick **Execute Workflow** and inspect:\n- Each guardrail node‚Äôs output  \n- The full execution data  \n\n---\n\n## ## Requirements\n- n8n (latest version recommended)  \n- Google Gemini API key  \n- Google Sheets API access  \n- Test dataset: *n8n Guardrails test data.csv*  \n\n---\n\n## ## Test Data Included\n\nThe included dataset allows instant testing:\n- Jailbreak prompts  \n- PII samples  \n- API key leaks  \n- NSFW text  \n- Malicious URL examples  \n- Off-topic content  \n- Keyword triggers  \n\n---\n\n## ## Template Metadata\n\n**Template Author:** Sandeep Patharkar  \n**Category:** AI Safety / Agent Security  \n**Difficulty:** Intermediate  \n**Estimated Setup Time:** 10‚Äì15 minutes  \n**Tags:** Guardrails, AI Agents, Safety, Enterprise  \n\n---\n\n## ## Connect With Me\n\n**Author:** Sandeep Patharkar**  \nüîó **LinkedIn:** https://www.linkedin.com/in/sandeeppatharkar  \nüè† **Skool AIC+:** https://www.skool.com/aic-plus\n",
  "featuredImage": "/data/workflows/11025/11025.webp",
  "author": {
    "id": 101,
    "slug": "sandy4v",
    "name": "Sandeep Patharkar | www.FastTrackAiMastery.com",
    "avatar": ""
  },
  "categories": [
    "SecOps",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 73,
  "downloads": 7,
  "createdAt": "2025-11-19T23:33:38.959Z",
  "updatedAt": "2026-01-16T09:07:10.956Z",
  "publishedAt": "2025-11-19T23:33:38.959Z",
  "nodes": 32,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11025"
}