{
  "id": 9945,
  "slug": "9945",
  "title": "Scrape detailed GitHub profiles to Google Sheets using BrowserAct",
  "description": "![Scraping GitHub Users Activity](https://i.postimg.cc/wM34W9T0/Screen-Shot-20251025115912.png)\n\n## Scrape Detailed GitHub Profiles to Google Sheets Using BrowserAct\n\n### This template is a sophisticated **data enrichment** and **reporting tool** that scrapes detailed GitHub user profiles and organizes the information into dedicated, structured reports within a Google Sheet.\n\nThis workflow is essential for technical recruiters, talent acquisition teams, and business intelligence analysts who need to dive deep into a pre-qualified list of developers to understand their recent activity, repositories, and technical footprint.\n\n---\n\n### **Self-Hosted Only** \nThis Workflow uses a community contribution and is designed and tested for **self-hosted n8n instances** only.\n\n---\n### How it works\n* The workflow is triggered **manually** but can be started by a Schedule Trigger or by integrating directly with a candidate sourcing workflow (like the \"Source Top GitHub Contributors\" template).\n* A **Google Sheets** node reads a list of target GitHub user profile URLs from a master candidate sheet.\n* The **Loop Over Items** node processes each user one by one.\n* A **Slack** notification is sent at the beginning of the loop to announce that the scraping process has started for the user.\n* A **BrowserAct** node visits the user's GitHub profile URL and scrapes all available data, including **profile info**, **repositories**, and **social links**.\n* A custom **Code** node (labeled **\"Code in JavaScript\"**) performs a critical task: it cleans, fixes, and consolidates the complex, raw scraped data into a single, clean JSON object.\n* The workflow then dynamically manages your output. It **creates a new sheet** dedicated to the user (named after them) and **clears** it to ensure a fresh report every time.\n* The consolidated data is separated into three paths: main profile data, links, and repositories.\n* Three final **Google Sheets** nodes then **append** the structured data to the user's dedicated sheet, creating a clear, multi-section report (User Data, User Links, User Repositories).\n\n---\n### Requirements\n* **BrowserAct** API account for web scraping\n* **BrowserAct** \"**Scraping GitHub Users Activity & Data**\" Template\n* **BrowserAct** \"** Source Top GitHub Contributors by Language & Location**\" Template Output\n* **BrowserAct** n8n Community Node -&gt; ([n8n Nodes BrowserAct](https://www.npmjs.com/package/n8n-nodes-browseract-workflows))\n* **Google Sheets** credentials for input (candidate list) and structured output (individual user sheets)\n* **Slack** credentials for sending notifications\n\n---\n\n### Need Help?\n* #### [How to Find Your BrowseAct API Key & Workflow ID](https://www.youtube.com/watch?v=pDjoZWEsZlE)\n* #### [How to Connect n8n to Browseract](https://www.youtube.com/watch?v=RoYMdJaRdcQ)\n* #### [How to Use & Customize BrowserAct Templates](https://www.youtube.com/watch?v=CPZHFUASncY)\n* #### [How to Use the BrowserAct N8N Community Node](https://youtu.be/j0Nlba2pRLU)\n\n---\n### Workflow Guidance and Showcase\n\n* #### [GitHub Data Mining: Extracting User Profiles & Repositories with N8N](https://youtu.be/YjINoZgqx0M)",
  "featuredImage": "/data/workflows/9945/9945.webp",
  "author": {
    "id": 101,
    "slug": "madame-ai",
    "name": "Madame AI Team | Kai",
    "avatar": ""
  },
  "categories": [
    "Lead Generation"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 52,
  "downloads": 5,
  "createdAt": "2025-10-20T15:34:04.771Z",
  "updatedAt": "2026-01-16T09:02:45.993Z",
  "publishedAt": "2025-10-20T15:34:04.771Z",
  "nodes": 30,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9945"
}