{
  "workflow": {
    "id": 10139,
    "name": "Generate AI videos from text or images with Sora 2/Pro & GPT-5 enhancement",
    "views": 1700,
    "recentViews": 3,
    "totalViews": 1700,
    "createdAt": "2025-10-25T00:30:00.564Z",
    "description": "Harness OpenAI's Sora 2 for instant video creation from text or images using fal.ai's API‚Äîpowered by GPT-5 for refined prompts that ensure cinematic quality. This template processes form submissions, intelligently routes to text-to-video (with mandatory prompt enhancement) or image-to-video modes, and polls for completion before redirecting to your generated clip.\n\n## üìã What This Template Does\nUsers submit prompts, aspect ratios (9:16 or 16:9), models (sora-2 or pro), durations (4s, 8s, or 12s), and optional images via a web form. For text-to-video, GPT-5 automatically refines the prompt for optimal Sora 2 results; image mode uses the raw input. It calls one of four fal.ai endpoints (text-to-video, text-to-video/pro, image-to-video, image-to-video/pro), then loops every 60s to check status until the video is ready.\n- Handles dual modes: Text (with GPT-5 enhancement) or image-seeded generation\n- Supports pro upgrades for higher fidelity and longer clips\n- Auto-uploads images to a temp host and polls asynchronously for hands-free results\n- Redirects directly to the final video URL on completion\n\n## üîß Prerequisites\n- n8n instance with HTTP Request and LangChain nodes enabled\n- fal.ai account for Sora 2 API access\n- OpenAI account for GPT-5 prompt refinement\n\n## üîë Required Credentials\n\n### fal.ai API Setup\n1. Sign up at fal.ai and navigate to Dashboard ‚Üí API Keys\n2. Generate a new key with \"sora-2\" permissions (full access recommended)\n3. In n8n, create \"Header Auth\" credential: Name it \"fal.ai\", set Header Name to \"Authorization\", Value to \"Key [Your API Key]\"\n\n### OpenAI API Setup\n1. Log in at platform.openai.com ‚Üí API Keys (top-right profile menu)\n2. Click \"Create new secret key\" and copy it (store securely)\n3. In n8n, add \"OpenAI API\" credential: Paste key, select GPT-5 model in the LLM node\n\n## ‚öôÔ∏è Configuration Steps\n1. Import the workflow JSON into your n8n instance via Settings ‚Üí Import from File\n2. Assign fal.ai and OpenAI credentials to the relevant HTTP Request and LLM nodes\n3. Activate the workflow‚Äîthe form URL auto-generates in the trigger node\n4. Test by submitting a sample prompt (e.g., \"A cat chasing a laser\"); monitor executions for video output\n5. Adjust polling wait (60s node) for longer generations if needed\n\n## üéØ Use Cases\n- **Social Media Teams**: Generate 9:16 vertical Reels from text ideas, like quick product animations enhanced by GPT-5 for professional polish\n- **Content Marketers**: Animate uploaded images into 8s promo clips, e.g., turning a static ad graphic into a dynamic story for email campaigns\n- **Educators and Trainers**: Create 4s explainer videos from outlines, such as historical reenactments, using pro mode for detailed visuals\n- **App Developers**: Embed as a backend service to process user prompts into Sora 2 videos on-demand for creative tools\n\n## ‚ö†Ô∏è Troubleshooting\n- **API quota exceeded**: Check fal.ai dashboard for usage limits; upgrade to pro tier or extend polling waits\n- **Prompt refinement fails**: Ensure GPT-5 credential is set and output matches JSON schema‚Äîtest LLM node independently\n- **Image upload errors**: Confirm file is JPG/PNG under 10MB; verify tmpfiles.org endpoint with a manual curl test\n- **Endless polling loop**: Add an IF node after 10 checks to timeout; increase wait to 120s for 12s pro generations",
    "workflow": {
      "meta": {
        "instanceId": "3d7eb9567ae690bf8c9bba1cb43396e6e40c18e15eb5889cf9673ed1713da6db",
        "templateCredsSetupCompleted": true
      },
      "nodes": [
        {
          "id": "a85d1e91-bf05-4a5a-9759-15de2b1b50e8",
          "name": "Note: Mode Router",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            5280,
            2640
          ],
          "parameters": {
            "color": 3,
            "width": 332,
            "height": 192,
            "content": "## üîÄ Input Mode Router\n\n**Purpose:** Branches to image-to-video if file uploaded, else text-to-video with refinement.\n\n**Note:** Switch checks filename; ensures GPT-5 processes text prompts."
          },
          "typeVersion": 1
        },
        {
          "id": "eda124e2-e1aa-4064-96a7-c31cbde19521",
          "name": "Note: Image Upload",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            5744,
            2080
          ],
          "parameters": {
            "color": 6,
            "width": 332,
            "height": 192,
            "content": "## üñºÔ∏è Temp Image Upload\n\n**Purpose:** Uploads reference image to tmpfiles.org for Sora image-to-video.\n\n**Note:** Multipart POST; swaps URL to /dl/ for direct API access."
          },
          "typeVersion": 1
        },
        {
          "id": "1c76b2c1-9778-4f10-a078-6ce8eba97641",
          "name": "Note: Prompt Refiner",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            5488,
            2928
          ],
          "parameters": {
            "color": 5,
            "width": 332,
            "height": 192,
            "content": "## ü§ñ Prompt Refiner\n\n**Purpose:** Uses GPT-5 to enhance text prompts for Sora 2 text-to-video mode.\n\n**Note:** Mandatory for text branch; outputs JSON with refined prompt, ratio, duration."
          },
          "typeVersion": 1
        },
        {
          "id": "707ea9aa-81eb-47d1-b000-eb3238c70b94",
          "name": "Note: JSON Parser",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            5920,
            2944
          ],
          "parameters": {
            "color": 3,
            "width": 332,
            "height": 192,
            "content": "## üîç JSON Output Parser\n\n**Purpose:** Validates GPT-5 response against schema for clean API params.\n\n**Note:** Ensures prompt (50-4000 chars), ratio (16:9/9:16), duration (4/8/12)."
          },
          "typeVersion": 1
        },
        {
          "id": "c474d947-6610-4731-bc3b-af7c09f926be",
          "name": "Note: Text-to-Video",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            6288,
            2752
          ],
          "parameters": {
            "color": 5,
            "width": 332,
            "height": 192,
            "content": "## üé• Text-to-Video Call\n\n**Purpose:** Submits refined prompt to fal.ai Sora 2 text endpoint (pro if selected).\n\n**Note:** Uses 720p res; calls /text-to-video or /pro; returns request_id for polling."
          },
          "typeVersion": 1
        },
        {
          "id": "607e987b-df5f-4d7a-8d49-b79440c62962",
          "name": "Note: Image-to-Video",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            6240,
            2144
          ],
          "parameters": {
            "color": 5,
            "width": 332,
            "height": 192,
            "content": "## üñºÔ∏è Image-to-Video Call\n\n**Purpose:** Sends raw prompt + image URL to fal.ai Sora 2 image endpoint.\n\n**Note:** Auto res; calls /image-to-video or /pro; uses form ratio/duration directly."
          },
          "typeVersion": 1
        },
        {
          "id": "f50b63a0-dee7-4783-bcff-8b5d5b75949b",
          "name": "Video Input Form",
          "type": "n8n-nodes-base.formTrigger",
          "position": [
            5392,
            2448
          ],
          "webhookId": "45e6e98c-ff89-46c5-b143-c5d4c9dab16f",
          "parameters": {
            "options": {
              "appendAttribution": false
            },
            "formTitle": "Create a Video using Sora 2",
            "formFields": {
              "values": [
                {
                  "fieldLabel": "Prompt",
                  "requiredField": true
                },
                {
                  "fieldType": "dropdown",
                  "fieldLabel": "Aspect Ratio",
                  "fieldOptions": {
                    "values": [
                      {
                        "option": "9:16 (vertical)"
                      },
                      {
                        "option": "16:9 (Horizontal)"
                      }
                    ]
                  },
                  "requiredField": true
                },
                {
                  "fieldType": "checkbox",
                  "fieldLabel": "Model",
                  "fieldOptions": {
                    "values": [
                      {
                        "option": "sora-2"
                      },
                      {
                        "option": "sora-2-pro"
                      }
                    ]
                  },
                  "requiredField": true,
                  "limitSelection": "exact"
                },
                {
                  "fieldType": "checkbox",
                  "fieldLabel": "Lenght",
                  "fieldOptions": {
                    "values": [
                      {
                        "option": "4s"
                      },
                      {
                        "option": "8s"
                      },
                      {
                        "option": "12s"
                      }
                    ]
                  },
                  "requiredField": true,
                  "limitSelection": "exact"
                },
                {
                  "fieldType": "file",
                  "fieldLabel": "Image",
                  "multipleFiles": false,
                  "acceptFileTypes": ".jpg,.jpeg,.png"
                }
              ]
            }
          },
          "typeVersion": 2.3
        },
        {
          "id": "0c7ab4d0-5a34-41c1-9ea8-5a145056cee6",
          "name": "Prompt Refiner",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            5840,
            2592
          ],
          "parameters": {
            "text": "=User Query: {{ $json.Prompt }}\n\nApect Ratio: {{ $json['Aspect Ratio'] }}\n\nLenght: {{ $json.Lenght[0] }}",
            "batching": {},
            "messages": {
              "messageValues": [
                {
                  "message": "=You are an expert AI video prompt engineer specializing in OpenAI's Sora 2 video generation model. Your role is to transform user input into professionally structured, cinematic prompts optimized for high-quality video generation.\n\n## Core Principles\n\n1. **Brevity for Reliability**: Shorter clips (4s) follow instructions more reliably than longer ones. Recommend 4s duration unless user specifically needs longer content.\n\n2. **Specificity Over Vagueness**: Replace abstract concepts with concrete, visual details. Transform \"beautiful street\" into \"wet asphalt, zebra crosswalk, neon signs reflecting in puddles.\"\n\n3. **One Beat Per Shot**: Each shot should contain ONE clear camera movement and ONE clear subject action. Avoid cramming multiple complex actions into a single clip.\n\n4. **Cinematic Thinking**: Treat prompts as storyboard descriptions or cinematographer briefs, not casual requests.\n\n## Prompt Structure Framework\n\nOrganize enhanced prompts using this hierarchy:\n\n### 1. Style & Format (Optional but Powerful)\n- Establish overall aesthetic early: \"1970s film,\" \"IMAX aerial,\" \"handheld documentary\"\n- Film stock references: \"35mm film,\" \"16mm with grain,\" \"digital capture\"\n- Color treatment: \"Kodak warm grade,\" \"teal and orange palette,\" \"desaturated noir\"\n\n### 2. Scene Description\n- Setting and environment with specific visual details\n- Character descriptions (clothing, age, demeanor)\n- Atmospheric elements (weather, time of day, lighting quality)\n- Props and set dressing that matter to the shot\n\n### 3. Cinematography\n**Camera shot**: Specify framing and angle\n- Examples: \"wide establishing shot, eye level,\" \"medium close-up, slight low angle,\" \"aerial wide shot, downward tilt\"\n\n**Lens/DOF**: When detail matters\n- Examples: \"35mm lens, shallow depth of field,\" \"50mm with background softness,\" \"wide angle for environmental context\"\n\n**Camera movement**: Keep it simple and precise\n- Examples: \"slow push-in,\" \"dolly left to right,\" \"static handheld,\" \"crane up revealing skyline\"\n\n**Mood**: Emotional tone\n- Examples: \"tense and cinematic,\" \"warm and nostalgic,\" \"playful suspense\"\n\n### 4. Lighting & Palette\nDescribe light quality and color anchors:\n- Light quality: \"soft window light,\" \"hard single source,\" \"diffused overhead\"\n- Direction: \"from camera left,\" \"backlit,\" \"rim lighting\"\n- Color anchors: Name 3-5 specific colors for palette consistency\n- Examples: \"warm key from overhead, cool rim from window; palette: amber, cream, teal\"\n\n### 5. Actions (Time-Based Beats)\nBreak down motion into countable beats:\n- Use specific verbs and counts: \"takes four steps,\" \"pauses for two seconds,\" \"turns and catches\"\n- Avoid: \"walks around\" ‚Üí Use: \"takes three steps forward, pauses, looks left\"\n- Keep actions achievable within the duration\n\n### 6. Dialogue (If Applicable)\nFormat dialogue clearly:\n- Place in dedicated block with speaker labels\n- Keep lines short and natural (4s = 1-2 exchanges, 8s = 3-4 exchanges)\n- Example format:\n  ```\n  Dialogue:\n  - Character A: \"Short, natural line.\"\n  - Character B: \"Response that fits timing.\"\n  ```\n\n### 7. Audio/Sound (Optional)\nSuggest diegetic sounds to establish rhythm:\n- Examples: \"distant traffic hum,\" \"coffee machine hiss,\" \"paper rustle\"\n- Note: This is for pacing cues, not full soundtracks\n\n## Enhancement Guidelines\n\n### What to ADD:\n- Concrete visual details (colors, textures, specific objects)\n- Professional cinematography terms (shot types, camera movements)\n- Lighting direction and quality\n- Precise action beats with timing\n- Style references that set aesthetic tone\n- Specific color palette (3-5 colors)\n\n### What to REPLACE:\n- \"Beautiful\" ‚Üí Specific visual qualities\n- \"Moves\" ‚Üí Precise action with counts\n- \"Nice lighting\" ‚Üí Light source, direction, quality\n- \"Cinematic\" ‚Üí Actual film/lens specifications\n- \"Interesting angle\" ‚Üí Specific shot type and framing\n\n### What to AVOID:\n- Multiple complex actions in one shot\n- Vague descriptors without visual specifics\n- Requesting duration/resolution in prose (these are API parameters)\n- Overcrowding shots with too many elements\n- Abstract emotions without visual manifestations\n\n## Duration Recommendations\n\nBased on user intent:\n- **4 seconds**: Default recommendation. Most reliable for instruction following. Best for single clear action.\n- **8 seconds**: When user needs slightly more development. Warn that this may be less reliable; suggest stitching two 4s clips instead.\n- **12 seconds**: Only when explicitly requested. Strongly recommend breaking into multiple 4s shots for better control.\n\n## Aspect Ratio Selection\n\n- **16:9**: Landscape, traditional video, cinematic scenes, wide vistas, desktop viewing\n- **9:16**: Portrait, social media (TikTok, Instagram Stories, Reels), mobile-first content, vertical stories\n\n## Transformation Process\n\n1. **Analyze** user input for core intent\n2. **Identify** missing cinematic elements (camera, lighting, specific actions)\n3. **Expand** vague descriptions into concrete visuals\n4. **Structure** using the framework above\n5. **Optimize** for the chosen duration\n6. **Balance** detail with creative freedom based on user needs\n\n## Examples of Weak ‚Üí Strong Transformations\n\n**Weak**: \"A person walking down a street at night\"\n**Strong**: \"Style: Handheld 35mm with natural grain. A woman in a red coat takes five measured steps down a wet cobblestone street. Amber streetlights create pools of warm light; cool shadows between them. Camera: medium tracking shot, following from behind at shoulder level. Mood: solitary, urban noir. Lighting: practical streetlights only; reflections in puddles.\"\n\n**Weak**: \"Make it look cinematic\"\n**Strong**: \"Camera: wide shot, slow dolly-in. Lens: 40mm spherical with shallow DOF. Lighting: golden hour natural key from camera left, edge light on subject. Palette: warm amber, deep teal, cream. Mood: nostalgic, intimate.\"\n\n## Response Format\n\nAlways output your enhanced prompt as a JSON object with exactly three fields:\n- \"prompt\": The fully enhanced, professionally structured prompt (50-4000 characters)\n- \"aspect_ratio\": Either \"16:9\" or \"9:16\"\n- \"duration\": Either 4, 8, or 12 (integer, in seconds)\n\nAim for 60-150 words for standard prompts, more for complex cinematic shots requiring detailed specifications. Include professional cinematographic language while maintaining clarity."
                }
              ]
            },
            "promptType": "define",
            "hasOutputParser": true
          },
          "typeVersion": 1.7
        },
        {
          "id": "2cfdf665-263a-441a-abef-07136a766458",
          "name": "JSON Output Parser",
          "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
          "position": [
            5984,
            2768
          ],
          "parameters": {
            "schemaType": "manual",
            "inputSchema": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"Sora2VideoGenerationRequest\",\n  \"description\": \"Simplified schema for Sora 2 video generation with enhanced prompts\",\n  \"type\": \"object\",\n  \"required\": [\"prompt\", \"aspect_ratio\", \"duration\"],\n  \"properties\": {\n    \"prompt\": {\n      \"type\": \"string\",\n      \"description\": \"The fully enhanced, professionally structured prompt optimized for Sora 2 video generation with cinematography details, specific actions, lighting, and visual specifics\",\n      \"minLength\": 50,\n      \"maxLength\": 4000\n    },\n    \"aspect_ratio\": {\n      \"type\": \"string\",\n      \"enum\": [\"16:9\", \"9:16\"],\n      \"description\": \"Video aspect ratio. 16:9 for landscape/cinematic, 9:16 for portrait/social media\"\n    },\n    \"duration\": {\n      \"type\": \"integer\",\n      \"enum\": [4, 8, 12],\n      \"description\": \"Video duration in seconds. 4s is most reliable, 8s and 12s may have reduced instruction-following accuracy\"\n    }\n  }\n}"
          },
          "typeVersion": 1.3
        },
        {
          "id": "e857b653-7894-43d8-8598-8d6998076a65",
          "name": "Temp Image Upload",
          "type": "n8n-nodes-base.httpRequest",
          "position": [
            5888,
            2320
          ],
          "parameters": {
            "url": "=https://tmpfiles.org/api/v1/upload",
            "method": "POST",
            "options": {},
            "sendBody": true,
            "contentType": "multipart-form-data",
            "bodyParameters": {
              "parameters": [
                {
                  "name": "file",
                  "parameterType": "formBinaryData",
                  "inputDataFieldName": "Image"
                }
              ]
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "e8760386-b433-473d-9099-bb2f03c7c3aa",
          "name": "Text-to-Video Call",
          "type": "n8n-nodes-base.httpRequest",
          "position": [
            6144,
            2592
          ],
          "parameters": {
            "url": "=https://queue.fal.run/fal-ai/sora-2/text-to-video{{ $('Video Input Form').item.json.Model[0] === 'sora-2-pro' ? '/pro' : '' }}",
            "method": "POST",
            "options": {},
            "jsonBody": "={\n  \"prompt\": \"{{ JSON.stringify($('Prompt Refiner').item.json.output.prompt.replaceAll(/\\\\n/g, '')).slice(1, -1) }}\",\n  \"resolution\": \"720p\",\n  \"aspect_ratio\": \"{{ $('Prompt Refiner').item.json.output.aspect_ratio }}\",\n  \"duration\": {{ $('Prompt Refiner').item.json.output.duration }}\n}",
            "sendBody": true,
            "specifyBody": "json",
            "authentication": "genericCredentialType",
            "genericAuthType": "httpHeaderAuth"
          },
          "credentials": {
            "httpHeaderAuth": {
              "id": "credential-id",
              "name": "httpHeaderAuth Credential"
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "2d84b59f-4c4e-4fac-968a-81eb6482c04e",
          "name": "Input Mode Router",
          "type": "n8n-nodes-base.switch",
          "position": [
            5600,
            2448
          ],
          "parameters": {
            "rules": {
              "values": [
                {
                  "outputKey": "Image to Video",
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "dfdd231a-d2f6-4973-a068-ac13f2bbd506",
                        "operator": {
                          "type": "string",
                          "operation": "notEmpty",
                          "singleValue": true
                        },
                        "leftValue": "={{ $json.Image.filename }}",
                        "rightValue": ""
                      }
                    ]
                  },
                  "renameOutput": true
                },
                {
                  "outputKey": "Text to Video ",
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "68ac0648-f33e-4394-805d-a8a9b788f1df",
                        "operator": {
                          "type": "string",
                          "operation": "empty",
                          "singleValue": true
                        },
                        "leftValue": "={{ $json.Image.filename }}",
                        "rightValue": ""
                      }
                    ]
                  },
                  "renameOutput": true
                }
              ]
            },
            "options": {}
          },
          "typeVersion": 3.3
        },
        {
          "id": "eef5e174-4d2a-450f-8bac-dd343865ad6b",
          "name": "Image-to-Video Call",
          "type": "n8n-nodes-base.httpRequest",
          "position": [
            6064,
            2320
          ],
          "parameters": {
            "url": "=https://queue.fal.run/fal-ai/sora-2/image-to-video{{ $('Video Input Form').item.json.Model[0] === 'sora-2-pro' ? '/pro' : '' }}",
            "method": "POST",
            "options": {},
            "jsonBody": "={\n  \"prompt\": \"{{ JSON.stringify($('Video Input Form').item.json.Prompt.replaceAll(/\\\\n/g, '')).slice(1, -1) }}\",\n  \"resolution\": \"auto\",\n  \"aspect_ratio\": \"{{ $('Video Input Form').item.json['Aspect Ratio'].replaceAll(' (vertical)', '').replaceAll(' (Horizontal)', '') }}\",\n  \"duration\": {{ $('Video Input Form').item.json.Lenght[0].replaceAll('s', '') }},\n  \"image_url\": \"{{ $json.data.url.replaceAll('.org/', '.org/dl/') }}\"\n}",
            "sendBody": true,
            "specifyBody": "json",
            "authentication": "genericCredentialType",
            "genericAuthType": "httpHeaderAuth"
          },
          "credentials": {
            "httpHeaderAuth": {
              "id": "credential-id",
              "name": "httpHeaderAuth Credential"
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "c07d5074-c4b7-4f43-a0d7-f26e2cd37137",
          "name": "Wait 60 Seconds",
          "type": "n8n-nodes-base.wait",
          "position": [
            6336,
            2416
          ],
          "webhookId": "caad73e3-58d8-4fbd-a3e9-c42424f2d1ee",
          "parameters": {
            "amount": 60
          },
          "typeVersion": 1.1
        },
        {
          "id": "557e1785-4e6c-4f2e-a9a4-3098b1d638cb",
          "name": "Status Check",
          "type": "n8n-nodes-base.httpRequest",
          "position": [
            6544,
            2416
          ],
          "parameters": {
            "url": "=https://queue.fal.run/fal-ai/sora-2/requests/{{ $json.request_id }}/status",
            "options": {},
            "authentication": "genericCredentialType",
            "genericAuthType": "httpHeaderAuth"
          },
          "credentials": {
            "httpHeaderAuth": {
              "id": "credential-id",
              "name": "httpHeaderAuth Credential"
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "320c2ee0-767d-4106-a605-b03bd1a80631",
          "name": "Status Router",
          "type": "n8n-nodes-base.switch",
          "position": [
            6752,
            2416
          ],
          "parameters": {
            "rules": {
              "values": [
                {
                  "outputKey": "Done",
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "d8b8dbdc-1ad9-4ab9-8b2d-e76fd5db0899",
                        "operator": {
                          "type": "string",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $json.status }}",
                        "rightValue": "COMPLETED"
                      }
                    ]
                  },
                  "renameOutput": true
                },
                {
                  "outputKey": "Progress",
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "9c10982c-5f8c-4eec-9b8a-f4b42e99ecf9",
                        "operator": {
                          "type": "string",
                          "operation": "notEquals"
                        },
                        "leftValue": "={{ $json.status }}",
                        "rightValue": "COMPLETED"
                      }
                    ]
                  },
                  "renameOutput": true
                }
              ]
            },
            "options": {}
          },
          "typeVersion": 3.2
        },
        {
          "id": "cfa44af4-e910-40cf-b581-1acee757871d",
          "name": "Retrieve Video",
          "type": "n8n-nodes-base.httpRequest",
          "position": [
            6944,
            2400
          ],
          "parameters": {
            "url": "=https://queue.fal.run/fal-ai/sora-2/requests/{{ $json.request_id }}",
            "options": {},
            "authentication": "genericCredentialType",
            "genericAuthType": "httpHeaderAuth"
          },
          "credentials": {
            "httpHeaderAuth": {
              "id": "credential-id",
              "name": "httpHeaderAuth Credential"
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "6ce27f08-cae8-4a9b-bac3-2e01fa31c864",
          "name": "Video Redirect",
          "type": "n8n-nodes-base.form",
          "position": [
            7152,
            2400
          ],
          "webhookId": "7b9192c7-c2ff-47b1-b893-bfbea42dd268",
          "parameters": {
            "options": {},
            "operation": "completion",
            "redirectUrl": "={{ $json.video.url }}",
            "respondWith": "redirect"
          },
          "typeVersion": 2.3
        },
        {
          "id": "d110e220-883b-4e3f-bbda-cd195ddf23dd",
          "name": "Overview Note8",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            4528,
            1984
          ],
          "parameters": {
            "color": 4,
            "width": 696,
            "height": 1184,
            "content": "# üé¨ Sora 2 Video Generator via Fal with GPT-5 Refinement\n\n## üìã What This Template Does\nGenerate videos using OpenAI's Sora 2 via fal.ai's four endpoints (text-to-video, text-to-video/pro, image-to-video, image-to-video/pro). Accepts form inputs for prompts, aspect ratios, models, durations (4-12s), and optional images. For text mode, GPT-5 refines prompts for cinematic quality; image mode uses raw input. Polls status asynchronously and redirects to the final video.\n\n## üîß Prerequisites\n- n8n with HTTP Request and LangChain nodes\n- fal.ai account\n- OpenAI account (GPT-5 access)\n\n## üîë Required Credentials\n\n### fal.ai API Setup\n1. fal.ai ‚Üí Dashboard ‚Üí API Keys\n2. Generate key with sora-2 permissions\n3. n8n: Header Auth (\"fal.ai\", Header: \"Authorization\", Value: \"Key [Your Key]\")\n\n### OpenAI API Setup\n1. platform.openai.com ‚Üí API Keys ‚Üí Create secret key\n2. n8n: OpenAI API credential (paste key, select GPT-5)\n\n## ‚öôÔ∏è Configuration Steps\n1. Import JSON (Settings ‚Üí Import)\n2. Assign creds to HTTP/LLM nodes\n3. Activate‚Äîuse form URL from trigger\n4. Test prompt; check executions\n5. Tune polling for longer clips\n\n## üéØ Use Cases\n- Social: 9:16 Reels from refined text (e.g., product anims)\n- Marketing: Image-to-8s promos (e.g., logo intros)\n- Education: 4s explainers (e.g., science demos)\n- Dev: Backend for app video gen\n\n## ‚ö†Ô∏è Troubleshooting\n- Quota fail: Check fal.ai usage; upgrade/add waits\n- Refinement error: Verify GPT-5 schema output\n- Image reject: JPG/PNG <10MB; test tmpfiles\n- Poll timeout: Bump wait to 120s; add retry IF"
          },
          "typeVersion": 1
        },
        {
          "id": "6dad83d5-6cb1-4dca-90a1-c12048b5b544",
          "name": "Note: Form Trigger1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            5248,
            2176
          ],
          "parameters": {
            "color": 6,
            "width": 332,
            "height": 192,
            "content": "## üìù Video Input Form\n\n**Purpose:** Captures user prompt, ratio, model, duration, and optional image via web form.\n\n**Note:** Required fields validated; activates webhook URL on workflow start."
          },
          "typeVersion": 1
        },
        {
          "id": "6e91faf7-a3c5-48ce-94d6-a993ea8e5d8e",
          "name": "Note: Polling Loop1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            6688,
            2640
          ],
          "parameters": {
            "color": 2,
            "width": 332,
            "height": 192,
            "content": "## ‚è≥ Status Polling Loop\n\n**Purpose:** Waits 60s, checks Sora status, loops until COMPLETED.\n\n**Note:** Switch routes to result or retry; handles all four endpoints uniformly."
          },
          "typeVersion": 1
        },
        {
          "id": "ad9eadd7-1e7f-4922-8ca7-6a673812ffd0",
          "name": "Refiner Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            5840,
            2768
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-5",
              "cachedResultName": "gpt-5"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        }
      ],
      "pinData": {},
      "connections": {
        "Status Check": {
          "main": [
            [
              {
                "node": "Status Router",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Refiner Model": {
          "ai_languageModel": [
            [
              {
                "node": "Prompt Refiner",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Status Router": {
          "main": [
            [
              {
                "node": "Retrieve Video",
                "type": "main",
                "index": 0
              }
            ],
            [
              {
                "node": "Wait 60 Seconds",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Prompt Refiner": {
          "main": [
            [
              {
                "node": "Text-to-Video Call",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Retrieve Video": {
          "main": [
            [
              {
                "node": "Video Redirect",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Wait 60 Seconds": {
          "main": [
            [
              {
                "node": "Status Check",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Video Input Form": {
          "main": [
            [
              {
                "node": "Input Mode Router",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Input Mode Router": {
          "main": [
            [
              {
                "node": "Temp Image Upload",
                "type": "main",
                "index": 0
              }
            ],
            [
              {
                "node": "Prompt Refiner",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Temp Image Upload": {
          "main": [
            [
              {
                "node": "Image-to-Video Call",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "JSON Output Parser": {
          "ai_outputParser": [
            [
              {
                "node": "Prompt Refiner",
                "type": "ai_outputParser",
                "index": 0
              }
            ]
          ]
        },
        "Text-to-Video Call": {
          "main": [
            [
              {
                "node": "Wait 60 Seconds",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Image-to-Video Call": {
          "main": [
            [
              {
                "node": "Wait 60 Seconds",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 1,
    "workflowInfo": {
      "nodeCount": 22,
      "nodeTypes": {
        "n8n-nodes-base.form": {
          "count": 1
        },
        "n8n-nodes-base.wait": {
          "count": 1
        },
        "n8n-nodes-base.switch": {
          "count": 2
        },
        "n8n-nodes-base.stickyNote": {
          "count": 9
        },
        "n8n-nodes-base.formTrigger": {
          "count": 1
        },
        "n8n-nodes-base.httpRequest": {
          "count": 5
        },
        "@n8n/n8n-nodes-langchain.chainLlm": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.outputParserStructured": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Daniel Nkencho",
      "username": "daniel-automates",
      "bio": "AI Automation Consultant | Helping Business Implement AI systems | Book a call here ‚áæ http://cal.com/corefluxai",
      "verified": true,
      "links": [
        "https://linktr.ee/danielnkencho"
      ],
      "avatar": "https://gravatar.com/avatar/ff95e5857b31cd008b89e265e92fbda8839af4cd85eb8eb98fbe2ba00859dba1?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 19,
        "icon": "file:httprequest.svg",
        "name": "n8n-nodes-base.httpRequest",
        "codex": {
          "data": {
            "alias": [
              "API",
              "Request",
              "URL",
              "Build",
              "cURL"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                  "icon": "‚òÄÔ∏è",
                  "label": "2021: The Year to Automate the New You with n8n"
                },
                {
                  "url": "https://n8n.io/blog/why-business-process-automation-with-n8n-can-change-your-daily-life/",
                  "icon": "üß¨",
                  "label": "Why business process automation with n8n can change your daily life"
                },
                {
                  "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                  "icon": "üìà",
                  "label": "Automatically pulling and visualizing data with n8n"
                },
                {
                  "url": "https://n8n.io/blog/learn-how-to-automatically-cross-post-your-content-with-n8n/",
                  "icon": "‚úçÔ∏è",
                  "label": "Learn how to automatically cross-post your content with n8n"
                },
                {
                  "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                  "icon": "üßæ",
                  "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
                },
                {
                  "url": "https://n8n.io/blog/running-n8n-on-ships-an-interview-with-maranics/",
                  "icon": "üõ≥",
                  "label": "Running n8n on ships: An interview with Maranics"
                },
                {
                  "url": "https://n8n.io/blog/what-are-apis-how-to-use-them-with-no-code/",
                  "icon": " ü™¢",
                  "label": "What are APIs and how to use them with no code"
                },
                {
                  "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                  "icon": "‚ö°Ô∏è",
                  "label": "5 tasks you can automate with the new Notion API "
                },
                {
                  "url": "https://n8n.io/blog/world-poetry-day-workflow/",
                  "icon": "üìú",
                  "label": "Celebrating World Poetry Day with a daily poem in Telegram"
                },
                {
                  "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                  "icon": "üí°",
                  "label": "15 Google apps you can combine and automate to increase productivity"
                },
                {
                  "url": "https://n8n.io/blog/automate-designs-with-bannerbear-and-n8n/",
                  "icon": "üé®",
                  "label": "Automate Designs with Bannerbear and n8n"
                },
                {
                  "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                  "icon": " üï∏Ô∏è",
                  "label": "How uProc scraped a multi-page website with a low-code workflow"
                },
                {
                  "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                  "icon": "üì±",
                  "label": "Building an expense tracking app in 10 minutes"
                },
                {
                  "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                  "icon": "ü§ñ",
                  "label": "5 workflow automations for Mattermost that we love at n8n"
                },
                {
                  "url": "https://n8n.io/blog/how-to-use-the-http-request-node-the-swiss-army-knife-for-workflow-automation/",
                  "icon": "üß∞",
                  "label": "How to use the HTTP Request Node - The Swiss Army Knife for Workflow Automation"
                },
                {
                  "url": "https://n8n.io/blog/learn-how-to-use-webhooks-with-mattermost-slash-commands/",
                  "icon": "ü¶Ñ",
                  "label": "Learn how to use webhooks with Mattermost slash commands"
                },
                {
                  "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                  "icon": "üìà",
                  "label": "How a Membership Development Manager automates his work and investments"
                },
                {
                  "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                  "icon": "üìà",
                  "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
                },
                {
                  "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                  "icon": "üé°",
                  "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
                },
                {
                  "url": "https://n8n.io/blog/automations-for-activists/",
                  "icon": "‚ú®",
                  "label": "How Common Knowledge use workflow automation for activism"
                },
                {
                  "url": "https://n8n.io/blog/creating-scheduled-text-affirmations-with-n8n/",
                  "icon": "ü§ü",
                  "label": "Creating scheduled text affirmations with n8n"
                },
                {
                  "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                  "icon": "üõµ",
                  "label": "How Goomer automated their operations with over 200 n8n workflows"
                },
                {
                  "url": "https://n8n.io/blog/aws-workflow-automation/",
                  "label": "7 no-code workflow automations for Amazon Web Services"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/"
                }
              ]
            },
            "categories": [
              "Development",
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"output\"]",
        "defaults": {
          "name": "HTTP Request",
          "color": "#0004F5"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "HTTP Request",
        "typeVersion": 4,
        "nodeCategories": [
          {
            "id": 5,
            "name": "Development"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 112,
        "icon": "fa:map-signs",
        "name": "n8n-nodes-base.switch",
        "codex": {
          "data": {
            "alias": [
              "Router",
              "If",
              "Path",
              "Filter",
              "Condition",
              "Logic",
              "Branch",
              "Case"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                  "icon": "‚òÄÔ∏è",
                  "label": "2021: The Year to Automate the New You with n8n"
                },
                {
                  "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                  "icon": "üë•",
                  "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
                },
                {
                  "url": "https://n8n.io/blog/build-your-own-virtual-assistant-with-n8n-a-step-by-step-guide/",
                  "icon": "üë¶",
                  "label": "Build your own virtual assistant with n8n: A step by step guide"
                },
                {
                  "url": "https://n8n.io/blog/automation-for-maintainers-of-open-source-projects/",
                  "icon": "üè∑Ô∏è",
                  "label": "How to automatically manage contributions to open-source projects"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.switch/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Flow"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Switch",
          "color": "#506000"
        },
        "iconData": {
          "icon": "map-signs",
          "type": "icon"
        },
        "displayName": "Switch",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 514,
        "icon": "fa:pause-circle",
        "name": "n8n-nodes-base.wait",
        "codex": {
          "data": {
            "alias": [
              "pause",
              "sleep",
              "delay",
              "timeout"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                  "icon": "üë•",
                  "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
                },
                {
                  "url": "https://n8n.io/blog/aws-workflow-automation/",
                  "label": "7 no-code workflow automations for Amazon Web Services"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.wait/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers",
                "Flow"
              ]
            }
          }
        },
        "group": "[\"organization\"]",
        "defaults": {
          "name": "Wait",
          "color": "#804050"
        },
        "iconData": {
          "icon": "pause-circle",
          "type": "icon"
        },
        "displayName": "Wait",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1123,
        "icon": "fa:link",
        "name": "@n8n/n8n-nodes-langchain.chainLlm",
        "codex": {
          "data": {
            "alias": [
              "LangChain"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Chains",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Basic LLM Chain",
          "color": "#909298"
        },
        "iconData": {
          "icon": "link",
          "type": "icon"
        },
        "displayName": "Basic LLM Chain",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1179,
        "icon": "fa:code",
        "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "codex": {
          "data": {
            "alias": [
              "json",
              "zod"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Output Parsers"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Structured Output Parser"
        },
        "iconData": {
          "icon": "code",
          "type": "icon"
        },
        "displayName": "Structured Output Parser",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1225,
        "icon": "file:form.svg",
        "name": "n8n-nodes-base.formTrigger",
        "codex": {
          "data": {
            "alias": [
              "table",
              "submit",
              "post"
            ],
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.formtrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Other Trigger Nodes"
              ]
            }
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "On form submission"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0NiIgaGVpZ2h0PSI0MCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iIzAwQjdCQyIgZmlsbC1ydWxlPSJldmVub2RkIiBkPSJNMzQuOTc4IDM3LjczMmExLjU2IDEuNTYgMCAwIDEtMS41NjIgMS41NjNINi4yNmExLjU2IDEuNTYgMCAwIDEtMS41NjMtMS41NjNWOS42MDdjMC0uNDA1LjE1Ny0uNzk0LjQzOC0xLjA4Nmw2LjMwNC02LjUzMXY1LjM0NEg4LjIxM2ExLjE3MiAxLjE3MiAwIDEgMCAwIDIuMzQzaDQuNDNhMS4xNyAxLjE3IDAgMCAwIDEuMTcxLTEuMTcxVi4yMzJoMTkuNjAyYTEuNTYgMS41NiAwIDAgMSAxLjU2MiAxLjU2M3YxMC4zMjdsLTIuODYgMi44Ni04LjI1MiA4LjI3NmE0MTMuMDA2IDQxMy4wMDYgMCAwIDEtMS42NTQgMS42NjJsLS4zMzcuMzM3YTIgMiAwIDAgMC0uNTU3IDEuMDhMMjAuMyAzMS45MjJjLS4xMDguNjM4LS4yMTUgMS4wNzkuMjExIDEuNDE4LjQwMy4zMi45LjE3NCAxLjU0LjA2Nmw1LjQwOC0uOTI4YTIgMiAwIDAgMCAxLjA4LS41NTZsNi40NC02LjQyOXptLTI0LjAzLTIxLjI2NWExLjE4IDEuMTggMCAwIDAgMS4xNzEgMS4xNzJoMTMuMTYzYTEuMTcyIDEuMTcyIDAgMSAwIDAtMi4zNDRIMTIuMTE5YTEuMTcgMS4xNyAwIDAgMC0xLjE3MiAxLjE3Mm03LjI5NCAxNC43NjZhMS4xNyAxLjE3IDAgMCAwLTEuMTcyLTEuMTcySDEyLjEyYTEuMTcyIDEuMTcyIDAgMSAwIDAgMi4zNDNoNC45NTFhMS4xNyAxLjE3IDAgMCAwIDEuMTcyLTEuMTcybS44Ni03LjM5MWExLjE3IDEuMTcgMCAwIDAtMS4xNzItMS4xNzJoLTUuODExYTEuMTcyIDEuMTcyIDAgMSAwIDAgMi4zNDNoNS44MWExLjE2NCAxLjE2NCAwIDAgMCAxLjE3My0xLjE3MSIgY2xpcC1ydWxlPSJldmVub2RkIi8+PHBhdGggZmlsbD0iIzAwQjdCQyIgZD0ibTMzLjUzMiAxNi4zOTcgNC4yODktNC4yODkgMy43NTggMy43MSAxLjYxNy0xLjYxNiAyLjI1OCAyLjI1N2MuMjE4LjIxOC4zNC41MTMuMzQzLjgyLS4wMDIuMzExLS4xMjUuNjA4LS4zNDQuODNsLTYuODA0IDYuNzk2YTEuMTMgMS4xMyAwIDAgMS0uODI4LjM0MyAxLjE1IDEuMTUgMCAwIDEtLjgyOC0uMzQzIDEuMTggMS4xOCAwIDAgMSAwLTEuNjU3bDUuOTc2LTUuOTY4LTEuMzEyLTEuMzEzLTEuMzgzIDEuNDE0LTEzLjE0OSAxMy4xMjUtNC42MTcuNzgyLjc4Mi00LjYxNy4zMzYtLjMzNyAyLjU2MiAyLjU1NWExLjEgMS4xIDAgMCAwIC44MjguMzQ0Yy4zMTIuMDA1LjYxMi0uMTIuODI4LS4zNDRhMS4xOCAxLjE4IDAgMCAwIDAtMS42NTZsLTIuNTYyLTIuNTYyek00NC43MzYgMTIuMjRjMCAuNDE0LS4xNjMuODEtLjQ1NCAxLjEwMmwtLjkyMi45MTQtMy44NTItMy44MjguOTMtLjkzYTEuNTYzIDEuNTYzIDAgMCAxIDIuMjAzIDBsMS42NCAxLjY0MWMuMjkxLjI5My40NTUuNjkuNDU1IDEuMTAyIi8+PC9zdmc+"
        },
        "displayName": "n8n Form Trigger",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1274,
        "icon": "file:form.svg",
        "name": "n8n-nodes-base.form",
        "codex": {
          "data": {
            "alias": [
              "_Form",
              "form",
              "table",
              "submit",
              "post",
              "page",
              "step",
              "stage",
              "multi"
            ],
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.form/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Form"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0NiIgaGVpZ2h0PSI0MCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iIzAwQjdCQyIgZmlsbC1ydWxlPSJldmVub2RkIiBkPSJNMzQuOTc4IDM3LjczMmExLjU2IDEuNTYgMCAwIDEtMS41NjIgMS41NjNINi4yNmExLjU2IDEuNTYgMCAwIDEtMS41NjMtMS41NjNWOS42MDdjMC0uNDA1LjE1Ny0uNzk0LjQzOC0xLjA4Nmw2LjMwNC02LjUzMXY1LjM0NEg4LjIxM2ExLjE3MiAxLjE3MiAwIDEgMCAwIDIuMzQzaDQuNDNhMS4xNyAxLjE3IDAgMCAwIDEuMTcxLTEuMTcxVi4yMzJoMTkuNjAyYTEuNTYgMS41NiAwIDAgMSAxLjU2MiAxLjU2M3YxMC4zMjdsLTIuODYgMi44Ni04LjI1MiA4LjI3NmE0MTMuMDA2IDQxMy4wMDYgMCAwIDEtMS42NTQgMS42NjJsLS4zMzcuMzM3YTIgMiAwIDAgMC0uNTU3IDEuMDhMMjAuMyAzMS45MjJjLS4xMDguNjM4LS4yMTUgMS4wNzkuMjExIDEuNDE4LjQwMy4zMi45LjE3NCAxLjU0LjA2Nmw1LjQwOC0uOTI4YTIgMiAwIDAgMCAxLjA4LS41NTZsNi40NC02LjQyOXptLTI0LjAzLTIxLjI2NWExLjE4IDEuMTggMCAwIDAgMS4xNzEgMS4xNzJoMTMuMTYzYTEuMTcyIDEuMTcyIDAgMSAwIDAtMi4zNDRIMTIuMTE5YTEuMTcgMS4xNyAwIDAgMC0xLjE3MiAxLjE3Mm03LjI5NCAxNC43NjZhMS4xNyAxLjE3IDAgMCAwLTEuMTcyLTEuMTcySDEyLjEyYTEuMTcyIDEuMTcyIDAgMSAwIDAgMi4zNDNoNC45NTFhMS4xNyAxLjE3IDAgMCAwIDEuMTcyLTEuMTcybS44Ni03LjM5MWExLjE3IDEuMTcgMCAwIDAtMS4xNzItMS4xNzJoLTUuODExYTEuMTcyIDEuMTcyIDAgMSAwIDAgMi4zNDNoNS44MWExLjE2NCAxLjE2NCAwIDAgMCAxLjE3My0xLjE3MSIgY2xpcC1ydWxlPSJldmVub2RkIi8+PHBhdGggZmlsbD0iIzAwQjdCQyIgZD0ibTMzLjUzMiAxNi4zOTcgNC4yODktNC4yODkgMy43NTggMy43MSAxLjYxNy0xLjYxNiAyLjI1OCAyLjI1N2MuMjE4LjIxOC4zNC41MTMuMzQzLjgyLS4wMDIuMzExLS4xMjUuNjA4LS4zNDQuODNsLTYuODA0IDYuNzk2YTEuMTMgMS4xMyAwIDAgMS0uODI4LjM0MyAxLjE1IDEuMTUgMCAwIDEtLjgyOC0uMzQzIDEuMTggMS4xOCAwIDAgMSAwLTEuNjU3bDUuOTc2LTUuOTY4LTEuMzEyLTEuMzEzLTEuMzgzIDEuNDE0LTEzLjE0OSAxMy4xMjUtNC42MTcuNzgyLjc4Mi00LjYxNy4zMzYtLjMzNyAyLjU2MiAyLjU1NWExLjEgMS4xIDAgMCAwIC44MjguMzQ0Yy4zMTIuMDA1LjYxMi0uMTIuODI4LS4zNDRhMS4xOCAxLjE4IDAgMCAwIDAtMS42NTZsLTIuNTYyLTIuNTYyek00NC43MzYgMTIuMjRjMCAuNDE0LS4xNjMuODEtLjQ1NCAxLjEwMmwtLjkyMi45MTQtMy44NTItMy44MjguOTMtLjkzYTEuNTYzIDEuNTYzIDAgMCAxIDIuMjAzIDBsMS42NCAxLjY0MWMuMjkxLjI5My40NTUuNjkuNDU1IDEuMTAyIi8+PC9zdmc+"
        },
        "displayName": "n8n Form",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 31,
        "name": "Content Creation"
      },
      {
        "id": 51,
        "name": "Multimodal AI"
      }
    ],
    "image": []
  }
}