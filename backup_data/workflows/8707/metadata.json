{
  "id": 8707,
  "slug": "8707",
  "title": "From sitemap crawling to vector storage: Creating an efficient workflow for RAG",
  "description": "**This template crawls a website from its sitemap, deduplicates URLs in Supabase, scrapes pages with Crawl4AI, cleans and validates the text, then stores content + metadata in a Supabase vector store using OpenAI embeddings. It’s a reliable, repeatable pipeline for building searchable knowledge bases, SEO research corpora, and RAG datasets.**\n⸻\n## **Good to know**\n\t•\tBuilt-in de-duplication via a scrape_queue table (status: pending/completed/error).\n\t•\tResilient flow: waits, retries, and marks failed tasks.\n\t•\tCosts depend on Crawl4AI usage and OpenAI embeddings.\n\t•\tReplace any placeholders (API keys, tokens, URLs) before running.\n\t•\tRespect website robots/ToS and applicable data laws when scraping.\n\n## **How it works**\n\t1.\tSitemap fetch & parse — Load sitemap.xml, extract all URLs.\n\t2.\tDe-dupe — Normalize URLs, check Supabase scrape_queue; insert only new ones.\n\t3.\tScrape — Send URLs to Crawl4AI; poll task status until completed.\n\t4.\tClean & score — Remove boilerplate/markup, detect content type, compute quality metrics, extract metadata (title, domain, language, length).\n\t5.\tChunk & embed — Split text, create OpenAI embeddings.\n\t6.\tStore — Upsert into Supabase vector store (documents) with metadata; update job status.\n## **Requirements**\n\t•\tSupabase (Postgres + Vector extension enabled)\n\t•\tCrawl4AI API key (or header auth)\n\t•\tOpenAI API key (for embeddings)\n\t•\tn8n credentials set for HTTP, Postgres/Supabase\n## **How to use**\n\t1.\tConfigure credentials (Supabase/Postgres, Crawl4AI, OpenAI).\n\t2.\t(Optional) Run the provided SQL to create scrape_queue and documents.\n\t3.\tSet your sitemap URL in the HTTP Request node.\n\t4.\tExecute the workflow (manual trigger) and monitor Supabase statuses.\n\t5.\tQuery your documents table or vector store from your app/RAG stack.\n\n## **Potential Use Cases**\n\nThis automation is ideal for:\n\n- Market research teams collecting competitive data\n- Content creators monitoring web trends\n- SEO specialists tracking website content updates\n- Analysts gathering structured data for insights\n- Anyone needing reliable, structured web content for analysis\n\n## **Need help customizing?**\nContact me for consulting and support: [LinkedIn](https://www.linkedin.com/in/mariela-ceo-founder/)\n",
  "featuredImage": "/data/workflows/8707/8707.webp",
  "author": {
    "id": 101,
    "slug": "marielabg",
    "name": "Mariela Slavenova",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 787,
  "downloads": 78,
  "createdAt": "2025-09-18T07:44:34.895Z",
  "updatedAt": "2026-01-16T08:57:18.962Z",
  "publishedAt": "2025-09-18T07:44:34.895Z",
  "nodes": 40,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/8707"
}