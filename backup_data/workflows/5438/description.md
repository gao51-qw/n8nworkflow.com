# ğŸ¤– Create a Telegram Bot with Mistral AI and Conversation Memory

A sophisticated Telegram bot that provides AI-powered responses with conversation memory. This template demonstrates how to integrate any AI API service with Telegram, making it easy to swap between different AI providers like OpenAI, Anthropic, Google AI, or any other API-based AI model.

## ğŸ”§ How it works

The workflow creates an intelligent Telegram bot that:
- ğŸ’¬ Maintains conversation history for each user
- ğŸ§  Provides contextual AI responses using **any AI API service**
- ğŸ“± Handles different message types and commands
- ğŸ”„ Manages chat sessions with clear functionality
- ğŸ”Œ **Easily adaptable to any AI provider** (OpenAI, Anthropic, Google AI, etc.)

## âš™ï¸ Set up steps

### ğŸ“‹ Prerequisites
- ğŸ¤– Telegram Bot Token (from @BotFather)
- ğŸ”‘ AI API Key (from any AI service provider)
- ğŸš€ n8n instance with webhook capability

### ğŸ› ï¸ Configuration Steps

1. **ğŸ¤– Create Telegram Bot**
   - Message @BotFather on Telegram
   - Create new bot with `/newbot` command
   - Save the bot token for credentials setup

2. **ğŸ§  Choose Your AI Provider**
   - **OpenAI**: Get API key from OpenAI platform
   - **Anthropic**: Sign up for Claude API access
   - **Google AI**: Get Gemini API key
   - **NVIDIA**: Access LLaMA models
   - **Hugging Face**: Use inference API
   - **Any other AI API service**

3. **ğŸ” Set up Credentials in n8n**
   - Add Telegram API credentials with your bot token
   - Add Bearer Auth/API Key credentials for your chosen AI service
   - Test both connections

4. **ğŸš€ Deploy Workflow**
   - Import the workflow JSON
   - **Customize the AI API call** (see customization section)
   - Activate the workflow
   - Set webhook URL in Telegram bot settings

## âœ¨ Features

### ğŸš€ Core Functionality
- **ğŸ“¨ Smart Message Routing**: Automatically categorizes incoming messages (commands, text, non-text)
- **ğŸ§  Conversation Memory**: Maintains chat history for each user (last 10 messages)
- **ğŸ¤– AI-Powered Responses**: Integrates with any AI API service for intelligent replies
- **âš¡ Command Support**: Built-in `/start` and `/clear` commands

### ğŸ“± Message Types Handled
- **ğŸ’¬ Text Messages**: Processed through AI model with context
- **ğŸ”§ Commands**: Special handling for bot commands
- **âŒ Non-text Messages**: Polite error message for unsupported content

### ğŸ’¾ Memory Management
- ğŸ‘¤ User-specific chat history storage
- ğŸ”„ Automatic history trimming (keeps last 10 messages)
- ğŸŒ Global state management across workflow executions

## ğŸ¤– Bot Commands

- `/start` ğŸ¯ - Welcome message with bot introduction
- `/clear` ğŸ—‘ï¸ - Clears conversation history for fresh start
- Regular text ğŸ’¬ - Processed by AI with conversation context

## ğŸ”§ Technical Details

### ğŸ—ï¸ Workflow Structure
1. **ğŸ“¡ Telegram Trigger** - Receives all incoming messages
2. **ğŸ”€ Message Filtering** - Routes messages based on type/content
3. **ğŸ’¾ History Management** - Maintains conversation context
4. **ğŸ§  AI Processing** - Generates intelligent responses
5. **ğŸ“¤ Response Delivery** - Sends formatted replies back to user

### ğŸ¤– AI API Integration (Customizable)
**Current Example (NVIDIA):**
- Model: `mistralai/mistral-nemotron`
- Temperature: 0.6 (balanced creativity)
- Max tokens: 4096
- Response limit: Under 200 words

**ğŸ”„ Easy to Replace with Any AI Service:**

**OpenAI Example:**
```json
{
  "model": "gpt-4",
  "messages": [...],
  "temperature": 0.7,
  "max_tokens": 1000
}
```

**Anthropic Claude Example:**
```json
{
  "model": "claude-3-sonnet-20240229",
  "messages": [...],
  "max_tokens": 1000
}
```

**Google Gemini Example:**
```json
{
  "contents": [...],
  "generationConfig": {
    "temperature": 0.7,
    "maxOutputTokens": 1000
  }
}
```

### ğŸ›¡ï¸ Error Handling
- âŒ Non-text message detection and appropriate responses
- ğŸ”§ API failure handling
- âš ï¸ Invalid command processing

## ğŸ¨ Customization Options

### ğŸ¤– AI Provider Switching
**To use a different AI service, modify the "NVIDIA LLaMA Chat Model" node:**

1. **ğŸ“ Change the URL** in HTTP Request node
2. **ğŸ”§ Update the request body** format in "Prepare API Request" node
3. **ğŸ” Update authentication** method if needed
4. **ğŸ“Š Adjust response parsing** in "Save AI Response to History" node

### ğŸ§  AI Behavior
- ğŸ“ Modify system prompt in "Prepare API Request" node
- ğŸŒ¡ï¸ Adjust temperature and response parameters
- ğŸ“ Change response length limits
- ğŸ¯ Customize model-specific parameters

### ğŸ’¾ Memory Settings
- ğŸ“Š Adjust history length (currently 10 messages)
- ğŸ‘¤ Modify user identification logic
- ğŸ—„ï¸ Customize data persistence approach

### ğŸ­ Bot Personality
- ğŸ‰ Update welcome message content
- âš ï¸ Customize error messages and responses
- â• Add new command handlers

## ğŸ’¡ Use Cases

- **ğŸ§ Customer Support**: Automated first-line support with context awareness
- **ğŸ“š Educational Assistant**: Homework help and learning support
- **ğŸ‘¥ Personal AI Companion**: General conversation and assistance
- **ğŸ’¼ Business Assistant**: FAQ handling and information retrieval
- **ğŸ”¬ AI API Testing**: Perfect template for testing different AI services
- **ğŸš€ Prototype Development**: Quick AI chatbot prototyping

## ğŸ“ Notes

- ğŸŒ Requires active n8n instance for webhook handling
- ğŸ’° AI API usage may have rate limits and costs (varies by provider)
- ğŸ’¾ Bot memory persists across workflow restarts
- ğŸ‘¥ Supports multiple concurrent users with separate histories
- ğŸ”„ **Template is provider-agnostic** - easily switch between AI services
- ğŸ› ï¸ **Perfect starting point** for any AI-powered Telegram bot project

## ğŸ”§ Popular AI Services You Can Use

| Provider | Model Examples | API Endpoint Style |
|----------|---------------|-------------------|
| ğŸŸ¢ **OpenAI** | GPT-4, GPT-3.5 | `https://api.openai.com/v1/chat/completions` |
| ğŸ”µ **Anthropic** | Claude 3 Opus, Sonnet | `https://api.anthropic.com/v1/messages` |
| ğŸ”´ **Google** | Gemini Pro, Gemini Flash | `https://generativelanguage.googleapis.com/v1beta/models/` |
| ğŸŸ¡ **NVIDIA** | LLaMA, Mistral | `https://integrate.api.nvidia.com/v1/chat/completions` |
| ğŸŸ  **Hugging Face** | Various OSS models | `https://api-inference.huggingface.co/models/` |
| ğŸŸ£ **Cohere** | Command, Generate | `https://api.cohere.ai/v1/generate` |

*Simply replace the HTTP Request node configuration to switch providers!*