{
  "id": 10952,
  "slug": "10952",
  "title": "Automated daily AI news digest: scrape, categorize & save to Google Sheets",
  "description": "This workflow is designed to automatically process AI news emails, extract and summarize articles, categorize them, and store the results in a structured Google Sheet for daily tracking and insights.\n\nThis automated workflow processes a daily AI newsletter from AlphaSignal, extracting individual articles, summarizing them, categorizing them, and saving the results to a Google Sheet.\n\n---\n\n###  Key Features\n\n#### 1. ✅ **Fully Automated Daily News Pipeline**\n\nNo manual work is required — the workflow runs autonomously every time a new email arrives. This eliminates repetitive human tasks such as opening, reading, and summarizing newsletters.\n\n#### 2. ✅ **Cross-AI Model Integration**\n\nIt combines multiple AI systems:\n\n* **Google Gemini** and **OpenAI GPT-5 Mini** for natural language processing and categorization.\n* **Scrapegraph AI** for external web scraping and summarization.\n\nThis multi-model approach enhances accuracy and flexibility.\n\n#### 3. ✅ **Accurate Content Structuring**\n\nThe workflow transforms unstructured email text into **clean, structured JSON data**, ensuring reliability and easy export or reuse.\n\n#### 4. ✅ **Multi-Language Support**\n\nThe summaries are generated **in Italian**, which is ideal for local or internal reporting, while the metadata and logic remain in English — enabling global adaptability.\n\n#### 5. ✅ **Scalable and Extensible**\n\nNew newsletters, categories, or destinations (like Notion, Slack, or a database) can be added easily without changing the core logic.\n\n#### 6. ✅ **Centralized Knowledge Repository**\n\nBy appending to Google Sheets, the team can:\n\n* Track daily AI developments at a glance.\n* Filter or visualize trends across categories.\n* Use the dataset for further analysis or content creation.\n\n#### 7. ✅ **Error-Resilient and Maintainable**\n\nThe **JSON validation** and **loop-based design** ensure that if a single article fails, the rest continue to process smoothly.\n\n---\n\n### How it Works\n\n1.  **Email Trigger & Processing:** The workflow is automatically triggered when a new email arrives from `news@alphasignal.ai`. It retrieves the full email content and converts its HTML body into clean Markdown format for easier parsing.\n\n2.  **Article Extraction & Scraping:** A LangChain Agent, powered by Google Gemini, analyzes the newsletter's Markdown text. Its task is to identify and split the content into individual articles. For each article it finds, it outputs a JSON object containing the title, URL, and an initial summary. Crucially, the agent uses the \"Scrape\" tool to visit each article's URL and generate a more accurate summary in Italian based on the full page content.\n\n3.  **Data Preparation & Categorization:** The JSON output from the previous step is validated and split into individual data items (one per article). Each article is then processed in a loop:\n    *   **Categorization:** An OpenAI model analyzes the article's title and summary, assigning it to the most relevant pre-defined category (e.g., \"LLM & Foundation Models,\" \"AI Automation & WF\").\n    *   **URL Shortening:** The article's link is sent to the CleanURI API to generate a shortened URL.\n\n4.  **Data Storage:** Finally, for each article, a new row is appended to a specified Google Sheet. The row includes the current date, the article's title, the shortened link, the Italian summary, and its assigned category.\n---\n\n\n### Set up Steps\n\nTo implement this workflow, you need to configure the following credentials and nodes in n8n:\n\n1.  **Email Credentials:** Set up a Gmail OAuth2 credential (named \"Gmail account\" in the workflow) to allow n8n to access and read emails from the specified inbox.\n\n2.  **AI Model APIs:**\n    *   **Google Gemini:** Configure the \"Google Gemini(PaLM)\" credential with a valid API key to power the initial article extraction and scraping agent.\n    *   **OpenAI:** Configure the \"OpenAi account (Eure)\" credential with a valid API key to power the article categorization step.\n\n3.  **Scraping Tool:** Set up the [ScrapegraphAI account credential](https://dashboard.scrapegraphai.com/?via=n3witalia) with its required API key to enable the agent to access and scrape content from the article URLs.\n\n4.  **Google Sheets Destination:** Configure the \"Google Sheets account\" credential via OAuth2. You must also specify the exact Google Sheet ID and sheet name (tab) where the processed article data will be stored.\n\n5.  **Activation:** Once all credentials are tested and correctly configured, the workflow can be activated. It will then run automatically upon receiving a new newsletter from the specified sender.\n\n---\n\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
  "featuredImage": "/data/workflows/10952/10952.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 205,
  "downloads": 20,
  "createdAt": "2025-11-18T09:40:19.479Z",
  "updatedAt": "2026-01-16T09:06:55.080Z",
  "publishedAt": "2025-11-18T09:40:19.479Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10952"
}