{
  "id": 7519,
  "slug": "7519",
  "title": "Extract & summarize LinkedIn profiles with Bright Data, Google Gemini & Supabase",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n### Overview\n\nThis workflow connects to LinkedIn via automation nodes and enriches profile data using AI to generate insights such as professional summary, skills highlights, and potential interest areas. All parsed information will be persisted on Supabase for further analysis and reporting purposes.\n\n### Who this is for?\n\nThis workflow is for recruiters, HR tech builders, data analysts, and growth teams who want to:\n\n- Automate LinkedIn data collection\n\n- Enrich raw profile/job data with AI\n\n- Store structured insights for dashboards, CRMs, or analytics\n\n### Good to know\n\nAt time of writing, each data enrichment request to Gemini costs ~$0.002–$0.004 USD depending on model. See [Gemini Pricing](Gemini Pricing) for updated info.\n\nThe Gemini enrichment model is geo-restricted. If you encounter \"model not found,\" it may not be available in your country.\n\nScraping via Bright Data carries cost depending on volume. See [Bright Data Pricing](Bright Data Pricing).\n\n### What problem is this workflow solving?\n\nManually extracting insights from LinkedIn is:\n\n- Slow → Recruiters spend hours on profile research\n\n- Unstructured → Scraping only gives raw HTML/text\n\n- Incomplete → No standardized skills or trend insights\n\nThis workflow provides a repeatable pipeline that converts raw LinkedIn data into structured, enriched insights stored in Supabase for immediate use.\n\n### What this workflow does\n\n- Webhook by default but it could be updated to trigger manually or it could be scheduled as well\n\n- Scrape LinkedIn data via Bright Data API\n\n- Clean and normalize profile or job post data\n\n- AI Enrichment with Gemini → extract skills, roles, industries, seniority, career paths\n\n- Store results in Supabase for querying, dashboards, or API access\n\n### Setup\n\n#### Accounts required:\n\n- [Bright Data](https://get.brightdata.com/5blibaeyszij ) (LinkedIn scraping API)\n\n- Gemini API key (for AI enrichment)\n\n- Supabase project (for structured storage)\n\n- n8n instance (self-hosted or cloud)\n\n#### Nodes in the workflow:\n\n- Manual Trigger (replace with webhook or cron if needed)\n\n- Bright Data Node (Bright Data API call)\n\n- Gemini Node (LLM enrichment)\n\n- Supabase Node (insert structured records)\n\n#### Supabase DB Setup\n\nPlease create a project on Supabase and use the following script for the creation of a new table and indexes for persisting the LinkedIn data extract or mining information.\n\n```\nCREATE TABLE linkedin_data_mining (\n    id BIGSERIAL PRIMARY KEY,  -- Auto-generated unique ID\n    loggedin_user TEXT NOT NULL,\n\n    -- LinkedIn profile identity fields\n    first_name TEXT NOT NULL,\n    last_name TEXT NOT NULL,\n    title TEXT NOT NULL,\n    full_name TEXT GENERATED ALWAYS AS (first_name || ' ' || last_name) STORED,\n    \n    skills JSONB NOT NULL,\n    basic_profile JSONB NOT NULL,\n    emerging_roles JSONB NOT NULL,\n    markdown_content JSONB NOT NULL,\n    summary JSONB NOT NULL,\n    \n    -- Audit fields\n    created_by TEXT NOT NULL,\n    created_date TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL,\n    updated_by TEXT NULL,\n    updated_date TIMESTAMP WITH TIME ZONE NULL\n);\n\n-- Indexes for performance\nCREATE INDEX idx_linkedin_data_mining_full_name ON linkedin_data_mining(full_name);\nCREATE INDEX idx_linkedin_data_mining_first_name ON linkedin_data_mining(first_name);\nCREATE INDEX idx_linkedin_data_mining_last_name ON linkedin_data_mining(last_name);\nCREATE INDEX idx_linkedin_data_mining_skills ON linkedin_data_mining USING GIN (skills);\nCREATE INDEX idx_linkedin_data_mining_basic_profile ON linkedin_data_mining USING GIN (basic_profile);\nCREATE INDEX idx_linkedin_data_mining_emerging_roles ON linkedin_data_mining USING GIN (emerging_roles);\nCREATE INDEX idx_linkedin_data_mining_markdown_content ON linkedin_data_mining USING GIN (markdown_content);\nCREATE INDEX idx_linkedin_data_mining_summary ON linkedin_data_mining USING GIN (summary);\n```\n\n#### Connections:\n\nConfigure your API credentials for Bright Data, Gemini, and Supabase inside n8n’s credentials manager.\n\n### How to customize this workflow to your needs\n\n- **Triggers**: Replace manual trigger with webhook → scrape & enrich on demand (e.g., when a lead form is submitted).\n\n- **Prompts**: Adjust Gemini prompts to extract attributes like seniority, technologies, career transitions, or hiring signals.\n\n- **Destinations**: Store enriched data in Supabase, or send to Google Sheets, Slack, or HubSpot for immediate team use.\n\n### Connect with Me\n\n**Email**: ranjancse@gmail.com\n\n**LinkedIn**: https://www.linkedin.com/in/ranjan-dailata/\n\n**Get Bright Data**: [Bright Data](https://get.brightdata.com/5blibaeyszij ) (Supports free workflows with a small commission)\n\n#LinkedInAutomation #n8n #WebScraping #DataAutomation #BrightData #GeminiAI #Supabase #AIEnrichment #RecruitmentTech #HRTech #SalesAutomation #MarketIntelligence #DataPipeline #WorkflowAutomation #OpenSourceAutomation",
  "featuredImage": "/data/workflows/7519/7519.webp",
  "author": {
    "id": 101,
    "slug": "ranjancse",
    "name": "Ranjan Dailata",
    "avatar": ""
  },
  "categories": [
    "AI Summarization",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 89,
  "downloads": 8,
  "createdAt": "2025-08-17T14:36:43.238Z",
  "updatedAt": "2026-01-16T08:50:47.405Z",
  "publishedAt": "2025-08-17T14:36:43.238Z",
  "nodes": 31,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7519"
}