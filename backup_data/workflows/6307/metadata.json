{
  "id": 6307,
  "slug": "6307",
  "title": "Google Maps lead generation with Apify & email extraction for Airtable",
  "description": "## ğŸ§  What It Does\nThis n8n workflow collects **leads** from **Google Maps**, scrapes their websites via direct **HTTP requests**, and extracts **valid email addresses** â€” all while mimicking real user behavior to improve scraping reliability. It rotates User-Agent headers, introduces randomized delays, and refines URLs by removing only query parameters and fragments to preserve valid page paths (like social media links).\nThe workflow blends **Apify actors, raw HTTP requests, HTML-to-Markdown** conversion, and **smart email extraction** to deliver clean, actionable lead data â€” ready to be sent to **Airtable**, Google Sheets, or any CRM. \nPerfect for lean, scalable B2B lead generation using n8nâ€™s native logic and no external scrapers.\n\n## ğŸ’¡Why this workflow\nModest lead scrapers rely on heavy tools or APIs like Firecrawl. This workflow:\n- Uses lightweight HTTP requests (with randomized user-agents) to scrape websites.\n- Adds natural wait times to avoid rate limits and IP bans.\n- Avoid full-page crawlers, yet still pulls emails effectively.\n- Works great for freelancers, marketers, or teams targeting niche B2B leads.\n- Designed for stealth and resilience.\n\n## ğŸ‘¤ Who itâ€™s for\n- Lead generation freelancers or consultants.\n- B2B marketers looking to extract real contact info.\n- Small businesses doing targeted outreach.\n- Developers who want a fast, low-footprint scraper.\n- Anyone who wants **email + website leads** from **Google Maps.**\n\n\n## âš™ï¸ How It Works\n#### 1. ğŸ“¥ Form Submission (Lead Input)\nA Form Trigger collects:\n     - **Keyword**\n     - **Location**     \n     - **No. of Leads** (defaults to 10)\n\nThis makes the workflow dynamic and user-friendly â€” ready for multiple use cases and teams.\n\n#### 2. ğŸ“Š Scrape Business Info (via Apify)\n- Apifyâ€™s Google Maps Actor searches for matching businesses.\n- The Dataset Node fetches all relevant business details.\n- A Set Node parses key fields like name, phone, website, and category.\n- A Limit Node ensures the workflow only processes the desired number of leads.\n\n#### 3. ğŸ” First Loop â€“ Visit & Scrape Website\nEach business website is processed in a loop.\n- A Code Node cleans the website URL by removing only query parameters/fragments â€” keeping full paths like /contact.\n- A HTTP Request Node fetches the raw HTML of the site:\n     - Uses randomized User-Agent headers (5 variants) to mimic real devices and browsers. This makes requests appear more human and reduces the risk of detection or blocking.\n- HTML is converted to Markdown using the Markdown Node, making it easier to scan for text patterns.\n- A Wait Node introduces a random delay between 2-7 seconds:\n     - Helps avoid triggering rate limits,\n     - Reduces likelihood of being flagged as a bot.\n- A Merge Node combines scraped markdown + lead info for use in the second loop.\n\n#### 4. ğŸ” Second Loop â€“ Extract Emails\nIn this second loop, the markdown data is processed.\n- A Code Node applies regex to extract the first valid email address.\n- If no email is found, \"N/A\" is returned.\n- A brief 1 second Wait Node simulates realistic browsing time.\n- Another Merge Node attaches the email result to the original lead data.\n\n#### 5. âœ… Filter, Clean & Store\n- A Filter Node removes all entries with \"N/A\" or invalid email results.\n- A Set Node ensures only required fields (like website, email, and company name) are passed forward.\n- The clean leads are saved to **Airtable** (or optionally, Google Sheets) using an upsert-style insert to avoid duplicates.\n\n## ğŸ›¡ï¸ Anti-Flagging Design\nThis workflow is optimized for stealth:\n- No scraping tools or headless browsers (like Puppeteer or Firecrawl).\n- Direct HTTP requests with rotating User-Agents.\n- Randomized wait intervals (2-7s).\n- Only non-intrusive parsing â€” no automation footprints.\n\n## ğŸ›  How to Set It Up\n**Open n8n** (Cloud or Self-Hosted).\n**Install Apify node**\n  - search **Apify** and click on **Install**. Do this before importing your file.\n  \n**Import the provided .json file** into your n8n editor.\n**Set up the required credentials:**\n- **ğŸ”‘ Apify API Key** (used for Google Maps scraping)\n- **ğŸ”‘ Airtable API Key** (or connect Google Sheets instead)\n\n#### Recommended \n- Prepare your Airtable base or Google Sheet with fields like: Email, Website, Phone, Company Name.\n- Review the Set node if you'd like to collect more fields from Apify (e.g., Ratings, Categories, etc.).\n\n## ğŸ” Customization Tips\n- The Apify scraper returns rich business data. By default, this workflow collects name, phone, and website â€” but you can add more in the **\"Grab Desired Fields\"** node.\n- Need safer scraping at scale? Swap the HTTP Request for Firecrawlâ€™s Single URL scraper (or any headless service like Browserless, Oxylabs, Bright Date, or ScrapingBee) â€” they handle rendering and IP rotation.\n- Want to extract from internal pages (like /contact or /about)? Use Firecrawlâ€™s async crawl mode â€” just note it takes longer.\n- For speed and efficiency, this built-in **HTTP + Markdown** setup is usually the fastest way to grab emails.\n",
  "featuredImage": "/data/workflows/6307/6307.webp",
  "author": {
    "id": 101,
    "slug": "kingsley",
    "name": "Ezema Kingsley Chibuzo",
    "avatar": ""
  },
  "categories": [
    "Lead Generation"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1077,
  "downloads": 107,
  "createdAt": "2025-07-23T06:50:51.634Z",
  "updatedAt": "2026-01-16T08:44:23.302Z",
  "publishedAt": "2025-07-23T06:50:51.634Z",
  "nodes": 26,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6307"
}