{
  "id": 8944,
  "slug": "8944",
  "title": "My solution for the \"Agentic Arena Community Contest\" (RAG, Qdrant, Mistral OCR)",
  "description": "ðŸ¤–ðŸ“ˆ This workflow is **my personal solution** for the **Agentic Arena Community Contest**, where the goal is to build a Retrieval-Augmented Generation (RAG) AI agent capable of answering questions based on a provided PDF knowledge base.\n\n\n---\n\n### Key Advantages\n\n* âœ… **End-to-End RAG Implementation**\n  Fully automates the ingestion, processing, and retrieval of knowledge from PDFs into a vector database.\n\n* âœ… **Accuracy through Multi-Layered Retrieval**\n  Combines embeddings, Qdrant search, and Cohere reranking to ensure the agent retrieves the most relevant policy information.\n\n* âœ… **Robust Evaluation System**\n  Includes an automated correctness evaluation pipeline powered by GPT-4.1 as a judge, ensuring transparent scoring and continuous improvement.\n\n* âœ… **Citation-Driven Compliance**\n  The AI agent is instructed to provide **citations for every answer**, making it suitable for high-stakes use cases like policy compliance.\n\n* âœ… **Scalability and Modularity**\n  Can easily integrate with different data sources (Google Drive, APIs, other storage systems) and be extended to new use cases.\n\n* âœ… **Seamless Collaboration with Google Sheets**\n  Both the evaluation set and the results are integrated with Google Sheets, enabling easy monitoring, iteration, and reporting.\n\n* âœ… **Cloud and Self-Hosted Flexibility**\n  Works with self-hosted **Qdrant** on Hetzner, Mistral Cloud for OCR, and OpenAI/Cohere APIs, combining local control with powerful cloud AI services.\n\n---\n### **How it Works**\n\n1.  **Knowledge Base Ingestion (The \"Setup\" Execution):**\n    *   When started manually, the workflow first clears an existing Qdrant vector database collection.\n    *   It then searches a specified Google Drive folder for PDF files. For each PDF found, it performs the following steps:\n        *   **Uploads the file** to the Mistral AI API.\n        *   **Processes the PDF** using Mistral's OCR service to extract text and convert it into a structured markdown format.\n        *   **Splits the text** into manageable chunks.\n        *   **Generates embeddings** for each text chunk using OpenAI's model.\n        *   **Stores the embeddings** in the Qdrant vector store, creating a searchable knowledge base.\n\n2.  **Agent Evaluation (The \"Testing\" Execution):**\n    *   The workflow is triggered by an evaluation Google Sheet containing questions and correct answers.\n    *   For each question, the core **AI Agent** is activated. This agent:\n        *   Uses the **RAG tool** to search the pre-populated Qdrant vector store for relevant information from the PDFs.\n        *   Employs a **Cohere reranker** to refine the search results for the highest quality context.\n        *   Leverages a **GPT-4.1 model** to generate an answer based strictly on the retrieved context.\n    *   The agent's answer is then passed to an **\"LLM as a Judge\"** (another GPT-4.1 instance), which compares it to the ground truth answer from the evaluation sheet.\n    *   The judge provides a detailed score (1-5) based on factual correctness and citation accuracy.\n    *   Finally, both the agent's answer and the correctness score are saved back to a Google Sheet for review.\n\n---\n\n### **Set up Steps**\n\nTo implement this solution, you need to configure the following components and credentials:\n\n1.  **Configure Core AI Services:**\n    *   **OpenAI API Credentials:** Required for the main AI agent, the judge LLM, and generating embeddings.\n    *   **Mistral AI API Credentials:** Necessary for the OCR service that processes PDF files.\n    *   **Cohere API Credentials:** Used for the reranker node that improves retrieval quality.\n    *   **Google Service Accounts:** Set up OAuth for Google Sheets (to read questions and save results) and Google Drive (to access the PDF source files).\n\n2.  **Set up the Vector Database (Qdrant):**\n    *   This workflow uses a self-hosted Qdrant instance. You must deploy and configure your own Qdrant server.\n    *   Update the **Qdrant Vector Store** and **RAG** nodes with the correct API endpoint URL and credentials for your Qdrant instance.\n    *   Ensure the collection name (`agentic-arena`) is created or matches your setup.\n\n3.  **Connect Data Sources:**\n    *   **PDF Source:** In the **\"Search PDFs\"** node, update the `folderId` parameter to point to your own Google Drive folder containing the contest PDFs.\n    *   **Evaluation Sheet:** In the **\"Eval Set\"** node, update the `documentId` to point to your own copy of the evaluation Google Sheet containing the test questions and answers.\n    *   **Results Sheet:** In the **\"Save Eval\"** node, update the `documentId` to point to the Google Sheet where you want to save the evaluation results.\n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
  "featuredImage": "/data/workflows/8944/8944.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 681,
  "downloads": 68,
  "createdAt": "2025-09-26T09:12:39.109Z",
  "updatedAt": "2026-01-16T08:58:29.380Z",
  "publishedAt": "2025-09-26T09:12:39.109Z",
  "nodes": 41,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/8944"
}