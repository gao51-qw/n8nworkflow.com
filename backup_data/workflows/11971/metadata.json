{
  "id": 11971,
  "slug": "11971",
  "title": "Synchronize MySQL database schemas to Pinecone with OpenAI embeddings",
  "description": "This workflow synchronizes MySQL database table schemas with a vector database in a controlled, idempotent manner.\nEach database table is indexed as a single vector to preserve complete schema context for AI-based retrieval and reasoning.\nThe workflow prevents duplicate vectors and automatically handles schema changes by detecting differences and re-indexing only when required.\n\n### How it works\n- The workflow starts with a manual trigger and loads global configuration values.\n- All database tables are discovered and processed one by one inside a loop.\n- For each table, a normalized schema representation is generated, and a deterministic hash is calculated.\n- A metadata table is checked to determine whether a vector already exists for the table.\n- If a vector exists, the stored schema hash is compared with the current hash to detect schema changes.\n- When a schema change is detected, the existing vector and metadata are deleted.\n- The updated table schema is embedded as a single vector (without chunking) and upserted into the vector database.\n- Vector identifiers and schema hashes are persisted for future executions.\n\n### Setup steps\n- Set the MySQL database name using mysql_database_name.\n- Configure the Pinecone index name using pinecone_index.\n- Set the vector namespace using vector_namespace.\n- Configure the Pinecone index host using vector_index_host.\n- Add your Pinecone API key using pinecone_apikey.\n- Select the embedding model using embedding_model.\n- Configure text processing options:\n    - chunk_size\n    - chunk_overlap\n- Set the metadata table identifier using dataTable_Id.\n- Save and run the workflow manually to perform the initial schema synchronization.\n\n### Limitations\n- This workflow indexes database table schemas only. Table data (rows) are not embedded or indexed.\n- Each table is stored as a single vector. Very large or highly complex schemas may approach model token limits depending on the selected embedding model.\n- Schema changes are detected using a hash-based comparison. Non-structural changes that do not affect the schema representation will not trigger re-indexing.",
  "featuredImage": "/data/workflows/11971/11971.webp",
  "author": {
    "id": 101,
    "slug": "coolchandan62",
    "name": "Chandan Singh",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 60,
  "downloads": 6,
  "createdAt": "2025-12-19T19:45:32.461Z",
  "updatedAt": "2026-01-16T09:10:53.227Z",
  "publishedAt": "2025-12-19T19:45:32.461Z",
  "nodes": 22,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11971"
}