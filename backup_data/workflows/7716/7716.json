{
  "workflow": {
    "id": 7716,
    "name": "Measure AI model carbon footprint with Ecologits.ai methodology",
    "views": 74,
    "recentViews": 0,
    "totalViews": 74,
    "createdAt": "2025-08-21T21:15:58.451Z",
    "description": "This template provides a straightforward technique to measure and raise awareness about the environmental impact of your AI automations. \n\nBy adding a simple calculation step to your workflow, you can estimate the carbon footprint (in grams of CO‚ÇÇ equivalent) generated by each call to a Large Language Model.\n\nBased on the open methodology from **Ecologits.ai**, this workflow empowers you to build more responsible AI applications. You can use the calculated footprint to inform your users, track your organization's impact, or simply be more mindful of the resources your workflows consume.\n\n## Who is this for?\n\n* **Environmentally-conscious developers:** Build AI-powered applications with an awareness of their ecological impact.\n* **Businesses and organizations:** Track and report on the carbon footprint of your AI usage as part of your sustainability goals.\n* **Any n8n user using AI:** A simple and powerful snippet that can be added to almost any AI workflow to make its invisible environmental costs visible.\n* **Educators and advocates:** Use this as a practical tool to demonstrate and discuss the real-world impact of AI technologies.\n\n## What problem does this solve?\n\n* **Makes the abstract tangible:** The environmental cost of a single AI call is often overlooked. This workflow translates it into a concrete, measurable number (grams of CO‚ÇÇe).\n* **Promotes responsible AI development:** Encourages builders to consider the efficiency of their prompts and models by showing the direct impact of the generated output.\n* **Provides a standardized starting point:** Offers a simple, transparent, and extensible method for carbon accounting in your AI workflows, based on a credible, open-source methodology.\n* **Facilitates transparent communication:** Gives you the data needed to transparently communicate the impact of your AI features to stakeholders and users.\n\n\n## How it works\n\nThis template demonstrates a simple calculation snippet that you can adapt and add to your own workflows.\n\n1.  **Set conversion factor:** A dedicated **Conversion factor** node at the beginning of the workflow holds the gCO‚ÇÇe per token value. This makes it easy to configure.\n2.  **AI generates output:** An AI node (in this example, a **Basic LLM Chain**) runs and produces a text output.\n3.  **Estimate token count:** The **Calculate gCO‚ÇÇe** node takes the character length of the AI's text output and divides it by 4. This provides a reasonable estimate of the number of tokens generated.\n4.  **Calculate carbon footprint:** The estimated token count is then multiplied by the **conversion factor** defined in the first node. The result is the carbon footprint for that single AI call.\n\n## Setup\n\n1.  **Set your conversion factor (Critical Step):**\n    * The default factor (`0.0612`) is for **GPT-4o hosted in the US**.\n    * Visit **ecologits.ai/latest** to find the specific conversion factor for *your* AI model and server region.\n    * In the **Conversion factor** node, replace the default value with the correct factor.\n2.  **Integrate the snippet into your workflow:**\n    * Copy the **Conversion factor** and **Calculate gCO‚ÇÇe** nodes from this template.\n    * Place the **Conversion factor** node near the start of your workflow (before your AI node).\n    * Place the **Calculate gCO‚ÇÇe** node *after* your AI node.\n3.  **Link your AI output:**\n    * Click on the **Calculate gCO‚ÇÇe** node.\n    * In the `AI output` field, replace the expression with the output from *your* AI node (e.g., `{{ $('My OpenAI Node').item.json.choices[0].message.content }}`). The carbon calculation will now work with your data.\n4.  **Activate your workflow.** The carbon footprint will now be calculated with each execution.\n\n## Taking it further\n\n* **Improve accuracy with token counts:** If your AI node (like the native **OpenAI** node) directly provides the number of output tokens (e.g., `completion_tokens`), use that number instead of estimating from the text length. This will give you a more precise calculation.\n* **Calculate total workflow footprint:** If you have multiple AI nodes, add a calculation step after each one. Then, add a final **Set** node at the end of your workflow to sum all the individual gCO‚ÇÇe values.\n* **Display the impact:** Add the final `AI output gCO‚ÇÇe` value to your workflow's results, whether it's a Slack message, an email, or a custom dashboard, to keep the environmental impact top-of-mind.\n* **A note on AI agents:** This estimation method is difficult to apply accurately to AI Agents at this time, as the token usage of their intermediary \"thinking\" steps is not yet exposed in the workflow data.",
    "workflow": {
      "nodes": [
        {
          "id": "e374f8b8-ff4a-4b98-af50-d609338ec38f",
          "name": "When clicking ‚ÄòExecute workflow‚Äô",
          "type": "n8n-nodes-base.manualTrigger",
          "position": [
            0,
            -160
          ],
          "parameters": {},
          "typeVersion": 1
        },
        {
          "id": "6cce6b66-bd1a-419b-86c1-b76aa257e96c",
          "name": "Basic LLM Chain",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            608,
            -160
          ],
          "parameters": {
            "text": "Enter here your user prompt",
            "batching": {},
            "messages": {
              "messageValues": [
                {
                  "message": "Enter here the system prompt"
                }
              ]
            },
            "promptType": "define"
          },
          "typeVersion": 1.7
        },
        {
          "id": "d0ea8139-307d-4de6-9f29-11216958f362",
          "name": "OpenAI Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            672,
            64
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4o",
              "cachedResultName": "gpt-4o"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "0fca2f27-8a0b-46d0-9dfc-27967afe2ae5",
          "name": "Calculate gCO‚ÇÇe",
          "type": "n8n-nodes-base.set",
          "position": [
            960,
            -160
          ],
          "parameters": {
            "options": {},
            "assignments": {
              "assignments": [
                {
                  "id": "cc17f2be-ce12-488f-89c7-de200b4c4869",
                  "name": "AI output",
                  "type": "string",
                  "value": "={{ $json.text }}"
                },
                {
                  "id": "c396e3b8-f07f-4153-9892-1b499a724dbc",
                  "name": "AI output gCO‚ÇÇe",
                  "type": "number",
                  "value": "={{ Math.ceil($json.text.length / 4) * $('Conversion factor').item.json['Conversion factor (in gCO‚ÇÇe/token)'] }}"
                }
              ]
            }
          },
          "typeVersion": 3.4
        },
        {
          "id": "5c25ded0-c24d-455b-82fb-d54d267ca591",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -624,
            -384
          ],
          "parameters": {
            "width": 560,
            "height": 672,
            "content": "# Measure Your AI's Carbon Footprint\n\nThis workflow demonstrates a technique to calculate the gCO‚ÇÇe (grams of CO‚ÇÇ equivalent) of an AI model's output, based on the methodology from **Ecologits.ai**.\n\n## How it works\n\nA dedicated **Conversion factor** node makes it easy to set your parameters. The **Calculate gCO‚ÇÇe** node then uses this factor and the AI's text output to estimate the carbon footprint.\n\n## How to use this snippet\n\n1.  **Set your conversion factor (Important!):** The default factor is for **GPT-4o in the US**. You **must** visit **ecologits.ai/latest** to find the correct factor for *your model and server region* and update the value in the **\"Conversion factor\"** node.\n2.  **Connect the snippet:** Place the **\"Conversion factor\"** node before your AI node and the **\"Calculate gCO‚ÇÇe\"** node after it.\n3.  **Update the calculation:** Modify the **\"Calculate gCO‚ÇÇe\"** node to use the output text from *your* AI node.\n\n**Pro-Tip:** For higher accuracy, use the direct `output_tokens` value from your AI node's data if it's available."
          },
          "typeVersion": 1
        },
        {
          "id": "941043b0-01ee-4553-87ec-1246a4cb2f2b",
          "name": "Conversion factor",
          "type": "n8n-nodes-base.set",
          "position": [
            304,
            -160
          ],
          "parameters": {
            "options": {},
            "assignments": {
              "assignments": [
                {
                  "id": "a2c5484b-173e-4647-8dc1-23c32a899f75",
                  "name": "Conversion factor (in gCO‚ÇÇe/token)",
                  "type": "number",
                  "value": 0.0612
                }
              ]
            }
          },
          "typeVersion": 3.4
        },
        {
          "id": "430fc390-50b7-4feb-8c8f-be196a342d60",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            224,
            -240
          ],
          "parameters": {
            "color": 5,
            "width": 272,
            "height": 336,
            "content": "### Adapt this value to your model & settings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the expert mode here to find the factor that fits best:\nhttps://huggingface.co/spaces/genai-impact/ecologits-calculator"
          },
          "typeVersion": 1
        }
      ],
      "connections": {
        "Basic LLM Chain": {
          "main": [
            [
              {
                "node": "Calculate gCO‚ÇÇe",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Conversion factor": {
          "main": [
            [
              {
                "node": "Basic LLM Chain",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "OpenAI Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "Basic LLM Chain",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "When clicking ‚ÄòExecute workflow‚Äô": {
          "main": [
            [
              {
                "node": "Conversion factor",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 7,
      "nodeTypes": {
        "n8n-nodes-base.set": {
          "count": 2
        },
        "n8n-nodes-base.stickyNote": {
          "count": 2
        },
        "n8n-nodes-base.manualTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chainLlm": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Guillaume Duvernay",
      "username": "duv",
      "bio": "AI and automation expert",
      "verified": true,
      "links": [
        "https://www.linkedin.com/in/guillaume-duvernay/"
      ],
      "avatar": "https://gravatar.com/avatar/1e93ed2388069da40b3202c5566318982166f1a0b4c4c35c4802c8ca4de79991?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 38,
        "icon": "fa:pen",
        "name": "n8n-nodes-base.set",
        "codex": {
          "data": {
            "alias": [
              "Set",
              "JS",
              "JSON",
              "Filter",
              "Transform",
              "Map"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/learn-to-automate-your-factorys-incident-reporting-a-step-by-step-guide/",
                  "icon": "üè≠",
                  "label": "Learn to Automate Your Factory's Incident Reporting: A Step by Step Guide"
                },
                {
                  "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                  "icon": "‚òÄÔ∏è",
                  "label": "2021: The Year to Automate the New You with n8n"
                },
                {
                  "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                  "icon": "üìà",
                  "label": "Automatically pulling and visualizing data with n8n"
                },
                {
                  "url": "https://n8n.io/blog/database-monitoring-and-alerting-with-n8n/",
                  "icon": "üì°",
                  "label": "Database Monitoring and Alerting with n8n"
                },
                {
                  "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                  "icon": "üßæ",
                  "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
                },
                {
                  "url": "https://n8n.io/blog/no-code-ecommerce-workflow-automations/",
                  "icon": "store",
                  "label": "6 e-commerce workflows to power up your Shopify s"
                },
                {
                  "url": "https://n8n.io/blog/how-to-build-a-low-code-self-hosted-url-shortener/",
                  "icon": "üîó",
                  "label": "How to build a low-code, self-hosted URL shortener in 3 steps"
                },
                {
                  "url": "https://n8n.io/blog/automate-your-data-processing-pipeline-in-9-steps-with-n8n/",
                  "icon": "‚öôÔ∏è",
                  "label": "Automate your data processing pipeline in 9 steps"
                },
                {
                  "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                  "icon": "üë•",
                  "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
                },
                {
                  "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                  "icon": "‚ö°Ô∏è",
                  "label": "5 tasks you can automate with the new Notion API "
                },
                {
                  "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                  "icon": "üí°",
                  "label": "15 Google apps you can combine and automate to increase productivity"
                },
                {
                  "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                  "icon": " üï∏Ô∏è",
                  "label": "How uProc scraped a multi-page website with a low-code workflow"
                },
                {
                  "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                  "icon": "üì±",
                  "label": "Building an expense tracking app in 10 minutes"
                },
                {
                  "url": "https://n8n.io/blog/the-ultimate-guide-to-automate-your-video-collaboration-with-whereby-mattermost-and-n8n/",
                  "icon": "üìπ",
                  "label": "The ultimate guide to automate your video collaboration with Whereby, Mattermost, and n8n"
                },
                {
                  "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                  "icon": "ü§ñ",
                  "label": "5 workflow automations for Mattermost that we love at n8n"
                },
                {
                  "url": "https://n8n.io/blog/learn-to-build-powerful-api-endpoints-using-webhooks/",
                  "icon": "üß∞",
                  "label": "Learn to Build Powerful API Endpoints Using Webhooks"
                },
                {
                  "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                  "icon": "üìà",
                  "label": "How a Membership Development Manager automates his work and investments"
                },
                {
                  "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                  "icon": "üìà",
                  "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
                },
                {
                  "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                  "icon": "üé°",
                  "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
                },
                {
                  "url": "https://n8n.io/blog/benefits-of-automation-and-n8n-an-interview-with-hubspots-hugh-durkin/",
                  "icon": "üéñ",
                  "label": "Benefits of automation and n8n: An interview with HubSpot's Hugh Durkin"
                },
                {
                  "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                  "icon": "üõµ",
                  "label": "How Goomer automated their operations with over 200 n8n workflows"
                },
                {
                  "url": "https://n8n.io/blog/aws-workflow-automation/",
                  "label": "7 no-code workflow automations for Amazon Web Services"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Edit Fields"
        },
        "iconData": {
          "icon": "pen",
          "type": "icon"
        },
        "displayName": "Edit Fields (Set)",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 838,
        "icon": "fa:mouse-pointer",
        "name": "n8n-nodes-base.manualTrigger",
        "codex": {
          "data": {
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.manualworkflowtrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0"
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When clicking ‚ÄòExecute workflow‚Äô",
          "color": "#909298"
        },
        "iconData": {
          "icon": "mouse-pointer",
          "type": "icon"
        },
        "displayName": "Manual Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1123,
        "icon": "fa:link",
        "name": "@n8n/n8n-nodes-langchain.chainLlm",
        "codex": {
          "data": {
            "alias": [
              "LangChain"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Chains",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Basic LLM Chain",
          "color": "#909298"
        },
        "iconData": {
          "icon": "link",
          "type": "icon"
        },
        "displayName": "Basic LLM Chain",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 49,
        "name": "AI Summarization"
      },
      {
        "id": 51,
        "name": "Multimodal AI"
      }
    ],
    "image": []
  }
}