{
  "id": 9174,
  "slug": "9174",
  "title": "Auto-update knowledge base with Drive, LlamaIndex & Azure OpenAI embeddings",
  "description": "This Workflow auto-ingests Google Drive documents, parses them with LlamaIndex, and stores Azure OpenAI embeddings in an in-memory vector store—cutting manual update time from ~30 minutes to under 2 minutes per doc.\n\n## Why Use This Workflow?\n \n**Cost Reduction:** Eliminates pays monthly fee on cloud just for store knowledge\n\n## Ideal For\n\n- **Knowledge Managers / Documentation Teams:** Automatically keep product docs and SOPs in sync when source files change on Google Drive.\n- **Support Teams:** Ensure the searchable KB is always up-to-date after doc edits, speeding agent onboarding and resolution time.\n- **Developer / AI Teams:** Populate an in-memory vector store for experiments, rapid prototyping, or local RAG demos.\n\n## How It Works\n\n1. **Trigger:** Google Drive Trigger watches a specific document or folder for updates.\n2. **Data Collection:** The updated file is downloaded from Google Drive.\n3. **Processing:** The file is uploaded to LlamaIndex cloud via an HTTP Request to create a parsing job.\n4. **Intelligence Layer:** Workflow polls LlamaIndex job status (Wait + Monitor loop). If parsing status equals SUCCESS, the result is retrieved as markdown.\n5. **Output & Delivery:** Parsed markdown is loaded into LangChain's Default Data Loader, passed to Azure OpenAI embeddings (deployment \"3small\"), then inserted into an in-memory vector store.\n6. **Storage & Logging:** Vector store holds embeddings in memory (good for prototyping). Optionally persist to an external vector DB for production.\n\n## Setup Guide\n\n### Prerequisites\n\n| Requirement | Type | Purpose |\n|-------------|------|---------|\n| n8n instance | Essential | Execute and import the workflow — use the [n8n instance](https://n8n.partnerlinks.io/khmuhtadin) |\n| Google Drive OAuth2 | Essential | Watch and download documents from Google Drive |\n| LlamaIndex Cloud API | Essential | Parse and convert documents to structured markdown |\n| Azure OpenAI Account | Essential | Generate embeddings (deployment configured to model name \"3small\") |\n| Persistent Vector DB (e.g., Pinecone) | Optional | Persist embeddings for production-scale search |\n\n### Installation Steps\n\n1. Import the workflow JSON into your n8n instance: open your [n8n instance](https://n8n.partnerlinks.io/khmuhtadin) and import the file.\n2. Configure credentials:\n   - Azure OpenAI: Provide Endpoint, API Key and set deployment name.\n   - LlamaIndex API: Create an HTTP Header Auth credential in n8n. Header Name: Authorization. Header Value: Bearer YOUR_API_KEY.\n   - Google Drive OAuth2: Create OAuth 2.0 credentials in Google Cloud Console, enable Drive API, and configure the Google Drive OAuth2 credential in n8n.\n3. Update environment-specific values:\n   - Replace the workflow's Google Drive fileId with the GUID or folder ID you want to watch (do not commit public IDs).\n4. Customize settings:\n   - Polling interval (Wait node): adjust for faster or slower job status checks.\n   - Target file or folder: toggled on the Google Drive Trigger node.\n   - Embedding model: change Azure OpenAI deployment if needed.\n5. Test execution:\n   - Save changes and trigger a sample file update on Drive. Verify each node runs and the vector store receives embeddings.\n\n## Technical Details\n\n### Core Nodes\n\n| Node | Purpose | Key Configuration |\n|------|---------|-------------------|\n| Knowledge Base Updated Trigger (Google Drive Trigger) | Triggers on file/folder changes | Set trigger type to specific file or folder; configure OAuth2 credential |\n| Download Knowledge Document (Google Drive) | Downloads file binary | Operation: download; ensure OAuth2 credential is selected |\n| Parse Document via LlamaIndex (HTTP Request) | Uploads file to LlamaIndex parsing endpoint | POST multipart/form-data to /parsing/upload; use HTTP Header Auth credential |\n| Monitor Document Processing (HTTP Request) | Polls parsing job status | GET /parsing/job/{{jobId}}; check status field |\n| Check Parsing Completion (If) | Branches on job status | Condition: {{$json.status}} equals SUCCESS |\n| Retrieve Parsed Content (HTTP Request) | Fetches parsed markdown result | GET /parsing/job/{{jobId}}/result/markdown |\n| Default Data Loader (LangChain) | Loads parsed markdown into document format | Use as document source for embeddings |\n| Embeddings Azure OpenAI | Generates embeddings for documents | Credentials: Azure OpenAI; Model/Deployment: 3small |\n| Insert Data to Store (vectorStoreInMemory) | Stores documents + embeddings | Use memory store for prototyping; switch to DB for persistence |\n\n### Workflow Logic\n\n- On Drive change, the file binary is downloaded and sent to LlamaIndex.\n- Workflow enters a monitor loop: Monitor Document Processing fetches job status, If node checks status. If not SUCCESS, Wait node delays before re-check.\n- When parsing completes, the workflow retrieves markdown, loads documents, creates embeddings via Azure OpenAI, and inserts data into an in-memory vector store.\n\n## Customization Options\n\nBasic Adjustments:\n- Poll Delay: Set Wait node (default: every minute) to balance speed vs. API quota.\n- Target Scope: Switch the trigger from a single file to a folder to auto-handle many docs.\n- Embedding Model: Swap Azure deployment for a different model name as needed.\n\nAdvanced Enhancements:\n- Persistent Vector DB Integration: Replace vectorStoreInMemory with Pinecone or Milvus for production search.\n- Notification: Add Slack or email nodes to notify when parsing completes or fails.\n- Summarization: Add an LLM summarization step to generate chunk-level summaries.\n\nScaling option:\n- Batch uploads and chunking to reduce embedding calls; use a queue (Redis or n8n queue patterns) and horizontal workers for high throughput.\n\n## Performance & Optimization\n\n| Metric | Expected Performance | Optimization Tips |\n|--------|----------------------|-------------------|\n| Execution time (per doc) | ~10s–2min (depends on file size & LlamaIndex processing) | Chunk large docs; run embeddings in batches |\n| API calls (per doc) | 3–8 (upload, poll(s), retrieve, embedding calls) | Increase poll interval; consolidate requests |\n| Error handling | Retries via Wait loop and If checks | Add exponential backoff, failure notifications, and retry limits |\n\n## Troubleshooting\n\n| Problem | Cause | Solution |\n|---------|-------|----------|\n| Authentication errors | Invalid/missing credentials | Reconfigure n8n Credentials; do not paste API keys directly into nodes |\n| File not found | Incorrect fileId or permissions | Verify Drive fileId and OAuth scopes; share file with the service account if needed |\n| Parsing stuck in PENDING | LlamaIndex processing delay or rate limit | Increase Wait node interval, monitor LlamaIndex dashboard, add retry limits |\n| Embedding failures | Model/deployment mismatch or quota limits | Confirm Azure deployment name (3small) and subscription quotas |\n\n---\n\n**Created by:** [khmuhtadin](https://khmuhtadin.com)  \n**Category:** Knowledge Management\n**Tags:** google-drive, llamaindex, azure-openai, embeddings, knowledge-base, vector-store\n\nNeed custom workflows? [Contact us](https://khaisa.studio/contact)",
  "featuredImage": "/data/workflows/9174/9174.webp",
  "author": {
    "id": 101,
    "slug": "khmuhtadin",
    "name": "Khairul Muhtadin",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 267,
  "downloads": 26,
  "createdAt": "2025-10-02T01:25:25.701Z",
  "updatedAt": "2026-01-16T08:59:21.138Z",
  "publishedAt": "2025-10-02T01:25:25.701Z",
  "nodes": 13,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9174"
}