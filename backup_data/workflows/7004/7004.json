{
  "workflow": {
    "id": 7004,
    "name": "AI orchestrator: dynamically selects models based on input type",
    "views": 10060,
    "recentViews": 4,
    "totalViews": 10060,
    "createdAt": "2025-08-05T10:21:49.772Z",
    "description": "This workflow is designed to intelligently **route user queries to the most suitable large language model (LLM)** based on the type of request received in a chat environment. It uses structured classification and model selection to optimize both performance and cost-efficiency in AI-driven conversations.\n\nIt dynamically routes requests to specialized AI models based on content type, optimizing response quality and efficiency.\n\n---\n\n###  **Benefits**\n\n* **Smart Model Routing**: Reduces costs by using lighter models for general tasks and reserving heavier models for complex needs.\n* **Scalability**: Easily expandable by adding more request types or LLMs.\n* **Maintainability**: Clear logic separation between classification, model routing, and execution.\n* **Personalization**: Can be integrated with session IDs for per-user memory, enabling personalized conversations.\n* **Speed Optimization**: Fast models like `GPT-4.1 mini` or `Gemini Flash` are chosen for tasks where speed is a priority.\n---\n\n### **How It Works**\n1. **Input Handling**:  \n   - The workflow starts with the \"When chat message received\" node, which triggers the process when a chat message is received. The input includes the chat message (`chatInput`) and a session ID (`sessionId`).\n\n2. **Request Classification**:  \n   - The \"Request Type\" node uses an OpenAI model (`gpt-4.1-mini`) to classify the incoming request into one of four categories:  \n     - `general`: For general queries.  \n     - `reasoning`: For reasoning-based questions.  \n     - `coding`: For code-related requests.  \n     - `search`: For queries requiring search tools.  \n   - The classification is structured using the \"Structured Output Parser\" node, which enforces a consistent output format.\n\n3. **Model Selection**:  \n   - The \"Model Selector\" node routes the request to one of four AI models based on the classification:  \n     - **Opus 4** (Claude 4 Sonnet): Used for `coding` requests.  \n     - **Gemini Thinking Pro**: Used for `reasoning` requests.  \n     - **GPT 4.1 mini**: Used for `general` requests.  \n     - **Perplexity**: Used for `search` (Google-related) requests.  \n\n4. **AI Processing**:  \n   - The selected model processes the request via the \"AI Agent\" node, which includes intermediate steps for complex tasks.  \n   - The \"Simple Memory\" node retains session context using the provided `sessionId`, enabling multi-turn conversations.  \n\n5. **Output**:  \n   - The final response is generated by the chosen model and returned to the user.  \n\n---\n\n### **Set Up Steps**\n1. **Configure Trigger**:  \n   - Ensure the \"When chat message received\" node is set up with the correct webhook ID to receive chat inputs.  \n\n2. **Define Classification Logic**:  \n   - Adjust the prompt in the \"Request Type\" node to refine classification accuracy.  \n   - Verify the output schema in the \"Structured Output Parser\" node matches expected categories (`general`, `reasoning`, `coding`, `search`).  \n\n3. **Connect AI Models**:  \n   - Link each model node (Opus 4, Gemini Thinking Pro, GPT 4.1 mini, Perplexity) to the \"Model Selector\" node.  \n   - Ensure credentials (API keys) for each model are correctly configured in their respective nodes.  \n\n4. **Set Up Memory**:  \n   - Configure the \"Simple Memory\" node to use the `sessionId` from the input for context retention.  \n\n5. **Test Workflow**:  \n   - Send test inputs to verify classification and model routing.  \n   - Check intermediate outputs (e.g., `request_type`) to ensure correct model selection.  \n\n6. **Activate Workflow**:  \n   - Toggle the workflow to \"Active\" in n8n after testing.  \n\n---\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/). ",
    "workflow": {
      "id": "abSdfsaYgkssXX7g",
      "meta": {
        "instanceId": "a4bfc93e975ca233ac45ed7c9227d84cf5a2329310525917adaf3312e10d5462",
        "templateCredsSetupCompleted": true
      },
      "name": "Dynamically Selects Models Based on Input Type",
      "tags": [],
      "nodes": [
        {
          "id": "daf34daa-19e5-42a8-b820-5aa3d78c29a4",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            -528,
            -112
          ],
          "webhookId": "56b65a7f-0698-4e99-81eb-fd87e0cb5bfa",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.1
        },
        {
          "id": "85be9290-50ac-457e-9fa1-0c00a88667da",
          "name": "AI Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            160,
            -112
          ],
          "parameters": {
            "text": "={{ $('When chat message received').item.json.chatInput }}",
            "options": {
              "returnIntermediateSteps": true
            },
            "promptType": "define"
          },
          "typeVersion": 2.1
        },
        {
          "id": "0721d812-2dc6-4069-87e6-844b8f94214b",
          "name": "Model Selector",
          "type": "@n8n/n8n-nodes-langchain.modelSelector",
          "position": [
            80,
            128
          ],
          "parameters": {
            "rules": {
              "rule": [
                {
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "976d83bb-7e9e-4aab-9722-25a9e238164f",
                        "operator": {
                          "name": "filter.operator.equals",
                          "type": "string",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $json.output.request_type }}",
                        "rightValue": "coding"
                      }
                    ]
                  }
                },
                {
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "1e68688d-73fe-47c1-9b35-a1e226220bcd",
                        "operator": {
                          "name": "filter.operator.equals",
                          "type": "string",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $json.output.request_type }}",
                        "rightValue": "reasoning"
                      }
                    ]
                  },
                  "modelIndex": 2
                },
                {
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "61d58197-db59-4cd7-bc41-bbeaf5e7b069",
                        "operator": {
                          "name": "filter.operator.equals",
                          "type": "string",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $json.output.request_type }}",
                        "rightValue": "general"
                      }
                    ]
                  },
                  "modelIndex": 3
                },
                {
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "fca2ec99-fd1d-458f-9919-73bfbba55c4f",
                        "operator": {
                          "name": "filter.operator.equals",
                          "type": "string",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $json.output.request_type }}",
                        "rightValue": "search"
                      }
                    ]
                  },
                  "modelIndex": 4
                }
              ]
            },
            "numberInputs": 4
          },
          "typeVersion": 1
        },
        {
          "id": "449b0bae-3749-493d-b6f6-dad155537bc9",
          "name": "Structured Output Parser",
          "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
          "position": [
            -80,
            32
          ],
          "parameters": {
            "schemaType": "manual",
            "inputSchema": "{\n\t\"type\": \"object\",\n\t\"properties\": {\n\t\t\"request_type\": {\n\t\t\t\"type\": \"string\"\n\t\t}\n\t}\n}"
          },
          "typeVersion": 1.3
        },
        {
          "id": "03339701-3ed8-43c9-a490-3ebca30d39bb",
          "name": "Simple Memory",
          "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
          "position": [
            400,
            128
          ],
          "parameters": {
            "sessionKey": "={{ $('When chat message received').item.json.sessionId }}",
            "sessionIdType": "customKey"
          },
          "typeVersion": 1.3
        },
        {
          "id": "1d86d306-bbdd-45b0-9b96-fce0cbcdc0a0",
          "name": "Request Type",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            -288,
            -112
          ],
          "parameters": {
            "batching": {},
            "messages": {
              "messageValues": [
                {
                  "message": "=Your task is to classify the type of request you receive as input.\nYou must provide the following output:\n- general: if it is a general request\n- reasoning: if it is a reasoning request\n- coding: if it is a request related to code development\n- search: if it is a request that involves the use of Google tools"
                }
              ]
            },
            "hasOutputParser": true
          },
          "typeVersion": 1.7
        },
        {
          "id": "f49883cd-fc48-4c26-8596-6267beb74c3d",
          "name": "Opus 4",
          "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
          "position": [
            -64,
            352
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "claude-sonnet-4-20250514",
              "cachedResultName": "Claude 4 Sonnet"
            },
            "options": {}
          },
          "credentials": {
            "anthropicApi": {
              "id": "credential-id",
              "name": "anthropicApi Credential"
            }
          },
          "typeVersion": 1.3
        },
        {
          "id": "0f19c20b-298b-45d8-b855-3a92c0dac675",
          "name": "Gemini Thinking Pro",
          "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
          "position": [
            80,
            352
          ],
          "parameters": {
            "options": {},
            "modelName": "models/gemini-2.0-flash-thinking-exp"
          },
          "credentials": {
            "googlePalmApi": {
              "id": "credential-id",
              "name": "googlePalmApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "d2676326-64f2-47db-84f4-17fbf194d31b",
          "name": "GPT 4.1 mini",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            224,
            352
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4.1-mini"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "1f8d38d9-0298-4588-a763-7fac0132edf5",
          "name": "Perplexity",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            352,
            352
          ],
          "parameters": {
            "model": "perplexity/sonar",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "fc7a67be-d46a-4fec-b1d2-9f8ce3b86462",
          "name": "OpenAI Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            -320,
            48
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4.1-mini"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "de2fc53a-bf97-475a-b978-0cde88483ee0",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -528,
            -416
          ],
          "parameters": {
            "width": 624,
            "height": 256,
            "content": "## AI Orchestrator: dynamically Selects Models Based on Input Type\n\nThis workflow is designed to intelligently **route user queries to the most suitable large language model (LLM)** based on the type of request received in a chat environment. It uses structured classification and model selection to optimize both performance and cost-efficiency in AI-driven conversations.\n\nIt dynamically routes requests to specialized AI models based on content type, optimizing response quality and efficiency."
          },
          "typeVersion": 1
        }
      ],
      "active": false,
      "pinData": {},
      "settings": {
        "executionOrder": "v1"
      },
      "versionId": "d852ebdf-2860-4611-a58e-e58c8cd4cc35",
      "connections": {
        "Opus 4": {
          "ai_languageModel": [
            [
              {
                "node": "Model Selector",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Perplexity": {
          "ai_languageModel": [
            [
              {
                "node": "Model Selector",
                "type": "ai_languageModel",
                "index": 3
              }
            ]
          ]
        },
        "GPT 4.1 mini": {
          "ai_languageModel": [
            [
              {
                "node": "Model Selector",
                "type": "ai_languageModel",
                "index": 2
              }
            ]
          ]
        },
        "Request Type": {
          "main": [
            [
              {
                "node": "AI Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Simple Memory": {
          "ai_memory": [
            [
              {
                "node": "AI Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "Model Selector": {
          "ai_languageModel": [
            [
              {
                "node": "AI Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "OpenAI Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "Request Type",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Gemini Thinking Pro": {
          "ai_languageModel": [
            [
              {
                "node": "Model Selector",
                "type": "ai_languageModel",
                "index": 1
              }
            ]
          ]
        },
        "Structured Output Parser": {
          "ai_outputParser": [
            [
              {
                "node": "Request Type",
                "type": "ai_outputParser",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "Request Type",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 12,
      "nodeTypes": {
        "n8n-nodes-base.stickyNote": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chainLlm": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.modelSelector": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatAnthropic": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenRouter": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatGoogleGemini": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.outputParserStructured": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Davide",
      "username": "n3witalia",
      "bio": "Full-stack Web Developer based in Italy specialising in Marketing & AI-powered automations. For business enquiries, send me an email at info@n3w.it or add me on Linkedin.com/in/davideboizza",
      "verified": true,
      "links": [
        "https://n3w.it"
      ],
      "avatar": "https://gravatar.com/avatar/d41b8a0aa81139243509c58870f5b4be292824a507ab57d10ed066d8628ed8da?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1123,
        "icon": "fa:link",
        "name": "@n8n/n8n-nodes-langchain.chainLlm",
        "codex": {
          "data": {
            "alias": [
              "LangChain"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Chains",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Basic LLM Chain",
          "color": "#909298"
        },
        "iconData": {
          "icon": "link",
          "type": "icon"
        },
        "displayName": "Basic LLM Chain",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1145,
        "icon": "file:anthropic.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
        "codex": {
          "data": {
            "alias": [
              "claude",
              "sonnet",
              "opus"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatanthropic/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Anthropic Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0NiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTMyLjczIDBoLTYuOTQ1TDM4LjQ1IDMyaDYuOTQ1ek0xMi42NjUgMCAwIDMyaDcuMDgybDIuNTktNi43MmgxMy4yNWwyLjU5IDYuNzJoNy4wODJMMTkuOTI5IDB6bS0uNzAyIDE5LjMzNyA0LjMzNC0xMS4yNDYgNC4zMzQgMTEuMjQ2eiIvPjwvc3ZnPg=="
        },
        "displayName": "Anthropic Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1163,
        "icon": "fa:database",
        "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "For beginners"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Simple Memory"
        },
        "iconData": {
          "icon": "database",
          "type": "icon"
        },
        "displayName": "Simple Memory",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1179,
        "icon": "fa:code",
        "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "codex": {
          "data": {
            "alias": [
              "json",
              "zod"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Output Parsers"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Structured Output Parser"
        },
        "iconData": {
          "icon": "code",
          "type": "icon"
        },
        "displayName": "Structured Output Parser",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1262,
        "icon": "file:google.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Google Gemini Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
        },
        "displayName": "Google Gemini Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1281,
        "icon": "file:openrouter.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenRouter Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjOTRBM0I4IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHdpZHRoPSI0MCIgaGVpZ2h0PSI0MCIgdmlld0JveD0iMCAwIDI0IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjx0aXRsZT5PcGVuUm91dGVyPC90aXRsZT48cGF0aCBkPSJNMTYuODA0IDEuOTU3bDcuMjIgNC4xMDV2LjA4N0wxNi43MyAxMC4yMWwuMDE3LTIuMTE3LS44MjEtLjAzYy0xLjA1OS0uMDI4LTEuNjExLjAwMi0yLjI2OC4xMS0xLjA2NC4xNzUtMi4wMzguNTc3LTMuMTQ3IDEuMzUyTDguMzQ1IDExLjAzYy0uMjg0LjE5NS0uNDk1LjMzNi0uNjguNDU1bC0uNTE1LjMyMi0uMzk3LjIzNC4zODUuMjMuNTMuMzM4Yy40NzYuMzE0IDEuMTcuNzk2IDIuNzAxIDEuODY2IDEuMTEuNzc1IDIuMDgzIDEuMTc3IDMuMTQ3IDEuMzUybC4zLjA0NWMuNjk0LjA5MSAxLjM3NS4wOTQgMi44MjUuMDMzbC4wMjItMi4xNTkgNy4yMiA0LjEwNXYuMDg3TDE2LjU4OSAyMmwuMDE0LTEuODYyLS42MzUuMDIyYy0xLjM4Ni4wNDItMi4xMzcuMDAyLTMuMTM4LS4xNjItMS42OTQtLjI4LTMuMjYtLjkyNi00Ljg4MS0yLjA1OWwtMi4xNTgtMS41YTIxLjk5NyAyMS45OTcgMCAwMC0uNzU1LS40OThsLS40NjctLjI4YTU1LjkyNyA1NS45MjcgMCAwMC0uNzYtLjQzQzIuOTA4IDE0LjczLjU2MyAxNC4xMTYgMCAxNC4xMTZWOS44ODhsLjE0LjAwNGMuNTY0LS4wMDcgMi45MS0uNjIyIDMuODA5LTEuMTI0bDEuMDE2LS41OC40MzgtLjI3NGMuNDI4LS4yOCAxLjA3Mi0uNzI2IDIuNjg2LTEuODUzIDEuNjIxLTEuMTMzIDMuMTg2LTEuNzggNC44ODEtMi4wNTkgMS4xNTItLjE5IDEuOTc0LS4yMTMgMy44MTQtLjEzOGwuMDItMS45MDd6Ij48L3BhdGg+PC9zdmc+Cg=="
        },
        "displayName": "OpenRouter Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1306,
        "icon": "fa:map-signs",
        "name": "@n8n/n8n-nodes-langchain.modelSelector",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.modelselector/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Model Selector"
        },
        "iconData": {
          "icon": "map-signs",
          "type": "icon"
        },
        "displayName": "Model Selector",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 5,
        "name": "Engineering"
      },
      {
        "id": 47,
        "name": "AI Chatbot"
      }
    ],
    "image": []
  }
}