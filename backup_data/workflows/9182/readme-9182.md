# Extract Zillow property data to Google Sheets with Scrape.do

> # üè† Extract Zillow Property Data to Google Sheets with Scrape.do

This template requires a self-hosted n8n instance to run.

A complete n8n automation that extracts property listing data from Zillow URLs using [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) web scraping API, parses key property information, and saves structured results into Google Sheets for real estate analysis, market research, and property tracking.

## üìã Overview

This workflow provides a lightweight real estate data extraction solution that pulls property details from Zillow listings and organizes them into a structured spreadsheet. Ideal for real estate professionals, investors, market analysts, and property managers who need automated property data collection without manual effort.

**Who is this for?**

- Real estate investors tracking properties
- Market analysts conducting property research
- Real estate agents monitoring listings
- Property managers organizing data
- Data analysts building real estate databases

**What problem does this workflow solve?**

- Eliminates manual copy-paste from Zillow
- Processes multiple property URLs in bulk
- Extracts structured data (price, address, zestimate, etc.)
- Automates saving results into Google Sheets
- Ensures repeatable & consistent data collection

## ‚öôÔ∏è What this workflow does

1. **Manual Trigger** ‚Üí Starts the workflow manually
2. **Read Zillow URLs from Google Sheets** ‚Üí Reads property URLs from a Google Sheet
3. **Scrape Zillow URL via [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow)** ‚Üí Fetches full HTML from Zillow (bypasses PerimeterX protection)
4. **Parse Zillow Data** ‚Üí Extracts structured property information from HTML
5. **Write Results to Google Sheets** ‚Üí Saves parsed data into a results sheet

## üìä Output Data Points

| Field | Description | Example |
|-------|-------------|---------|
| URL | Original Zillow listing URL | https://www.zillow.com/homedetails/... |
| Price | Property listing price | $300,000 |
| Address | Street address | 8926 Silver City |
| City | City name | San Antonio |
| State | State abbreviation | TX |
| Days on Zillow | How long listed | 5 |
| Zestimate | Zillow's estimated value | $297,800 |
| Scraped At | Timestamp of extraction | 2025-01-29T12:00:00.000Z |

## ‚öôÔ∏è Setup

### Prerequisites

- n8n instance (self-hosted)
- Google account with Sheets access
- [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) account with API token ([Get 1000 free credits/month](https://dashboard.scrape.do/sign-up))

### Google Sheet Structure

This workflow uses one Google Sheet with two tabs:

**Input Tab: "Sheet1"**

| Column | Type | Description | Example |
|--------|------|-------------|---------|
| URLs | URL | Zillow listing URL | https://www.zillow.com/homedetails/123... |

**Output Tab: "Results"**

| Column | Type | Description | Example |
|--------|------|-------------|---------|
| URL | URL | Original listing URL | https://www.zillow.com/homedetails/... |
| Price | Text | Property price | $300,000 |
| Address | Text | Street address | 8926 Silver City |
| City | Text | City name | San Antonio |
| State | Text | State code | TX |
| Days on Zillow | Number | Days listed | 5 |
| Zestimate | Text | Estimated value | $297,800 |
| Scraped At | Timestamp | When scraped | 2025-01-29T12:00:00.000Z |

## üõ† Step-by-Step Setup

1. **Import Workflow**: Copy the JSON ‚Üí n8n ‚Üí Workflows ‚Üí + Add ‚Üí Import from JSON

2. **Configure [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) API**:
   - Sign up at [Scrape.do Dashboard](https://dashboard.scrape.do/sign-up)
   - Get your API token
   - In HTTP Request node, replace `YOUR_SCRAPE_DO_TOKEN` with your actual token
   - The workflow uses `super=true` for premium residential proxies (10 credits per request)

3. **Configure Google Sheets**:
   - Create a new Google Sheet
   - Add two tabs: "Sheet1" (input) and "Results" (output)
   - In Sheet1, add header "URLs" in cell A1
   - Add Zillow URLs starting from A2
   - Set up Google Sheets OAuth2 credentials in n8n
   - Replace `YOUR_SPREADSHEET_ID` with your actual Google Sheet ID
   - Replace `YOUR_GOOGLE_SHEETS_CREDENTIAL_ID` with your credential ID

4. **Run & Test**:
   - Add 1-2 test Zillow URLs in Sheet1
   - Click "Execute workflow"
   - Check results in Results tab

## üß∞ How to Customize

- **Add more fields**: Extend parsing logic in "Parse Zillow Data" node to capture additional data (bedrooms, bathrooms, square footage)
- **Filtering**: Add conditions to skip certain properties or price ranges
- **Rate Limiting**: Insert a Wait node between requests if processing many URLs
- **Error Handling**: Add error branches to handle failed scrapes gracefully
- **Scheduling**: Replace Manual Trigger with Schedule Trigger for automated daily/weekly runs

## üìä Use Cases

- **Investment Analysis**: Track property prices and zestimates over time
- **Market Research**: Analyze listing trends in specific neighborhoods
- **Portfolio Management**: Monitor properties for sale in target areas
- **Competitive Analysis**: Compare similar properties across locations
- **Lead Generation**: Build databases of properties matching specific criteria

## üìà Performance & Limits

- **Single Property**: ~5-10 seconds per URL
- **Batch of 10**: 1-2 minutes typical
- **Large Sets (50+)**: 5-10 minutes depending on [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) credits
- **API Calls**: 1 [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) request per URL (10 credits with `super=true`)
- **Reliability**: 95%+ success rate with premium proxies

## üß© Troubleshooting

| Problem | Solution |
|---------|----------|
| API error 400 | Check your [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) token and credits |
| URL showing "undefined" | Verify Google Sheet column name is "URLs" (capital U) |
| No data parsed | Check if Zillow changed their HTML structure |
| Permission denied | Re-authenticate Google Sheets OAuth2 in n8n |
| 50000 character error | Verify Parse Zillow Data code is extracting fields, not returning raw HTML |
| Price shows HTML/CSS | Update price extraction regex in Parse Zillow Data node |

## ü§ù Support & Community

- [Scrape.do Documentation](https://scrape.do/documentation/?utm_source=n8n&utm_medium=zillow_workflow)
- [Scrape.do Dashboard](https://dashboard.scrape.do/?utm_source=n8n&utm_medium=zillow_workflow)
- [Scrape.do Zillow Scraping Guide](https://scrape.do/blog/zillow-scraping/?utm_source=n8n&utm_medium=zillow_workflow)
- [n8n Forum](https://community.n8n.io)
- [n8n Docs](https://docs.n8n.io)

## üéØ Final Notes

This workflow provides a repeatable foundation for extracting Zillow property data with [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) and saving to Google Sheets. You can extend it with:

- Historical tracking (append timestamps)
- Price change alerts (compare with previous scrapes)
- Multi-platform scraping (Redfin, Realtor.com)
- Integration with CRM or reporting dashboards

**Important**: [Scrape.do](https://scrape.do/?utm_source=n8n&utm_medium=zillow_workflow) handles all anti-bot bypassing (PerimeterX, CAPTCHAs) automatically with rotating residential proxies, so you only pay for successful requests. Always use `super=true` parameter for Zillow to ensure high success rates.

## üìä Basic Information

- **Workflow ID:** 9182
- **Complexity:** intermediate
- **Node Count:** 6
- **Views:** 217
- **Downloads:** 21
- **Created:** 2025/10/2
- **Last Updated:** 2026/1/16
- **Source:** [View on n8n.io](https://n8n.io/workflows/9182)

## üë§ Author

- **Name:** Onur
- **Username:** @onurpolat05

## üè∑Ô∏è Categories

- Market Research

## üîó Nodes Used

- **manualTrigger** 
- **googleSheets** (√ó2)
- **httpRequest** 
- **code** 
- **if** 

## üöÄ How to Use

1. Download the workflow JSON file
2. Import it into your n8n instance
3. Configure the credentials for the nodes
4. Activate and test the workflow

## üîÄ Workflow Structure

This workflow contains 6 nodes with 5 node connections.

---

*This workflow was sourced from [n8n.io](https://n8n.io) community templates.*
