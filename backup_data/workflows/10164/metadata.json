{
  "id": 10164,
  "slug": "10164",
  "title": "Customer pain analysis & AI briefing with Anthropic, Reddit, X, and SerpAPI",
  "description": "**The competitive edge, delivered.** This Customer Intelligence Engine simultaneously analyzes the web, Reddit, and X/Twitter to generate a professional, actionable executive briefing.\n\n---\n\n### üéØ Problem Statement\n\nTraditional market research for **Customer Intelligence (CI)** is manual, slow, and often relies on surface-level social media scraping or expensive external reports. Service companies, like HVAC providers, struggle to efficiently synthesize vast volumes of online feedback (Reddit discussions, real-time tweets, web articles) to accurately diagnose systemic service gaps (e.g., scheduling friction, poor automated systems). This inefficiency leads to delayed strategic responses and missed opportunities to invest in high-impact solutions like **AI voice agents**.\n\n---\n\n### ‚ú® Solution\n\nThis workflow deploys a sophisticated **Multisource Intelligence Pipeline** that runs on a scheduled or ad-hoc basis. It uses parallel processing to ingest data from three distinct source types (**SERP API, Reddit, and X/Twitter**), employs a zero-cost **Hybrid Categorization** method to semantically identify operational bottlenecks, and uses the **Anthropic LLM** to synthesize the findings into a clear, executive-ready strategic brief. The data is logged for historical analysis while the brief is dispatched for immediate action.\n\n---\n\n### ‚öôÔ∏è How It Works (Multi-Step Execution)\n#### 1.  Ingestion and Parallel Processing (**The Data Fabric**)\n\n* **Trigger:** The workflow is initiated either on an ad-hoc basis via an n8n Form Trigger or on a schedule (Time Trigger).\n* **Parallel Ingestion:** The workflow immediately splits into three parallel branches to fetch data simultaneously:\n\n  * **SERP API:** Captures authoritative content and industry commentary (*Strategic Context*).\n  * **Reddit (Looping Structure):** Fetches posts from multiple subreddits via an Aggregate Node workaround to get authentic user experiences (*Qualitative Signal*).\n  * **X/Twitter (HTTP Request):** Bypasses standard rate limits to capture real-time social complaints (*Sentiment Signal*).\n\n#### 2. Analysis and Fusion (**The Intelligence Layer**)\n\n* **Cleanup and Labeling (Function Nodes):** Each branch uses dedicated Function Nodes to filter noise (e.g., low-score posts) and normalize the data by adding a source tag (e.g., 'Reddit').\n* **Merge:** A Merge Node (Append Mode) fuses all three parallel streams into a single, unified dataset.\n* **Hybrid Categorization (Function Node):** A single Function Node applies the Hybrid Categorization Logic. This cost-free step semantically assigns a `pain_point` category (e.g., 'Call Hold/Availability') and a `sentiment_score` to every item, transforming raw text into labeled metrics.\n\n#### 3. Dispatch and Reporting (**The Executive Output**)\n\n* **Aggregation and Split (Function Node):** The final Function Node calculates the total counts, deduplicates the final results, and generates the comprehensive `summaryString`.\n* **Data Logging:** The aggregated counts and metrics are appended to **Google Sheets** for historical logging.\n* **LLM Input Retrieval (Function Node):** A final Function Node retrieves the summary data using the `$items()` helper (the serial route workaround).\n* **AI Briefing:** The *Message a model (Anthropic)* Node receives the `summaryString` and uses a strict HTML System Prompt to synthesize the strategic brief, identifying the top pain points and suggesting AI features.\n* **Delivery:** The **Gmail Node** sends the final, professional HTML brief to the executive team.\n\n---\n\n### üõ†Ô∏è Setup Steps\n\n#### Credentials\n\n* **Anthropic:** Configure credentials for the Language Model (Claude) used in the Message a model node.\n* **SERP API, Reddit, and X/Twitter:** Configure API keys/credentials for the data ingestion nodes.\n* **Google Services:** Set up OAuth2 credentials for Google Sheets (for logging data) and Gmail (for email dispatch).\n\n#### Configuration\n\n* **Form Configuration:** If using the Form Trigger, ensure the Target Keywords and Target Subreddits are mapped correctly to the ingestion nodes.\n* **Data Integrity:** Due to the serial route, ensure the Function (Get LLM Summary) node is correctly retrieving the `LLM_SUMMARY_HOLDER` field from the preceding node's output memory.\n\n---\n\n### ‚úÖ Benefits\n\n* **Proactive CI & Strategy:** Shifts market research from manual, reactive browsing to proactive, scheduled data diagnostic.\n* **Cost Efficiency:** Utilizes a zero-cost Hybrid Categorization method (Function Node) for intent analysis, avoiding expensive per-item LLM token costs.\n* **Actionable Output:** Delivers a fully synthesized, HTML-formatted executive brief, ready for immediate presentation and strategic sales positioning.\n* **High Reliability:** Employs parallel ingestion, API workarounds, and serial routing to ensure the complex workflow runs consistently and without failure.\n",
  "featuredImage": "/data/workflows/10164/10164.webp",
  "author": {
    "id": 101,
    "slug": "bhuvanesh",
    "name": "Bhuvanesh R",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 277,
  "downloads": 27,
  "createdAt": "2025-10-25T12:35:31.611Z",
  "updatedAt": "2026-01-16T09:03:48.008Z",
  "publishedAt": "2025-10-25T12:35:31.611Z",
  "nodes": 25,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10164"
}