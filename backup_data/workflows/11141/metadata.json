{
  "id": 11141,
  "slug": "11141",
  "title": "Complete AI safety suite: test 9 guardrail layers with Groq LLM",
  "description": "# Who's It For\nAI developers, automation engineers, and teams building chatbots, AI agents, or workflows that process user input. Perfect for those concerned about security, compliance, and content safety.\n\n# What It Does\nThis workflow demonstrates all 9 guardrail types available in n8n's Guardrails node through real-world test cases. It provides a comprehensive safety testing suite that validates:\n\n- Keyword blocking for profanity and banned terms\n- Jailbreak detection to prevent prompt injection attacks\n- NSFW content filtering for inappropriate material\n- PII detection and sanitization for emails, phone numbers, and credit cards\n- Secret key detection to catch leaked API keys and tokens\n- Topical alignment to keep conversations on-topic\n- URL whitelisting to block malicious domains\n- Credential URL blocking to prevent URLs with embedded passwords\n- Custom regex patterns for organization-specific rules (employee IDs, order numbers)\n- Each test case flows through its corresponding guardrail node, with results formatted into clear pass/fail reports showing violations and sanitized text.\n# How to Set Up\n\n- Add your Groq API credentials (free tier works fine)\n- Import the workflow\n- Click \"Test workflow\" to run all 9 cases\n- Review the formatted results to understand each guardrail's behavior\n\n# Requirements\n\n- n8n version 1.119.1 or later (for Guardrails node)\n- Groq API account (free tier sufficient)\n- Self-hosted instance (some guardrails use LLM-based detection)\n\n# How to Customize\n\n- Modify test cases in the \"Test Cases Data\" node to match your specific scenarios\n- Adjust threshold values (0.0-1.0) for AI-based guardrails to fine-tune sensitivity\n- Add or remove guardrails based on your security requirements\n- Integrate individual guardrail nodes into your production workflows\n- Use the sticky notes as reference documentation for implementation\n\nThis is a plug-and-play educational template that serves as both a testing suite and implementation reference for building production-ready AI safety layers.",
  "featuredImage": "/data/workflows/11141/11141.webp",
  "author": {
    "id": 101,
    "slug": "shaheer03",
    "name": "Muhammad Shaheer Awan",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 241,
  "downloads": 24,
  "createdAt": "2025-11-22T20:33:07.889Z",
  "updatedAt": "2026-01-16T09:07:41.068Z",
  "publishedAt": "2025-11-22T20:33:07.889Z",
  "nodes": 19,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11141"
}