
# ğŸ” AI-Powered Website Prompt Executor (Apify + OpenRouter)

This workflow combines the power of [Apify](https://apify.com) and [OpenRouter](https://openrouter.ai) to **scrape website content** and **execute any custom prompt** using AI. You define what you want â€” whether itâ€™s extracting contact details, summarizing content, collecting job offers, or anything else â€” and the system intelligently processes the site to give you results.

## ğŸš€ Overview

This workflow allows you to:
1. Input a URL and define a prompt.
2. Scrape the specified number of pages from the website.
3. Process each pageâ€™s metadata and Markdown content.
4. Use AI to interpret and respond to the prompt on each page.
5. Aggregate and return structured output.

## ğŸ§  How It Works

### Input Example

```json
{
  "enqueue": true,
  "maxPages": 5,
  "url": "https://apify.com",
  "method": "GET",
  "prompt": "collect all contact informations available on this website"
}
````

### Workflow Steps

| Step | Action                                                                                                                                                                         |
| ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 1    | Triggered by another workflow with JSON input.                                                                                                                                 |
| 2    | Calls the Apify actor [`firescraper-ai-website-content-markdown-scraper`](https://apify.com/mohamedgb00714/firescraper-ai-website-content-markdown-scraper) to scrape content. |
| 3    | Loops through the scraped pages.                                                                                                                                               |
| 4    | AI analyzes each page based on the input prompt.                                                                                                                               |
| 5    | Aggregates AI outputs across all pages.                                                                                                                                        |
| 6    | Final AI processing step to return a clean structured result.                                                                                                                  |

---

## ğŸ›  Technologies Used

* **Apify** â€“ Scrapes structured content and Markdown from websites.
* **OpenRouter** â€“ Provides access to advanced AI models like Gemini.
* **LangChain** â€“ Handles AI agent orchestration and prompt interpretation.

---

## ğŸ”§ Customization

Customize the workflow via the following input fields:

* `url`: Starting point for scraping
* `maxPages`: Limit the number of pages to crawl
* `prompt`: Define any instruction (e.g., â€œsummarize this website,â€ â€œextract product data,â€ â€œlist all emails,â€ etc.)

This allows dynamic, flexible use across various use cases.

---

## ğŸ“¦ Output

The workflow returns a JSON result that includes:

* Processed prompt responses from each page
* Aggregated AI insights
* Structured and machine-readable format

---

## ğŸ§ª Example Use Cases

* ğŸ” Extracting contact information from websites
* ğŸ“„ Summarizing articles or company profiles
* ğŸ›ï¸ Collecting product information
* ğŸ“‹ Extracting job listings or news
* ğŸ“¬ Generating outreach lists from public data
* ğŸ¤– **Used as a tool within other AI agents for real-time web analysis**
* ğŸ§© **Integrated as an external tool in MCP (Multi-Component Prompt) servers to enhance AI capabilities**

---

## ğŸ” API Credentials Required

You will need:

* **Apify API token** â€“ For running the scraper actor
* **OpenRouter API key** â€“ For AI-powered prompt processing

Set these credentials in your environment or n8n credential manager before running.




