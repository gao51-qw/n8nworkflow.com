Transform your local N8N instance into a powerful chat interface using any local & private Ollama model, with zero cloud dependencies â˜ï¸. This workflow creates a structured chat experience that processes messages locally through a language model chain and returns formatted responses ğŸ’¬.

## How it works ğŸ”„
- ğŸ’­ Chat messages trigger the workflow
- ğŸ§  Messages are processed through Llama 3.2 via Ollama (or any other Ollama compatible model)
- ğŸ“Š Responses are formatted as structured JSON
- âš¡ Error handling ensures robust operation

## Set up steps ğŸ› ï¸
- ğŸ“¥ Install N8N and Ollama
- âš™ï¸ Download Ollama 3.2 model (or other model)
- ğŸ”‘ Configure Ollama API credentials
- âœ¨ Import and activate workflow

This template provides a foundation for building AI-powered chat applications while maintaining full control over your data and infrastructure ğŸš€.
