{
  "id": 2729,
  "slug": "2729",
  "title": "ğŸ”ğŸ¦™ğŸ¤– Private & local Ollama self-hosted AI assistant",
  "description": "Transform your local N8N instance into a powerful chat interface using any local & private Ollama model, with zero cloud dependencies â˜ï¸. This workflow creates a structured chat experience that processes messages locally through a language model chain and returns formatted responses ğŸ’¬.\n\n## How it works ğŸ”„\n- ğŸ’­ Chat messages trigger the workflow\n- ğŸ§  Messages are processed through Llama 3.2 via Ollama (or any other Ollama compatible model)\n- ğŸ“Š Responses are formatted as structured JSON\n- âš¡ Error handling ensures robust operation\n\n## Set up steps ğŸ› ï¸\n- ğŸ“¥ Install N8N and Ollama\n- âš™ï¸ Download Ollama 3.2 model (or other model)\n- ğŸ”‘ Configure Ollama API credentials\n- âœ¨ Import and activate workflow\n\nThis template provides a foundation for building AI-powered chat applications while maintaining full control over your data and infrastructure ğŸš€.\n",
  "featuredImage": "/data/workflows/2729/2729.webp",
  "author": {
    "id": 101,
    "slug": "joe",
    "name": "Joseph LePage",
    "avatar": ""
  },
  "categories": [
    "Personal Productivity",
    "AI Chatbot"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 60225,
  "downloads": 6022,
  "createdAt": "2025-01-15T05:39:06.856Z",
  "updatedAt": "2026-01-16T08:26:10.503Z",
  "publishedAt": "2025-01-15T05:39:06.856Z",
  "nodes": 14,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2729"
}