# Salesforce to S3 file migration & cleanup

> # Salesforce to S3 File Migration & Cleanup

Automate archiving old Salesforce files to Amazon S3, log them back in Salesforce, and free up org storage â€” all from a scheduled n8n workflow.

---

## ğŸ”§ How It Works (High-Level)

1. **Schedule Trigger** kicks off (e.g., daily).  
2. **Query Salesforce** for `ContentDocument` records older than 365 days.  
3. **Loop Each File** â†’ download binary via REST.  
4. **Upload to S3** with the original filename.  
5. **Lookup Links** (`ContentDocumentLink`) to keep the parent record reference.  
6. **Filter Out Users** (ignore `LinkedEntityId` starting with `005`).  
7. **Create `S3_File__c`** record in Salesforce for traceability.  
8. **Delete Original File** from Salesforce to reclaim storage.  
9. **Notify via Slack** when the batch is done.

![Screenshot 20250723 135316.png](fileId:1840)
---

## ğŸš€ Set Up Steps (Time: ~45â€“90 mins)

1. **Import n8n Workflow JSON** and wire up credentials (Salesforce OAuth2, AWS S3, Slack).  
2. **Install Salesforce Unmanaged Package** (Custom Object `S3_File__c`, Apex controller, LWC, settings).  
3. **Fill `S3Settings__c`** (bucket, region, keys, expiry) or swap to Named Credentials.  
4. **Test with a Sandbox Batch** (e.g., small date range) and verify upload/delete.  
5. **Schedule & Monitor** (tweak interval, Slack channel).


---

## ğŸ’– Why youâ€™ll love it
- ğŸ’¸ **Slash storage costs** â€” offload gigabytes to S3  
- ğŸ” **Full traceability** â€” every file still tracked in Salesforce  
- ğŸ§° **Plug & play** â€” import JSON, install package, plug in creds  
- ğŸ§± **Modular & extensible** â€” swap S3, add approvals, build an uploader UI  
- â± **Set it & forget it** â€” scheduled automation + Slack alerts

## ğŸ“¦ Whatâ€™s Included

- **n8n JSON Flow** â€“ ready to import.  
- **Salesforce Unmanaged Package** â€“ Apex (`S3FilesController.cls`), LWC (`s3FilesViewer`), `S3_File__c`, `S3Settings__c`.  
- **S3 + Salesforce Setup Guide** â€“ quick reference for configuring keys, permissions, and the LWC.

All components are editable â€” extend, replace, or integrate with your own processes.

---

## ğŸ§± Requirements

- n8n instance (self-hosted or Cloud) with HTTP Request, AWS S3, Slack, and Salesforce nodes.  
- Salesforce org with API access & permission to install unmanaged packages.  
- You have to have **Query All Files** permission. Setup-&gt; Permission Sets / Profile -&gt; App Permission -&gt; Content -&gt; Query All Files. Allows View All Data users to SOQL query all files in the org.
- AWS S3 bucket + IAM user/role with `GetObject`/`PutObject` (and optional `ListBucket`).  



## ğŸ“Š Basic Information

- **Workflow ID:** 6305
- **Complexity:** advanced
- **Node Count:** 23
- **Views:** 113
- **Downloads:** 11
- **Created:** 2025/7/23
- **Last Updated:** 2026/1/16
- **Source:** [View on n8n.io](https://n8n.io/workflows/6305)

## ğŸ‘¤ Author

- **Name:** Le Nguyen
- **Username:** @leeseifer

## ğŸ·ï¸ Categories

- File Management

## ğŸ”— Nodes Used

- **scheduleTrigger** 
- **stickyNote** (Ã—12)
- **splitInBatches** 
- **httpRequest** (Ã—2)
- **awsS3** 
- **salesforce** (Ã—3)
- **code** (Ã—2)
- **slack** 

## ğŸš€ How to Use

1. Download the workflow JSON file
2. Import it into your n8n instance
3. Configure the credentials for the nodes
4. Activate and test the workflow

## ğŸ”€ Workflow Structure

This workflow contains 23 nodes with 10 node connections.

---

*This workflow was sourced from [n8n.io](https://n8n.io) community templates.*
