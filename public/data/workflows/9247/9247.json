{
  "workflow": {
    "id": 9247,
    "name": "Smart chat routing between Gemini and GPT models based on query complexity",
    "views": 302,
    "recentViews": 0,
    "totalViews": 302,
    "createdAt": "2025-10-03T15:47:59.069Z",
    "description": "# Adaptive LLM Router for Optimized AI Chat Responses\n\nElevate your AI chatbots with intelligent model selection: automatically route simple queries to cost-effective LLMs and complex ones to powerful ones, balancing performance and expenses seamlessly.\n\n## What It Does\n\nThis workflow listens for chat messages, uses a lightweight Gemini model to classify query complexity, then selects and routes to the optimal LLM (Gemini 2.5 Pro for complex, OpenAI GPT-4.1 Nano for simple) to generate responses‚Äîensuring efficient resource use.\n\n## Key Features\n\n- **Complexity Classifier** - Quick assessment using Gemini 2.0 Flash\n- **Dynamic Model Switching** - Routes to premium or budget models based on needs\n- **Chat Trigger** - Webhook-based for real-time conversations\n- **Current Date Awareness** - Injects $now into system prompt\n- **Modular Design** - Easy to add more models or adjust rules\n- **Cost Optimization** - Reserves heavy models for demanding tasks only\n\n## Perfect For\n\n- **Chatbot Developers**: Build responsive, cost-aware AI assistants\n- **Customer Support**: Handle routine vs. technical queries efficiently\n- **Educational Tools**: Simple facts vs. in-depth explanations\n- **Content Creators**: Quick ideas vs. detailed writing assistance\n- **Researchers**: Basic lookups vs. complex analysis\n- **Business Apps**: Optimize API costs in production environments\n\n## Technical Highlights\n\nHarnessing n8n's LangChain nodes, this workflow demonstrates:\n- Webhook triggers for instant chat handling\n- Agent-based classification with strict output rules\n- Conditional model selection for AI chains\n- Integration of multiple LLM providers (Google Gemini, OpenAI)\n- Scalable architecture for expanding model options\n\nIdeal for minimizing AI costs while maximizing response quality. No coding required‚Äîimport, configure credentials, and deploy!",
    "workflow": {
      "meta": {
        "instanceId": "3d7eb9567ae690bf8c9bba1cb43396e6e40c18e15eb5889cf9673ed1713da6db",
        "templateCredsSetupCompleted": true
      },
      "nodes": [
        {
          "id": "77530f0b-8f16-4427-a45c-54c82c66588a",
          "name": "Model Selector",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            1184,
            1904
          ],
          "parameters": {
            "text": "={{ $json.chatInput }}",
            "options": {
              "systemMessage": "=# Overview\nYou are an AI agent responsible for selecting the most suitable large language model to handle a given user request. Determine whether the question is simple or complex.\n\n## Instructions\nAnalyze the user's request and return only a single number based on the complexity of the task.\n\n## Classification Rules\n- **Output 1**: Complex questions requiring deep reasoning, professional writing, research, coding, or multi-step problem solving\n- **Output 2**: Simple questions that are straightforward, conversational, or can be answered quickly\n\n## Output Format\nReturn only one of the following:\n- 1\n- 2\n\nNo explanations, no newline or spaces, no formatting, no extra text. Only the number."
            },
            "promptType": "define"
          },
          "typeVersion": 1.9
        },
        {
          "id": "9fe14e1d-1f15-4095-b338-c96ef00a9b47",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            976,
            1904
          ],
          "webhookId": "2c54aa53-9406-4d0c-9217-d78b8f9cb137",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.3
        },
        {
          "id": "530ca74e-ff27-4400-8527-57e9d62e3a61",
          "name": "Model selector",
          "type": "@n8n/n8n-nodes-langchain.modelSelector",
          "position": [
            1440,
            2096
          ],
          "parameters": {
            "rules": {
              "rule": [
                {
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "f7148b18-d2be-4618-a12c-6f144f1eab14",
                        "operator": {
                          "type": "number",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $('Model Selector').item.json.output.toNumber() }}",
                        "rightValue": 1
                      }
                    ]
                  }
                },
                {
                  "conditions": {
                    "options": {
                      "version": 2,
                      "leftValue": "",
                      "caseSensitive": true,
                      "typeValidation": "strict"
                    },
                    "combinator": "and",
                    "conditions": [
                      {
                        "id": "c30c1080-35d3-4cf0-a871-8034049d9d10",
                        "operator": {
                          "type": "number",
                          "operation": "equals"
                        },
                        "leftValue": "={{ $('Model Selector').item.json.output.toNumber() }}",
                        "rightValue": 2
                      }
                    ]
                  }
                }
              ]
            }
          },
          "typeVersion": 1
        },
        {
          "id": "ba211db9-bf65-4f71-9755-a47ebfea1b86",
          "name": "Main Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            1520,
            1904
          ],
          "parameters": {
            "text": "={{ $('When chat message received').item.json.chatInput }}",
            "options": {
              "systemMessage": "=Here is the current date/time: {{ $now }}"
            },
            "promptType": "define"
          },
          "typeVersion": 2.2
        },
        {
          "id": "6afd02b9-9a79-40fc-a26c-e73b837d3eda",
          "name": "4.1 nano",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            1488,
            2352
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "id",
              "value": "=gpt-4.1-nano"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "83ca2ffd-aff1-482b-b87b-052e9f9cc193",
          "name": "2.5 pro",
          "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
          "position": [
            1440,
            2240
          ],
          "parameters": {
            "options": {},
            "modelName": "=models/gemini-2.5-pro"
          },
          "credentials": {
            "googlePalmApi": {
              "id": "credential-id",
              "name": "googlePalmApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "9f603eb2-6ef2-43ef-8519-759eca7e91df",
          "name": "2.0 flash",
          "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
          "position": [
            1184,
            2112
          ],
          "parameters": {
            "options": {},
            "modelName": "models/gemini-2.0-flash"
          },
          "credentials": {
            "googlePalmApi": {
              "id": "credential-id",
              "name": "googlePalmApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "c60c1f49-3732-4307-9538-86fd8b93a58c",
          "name": "Overview Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            304,
            1776
          ],
          "parameters": {
            "color": 4,
            "width": 600,
            "height": 1000,
            "content": "# Adaptive LLM Router for Optimized AI Chat Responses\n\n## üìã What This Template Does\nThis workflow creates an intelligent chat agent that classifies incoming queries by complexity and routes them to the appropriate LLM: Gemini 2.5 Pro for complex tasks, OpenAI GPT-4.1 Nano for simple ones‚Äîoptimizing for cost and performance.\n\n## üîß Prerequisites\n- n8n instance with LangChain nodes enabled\n- Access to Google Gemini and OpenAI APIs\n\n## üîë Required Credentials\n\n### OpenAI API Setup\n1. Go to platform.openai.com/api-keys\n2. Create new secret key\n3. Add to n8n as OpenAI API credential\n\n### Google Gemini API Setup\n1. Visit makersuite.google.com/app/apikey\n2. Generate API key\n3. Add to n8n as Google PaLM API credential\n\n## ‚öôÔ∏è Configuration Steps\n1. Import workflow JSON into n8n\n2. Assign credentials to LLM nodes\n3. Activate the workflow\n4. Test via chat input (use n8n's chat interface or integrate with external tools)\n\n## üéØ Use Cases\n- Cost-effective AI assistants for customer support\n- Dynamic query handling in educational bots\n- Optimized response generation for content tools\n- Efficient processing in research assistants\n\n## ‚ö†Ô∏è Troubleshooting\n- Classification errors: Refine prompt in Model Selector\n- API issues: Check credentials and quotas\n- No response: Ensure webhook is active; test nodes individually\n- Output parsing: Verify selector outputs only 1 or 2"
          },
          "typeVersion": 1
        },
        {
          "id": "00acaca1-2394-4609-bfc0-409c1f281194",
          "name": "Note: Trigger",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            928,
            2096
          ],
          "parameters": {
            "width": 252,
            "height": 192,
            "content": "## üì• When chat message received\n\n**Purpose:** For real-time chat."
          },
          "typeVersion": 1
        },
        {
          "id": "fb5bad8f-6436-4a67-b0d5-fe7c2a3a58df",
          "name": "Note: Classifier",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1152,
            1712
          ],
          "parameters": {
            "color": 2,
            "width": 332,
            "content": "## ü§ñModel Selector\n\n**Purpose:** Classifies query complexity.\n\n**Note:** Outputs 1 (complex) or 2 (simple)."
          },
          "typeVersion": 1
        },
        {
          "id": "f91cfe72-69c0-4627-b508-0159497317ca",
          "name": "Note: Main Agent",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1744,
            2048
          ],
          "parameters": {
            "color": 5,
            "width": 284,
            "height": 192,
            "content": "## üí¨ Node: Main Agent\n\n**Purpose:** Generates response with selected model.\n\n**Note:** Includes current date in prompt."
          },
          "typeVersion": 1
        }
      ],
      "pinData": {},
      "connections": {
        "2.5 pro": {
          "ai_languageModel": [
            [
              {
                "node": "Model selector",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "4.1 nano": {
          "ai_languageModel": [
            [
              {
                "node": "Model selector",
                "type": "ai_languageModel",
                "index": 1
              }
            ]
          ]
        },
        "2.0 flash": {
          "ai_languageModel": [
            [
              {
                "node": "Model Selector",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Model Selector": {
          "main": [
            [
              {
                "node": "Main Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Model selector": {
          "ai_languageModel": [
            [
              {
                "node": "Main Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "Model Selector",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 1,
    "workflowInfo": {
      "nodeCount": 11,
      "nodeTypes": {
        "n8n-nodes-base.stickyNote": {
          "count": 4
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.modelSelector": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatGoogleGemini": {
          "count": 2
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Daniel Nkencho",
      "username": "daniel-automates",
      "bio": "AI Automation Consultant | Helping Business Implement AI systems | Book a call here ‚áæ http://cal.com/corefluxai",
      "verified": true,
      "links": [
        "https://linktr.ee/danielnkencho"
      ],
      "avatar": "https://gravatar.com/avatar/ff95e5857b31cd008b89e265e92fbda8839af4cd85eb8eb98fbe2ba00859dba1?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1262,
        "icon": "file:google.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Google Gemini Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
        },
        "displayName": "Google Gemini Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1306,
        "icon": "fa:map-signs",
        "name": "@n8n/n8n-nodes-langchain.modelSelector",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.modelselector/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Model Selector"
        },
        "iconData": {
          "icon": "map-signs",
          "type": "icon"
        },
        "displayName": "Model Selector",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 5,
        "name": "Engineering"
      },
      {
        "id": 47,
        "name": "AI Chatbot"
      }
    ],
    "image": []
  }
}