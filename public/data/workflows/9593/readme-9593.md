# Optimize technical manuals for RAG & agents with Blockify IdeaBlocks

> # BlockifyÂ® Technical Manual Data Optimization Workflow

## Blockify Optimizes Data for Technical Manual RAG and Agents - Giving Structure to Unstructured Data for ~78X Accuracy, when pairing Blockify Ingest and Blockify Distill

## Learn more at [https://iternal.ai/blockify](https://iternal.ai/blockify)

### Get Free Demo API Access here: [https://console.blockify.ai/signup](https://console.blockify.ai/signup)

### Read the Technical Whitepaper here: [https://iternal.ai/blockify-results](https://iternal.ai/blockify-results)

### See example Accuracy Comparison here: [https://iternal.ai/case-studies/medical-accuracy/](https://iternal.ai/case-studies/medical-accuracy/)

Blockify is a data optimization tool that takes messy, unstructured text, like hundreds of salesâ€‘meeting transcripts or long proposals, and intelligently optimizes the data into small, easyâ€‘toâ€‘understand "IdeaBlocks." Each IdeaBlock is just a couple of sentences in length that capture one clear idea, plus a builtâ€‘in contextualized question and answer.

With this approach, Blockify improves accuracy of LLMs (Large Language Models) by an average aggregate 78X, while shrinking the original mountain of text to about 2.5% of its size while keeping (and even improving) the important information.

When Blockify's IdeaBlocks are compared with the usual method of breaking text into equalâ€‘sized chunks, the results are dramatic. Answers pulled from the distilled IdeaBlocks are roughly 40X more accurate, and user searches return the right information about 52% more accurate. In short, Blockify lets you store less data, spend less on computing, and still get better answers- turning huge documents into a concise, highâ€‘quality knowledge base that anyone can search quickly.

Blockify works by processing chunks of text to create structured data from an unstructured data source.

BlockifyÂ® replaces the traditional "dumpâ€‘andâ€‘chunk" approach with an endâ€‘toâ€‘end pipeline that cleans and organizes content before it ever hits a vector store.

Admins first define who should see what, then the system ingests any file typeâ€”Word, PDF, slides, imagesâ€”inside public cloud, private cloud, or onâ€‘prem. A â€‹contextâ€‘aware splitter finds natural breaks, and a series of specially developed Blockify LLM model turns each segment into a draft IdeaBlock.

GenAI systems fed with this curated data return sharper answers, hallucinate far less, and comply with security policies out of the box.

The result: higher trust, lower operating cost, and a clear path to enterpriseâ€‘scale RAG without the cleanup headaches that stall most AI rollouts.

## ğŸ“Š Basic Information

- **Workflow ID:** 9593
- **Complexity:** advanced
- **Node Count:** 29
- **Views:** 51
- **Downloads:** 5
- **Created:** 2025/10/14
- **Last Updated:** 2026/1/16
- **Source:** [View on n8n.io](https://n8n.io/workflows/9593)

## ğŸ‘¤ Author

- **Name:** Iternal Technologies
- **Username:** @iternal

## ğŸ·ï¸ Categories

- Document Extraction
- AI RAG

## ğŸ”— Nodes Used

- **scheduleTrigger** 
- **httpRequest** (Ã—4)
- **wait** 
- **set** (Ã—3)
- **convertToFile** 
- **code** (Ã—3)
- **googleDrive** (Ã—3)
- **if** 
- **stickyNote** (Ã—8)
- **splitInBatches** (Ã—2)
- **awsS3** 
- **aggregate** 

## ğŸš€ How to Use

1. Download the workflow JSON file
2. Import it into your n8n instance
3. Configure the credentials for the nodes
4. Activate and test the workflow

## ğŸ”€ Workflow Structure

This workflow contains 29 nodes with 21 node connections.

---

*This workflow was sourced from [n8n.io](https://n8n.io) community templates.*
