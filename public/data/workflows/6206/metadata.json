{
  "id": 6206,
  "slug": "6206",
  "title": "Build a ServiceNow knowledge chatbot with OpenAI and Qdrant RAG",
  "description": "\n\n\n### **1. Data Ingestion Workflow (Left Panel – Pink Section)**\n\nThis part collects data from the ServiceNow Knowledge Article table, processes it into embeddings, and stores it in Qdrant.\n\n#### **Steps:**\n\n1. **Trigger: When clicking ‘Execute workflow’**\n\n   * The workflow starts manually when you click *Execute workflow* in n8n.\n\n2. **Get Many Table Records**\n\n   * Fetches multiple records from the ServiceNow Knowledge Article table.\n   * Each record typically contains knowledge article content that needs to be indexed.\n\n3. **Default Data Loader**\n\n   * Takes the fetched data and structures it into a format suitable for text splitting and embedding generation.\n\n4. **Recursive Character Text Splitter**\n\n   * Splits large text (e.g., long knowledge articles) into smaller, manageable chunks for embeddings.\n   * This step ensures that each text chunk can be properly processed by the embedding model.\n\n5. **Embeddings OpenAI**\n\n   * Uses OpenAI’s Embeddings API to convert each text chunk into a high-dimensional vector representation.\n   * These embeddings are essential for semantic search in the vector database.\n\n6. **Qdrant Vector Store**\n\n   * Stores the generated embeddings along with metadata (e.g., article ID, title) in the Qdrant vector database.\n   * This database will later be used for similarity searches during chatbot interactions.\n\n---\n\n### **2. RAG Chatbot Workflow (Right Panel – Green Section)**\n\nThis section powers the Retrieval-Augmented Generation (RAG) chatbot that retrieves relevant information from Qdrant and responds intelligently.\n\n#### **Steps:**\n\n1. **Trigger: When chat message received**\n\n   * Starts when a user sends a chat message to the system.\n\n2. **AI Agent**\n\n   * Acts as the orchestrator, combining memory, tools, and LLM reasoning.\n   * Connects to the OpenAI Chat Model and Qdrant Vector Store.\n\n3. **OpenAI Chat Model**\n\n   * Processes user messages and generates responses, enriched with context retrieved from Qdrant.\n\n4. **Simple Memory**\n\n   * Stores conversational history or context to ensure continuity in multi-turn conversations.\n\n5. **Qdrant Vector Store1**\n\n   * Performs a similarity search on stored embeddings using the user’s query.\n   * Retrieves the most relevant knowledge article chunks for the chatbot.\n\n6. **Embeddings OpenAI**\n\n   * Converts user query into embeddings for vector search in Qdrant.\n\n",
  "featuredImage": "/data/workflows/6206/6206.webp",
  "author": {
    "id": 101,
    "slug": "yajna",
    "name": "Tushar Mishra",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 824,
  "downloads": 82,
  "createdAt": "2025-07-20T17:59:22.729Z",
  "updatedAt": "2026-01-16T08:43:47.933Z",
  "publishedAt": "2025-07-20T17:59:22.729Z",
  "nodes": 14,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6206"
}