# Build RAG-powered support agent for Jira issues using Pinecone and OpenAI

> ## Load Jira open issues with comments into Pinecone + RAG Agent (Direct Tool or MCP)

## Who‚Äôs it for  
This workflow is designed for support teams, data engineers, and AI developers who want to centralize Jira issue data into a vector database.  
It collects open issues and their associated comments, converts them into embeddings, and loads them into Pinecone for semantic search, retrieval-augmented generation (RAG), or AI-powered support bots.  
It‚Äôs also published as an **MCP tool**, so external applications can query the indexed issues directly.  

## How it works  
The workflow automates Jira issue extraction, comment processing, and vector storage in Pinecone. Importantly, the Pinecone index is **recreated at every run** so that it always reflects the current set of unresolved tickets.  

1. **Trigger** ‚Äì A schedule trigger runs the workflow at defined times (e.g., 8, 11, 14, and 17 on weekdays).  
2. **Issue extraction with pagination** ‚Äì Calls the Jira REST API to fetch open issues matching a JQL query (unresolved cases created in the last year).  
   - Pagination is fully handled: issues are retrieved in batches of 25, and the workflow continues iterating until all open issues are loaded.  
3. **Data transformation** ‚Äì Extracts key fields (issue ID, key, summary, description, product, customer, classification, status, registration date).  
4. **Comments integration** ‚Äì Fetches all comments for each issue, filters out empty/irrelevant ones (images, dots, empty markdown), and merges them with the issue data.  
5. **Text cleaning** ‚Äì Converts HTML descriptions into clean plain text for processing.  
6. **Embedding generation** ‚Äì Uses the OpenAI Embeddings node to vectorize text.  
7. **Vector storage with index recreation** ‚Äì Loads embeddings and metadata into Pinecone under the `jira` namespace and the `openissues` index. The namespace is cleared at every run to ensure the index contains only unresolved tickets.  
8. **Document chunking** ‚Äì Splits long issue texts into smaller chunks (512 tokens, 50 overlap) for better embedding quality.  
9. **MCP publishing** ‚Äì Exposes the Pinecone index as an MCP tool (`openissues`), enabling external systems to query Jira issues semantically.

## How to set up  
1. **Jira** ‚Äì Configure a Jira account and generate a token. Update the Jira node with credentials and adjust the JQL query if needed.  
2. **OpenAI** ‚Äì Set up an OpenAI API key for embeddings. Configure embedding dimensions (default: 512).  
3. **Pinecone** ‚Äì Create an index (e.g., `openissues`) with matching dimensions (512). Configure Pinecone API credentials and namespace (`jira`).  
   - The index will be cleared automatically at every run before reloading unresolved issues.  
4. **Schedule** ‚Äì Adjust the cron expression in the Schedule Trigger to fit your update frequency.  
5. **Optional MCP** ‚Äì If you want to query Jira issues via MCP, configure the MCP trigger and tool nodes.  

## Requirements  
- Jira account with API access and permissions to read issues and comments.  
- OpenAI API key with access to the embedding model.  
- Pinecone account with an index created (dimensions = 512).  
- n8n instance with credentials set up for Jira, OpenAI, and Pinecone.  

## How to customize the workflow  
- **JQL query**: Modify it to control which issues are extracted (e.g., by project, type, or time window).  
- **Pagination size**: Adjust the `maxResults` parameter (default 25) if you want larger or smaller batches per iteration.  
- **Metadata fields**: Add or remove fields in the ‚ÄúExtract Relevant Info‚Äù code node.  
- **Chunk size**: Adjust chunk size/overlap in the Document Chunker for different embedding strategies.  
- **Embedding model**: Switch to a different embedding provider if preferred.  
- **Vector store**: Replace Pinecone with another supported vector database if needed.  
- **Downstream use**: Extend with notifications, dashboards, or AI assistants that consume the vector data.
---------------  

## AI Chatbot for Jira open tickets with SLA insights

### Who‚Äôs it for  
This workflow is designed for commercial teams, customer support, and service managers who need quick, conversational access to unresolved Jira tickets.  
It enables them to check whether a client has open issues, see related details, and understand SLA implications without manually browsing Jira.  

### How it works  
- **Chat interface** ‚Äì Provides a web-based chat that team members can use to ask natural language questions such as:  
  - *‚ÄúAre there any issues from client ACME?‚Äù*  
  - *‚ÄúDo we have tickets that have been open for a long time?‚Äù*  
- **AI Agent** ‚Äì Powered by OpenAI, it interprets questions and queries the Pinecone vector store (`openissues` index, `jira` namespace).  
- **Memory** ‚Äì Maintains short-term chat history for more natural conversations.  
- **Ticket retrieval** ‚Äì Uses Pinecone embeddings (dimension = 512) to fetch unresolved tickets enriched with metadata:  
  - Issue key, description, customer, product, severity color, status, AM contract type, and SLA.  
- **SLA integration** ‚Äì Service levels (Basic, Advanced, Full Service, with optional Fast Support) are provided via the SLA node. The agent explains which SLA applies based on ticket severity, registration date, and contract type.  
- **AI response** ‚Äì Returns a friendly, collaborative summary of all tickets found, including:  
  - Ticket identifier  
  - Description  
  - Customer and product  
  - Severity level (Red, Yellow, Green, White)  
  - Ticket status  
  - Contract level and SLA explanation  

### Setup  
1. Configure Jira ‚Üí Pinecone index (`openissues`, 512 dimensions) already populated with unresolved tickets.  
2. Provide OpenAI API credentials.  
3. Ensure the SLA node includes the correct service-level definitions.  
4. Adjust chat branding (title, subtitle, CSS) if desired.  

### Requirements  
- Jira account with API access.  
- Pinecone account with an index (`openissues`, dimensions = 512).  
- OpenAI API key.  
- n8n instance with LangChain and chatTrigger nodes enabled.  

### How to customize  
- Change the SLA node text if your service levels differ.  
- Adjust the chat interface design (colors, title, subtitle).  
- Expand metadata in Pinecone (e.g., add project type, priority, or assigned team).  
- Train with additional examples in the system message to refine AI behavior.  


## üìä Basic Information

- **Workflow ID:** 8720
- **Complexity:** advanced
- **Node Count:** 30
- **Views:** 387
- **Downloads:** 38
- **Created:** 2025/9/18
- **Last Updated:** 2026/1/16
- **Source:** [View on n8n.io](https://n8n.io/workflows/8720)

## üë§ Author

- **Name:** Br1
- **Username:** @bruno-menegolli

## üè∑Ô∏è Categories

- Support Chatbot
- AI RAG

## üîó Nodes Used

- **@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter** 
- **code** (√ó3)
- **httpRequest** (√ó2)
- **@n8n/n8n-nodes-langchain.vectorStorePinecone** (√ó3)
- **@n8n/n8n-nodes-langchain.embeddingsOpenAi** (√ó2)
- **scheduleTrigger** 
- **@n8n/n8n-nodes-langchain.mcpTrigger** 
- **stickyNote** (√ó7)
- **@n8n/n8n-nodes-langchain.documentDefaultDataLoader** 
- **switch** 
- **merge** (√ó2)
- **@n8n/n8n-nodes-langchain.agent** 
- **@n8n/n8n-nodes-langchain.lmChatOpenAi** 
- **@n8n/n8n-nodes-langchain.memoryBufferWindow** 
- **set** 
- **@n8n/n8n-nodes-langchain.chatTrigger** 
- **@n8n/n8n-nodes-langchain.mcpClientTool** 

## üöÄ How to Use

1. Download the workflow JSON file
2. Import it into your n8n instance
3. Configure the credentials for the nodes
4. Activate and test the workflow

## üîÄ Workflow Structure

This workflow contains 30 nodes with 20 node connections.

---

*This workflow was sourced from [n8n.io](https://n8n.io) community templates.*
