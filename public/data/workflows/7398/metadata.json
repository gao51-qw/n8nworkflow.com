{
  "id": 7398,
  "slug": "7398",
  "title": "LLM usage tracker & cost monitor with node-level analytics (v2)",
  "description": "# LLM Cost Monitor & Usage Tracker for n8n\n\n&gt; v2: Now it can read multiple types of LLM usages. Better dynamic approach for reading model usage. \n\n## üéØ What This Workflow Does\n\nThis workflow provides comprehensive monitoring and cost tracking for all LLM/AI agent usage across your n8n workflows. It extracts detailed token usage data from any workflow execution and calculates precise costs based on current model pricing. \n\n### The Problem It Solves\nWhen running LLM nodes in n8n workflows, the token usage and intermediate data are not directly accessible within the same workflow. This monitoring workflow bridges that gap by:\n- Retrieving execution data using the execution ID\n- Extracting all LLM usage from any nested structure\n- Calculating costs with customizable pricing\n- Providing detailed analytics per node and model\n- WARNING: it works after the full execution of the workflow (i.e. you can't get this data before completion of all tasks in the workflow)\n\n## ‚öôÔ∏è Setup Instructions\n\n### Prerequisites\n1. **Experience Required**: Basic familiarity with n8n LLM nodes and AI agents\n2. **Agent Configuration**: In your monitored workflows, go to agent settings and enable **\"Return Intermediate Steps\"** \n3. For getting execution data, you need to set upthe  n8n API in your instance (also available onthe  free version) \n\n\n### Installation Steps\n1. Import this monitoring workflow into your n8n instance\n2. Go to Settings &gt;&gt; select n8n API from left bar &gt;&gt; define an API. Now you can add this as the credential for your \"Get an Execution\" node\n3. Configure your model name mappings in the **\"Standardize Names\"** node\n4. Update model pricing in the **\"Model Prices\"** node (prices per 1M tokens)\n5. To monitor a workflow:\n   - Add an **\"Execute Workflow\"** node at the end of your target workflow\n   - Select this monitoring workflow\n   - **Important**: Turn OFF \"Wait For Sub-Workflow Completion\"\n   - Pass the execution ID as input\n\n## üîß Customization\n\n### When You See Errors\nIf the workflow enters the error path, it means an undefined model was detected. Simply:\n1. Add the model name to the **standardize_names_dic** \n2. Add its pricing to the **model_price_dic**\n3. Re-run the workflow\n\n### Configurable Elements\n- **Model Name Mapping**: Standardize different model name variations (e.g., \"gpt-4-0613\" ‚Üí \"gpt-4\")\n- **Pricing Dictionary**: Set costs per million tokens for input/output\n- **Extraction Depth**: Captures tokens from any nesting level automatically\n\n## üìä Output Data\n\n### Per LLM Call\n- **Cost Breakdown**: Prompt, completion, and total costs in USD\n- **Token Metrics**: Prompt tokens, completion tokens, total tokens\n- **Performance**: Execution time, start time, finish reason\n- **Content Preview**: First 100 chars of input/output for debugging\n- **Model Parameters**: Temperature, max tokens, timeout, retry count\n- **Execution Context**: Workflow name, node name, execution status\n- **Flow Tracking**: Previous nodes chain\n\n### Summary Statistics\n- Total executions and costs\n- Breakdown by model type\n- Breakdown by node\n- Average cost per call\n- Total execution time\n\n## ‚ú® Key Benefits\n\n- **No External Dependencies**: Everything runs within n8n\n- **Universal Compatibility**: Works with any workflow structure\n- **Automatic Detection**: Finds LLM usage regardless of nesting\n- **Real-time Monitoring**: Track costs as workflows execute\n- **Debugging Support**: Preview actual prompts and responses\n- **Scalable**: Handles multiple models and complex workflows\n\n## üìù Example Use Cases\n\n- **Cost Optimization**: Identify expensive nodes and optimize prompts\n- **Usage Analytics**: Track token consumption across teams/projects\n- **Budget Monitoring**: Set alerts based on cost thresholds\n- **Performance Analysis**: Find slow-running LLM calls\n- **Debugging**: Review actual inputs/outputs without logs\n- **Compliance**: Audit AI usage across your organization\n\n## üöÄ Quick Start\n\n1. Import workflow\n2. Update model prices (if needed)\n3. Add monitoring to any workflow with the Execute Workflow node\n4. View detailed cost breakdowns instantly\n\n---\n\n*Note: Prices are configured per million tokens. Default includes GPT-4, GPT-3.5, Claude, and other popular models. Add custom models as needed.*",
  "featuredImage": "/data/workflows/7398/7398.webp",
  "author": {
    "id": 101,
    "slug": "amirsafavi",
    "name": "Amir Safavi-Naini",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1074,
  "downloads": 107,
  "createdAt": "2025-08-14T20:13:23.211Z",
  "updatedAt": "2026-01-16T08:50:12.113Z",
  "publishedAt": "2025-08-14T20:13:23.211Z",
  "nodes": 18,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7398"
}