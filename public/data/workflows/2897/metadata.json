{
  "id": 2897,
  "slug": "2897",
  "title": "Use OpenRouter in n8n versions <1.78",
  "description": "## What it is:\n\nIn version 1.78, n8n introduced a dedicated node to use the OpenRouter service, which lets you to use a lot of different LLM models and providers and change models on the fly in an agentic workflow.\n\nFor prior n8n versions, there's a workaround to make OpenRouter accessible, by using the OpenAI node with a OpenRouter-specific BaseURL.\n\nThis trivial workflow demonstrates this for version before 1.78, so that you can use different LLM model dynamically with the available n8n nodes for OpenAI LLM and OpenAI credentials.\n\n## What you can do:\n\n* Use any of the [OpenRouter models](https://openrouter.ai/models)\n* Have the model even dynamically configured or changing (by some external config, some rule, or some specific chat message)\n\n## Setup steps:\n\n* Import the workflow\n* Ensure you have registered and account, purchased some credits and created and API key for [OpenRouter.ai](https://openrouter.ai)\n* Configure the \"OpenRouter\" credentials with your own credentials, using an _OpenAI  type_ credential, but making sure in the credential's config form its \"Base URL\" is set to _https://openrouter.ai/api/v1_ so OpenRouter is used instead of OpenAI. \n* Open the \"Settings\" node and change the model value to any valid model id from the [OpenRouter models list](https://openrouter.ai/models) or even have the model property set dynamically",
  "featuredImage": "/data/workflows/2897/2897.webp",
  "author": {
    "id": 101,
    "slug": "dnolde",
    "name": "Daniel Nolde",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "Multimodal AI"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 3418,
  "downloads": 341,
  "createdAt": "2025-02-13T12:32:31.015Z",
  "updatedAt": "2026-01-16T08:27:05.708Z",
  "publishedAt": "2025-02-13T12:32:31.015Z",
  "nodes": 8,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2897"
}