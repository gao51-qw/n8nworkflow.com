{
  "workflow": {
    "id": 4237,
    "name": "Dynamic AI model router for query optimization with OpenRouter",
    "views": 4630,
    "recentViews": 1,
    "totalViews": 4630,
    "createdAt": "2025-05-20T07:40:19.495Z",
    "description": "The **Agent Decisioner** is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query‚Äôs content and purpose.\n\nThis workflow ensures **dynamic, optimized AI responses** by intelligently routing queries to the best-suited model.\n\n---\n\n### **Advantages**\n\n* **üîÅ Automatic Model Routing:**\n  Automatically selects the best model for the job, improving efficiency and relevance of responses.\n\n* **üéØ Optimized Use of Resources:**\n  Avoids overuse of expensive models like GPT-4 by routing simpler queries to lightweight models.\n\n* **üìö Model-Aware Reasoning:**\n  Uses detailed metadata about model capabilities (e.g., reasoning, coding, web search) for intelligent selection.\n\n* **üì• Modular and Extendable:**\n  Easy to integrate with other tools or expand by adding more models or custom decision logic.\n\n* **üë®‚Äçüíª Ideal for RAG and Multi-Agent Systems:**\n  Can serve as the brain behind more complex agent frameworks or Retrieval-Augmented Generation pipelines.\n\n---\n\n\n### **How It Works**  \n\n1. **Chat Trigger**: The workflow starts when a user sends a message, triggering the **Routing Agent**.  \n2. **Model Selection**: The **AI Agent** analyzes the query and selects the best-suited model from the available options (e.g., Claude 3.7 Sonnet for coding, Perplexity/Sonar for web searches, GPT-4o Mini for reasoning).  \n3. **Structured Output**: The agent returns a **JSON response** with the user‚Äôs prompt and the chosen model.  \n4. **Execution**: The selected model processes the query and generates a response, ensuring optimal performance for the task.  \n\n### **Set Up Steps**  \n\n1. **Configure Nodes**:  \n   - **Chat Trigger**: Set up the webhook to receive user messages.  \n   - **Routing Agent (AI Agent)**: Define the system message with model strengths and JSON output rules.  \n   - **OpenRouter Chat Model**: Connect to OpenRouter for model access.  \n   - **Structured Output Parser**: Ensure it validates the JSON response format (`prompt` + `model`).  \n   - **Execution Agent (AI Agent1)**: Configure it to forward the prompt to the selected model.  \n\n2. **Connect Nodes**:  \n   - Link the **Chat Trigger** to the **Routing Agent**.  \n   - Connect the **OpenRouter Chat Model** and **Output Parser** to the **Routing Agent**.  \n   - Route the parsed JSON to the **Execution Agent**, which uses the chosen model via **OpenRouter Chat Model1**.  \n\n3. **Credentials**:  \n   - Ensure **OpenRouter API credentials** are correctly set for both chat model nodes.  \n\n4. **Test & Deploy**:  \n   - Activate the workflow and test with sample queries to verify model selection logic.  \n   - Adjust the routing rules if needed for better accuracy.  \n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/). ",
    "workflow": {
      "id": "uNLWQ7BSozpoehpU",
      "meta": {
        "instanceId": "a4bfc93e975ca233ac45ed7c9227d84cf5a2329310525917adaf3312e10d5462",
        "templateCredsSetupCompleted": true
      },
      "name": "Automated AI Routing with OpenRouter",
      "tags": [],
      "nodes": [
        {
          "id": "25903a04-24d2-41f9-bf34-5d6234e642e5",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            -180,
            -180
          ],
          "webhookId": "a0032740-26d8-491b-93f9-2250906d0e17",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.1
        },
        {
          "id": "fabffdee-3c1e-47db-a4e9-f6473a6e9257",
          "name": "OpenRouter Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            0,
            40
          ],
          "parameters": {
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "c53fe672-92cb-4d88-b4f6-f413fb00ad6a",
          "name": "Structured Output Parser",
          "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
          "position": [
            340,
            280
          ],
          "parameters": {
            "schemaType": "manual",
            "inputSchema": "{\n\t\"type\": \"object\",\n\t\"properties\": {\n\t\t\"prompt\": {\n\t\t\t\"type\": \"string\"\n\t\t},\n\t\t\"model\": {\n\t\t\t\"type\": \"string\"\n\t\t}\n\t}\n}"
          },
          "typeVersion": 1.2
        },
        {
          "id": "d60a9d61-c611-4813-bf85-e8f8faaa21b6",
          "name": "OpenRouter Chat Model1",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            420,
            40
          ],
          "parameters": {
            "model": "={{ $json.output.model }}",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "ef9ceacb-55e4-4795-aa18-976997ec3717",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -180,
            -420
          ],
          "parameters": {
            "width": 840,
            "height": 180,
            "content": "## Dynamic Model Selector for Optimal AI Responses\n\nThe **Agent Decisioner** is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query‚Äôs content and purpose.\n\nThis workflow ensures **dynamic, optimized AI responses** by intelligently routing queries to the best-suited model."
          },
          "typeVersion": 1
        },
        {
          "id": "4d688ad7-b463-4e72-9b79-4b9142f022d2",
          "name": "Routing Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            40,
            -180
          ],
          "parameters": {
            "options": {
              "systemMessage": "=You are a **Routing Agent**.\n\nYour task is to analyze user queries and determine the most appropriate model to handle each specific use case.\n\n## Available Models\n\nYou have access to the following models:\n\n1. **perplexity/sonar**\n2. **openai/gpt-4o-mini**\n3. **anthropic/claude-3.7-sonnet**\n4. **meta-llama/llama-3-70b-instruct**\n5. **google/gemini-2.5-pro-preview**\n6. **qwen/qwen-qwq-32b**\n7. **openai/codex-mini**\n8. **openai/o1-pro**\n\n## Model Strengths\n\n### 1. perplexity/sonar\n- Built-in web search capability\n- Provides citations and customizable sources\n- Ideal for retrieving live, up-to-date information from the web\n\n### 2. openai/gpt-4o-mini\n- Cost-efficient language model optimized for advanced reasoning tasks\n- Excels in science and mathematics\n- Best suited for problems requiring careful, well-thought-out responses involving multiple variables or connections\n\n### 3. anthropic/claude-3.7-sonnet\n- High proficiency in coding tasks, scoring ~94% on SWE-Bench Verified\n- Enhances data science expertise by navigating unstructured data and utilizing multiple tools for insights\n- Handles very long documents and maintains coherence over extended conversations or analyses\n- Performs well in creative writing tasks such as storytelling, dialogue generation, and summarization\n- Tends to produce responses that are more aligned with safety and ethical guidelines\n\n### 4. meta-llama/llama-3-70b-instruct\n- Strong performance in coding and reasoning tasks\n- Suitable for complex programming and technical problem-solving\n- Supports long context windows, making it ideal for extended analyses\n\n### 5. google/gemini-2.5-pro-preview\n- Advanced multimodal capabilities, handling both text and images\n- Excels in tasks requiring integration of visual and textual information\n- Ideal for complex problem-solving involving diverse data types\n\n### 6. qwen/qwen-qwq-32b\n- Specialized in reasoning and problem-solving tasks\n- Effective in handling logical puzzles and complex analytical queries\n\n### 7. openai/codex-mini\n- Optimized for code generation and completion tasks\n- Suitable for lightweight coding tasks and quick code snippets\n\n### 8. openai/o1-pro\n- Designed for complex reasoning with enhanced computational resources\n- Performs well in STEM-related tasks, including physics, chemistry, and biology\n- Capable of handling large context windows, making it suitable for in-depth analyses\n\n## Output Format\n\nYour output must always be a valid JSON object in the following format:\n\n```json\n{\n  \"prompt\": \"user query goes here\",\n  \"model\": \"selected-model-name\"\n}\n```\n\n- The **\"prompt\"** field should contain the exact query to be sent to the selected model.\n- The **\"model\"** field should contain the model name (one of: perplexity/sonar, openai/gpt-4o-mini, anthropic/claude-3.7-sonnet, meta-llama/llama-3-70b-instruct, google/gemini-2.5-pro-preview, qwen/qwen-qwq-32b, openai/codex-mini, openai/o1-pro).\n\n**Important:** Only return the JSON object. Do not include any explanations or additional text."
            },
            "hasOutputParser": true
          },
          "typeVersion": 1.9
        },
        {
          "id": "94c49c22-9697-4230-ba35-5159041cfdc7",
          "name": "AI Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            400,
            -180
          ],
          "parameters": {
            "text": "={{ $json.output.prompt }}",
            "options": {},
            "promptType": "define"
          },
          "typeVersion": 1.9
        },
        {
          "id": "54c4278e-c185-4ab4-b21e-d8e837b14818",
          "name": "Auto-fixing Output Parser",
          "type": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
          "position": [
            140,
            60
          ],
          "parameters": {
            "options": {
              "prompt": "Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "2813da6b-423b-41d6-8eb4-664f616ca8d5",
          "name": "OpenAI Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            140,
            220
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4o-mini"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        }
      ],
      "active": false,
      "pinData": {},
      "settings": {
        "executionOrder": "v1"
      },
      "versionId": "bb8e8d46-ce32-49e0-a843-496c6e026902",
      "connections": {
        "Routing Agent": {
          "main": [
            [
              {
                "node": "AI Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "OpenAI Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "Auto-fixing Output Parser",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "OpenRouter Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "Routing Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "OpenRouter Chat Model1": {
          "ai_languageModel": [
            [
              {
                "node": "AI Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Structured Output Parser": {
          "ai_outputParser": [
            [
              {
                "node": "Auto-fixing Output Parser",
                "type": "ai_outputParser",
                "index": 0
              }
            ]
          ]
        },
        "Auto-fixing Output Parser": {
          "ai_outputParser": [
            [
              {
                "node": "Routing Agent",
                "type": "ai_outputParser",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "Routing Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 9,
      "nodeTypes": {
        "n8n-nodes-base.stickyNote": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenRouter": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.outputParserAutofixing": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.outputParserStructured": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Davide",
      "username": "n3witalia",
      "bio": "Full-stack Web Developer based in Italy specialising in Marketing & AI-powered automations. For business enquiries, send me an email at info@n3w.it or add me on Linkedin.com/in/davideboizza",
      "verified": true,
      "links": [
        "https://n3w.it"
      ],
      "avatar": "https://gravatar.com/avatar/d41b8a0aa81139243509c58870f5b4be292824a507ab57d10ed066d8628ed8da?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1175,
        "icon": "fa:tools",
        "name": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Output Parsers"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Auto-fixing Output Parser"
        },
        "iconData": {
          "icon": "tools",
          "type": "icon"
        },
        "displayName": "Auto-fixing Output Parser",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1179,
        "icon": "fa:code",
        "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "codex": {
          "data": {
            "alias": [
              "json",
              "zod"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Output Parsers"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Structured Output Parser"
        },
        "iconData": {
          "icon": "code",
          "type": "icon"
        },
        "displayName": "Structured Output Parser",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1281,
        "icon": "file:openrouter.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenRouter Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjOTRBM0I4IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHdpZHRoPSI0MCIgaGVpZ2h0PSI0MCIgdmlld0JveD0iMCAwIDI0IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjx0aXRsZT5PcGVuUm91dGVyPC90aXRsZT48cGF0aCBkPSJNMTYuODA0IDEuOTU3bDcuMjIgNC4xMDV2LjA4N0wxNi43MyAxMC4yMWwuMDE3LTIuMTE3LS44MjEtLjAzYy0xLjA1OS0uMDI4LTEuNjExLjAwMi0yLjI2OC4xMS0xLjA2NC4xNzUtMi4wMzguNTc3LTMuMTQ3IDEuMzUyTDguMzQ1IDExLjAzYy0uMjg0LjE5NS0uNDk1LjMzNi0uNjguNDU1bC0uNTE1LjMyMi0uMzk3LjIzNC4zODUuMjMuNTMuMzM4Yy40NzYuMzE0IDEuMTcuNzk2IDIuNzAxIDEuODY2IDEuMTEuNzc1IDIuMDgzIDEuMTc3IDMuMTQ3IDEuMzUybC4zLjA0NWMuNjk0LjA5MSAxLjM3NS4wOTQgMi44MjUuMDMzbC4wMjItMi4xNTkgNy4yMiA0LjEwNXYuMDg3TDE2LjU4OSAyMmwuMDE0LTEuODYyLS42MzUuMDIyYy0xLjM4Ni4wNDItMi4xMzcuMDAyLTMuMTM4LS4xNjItMS42OTQtLjI4LTMuMjYtLjkyNi00Ljg4MS0yLjA1OWwtMi4xNTgtMS41YTIxLjk5NyAyMS45OTcgMCAwMC0uNzU1LS40OThsLS40NjctLjI4YTU1LjkyNyA1NS45MjcgMCAwMC0uNzYtLjQzQzIuOTA4IDE0LjczLjU2MyAxNC4xMTYgMCAxNC4xMTZWOS44ODhsLjE0LjAwNGMuNTY0LS4wMDcgMi45MS0uNjIyIDMuODA5LTEuMTI0bDEuMDE2LS41OC40MzgtLjI3NGMuNDI4LS4yOCAxLjA3Mi0uNzI2IDIuNjg2LTEuODUzIDEuNjIxLTEuMTMzIDMuMTg2LTEuNzggNC44ODEtMi4wNTkgMS4xNTItLjE5IDEuOTc0LS4yMTMgMy44MTQtLjEzOGwuMDItMS45MDd6Ij48L3BhdGg+PC9zdmc+Cg=="
        },
        "displayName": "OpenRouter Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 5,
        "name": "Engineering"
      },
      {
        "id": 47,
        "name": "AI Chatbot"
      }
    ],
    "image": []
  }
}