{
  "id": 4274,
  "slug": "4274",
  "title": "Evaluation metric example: String similarity",
  "description": "## AI evaluation in n8n\n\nThis is a template for n8n's [evaluation feature](https://docs.n8n.io/advanced-ai/evaluations/overview). \n\nEvaluation is a technique for getting confidence that your AI workflow performs reliably, by running a test dataset containing different inputs through the workflow.\n\nBy calculating a metric (score) for each input, you can see where the workflow is performing well and where it isn't.\n\n## How it works\n\nThis template shows how to calculate a workflow evaluation metric: **text similarity, measured character-by-character**.\n\nThe workflow takes images of hand-written codes, extracts the code and compares it with the expected answer from the dataset.\n\nThe images look like this:\n\n![image](https://storage.googleapis.com/n8n_template_data/handwriting_scans/doc20250302_08223946_001.jpg)\n\nThe workflow works as follows:\n\n- We use an evaluation trigger to read in our dataset \n- It is wired up in parallel with the regular trigger so that the workflow can be started from either one. [More info](https://docs.n8n.io/advanced-ai/evaluations/tips-and-common-issues/#combining-multiple-triggers)\n- We download the image and use AI to extract the code\n- If weâ€™re evaluating (i.e. the execution started from the evaluation trigger), we calculate the string distance metric\n- We pass this information back to n8n as a metric\n",
  "featuredImage": "/data/workflows/4274/4274.webp",
  "author": {
    "id": 101,
    "slug": "davidn8n",
    "name": "David Roberts",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 1057,
  "downloads": 105,
  "createdAt": "2025-05-21T08:23:13.742Z",
  "updatedAt": "2026-01-16T08:33:41.842Z",
  "publishedAt": "2025-05-21T08:23:13.742Z",
  "nodes": 12,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4274"
}