{
  "id": 12316,
  "slug": "12316",
  "title": "Synthesize and compare multiple LLM responses with OpenRouter council",
  "description": "This template adapts Andrej Karpathy‚Äôs **LLM Council** concept for use in **n8n**, creating a workflow that collects, evaluates, and synthesizes multiple large language model (LLM) responses to reduce individual model bias and improve answer quality.\n\n## üéØ The gist\n\nThis LLM Council workflow acts as a moderation board for multiple LLM ‚Äúopinions‚Äù:\n\n- The same question is answered independently by several models.\n- All answers are anonymized.\n- Each model then evaluates and ranks *all* responses.\n- A designated **Council Chairman** model synthesizes a final verdict based on these evaluations.\n- The final output includes:\n  - The original query\n  - The Chairman‚Äôs verdict\n  - The ranking of each response by each model\n  - The original responses from all models\n\nThe goal is to reduce single‚Äëmodel bias and arrive at more balanced, objective answers.\n\n## üß∞ Use cases\n\nThis workflow enables several practical applications:\n\n- Receiving more balanced answers by combining multiple model perspectives\n- Benchmarking and comparing LLM responses\n- Exploring diverse viewpoints on complex or controversial questions\n\n## ‚öôÔ∏è How it works\n\n- The workflow leverages **OpenRouter**, allowing access to many LLMs through a single API credential.\n- In the **Initialization** node, you define:\n  - **Council member models**: Models that answer the query and later evaluate all responses\n  - **Chairman model**: The model responsible for synthesizing the final verdict\n- Any OpenRouter-supported model can be used: https://openrouter.ai/models\n- For simplicity:\n  - Input is provided via a Chat Input trigger\n  - Output is sent via an email node with a structured summary of the council‚Äôs results\n\n## üë∑ How to use\n\n- Select the LLMs to include in your council:\n  - **Council member models**: Models that independently answer and evaluate the query. The default template uses:\n    - openai/gpt-4o\n    - google/gemini-2.5-flash\n    - anthropic/claude-sonnet-4.5\n    - perplexity/sonar-pro-search\n  - **Chairman model**: Choose a model with a sufficiently large context window to process all evaluations and rankings.\n- Start the Chat Input trigger.\n- Observe the workflow execution and review the synthesized result in your chosen output channel.\n\n‚ö†Ô∏è Avoid using too many models simultaneously. The total context size grows quickly (n responses + n¬≤ evaluations), which may exceed the Chairman model‚Äôs context window.\n\n## üö¶ Requirements\n\n- **OpenRouter API access** configured in n8n credentials\n- **SMTP credentials** for sending the final council output by email (or replace with another output method)\n\n## ü§° Customizing this workflow\n\n- Replace the Chat Input trigger with alternatives such as Telegram, email, or WhatsApp.\n- Redirect output to other channels instead of email.\n- Modify council member and chairman models directly in the Initialization node by updating their OpenRouter model names.\n",
  "featuredImage": "/data/workflows/12316/12316.webp",
  "author": {
    "id": 101,
    "slug": "syrom",
    "name": "Ulf Morys",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 15,
  "downloads": 1,
  "createdAt": "2025-12-30T19:36:59.696Z",
  "updatedAt": "2026-01-16T09:12:04.614Z",
  "publishedAt": "2025-12-30T19:36:59.696Z",
  "nodes": 26,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/12316"
}