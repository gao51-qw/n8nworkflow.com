{
  "workflow": {
    "id": 4547,
    "name": "Documentation Lookup AI Agent using Context7 and Gemini",
    "views": 1599,
    "recentViews": 0,
    "totalViews": 1599,
    "createdAt": "2025-06-01T03:32:24.786Z",
    "description": "**This n8n workflow template uses community nodes and is only compatible with the self-hosted version of n8n.** \n\nThis workflow demonstrates how to build and expose a sophisticated n8n AI Agent as a single, callable tool using the Multi-Agent Collaboration Protocol (MCP). It allows external clients or other AI systems to easily query software library documentation via Context7, without needing to manage the underlying tool orchestration or complex conversational logic.\n\n**Core Idea:**\nInstead of building complex agentic loops on the client-side (e.g., in Python, a VS Code extension, or another AI development environment), this workflow offloads the entire agent's reasoning and tool-use process to n8n. The client simply sends a natural language query (like \"How do I use Flexbox in Tailwind CSS?\") to an SSE endpoint, and the n8n agent handles the rest.\n\n**Key Features & How It Works:**\n\n1.  **Public MCP Endpoint:**\n    *   The main workflow uses the `Context7 MCP Server Trigger` node to create an SSE endpoint. This makes the agent accessible to any MCP-compatible client.\n    *   The path for the endpoint is kept long and random for basic 'security by obscurity'.\n2.  **Tool Workflow as an Interface:**\n    *   A `Tool Workflow` node (named `call_context7_ai_agent` in this example) is connected to the MCP Server Trigger. This node defines the single \"tool\" that external clients will see and call.\n3.  **Dedicated AI Agent Sub-Workflow:**\n    *   The `call_context7_ai_agent` tool invokes a separate sub-workflow which contains the actual AI logic.\n    *   This sub-workflow starts with a `Context7 Workflow Start` node to receive the user's `query`.\n    *   A `Context7 AI Agent` node (using Google Gemini in this example) is the brain, equipped with:\n        *   A system prompt to guide its behavior.\n        *   `Simple Memory` to retain context for each execution (using `{{ $execution.id }}` as the session key).\n        *   Two specialized Context7 MCP client tools:\n            *   `context7-resolve-library-id`: To convert library names (e.g., 'Next.js') into Context7-specific IDs.\n            *   `context7-get-library-docs`: To fetch documentation using the resolved ID, with options for specific topics and token limits.\n4.  **Seamless Tool Use:** The AI Agent autonomously decides when and how to use the `resolve-library-id` and `get-library-docs` tools based on the user's query, handling the multi-step process internally.\n\n**Benefits of This Approach:**\n\n*   **Simplified Client Integration:** Clients interact with a single, powerful tool, sending a simple query.\n*   **Reduced Client-Side Token Consumption:** The detailed prompts, tool descriptions, and conversational turns are managed server-side by n8n, saving tokens on the client (especially useful if the client is another LLM).\n*   **Centralized Agent Management:** Update your agent's capabilities, tools, or LLM model within n8n without any changes needed on the client side.\n*   **Modularity for Agentic Systems:** Perfect for building complex, multi-agent systems where this n8n workflow can act as a specialized \"expert\" agent callable by others (e.g., from environments like Smithery).\n*   **Cost-Effective:** By using a potentially less expensive model (like Gemini Flash) for the agent's orchestration and leveraging the free tier or efficient pricing of services like Context7, you can build powerful solutions economically.\n\n**Use Cases:**\n\n*   Providing an intelligent documentation lookup service for coding assistants or IDE extensions.\n*   Creating specialized AI \"micro-agents\" that can be consumed by larger AI applications.\n*   Building internal knowledge base query systems accessible via a simple API-like interface.\n\n**Setup:**\n\n*   Ensure you have the necessary n8n credentials for Google Gemini (or your chosen LLM) and the Context7 MCP client tools.\n*   The `Path` in the `Context7 MCP Server Trigger` node should be unique and secure.\n*   Clients connect to the \"Production URL\" (SSE endpoint) provided by the trigger node.\n\nThis workflow is a great example of how n8n can serve as a powerful backend for building and deploying modular AI agents.\n\nI've made a video to try and explain this a bit too https://www.youtube.com/watch?v=dudvmyp7Pyg",
    "workflow": {
      "id": "vqujIu65SFbZUz0n",
      "meta": {
        "instanceId": "3612a0c89f35a354ddd1216385240db51b4635fde7cae2a0d5004be915b832f3",
        "templateCredsSetupCompleted": true
      },
      "name": "Context7 Smithery AI Agent MCP Server",
      "tags": [],
      "nodes": [
        {
          "id": "a42ae423-a348-460e-888c-f3df2b82021d",
          "name": "Google Gemini Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
          "position": [
            440,
            380
          ],
          "parameters": {
            "options": {},
            "modelName": "models/gemini-2.5-flash-preview-05-20"
          },
          "credentials": {
            "googlePalmApi": {
              "id": "credential-id",
              "name": "googlePalmApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "22f3e783-4310-4d15-a875-cbb400a82c1b",
          "name": "context7-resolve-library-id",
          "type": "n8n-nodes-mcp.mcpClientTool",
          "position": [
            1280,
            480
          ],
          "parameters": {
            "toolName": "resolve-library-id",
            "operation": "executeTool",
            "connectionType": "http",
            "toolParameters": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Tool_Parameters', `Generate a JSON object with the parameters for this tool.\nThe tool expects a JSON object with one **required** key:\n- \"libraryName\": (string) The common name of the software library or framework.\nExample: {\"libraryName\": \"react\"}`, 'json') }}",
            "descriptionType": "manual",
            "toolDescription": "Resolves a general library name (e.g., 'nextjs', 'mongodb') into a unique Context7-compatible library ID (e.g., '/vercel/next.js', '/mongodb/docs'). Use this tool first to get the correct ID before attempting to fetch its documentation."
          },
          "credentials": {
            "mcpClientHttpApi": {
              "id": "credential-id",
              "name": "mcpClientHttpApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "526eab1c-7a08-45eb-8169-7e8d4578c117",
          "name": "context7-get-library-docs",
          "type": "n8n-nodes-mcp.mcpClientTool",
          "position": [
            1840,
            480
          ],
          "parameters": {
            "toolName": "get-library-docs",
            "operation": "executeTool",
            "connectionType": "http",
            "toolParameters": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Tool_Parameters', `Generate a JSON object with the parameters for this tool.\nThe tool expects a JSON object with the following keys:\n- \"context7CompatibleLibraryID\": (string, **required**) The exact Context7-compatible library ID (e.g., \"/vercel/next.js\").\n- \"topic\": (string, optional) A specific topic to focus the documentation on (e.g., \"routing\").\n- \"tokens\": (number, optional, default: 10000) Maximum number of tokens for the documentation. Minimum effective value is 10000.\nExample for required only: {\"context7CompatibleLibraryID\": \"/mongodb/docs\"}\nExample with optional: {\"context7CompatibleLibraryID\": \"/vercel/next.js\", \"topic\": \"authentication\", \"tokens\": 15000}`, 'json') }}",
            "descriptionType": "manual",
            "toolDescription": "Fetches documentation for a specified library using its Context7-compatible library ID. You can optionally focus on a specific topic within the documentation and set a maximum token limit for the returned content."
          },
          "credentials": {
            "mcpClientHttpApi": {
              "id": "credential-id",
              "name": "mcpClientHttpApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "5cafb0d4-19ac-4589-88d8-34b88404e0f1",
          "name": "Context7 MCP Server Trigger",
          "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
          "position": [
            120,
            -860
          ],
          "webhookId": "c597b9e9-33bf-41d9-8602-e63d2bee174b",
          "parameters": {
            "path": "dafdfsdfsdf6e8-ea19-43b7-b337-a5iuodsf98vjfewf"
          },
          "typeVersion": 1
        },
        {
          "id": "945d8818-c346-44ba-b4c1-56d166a4f381",
          "name": "Context7 AI Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            880,
            -20
          ],
          "parameters": {
            "text": "={{ $('Context7 Workflow Start').item.json.query }}",
            "options": {
              "systemMessage": "You are an AI assistant with access to Context7 tools to help users find software library documentation.\nYour primary functions are to:\n1.  **Resolve Library IDs:** When a user asks for documentation for a library like 'Next.js' or 'MongoDB', first use the `resolve-library-id` tool to find its specific Context7-compatible ID (e.g., '/vercel/next.js'). The input for this tool is the `libraryName`.\n2.  **Get Library Documentation:** Once you have the `context7CompatibleLibraryID` from the previous step, use the `get-library-docs` tool to fetch the documentation.\n    *   The required parameter is `context7CompatibleLibraryID`.\n    *   If the user specifies a particular `topic` (e.g., \"routing in Next.js\"), include this in the `topic` parameter.\n    *   You can also adjust the `tokens` parameter if a different length of documentation is implicitly or explicitly requested, keeping in mind the default and minimum is 10000.\n\nAlways use `resolve-library-id` before `get-library-docs` if you don't already have the exact Context7-compatible library ID. Be precise with the IDs."
            },
            "promptType": "define"
          },
          "typeVersion": 2
        },
        {
          "id": "1b0cd3cc-8566-4cb5-932c-005149a2467b",
          "name": "Context7 Workflow Start",
          "type": "n8n-nodes-base.executeWorkflowTrigger",
          "position": [
            100,
            -20
          ],
          "parameters": {
            "workflowInputs": {
              "values": [
                {
                  "name": "query"
                }
              ]
            }
          },
          "typeVersion": 1.1
        },
        {
          "id": "e955aa60-2b80-45d5-885b-24b7fe56a426",
          "name": "Simple Memory",
          "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
          "position": [
            700,
            520
          ],
          "parameters": {
            "sessionKey": "={{ $execution.id }}",
            "sessionIdType": "customKey"
          },
          "typeVersion": 1.3
        },
        {
          "id": "4927c593-5762-4a26-87eb-8a7e0a4b3d32",
          "name": "call_context7_ai_agent",
          "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
          "position": [
            280,
            -460
          ],
          "parameters": {
            "workflowId": {
              "__rl": true,
              "mode": "list",
              "value": "vqujIu65SFbZUz0n",
              "cachedResultName": "Context7 Smithery AI Agent MCP Server"
            },
            "description": "=Processes a natural language query to find and retrieve software library documentation using Context7. It intelligently uses sub-tools to first resolve library names to Context7 IDs and then fetches the relevant documentation.",
            "workflowInputs": {
              "value": {
                "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', `The user's natural language question or request for software library documentation. For example: 'How do I implement authentication in Next.js?' or 'Get docs for MongoDB aggregation framework'.`, 'string') }}"
              },
              "schema": [
                {
                  "id": "query",
                  "type": "string",
                  "display": true,
                  "removed": false,
                  "required": false,
                  "displayName": "query",
                  "defaultMatch": false,
                  "canBeUsedToMatch": true
                }
              ],
              "mappingMode": "defineBelow",
              "matchingColumns": [],
              "attemptToConvertTypes": false,
              "convertFieldsToString": false
            }
          },
          "typeVersion": 2.2
        },
        {
          "id": "d72a2661-5622-4bfa-9d42-8c96b5fef877",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1700,
            -40
          ],
          "parameters": {
            "width": 680,
            "height": 320,
            "content": "## MCP JSON for Roo Code etc\n\nTo use this in Roo Code, Cline etc use\n\n\"n8n-context7\": {\n      \"url\": \"https://n8n.coolify.au/mcp/dafd56e8-ea19-43b7-b337-a5881c3bc541/sse\",\n      \"alwaysAllow\": [\n        \"call_context7_ai_agent\"\n      ]\n    }\n\nwhere the url is the the path that you get from the mcp server node in n8n"
          },
          "typeVersion": 1
        },
        {
          "id": "c0dc815b-3d0f-49e2-8da0-08d2f45d0991",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -260,
            -1140
          ],
          "parameters": {
            "color": 4,
            "width": 580,
            "height": 420,
            "content": "This node is the public entry point for the Context7 AI Agent service.\nIt exposes an MCP (Multi-Agent Collaboration Protocol) SSE (Server-Sent Events) endpoint.\n\n- Path: The long, random path (e.g., /dafdfsdfsdf... ) acts as a simple 'security by obscurity' measure.\n- Function: It listens for incoming HTTP POST requests to its SSE endpoint.\n- Tool Exposed: This trigger makes the 'call_context7_ai_agent' tool (defined by the connected Tool Workflow node) available to external MCP clients.\n- Input: Expects a JSON payload from the client, typically like: {\"input\": {\"query\": \"user's question\"}}\n- Output: Streams SSE events back to the client, containing the AI agent's responses and intermediate steps."
          },
          "typeVersion": 1
        },
        {
          "id": "adc54a99-b04d-40be-a9a4-25f837453c14",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -260,
            -680
          ],
          "parameters": {
            "color": 4,
            "width": 580,
            "height": 340,
            "content": "This node represents the tool that external clients call via the MCP Server Trigger.\nWhen triggered, it executes the separate \"Context7 Smithery AI Agent MCP Server\" sub-workflow (ID: vqujIu65SFbZUz0n).\n\n- Action: Invokes the AI agent sub-workflow to process the user's request.\n- Inputs to Sub-Workflow:\n    - 'query': The user's natural language question, received from the external MCP client. This is passed directly to the sub-workflow.\n- Output: The result from the sub-workflow (the AI agent's final response or stream) is passed back through the MCP Server Trigger to the client."
          },
          "typeVersion": 1
        },
        {
          "id": "5cc037d1-4155-49dc-86f5-7af9976149bf",
          "name": "Sticky Note3",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1700,
            -660
          ],
          "parameters": {
            "color": 2,
            "width": 680,
            "height": 600,
            "content": "## Main MCP Server Workflow Overview\n\nThis workflow acts as the public gateway for the Context7 AI Documentation Agent.\n\n1.  **`Context7 MCP Server Trigger`**:\n    *   Receives requests from external clients (e.g., Roo Code, Cline) at its unique SSE endpoint URL.\n    *   The path is intentionally long and random for basic access control.\n    *   Client JSON for Roo Code etc.:\n        \"n8n-context7\": {\n          \"url\": \"https://n8n.coolify.au/mcp/YOUR_LONG_RANDOM_PATH/sse\",\n          \"alwaysAllow\": [\n            \"call_context7_ai_agent\"  // This is the tool name defined in the Tool Workflow node\n          ]\n        }\n        (Replace YOUR_LONG_RANDOM_PATH with the actual path from the trigger node)\n\n2.  **`call_context7_ai_agent` (Tool Workflow Node)**:\n    *   This is the \"tool\" the MCP Server Trigger exposes.\n    *   It calls the separate AI Agent Sub-Workflow (ID: vqujIu65SFbZUz0n), passing the user's `query`.\n\n**Data Flow:**\nExternal Client -> MCP Server Trigger -> call_context7_ai_agent (Tool) -> AI Agent Sub-Workflow -> (Response Stream) -> MCP Server Trigger -> External Client\n\n3.  ** There is a video I've made on youtube that explains this workflow a bit and why I created it: https://youtu.be/dudvmyp7Pyg?si=N59DYTe2WE6GPlvf"
          },
          "typeVersion": 1
        },
        {
          "id": "79bf63c1-b325-4a3c-950e-30df5aef15e4",
          "name": "Sticky Note4",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -20,
            -200
          ],
          "parameters": {
            "color": 5,
            "width": 360,
            "height": 200,
            "content": "This is the entry point for the AI Agent sub-workflow.\n- Receives:\n    - 'query': The user's natural language question from the main workflow.\n- Passes data to: The IF node (for API key check, if implemented) or directly to the AI Agent."
          },
          "typeVersion": 1
        },
        {
          "id": "2486cacc-b06a-4e30-b363-456930cf0ea5",
          "name": "Sticky Note5",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            760,
            -280
          ],
          "parameters": {
            "color": 5,
            "width": 560,
            "height": 440,
            "content": "The core AI logic unit.\n- Model: Uses Google Gemini.\n- System Prompt: Instructs the AI on how to use the Context7 tools.\n- Tools: Has access to 'context7-resolve-library-id' and 'context7-get-library-docs'.\n- Memory: Connected to 'Simple Memory' using the current execution ID ({{ $execution.id }}) as the session key for conversation context.\n- Input: Receives the user's 'query'.\n- Output: Generates a response by orchestrating calls to its tools based on the query."
          },
          "typeVersion": 1
        },
        {
          "id": "f5f12aa6-d90a-419c-9baa-2c7c451a71d1",
          "name": "Sticky Note6",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            580,
            640
          ],
          "parameters": {
            "color": 6,
            "width": 360,
            "height": 200,
            "content": "Provides conversational memory for the AI Agent.\n- Type: Window Buffer Memory (keeps a sliding window of recent messages).\n- Session Key: Uses `{{ $execution.id }}`. This ensures that memory is unique to each individual execution of this sub-workflow, preventing cross-talk between different user requests."
          },
          "typeVersion": 1
        },
        {
          "id": "d2598e8e-3931-436f-a480-b4bef659bccb",
          "name": "Sticky Note7",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1100,
            640
          ],
          "parameters": {
            "color": 6,
            "width": 480,
            "height": 500,
            "content": "This node allows the AI Agent to use the external 'resolve-library-id' Context7 MCP tool.\n\n- Connection: Uses the 'smithery_context7' credential to communicate with the Context7 MCP service.\n- Action: When invoked by the AI Agent, this node makes a call to the Context7 'resolve-library-id' tool.\n- Purpose of External Tool: To convert a common library name (e.g., \"react\") into a Context7-specific ID (e.g., \"/facebook/react\").\n- AI Agent Interaction:\n    - The AI Agent's system prompt guides it to use this tool first to get a library ID.\n    - The \"Tool Parameters\" for this node are configured to use an AI-generated JSON object. The AI is prompted with: \"Generate a JSON object with the parameters for this tool. The tool expects a JSON object with one **required** key: - \"libraryName\": (string) The common name of the software library or framework. Example: {\\\"libraryName\\\": \\\"react\\\"}\"\n    - The AI Agent will construct this JSON (e.g., `{\"libraryName\": \"nextjs\"}`) and pass it to this node.\n- Output: Returns the Context7-compatible library ID to the AI Agent."
          },
          "typeVersion": 1
        },
        {
          "id": "7bebd852-75e5-427e-a3ee-781cd85f20e6",
          "name": "Sticky Note8",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1620,
            640
          ],
          "parameters": {
            "color": 6,
            "width": 520,
            "height": 500,
            "content": "This node allows the AI Agent to use the external 'get-library-docs' Context7 MCP tool.\n\n- Connection: Uses the 'smithery_context7' credential to communicate with the Context7 MCP service.\n- Action: When invoked by the AI Agent, this node makes a call to the Context7 'get-library-docs' tool.\n- Purpose of External Tool: To fetch documentation for a library, given its Context7-specific ID.\n- AI Agent Interaction:\n    - The AI Agent's system prompt guides it to use this tool after obtaining a `context7CompatibleLibraryID` (usually from the 'resolve-library-id' tool).\n    - The \"Tool Parameters\" for this node are configured to use an AI-generated JSON object. The AI is prompted with details about expected keys like `context7CompatibleLibraryID` (required), `topic` (optional), and `tokens` (optional).\n    - Example JSON the AI might construct: `{\"context7CompatibleLibraryID\": \"/vercel/next.js\", \"topic\": \"routing\"}`.\n- Output: Returns the fetched library documentation (or relevant snippets) to the AI Agent."
          },
          "typeVersion": 1
        },
        {
          "id": "f4749f9a-6f9e-45c5-b6a9-a89d4dc77dec",
          "name": "Sticky Note9",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            500,
            -1380
          ],
          "parameters": {
            "color": 7,
            "width": 1140,
            "height": 1040,
            "content": "## n8n AI Agent as an MCP Service (Context7 Docs Example)\n\n**What This Workflow Does:**\nThis n8n setup transforms a complex AI agent into a single, callable tool exposed over an MCP (Multi-Agent Collaboration Protocol) SSE (Server-Sent Events) endpoint. It allows external clients (like development environments, other AI agents, or custom applications) to leverage the power of an n8n-hosted AI agent with a simple natural language query.\n\n**How It Works:**\n1.  **`Context7 MCP Server Trigger` (This Workflow):** Creates a public SSE endpoint. Its path is kept long and random for basic security by obscurity. This trigger exposes the `call_context7_ai_agent` tool.\n2.  **`call_context7_ai_agent` (Tool Workflow Node, This Workflow):** This node is the \"tool\" offered by the MCP server. When called by a client, it doesn't do the AI work itself; instead, it invokes a separate sub-workflow.\n3.  **AI Agent Sub-Workflow (e.g., \"Context7 Smithery AI Agent MCP Server\" - ID: vqujIu65SFbZUz0n):** This is where the magic happens!\n    *   It receives the `query` from the main workflow.\n    *   A `Context7 AI Agent` node, powered by a model like Google Gemini, orchestrates the task.\n    *   The agent uses connected tools:\n        *   `context7-resolve-library-id`: To find the correct ID for a software library.\n        *   `context7-get-library-docs`: To fetch documentation for that library.\n    *   It uses `Simple Memory` (scoped by execution ID) to maintain conversational context if needed for multi-turn interactions (though this example is primarily single-shot).\n\n**Why This Pattern is Useful & The Smithery Connection:**\n\n*   **Simplifies Client-Side Logic:** Clients (like **Smithery's Roo code**, VS Code extensions, or other AI systems) don't need to manage complex multi-step reasoning, tool selection, or API calls to different services. They just call *one tool* (`call_context7_ai_agent`) with a plain language request (e.g., \"What is flexbox in Tailwind CSS?\").\n*   **Reduces Client-Side Token Usage:** All the detailed system prompts, tool descriptions for the sub-tools (resolve-id, get-docs), and the actual execution of these tools happen *within n8n*. The client only sends a short query and receives the processed result. This is incredibly efficient, especially if the client is another LLM.\n*   **Centralized Agent Capabilities:** You can update, enhance, or swap out models and tools within your n8n AI agent sub-workflow without needing to update any of the client applications that consume it.\n*   **Ideal for Agentic Systems:** This pattern is a cornerstone of building robust **agentic systems**. By encapsulating specialized AI capabilities within n8n and exposing them as callable MCP tools:\n    *   You can create a \"team\" of specialized n8n agents.\n    *   A primary agent (in Smithery, or another n8n workflow) can delegate tasks to these specialized n8n agent-tools.\n    *   It promotes modularity, reusability, and scalability in AI application development.\n*   **Leverage n8n's Ecosystem:** Build your agent with n8n's visual interface, manage credentials securely, and easily integrate with hundreds of other services if your agent needs them.\n\n**Client Configuration Example (for Roo Code/Cline):**\nTo connect to this n8n agent from a client like Roo code, you'd configure it with the MCP server details:\n```json\n\"n8n-context7-agent\": { // A descriptive name for your client\n  \"url\": \"https://YOUR_N8N_INSTANCE/mcp/YOUR_LONG_RANDOM_PATH/sse\", // Path from MCP Server Trigger\n  \"alwaysAllow\": [\n    \"call_context7_ai_agent\" // Name of the Tool Workflow node\n  ]\n}"
          },
          "typeVersion": 1
        }
      ],
      "active": true,
      "pinData": {},
      "settings": {
        "executionOrder": "v1"
      },
      "versionId": "785e4ebf-bb80-48e3-872c-40d1b9a8d14b",
      "connections": {
        "Simple Memory": {
          "ai_memory": [
            [
              {
                "node": "Context7 AI Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "call_context7_ai_agent": {
          "ai_tool": [
            [
              {
                "node": "Context7 MCP Server Trigger",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "Context7 Workflow Start": {
          "main": [
            [
              {
                "node": "Context7 AI Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Google Gemini Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "Context7 AI Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "context7-get-library-docs": {
          "ai_tool": [
            [
              {
                "node": "Context7 AI Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "context7-resolve-library-id": {
          "ai_tool": [
            [
              {
                "node": "Context7 AI Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 51,
    "workflowInfo": {
      "nodeCount": 18,
      "nodeTypes": {
        "n8n-nodes-base.stickyNote": {
          "count": 10
        },
        "n8n-nodes-mcp.mcpClientTool": {
          "count": 2
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.mcpTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.toolWorkflow": {
          "count": 1
        },
        "n8n-nodes-base.executeWorkflowTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatGoogleGemini": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Jez",
      "username": "jez",
      "bio": "I'm passionate about combining traditional web development with AI and automation to create impactful online solutions. As Founder & CEO of Jezweb, an award-winning Newcastle, Australia agency, I lead a 30+ person team delivering high-quality web design, development, and hosting services to over 3000 clients.",
      "verified": true,
      "links": [
        "https://www.jezweb.com.au"
      ],
      "avatar": "https://gravatar.com/avatar/5f6cbb73f1a61b0bea48b1fac47a94e693ca6f6bc2359eff9c7e68159698efc6?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 837,
        "icon": "fa:sign-out-alt",
        "name": "n8n-nodes-base.executeWorkflowTrigger",
        "codex": {
          "data": {
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executeworkflowtrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When Executed by Another Workflow",
          "color": "#ff6d5a"
        },
        "iconData": {
          "icon": "sign-out-alt",
          "type": "icon"
        },
        "displayName": "Execute Workflow Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1163,
        "icon": "fa:database",
        "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "For beginners"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Simple Memory"
        },
        "iconData": {
          "icon": "database",
          "type": "icon"
        },
        "displayName": "Simple Memory",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1205,
        "icon": "fa:network-wired",
        "name": "@n8n/n8n-nodes-langchain.toolWorkflow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Tools"
              ],
              "Tools": [
                "Recommended Tools"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Call n8n Workflow Tool"
        },
        "iconData": {
          "icon": "network-wired",
          "type": "icon"
        },
        "displayName": "Call n8n Workflow Tool",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1262,
        "icon": "file:google.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Google Gemini Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
        },
        "displayName": "Google Gemini Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1293,
        "icon": "file:../mcp.svg",
        "name": "@n8n/n8n-nodes-langchain.mcpTrigger",
        "codex": {
          "data": {
            "alias": [
              "Model Context Protocol",
              "MCP Server"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.mcptrigger/"
                }
              ]
            },
            "categories": [
              "AI",
              "Core Nodes",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Root Nodes",
                "Model Context Protocol"
              ],
              "Core Nodes": [
                "Other Trigger Nodes"
              ]
            }
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "MCP Server Trigger"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTgwIiBoZWlnaHQ9IjE4MCIgdmlld0JveD0iMCAwIDE5NSAxOTUiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+Cgk8ZyBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMTIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+CgkJPHBhdGggZD0iTTI1IDk3Ljg1MjhMOTIuODgyMyAyOS45NzA2QzEwMi4yNTUgMjAuNTk4IDExNy40NTEgMjAuNTk4IDEyNi44MjMgMjkuOTcwNlYyOS45NzA2QzEzNi4xOTYgMzkuMzQzMSAxMzYuMTk2IDU0LjUzOTEgMTI2LjgyMyA2My45MTE3TDc1LjU1ODEgMTE1LjE3NyIvPgoJCTxwYXRoIGQ9Ik03Ni4yNjUzIDExNC40N0wxMjYuODIzIDYzLjkxMTdDMTM2LjE5NiA1NC41MzkxIDE1MS4zOTIgNTQuNTM5MSAxNjAuNzY1IDYzLjkxMTdMMTYxLjExOCA2NC4yNjUyQzE3MC40OTEgNzMuNjM3OCAxNzAuNDkxIDg4LjgzMzggMTYxLjExOCA5OC4yMDYzTDk5LjcyNDggMTU5LjZDOTYuNjAwNiAxNjIuNzI0IDk2LjYwMDYgMTY3Ljc4OSA5OS43MjQ4IDE3MC45MTNMMTEyLjMzMSAxODMuNTIiLz4KCQk8cGF0aCBkPSJNMTA5Ljg1MyA0Ni45NDExTDU5LjY0ODIgOTcuMTQ1N0M1MC4yNzU3IDEwNi41MTggNTAuMjc1NyAxMjEuNzE0IDU5LjY0ODIgMTMxLjA4N1YxMzEuMDg3QzY5LjAyMDggMTQwLjQ1OSA4NC4yMTY4IDE0MC40NTkgOTMuNTg5NCAxMzEuMDg3TDE0My43OTQgODAuODgyMiIvPgoJPC9nPgo8L3N2Zz4K"
        },
        "displayName": "MCP Server Trigger",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 42,
        "name": "Internal Wiki"
      },
      {
        "id": 48,
        "name": "AI RAG"
      }
    ],
    "image": []
  }
}