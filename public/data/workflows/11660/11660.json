{
  "workflow": {
    "id": 11660,
    "name": "Generate consensus answers with multiple AI models & peer review system",
    "views": 415,
    "recentViews": 3,
    "totalViews": 415,
    "createdAt": "2025-12-10T14:51:09.954Z",
    "description": "## AI Council: Multi-Model Consensus with Peer Review\n\n**Inspired by [Andrej Karpathy's LLM Council](https://github.com/karpathy/llm-council)**, but rebuilt in n8n.\n\nThis workflow creates a \"council\" of AI models that independently answer your question, then peer-review each other's responses before a final arbiter synthesizes the best answer.\n\n---\n\n## Who is this for?\n\n- If you want to prepare for an upcoming meeting with different people and prep for their different views\n- find any \"blind spots\" in your view on a certain subject\n- Researchers wanting more robust AI-generated answers\n- Developers exploring multi-model architectures\n- Anyone seeking higher-quality responses through AI consensus, potentially with faster/cheaper models.\n- Teams evaluating different LLM capabilities side-by-side\n\n---\n\n## How it works\n\n1. **Ask a Question** ‚Äî Submit your query via the Chat Trigger\n2. **Individual Answers** ‚Äî Four different models (Gemini, Llama, Gemma, Mistral) independently generate responses\n3. **Peer Review** ‚Äî Each model reviews ALL answers, identifying pros, cons, and overall assessment\n4. **Final Synthesis** ‚Äî DeepSeek R1 analyzes all peer reviews and produces a refined, consensus-based final answer\n\n---\n\n## Setup Instructions\n\n### Prerequisites\n- Access to an LLM (e.g. [OpenRouter](https://openrouter.ai/) account with API credits)\n\n### Steps\n1. **Create OpenRouter credentials** in n8n:\n   - Go to *Settings ‚Üí Credentials ‚Üí Add Credential*\n   - Select \"OpenRouter\" and paste your API key\n2. **Connect all model nodes** to your OpenRouter credential. In this example I used Gemini, Llama, Gemma, Mistral and Deepseek, but you can use whatever you want. You can also use the same models, but change their parameters. Play around to find out what suits you best.\n3. **Activate the workflow** and open the Chat interface to test\n\n---\n\n## Customization Ideas\n\n- You can add as many answer and review models as you want. Do note that each AI node is executed in series, so each will add to the total duration.\n- Swap models via OpenRouter's model selector (e.g., use Claude, GPT-4, etc.)\n- Adjust the peer review prompt to represent a certain persona or with domain-specific evaluation criteria\n- Add memory nodes for multi-turn conversations\n- Connect to Slack/Discord instead of the Chat Trigger\n",
    "workflow": {
      "id": "9tESvGqGhSgQFPjF",
      "meta": {
        "instanceId": "270df961c26b06fb53c9351539b186d0c4c354b2f535667162656638ccf297c6",
        "templateCredsSetupCompleted": true
      },
      "name": "n8n AI Council",
      "tags": [
        {
          "id": "URH8Z7hv6LzKCKnt",
          "name": "AI",
          "createdAt": "2025-12-10T14:25:01.584Z",
          "updatedAt": "2025-12-10T14:25:01.584Z"
        },
        {
          "id": "u3AOoAbD80e3kNro",
          "name": "Multi-modal",
          "createdAt": "2025-12-10T14:25:04.916Z",
          "updatedAt": "2025-12-10T14:25:04.916Z"
        },
        {
          "id": "XxznXQwOfWXPBWjw",
          "name": "Peer review",
          "createdAt": "2025-12-10T14:25:26.009Z",
          "updatedAt": "2025-12-10T14:25:26.009Z"
        },
        {
          "id": "RdCDIqrxijzthfXN",
          "name": "OpenRouter",
          "createdAt": "2025-12-10T14:25:28.680Z",
          "updatedAt": "2025-12-10T14:25:28.680Z"
        }
      ],
      "nodes": [
        {
          "id": "chat-trigger",
          "name": "Chat Trigger",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            80,
            944
          ],
          "webhookId": "7c3c1ec4-0362-4d72-af0c-40be816a4230",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.4
        },
        {
          "id": "model-gemini",
          "name": "Gemini Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            912,
            480
          ],
          "parameters": {
            "model": "google/gemini-2.0-flash-001",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "merge-answers",
          "name": "Merge Answers",
          "type": "n8n-nodes-base.merge",
          "position": [
            848,
            928
          ],
          "parameters": {
            "numberInputs": 4
          },
          "typeVersion": 3.2
        },
        {
          "id": "aggregate-answers",
          "name": "Aggregate Answers",
          "type": "n8n-nodes-base.aggregate",
          "position": [
            1008,
            960
          ],
          "parameters": {
            "options": {},
            "aggregate": "aggregateAllItemData",
            "destinationFieldName": "allAnswers"
          },
          "typeVersion": 1
        },
        {
          "id": "merge-reviews",
          "name": "Merge Reviews",
          "type": "n8n-nodes-base.merge",
          "position": [
            1648,
            928
          ],
          "parameters": {
            "numberInputs": 4
          },
          "typeVersion": 3.2
        },
        {
          "id": "aggregate-reviews",
          "name": "Aggregate Reviews",
          "type": "n8n-nodes-base.aggregate",
          "position": [
            1872,
            960
          ],
          "parameters": {
            "options": {},
            "aggregate": "aggregateAllItemData",
            "destinationFieldName": "allReviews"
          },
          "typeVersion": 1
        },
        {
          "id": "agent-final",
          "name": "Final Analysis Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            2096,
            960
          ],
          "parameters": {
            "text": "=You are the final arbitrator for the AI Council. Based on all the peer reviews below, synthesize a comprehensive final answer that:\n\nProvides the shortest and best possible answer to the original question\n\nOriginal question: {{ $('Chat Trigger').item.json.chatInput }}\n\nOriginal answers:\n1) {{ $json.allAnswers[0].text }}\n2) {{ $json.allAnswers[1].text }}\n3) {{ $json.allAnswers[2].text }}\n4) {{ $json.allAnswers[3].text }}\n\nPeer Reviews:\n1) {{ $json.allReviews[0].text }}\n2) {{ $json.allReviews[1].text }}\n3) {{ $json.allReviews[2].text }}\n4) {{ $json.allReviews[3].text }}",
            "options": {},
            "promptType": "define"
          },
          "typeVersion": 3
        },
        {
          "id": "2c74ce56-4ec9-44d9-bab2-cfc29d0c5b28",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -64,
            240
          ],
          "parameters": {
            "width": 384,
            "height": 1472,
            "content": "## Ask Question\nEnter your question as you would normally ask an LLM."
          },
          "typeVersion": 1
        },
        {
          "id": "3a1eb084-f416-43cd-94ba-3487393e26c8",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            768,
            832
          ],
          "parameters": {
            "color": 2,
            "width": 368,
            "height": 336,
            "content": "## Combine Answers\nPut all answers in a combined (anonymous) list.\n"
          },
          "typeVersion": 1
        },
        {
          "id": "141ddd28-b2db-4a29-b62c-e8061d64b928",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            352,
            240
          ],
          "parameters": {
            "color": 3,
            "width": 384,
            "height": 1472,
            "content": "## Individual Model Answers\nEach model provides an answer to your question. You can have as many nodes as you want, do note that these are executed in sequence so overall duration will increase with each model."
          },
          "typeVersion": 1
        },
        {
          "id": "f61dc5e2-f7b0-48fd-b446-2fe0ec96faf9",
          "name": "Sticky Note3",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1168,
            256
          ],
          "parameters": {
            "color": 4,
            "width": 384,
            "height": 1456,
            "content": "## Peer Reviews\nEach model reviews all answers (including their own), without knowing where the answer comes from."
          },
          "typeVersion": 1
        },
        {
          "id": "d9443b31-9aef-4a7b-b1c0-818696a88a2f",
          "name": "Sticky Note4",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1584,
            640
          ],
          "parameters": {
            "color": 5,
            "width": 784,
            "height": 752,
            "content": "## Analysis and Final Answer\nA final AI node that combines the reviews and provides you with a final answer.\n\nIt is currently configured to just provide the shortest answer to the original question, but you can also instruct it to provide the reasoning behind it, include the pros/cons of each variant etc."
          },
          "typeVersion": 1
        },
        {
          "id": "model-deepseek",
          "name": "Mistral Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            912,
            1584
          ],
          "parameters": {
            "model": "mistralai/mistral-nemo",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "model-claude",
          "name": "Gemma Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            912,
            1360
          ],
          "parameters": {
            "model": "google/gemma-3n-e4b-it",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "model-gpt4",
          "name": "Llama Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            912,
            688
          ],
          "parameters": {
            "model": "meta-llama/llama-3.2-1b-instruct",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "c754839b-030a-441d-ad38-a62faa8d6c50",
          "name": "Answer Agent #4",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            432,
            1440
          ],
          "parameters": {
            "batching": {}
          },
          "typeVersion": 1.7
        },
        {
          "id": "5d9d0aa0-761e-4683-9f5e-d1116517e7a7",
          "name": "Answer Agent #3",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            432,
            1216
          ],
          "parameters": {
            "batching": {}
          },
          "typeVersion": 1.7
        },
        {
          "id": "b8d0be20-35d0-4cf4-b86e-80a5c5876af1",
          "name": "Answer Agent #2",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            416,
            624
          ],
          "parameters": {
            "batching": {}
          },
          "typeVersion": 1.7
        },
        {
          "id": "acf0f9d5-8f4b-4854-bdbd-014190d54f10",
          "name": "Answer Agent #1",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            416,
            400
          ],
          "parameters": {
            "batching": {}
          },
          "typeVersion": 1.7
        },
        {
          "id": "fe7d0b5a-8b90-4cb5-a02c-6fa4570f9503",
          "name": "Review Agent #1",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            1232,
            400
          ],
          "parameters": {
            "text": "=You are a critical peer reviewer. Review all the answers provided below and provide:\n1. Pros of each answer\n2. Cons of each answer\n3. Overall assessment\n\nOriginal question: {{ $('Chat Trigger').item.json.chatInput }}\n\nAnswers to review:\n1) {{ $json.allAnswers[0].text }}\n2) {{ $json.allAnswers[1].text }}\n3) {{ $json.allAnswers[2].text }}\n4) {{ $json.allAnswers[3].text }}",
            "batching": {},
            "promptType": "define"
          },
          "typeVersion": 1.7
        },
        {
          "id": "584948fb-9cb0-44c2-93f8-20e0ceaf630b",
          "name": "Review Agent #2",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            1232,
            624
          ],
          "parameters": {
            "text": "=You are a critical peer reviewer. Review all the answers provided below and provide:\n1. Pros of each answer\n2. Cons of each answer\n3. Overall assessment\n\nOriginal question: {{ $('Chat Trigger').item.json.chatInput }}\n\nAnswers to review:\n1) {{ $json.allAnswers[0].text }}\n2) {{ $json.allAnswers[1].text }}\n3) {{ $json.allAnswers[2].text }}\n4) {{ $json.allAnswers[3].text }}",
            "batching": {},
            "promptType": "define"
          },
          "typeVersion": 1.7
        },
        {
          "id": "eb3a8ac1-7b88-4e7b-99ea-910fb1c9443e",
          "name": "Review Agent #3",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            1248,
            1200
          ],
          "parameters": {
            "text": "=You are a critical peer reviewer. Review all the answers provided below and provide:\n1. Pros of each answer\n2. Cons of each answer\n3. Overall assessment\n\nOriginal question: {{ $('Chat Trigger').item.json.chatInput }}\n\nAnswers to review:\n1) {{ $json.allAnswers[0].text }}\n2) {{ $json.allAnswers[1].text }}\n3) {{ $json.allAnswers[2].text }}\n4) {{ $json.allAnswers[3].text }}",
            "batching": {},
            "promptType": "define"
          },
          "typeVersion": 1.7
        },
        {
          "id": "e2cd5192-d703-4382-99e6-19f4e6af41fe",
          "name": "Review Agent #4",
          "type": "@n8n/n8n-nodes-langchain.chainLlm",
          "position": [
            1248,
            1424
          ],
          "parameters": {
            "text": "=You are a critical peer reviewer. Review all the answers provided below and provide:\n1. Pros of each answer\n2. Cons of each answer\n3. Overall assessment\n\nOriginal question: {{ $('Chat Trigger').item.json.chatInput }}\n\nAnswers to review:\n1) {{ $json.allAnswers[0].text }}\n2) {{ $json.allAnswers[1].text }}\n3) {{ $json.allAnswers[2].text }}\n4) {{ $json.allAnswers[3].text }}",
            "batching": {},
            "promptType": "define"
          },
          "typeVersion": 1.7
        },
        {
          "id": "1a64df00-f262-4bff-a013-340125f61408",
          "name": "Deepseek R1 model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
          "position": [
            2096,
            1232
          ],
          "parameters": {
            "model": "deepseek/deepseek-r1",
            "options": {}
          },
          "credentials": {
            "openRouterApi": {
              "id": "credential-id",
              "name": "openRouterApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "2cf3a499-df80-4872-b819-450346c84209",
          "name": "Sticky Note5",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -656,
            240
          ],
          "parameters": {
            "color": 7,
            "width": 560,
            "height": 1472,
            "content": "## AI Council: Multi-Model Consensus with Peer Review\n\n**Inspired by [Andrej Karpathy's LLM Council](https://github.com/karpathy/llm-council)**\n\nThis workflow creates a \"council\" of AI models that independently answer your question, then peer-review each other's responses before a final arbiter synthesizes the best answer.\n\n---\n\n## Who is this for?\n\n- Researchers wanting more robust AI-generated answers\n- Developers exploring multi-model architectures\n- Anyone seeking higher-quality responses through AI consensus\n- Teams evaluating different LLM capabilities side-by-side\n\n---\n\n## How it works\n\n1. **Ask a Question** ‚Äî Submit your query via the Chat Trigger\n2. **Individual Answers** ‚Äî Four different models (Gemini, Llama, Gemma, Mistral) independently generate responses\n3. **Peer Review** ‚Äî Each model reviews ALL answers, identifying pros, cons, and overall assessment\n4. **Final Synthesis** ‚Äî DeepSeek R1 analyzes all peer reviews and produces a refined, consensus-based final answer\n\n---\n\n## Setup Instructions\n\n### Prerequisites\n- Access to an LLM (e.g. [OpenRouter](https://openrouter.ai/) account with API credits)\n\n### Steps\n1. **Create OpenRouter credentials** in n8n:\n   - Go to *Settings ‚Üí Credentials ‚Üí Add Credential*\n   - Select \"OpenRouter\" and paste your API key\n2. **Connect all model nodes** to your OpenRouter credential. In this example I used Gemini, Llama, Gemma, Mistral and Deepseek, but you can use whatever you want. You can also use the same models, but change their parameters. Play around to find out what suits you best.\n3. **Activate the workflow** and open the Chat interface to test\n\n---\n\n## Customization Ideas\n\n- Swap models via OpenRouter's model selector (e.g., use Claude, GPT-4, etc.)\n- Adjust the peer review prompt for domain-specific evaluation criteria\n- Add memory nodes for multi-turn conversations\n- Connect to Slack/Discord instead of the Chat Trigger\n"
          },
          "typeVersion": 1
        }
      ],
      "active": false,
      "pinData": {},
      "settings": {
        "timezone": "Europe/Amsterdam",
        "callerPolicy": "workflowsFromSameOwner",
        "availableInMCP": false,
        "executionOrder": "v1",
        "saveManualExecutions": true,
        "saveExecutionProgress": true,
        "saveDataErrorExecution": "all",
        "saveDataSuccessExecution": "all"
      },
      "versionId": "410b05ce-d9d9-45d1-83ff-00978f686ccd",
      "connections": {
        "Gemma Model": {
          "ai_languageModel": [
            [
              {
                "node": "Answer Agent #3",
                "type": "ai_languageModel",
                "index": 0
              },
              {
                "node": "Review Agent #3",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Llama Model": {
          "ai_languageModel": [
            [
              {
                "node": "Answer Agent #2",
                "type": "ai_languageModel",
                "index": 0
              },
              {
                "node": "Review Agent #2",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Chat Trigger": {
          "main": [
            [
              {
                "node": "Answer Agent #1",
                "type": "main",
                "index": 0
              },
              {
                "node": "Answer Agent #2",
                "type": "main",
                "index": 0
              },
              {
                "node": "Answer Agent #3",
                "type": "main",
                "index": 0
              },
              {
                "node": "Answer Agent #4",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Gemini Model": {
          "ai_languageModel": [
            [
              {
                "node": "Answer Agent #1",
                "type": "ai_languageModel",
                "index": 0
              },
              {
                "node": "Review Agent #1",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Merge Answers": {
          "main": [
            [
              {
                "node": "Aggregate Answers",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Merge Reviews": {
          "main": [
            [
              {
                "node": "Aggregate Reviews",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Mistral Model": {
          "ai_languageModel": [
            [
              {
                "node": "Answer Agent #4",
                "type": "ai_languageModel",
                "index": 0
              },
              {
                "node": "Review Agent #4",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Answer Agent #1": {
          "main": [
            [
              {
                "node": "Merge Answers",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Answer Agent #2": {
          "main": [
            [
              {
                "node": "Merge Answers",
                "type": "main",
                "index": 1
              }
            ]
          ]
        },
        "Answer Agent #3": {
          "main": [
            [
              {
                "node": "Merge Answers",
                "type": "main",
                "index": 2
              }
            ]
          ]
        },
        "Answer Agent #4": {
          "main": [
            [
              {
                "node": "Merge Answers",
                "type": "main",
                "index": 3
              }
            ]
          ]
        },
        "Review Agent #1": {
          "main": [
            [
              {
                "node": "Merge Reviews",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Review Agent #2": {
          "main": [
            [
              {
                "node": "Merge Reviews",
                "type": "main",
                "index": 1
              }
            ]
          ]
        },
        "Review Agent #3": {
          "main": [
            [
              {
                "node": "Merge Reviews",
                "type": "main",
                "index": 2
              }
            ]
          ]
        },
        "Review Agent #4": {
          "main": [
            [
              {
                "node": "Merge Reviews",
                "type": "main",
                "index": 3
              }
            ]
          ]
        },
        "Aggregate Answers": {
          "main": [
            [
              {
                "node": "Review Agent #4",
                "type": "main",
                "index": 0
              },
              {
                "node": "Review Agent #3",
                "type": "main",
                "index": 0
              },
              {
                "node": "Review Agent #2",
                "type": "main",
                "index": 0
              },
              {
                "node": "Review Agent #1",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Aggregate Reviews": {
          "main": [
            [
              {
                "node": "Final Analysis Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Deepseek R1 model": {
          "ai_languageModel": [
            [
              {
                "node": "Final Analysis Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Final Analysis Agent": {
          "main": [
            []
          ]
        }
      }
    },
    "lastUpdatedBy": 1,
    "workflowInfo": {
      "nodeCount": 25,
      "nodeTypes": {
        "n8n-nodes-base.merge": {
          "count": 2
        },
        "n8n-nodes-base.aggregate": {
          "count": 2
        },
        "n8n-nodes-base.stickyNote": {
          "count": 6
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chainLlm": {
          "count": 8
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenRouter": {
          "count": 5
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Guido X Jansen",
      "username": "gxjansen",
      "bio": "Biz & Tech Evangelist @ Spryker.com üõí #ecommerce #community #DevRel ü•ë\nCognitive Psychologist üß† #UX #HCI\nOccasional automator of things",
      "verified": false,
      "links": [
        "https://gui.do"
      ],
      "avatar": "https://gravatar.com/avatar/a750e7873cd5163766855bc84f7802a1cf2db764c245ab7260941b418126aa91?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 24,
        "icon": "file:merge.svg",
        "name": "n8n-nodes-base.merge",
        "codex": {
          "data": {
            "alias": [
              "Join",
              "Concatenate",
              "Wait"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/how-to-sync-data-between-two-systems/",
                  "icon": "üè¨",
                  "label": "How to synchronize data between two systems (one-way vs. two-way sync"
                },
                {
                  "url": "https://n8n.io/blog/supercharging-your-conference-registration-process-with-n8n/",
                  "icon": "üé´",
                  "label": "Supercharging your conference registration process with n8n"
                },
                {
                  "url": "https://n8n.io/blog/migrating-community-metrics-to-orbit-using-n8n/",
                  "icon": "üìà",
                  "label": "Migrating Community Metrics to Orbit using n8n"
                },
                {
                  "url": "https://n8n.io/blog/build-your-own-virtual-assistant-with-n8n-a-step-by-step-guide/",
                  "icon": "üë¶",
                  "label": "Build your own virtual assistant with n8n: A step by step guide"
                },
                {
                  "url": "https://n8n.io/blog/sending-automated-congratulations-with-google-sheets-twilio-and-n8n/",
                  "icon": "üôå",
                  "label": "Sending Automated Congratulations with Google Sheets, Twilio, and n8n "
                },
                {
                  "url": "https://n8n.io/blog/aws-workflow-automation/",
                  "label": "7 no-code workflow automations for Amazon Web Services"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.merge/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Flow",
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Merge"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "Merge",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1123,
        "icon": "fa:link",
        "name": "@n8n/n8n-nodes-langchain.chainLlm",
        "codex": {
          "data": {
            "alias": [
              "LangChain"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Chains",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Basic LLM Chain",
          "color": "#909298"
        },
        "iconData": {
          "icon": "link",
          "type": "icon"
        },
        "displayName": "Basic LLM Chain",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1236,
        "icon": "file:aggregate.svg",
        "name": "n8n-nodes-base.aggregate",
        "codex": {
          "data": {
            "alias": [
              "Aggregate",
              "Combine",
              "Flatten",
              "Transform",
              "Array",
              "List",
              "Item"
            ],
            "details": "",
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.aggregate/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Aggregate"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1MTIiIGhlaWdodD0iNTEyIiBmaWxsPSJub25lIj48ZyBmaWxsPSIjRkY2RDVBIiBjbGlwLXBhdGg9InVybCgjYSkiPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgZD0iTTMyIDE0OGMwLTYuNjI3IDUuMzczLTEyIDEyLTEyaDE0NmM2LjYyNyAwIDEyIDUuMzczIDEyIDEydjI0YzAgNi42MjctNS4zNzMgMTItMTIgMTJINDRjLTYuNjI3IDAtMTItNS4zNzMtMTItMTJ6bTAgOTZjMC02LjYyNyA1LjM3My0xMiAxMi0xMmgxNDZjNi42MjcgMCAxMiA1LjM3MyAxMiAxMnYyNGMwIDYuNjI3LTUuMzczIDEyLTEyIDEySDQ0Yy02LjYyNyAwLTEyLTUuMzczLTEyLTEyem0wIDk2YzAtNi42MjcgNS4zNzMtMTIgMTItMTJoMTQ2YzYuNjI3IDAgMTIgNS4zNzMgMTIgMTJ2MjRjMCA2LjYyNy01LjM3MyAxMi0xMiAxMkg0NGMtNi42MjcgMC0xMi01LjM3My0xMi0xMnoiIGNsaXAtcnVsZT0iZXZlbm9kZCIvPjxwYXRoIGQ9Ik03NCA3NmMwIDYuNjI3IDUuMzczIDEyIDEyIDEyaDExNi4yMTdjMTcuNjczIDAgMzIgMTQuMzI3IDMyIDMydjU2YzAgMjYuOTc4IDEwLjI3MiA1MS41NTcgMjcuMTE5IDcwLjAzOSA1LjA1NSA1LjU0NSA1LjA1NSAxNC4zNzcgMCAxOS45MjItMTYuODQ3IDE4LjQ4Mi0yNy4xMTkgNDMuMDYxLTI3LjExOSA3MC4wMzl2NTZjMCAxNy42NzMtMTQuMzI3IDMyLTMyIDMySDg2Yy02LjYyNyAwLTEyIDUuMzczLTEyIDEydjI0YzAgNi42MjcgNS4zNzMgMTIgMTIgMTJoMTE2LjIxN2M0NC4xODMgMCA4MC0zNS44MTcgODAtODB2LTU2YzAtMzAuOTI4IDI1LjA3Mi01NiA1Ni01NmE1Ljc4MyA1Ljc4MyAwIDAgMCA1Ljc4My01Ljc4M3YtMzYuNDM0YTUuNzgzIDUuNzgzIDAgMCAwLTUuNzgzLTUuNzgzYy0zMC45MjggMC01Ni0yNS4wNzItNTYtNTZ2LTU2YzAtNDQuMTgzLTM1LjgxNy04MC04MC04MEg4NmMtNi42MjcgMC0xMiA1LjM3My0xMiAxMnoiLz48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0zNzYgMjQ0YzAtNi42MjcgNS4zNzMtMTIgMTItMTJoMTEyYzYuNjI3IDAgMTIgNS4zNzMgMTIgMTJ2MjRjMCA2LjYyNy01LjM3MyAxMi0xMiAxMkgzODhjLTYuNjI3IDAtMTItNS4zNzMtMTItMTJ6IiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L2c+PGRlZnM+PGNsaXBQYXRoIGlkPSJhIj48cGF0aCBmaWxsPSIjZmZmIiBkPSJNMCAwaDUxMnY1MTJIMHoiLz48L2NsaXBQYXRoPjwvZGVmcz48L3N2Zz4="
        },
        "displayName": "Aggregate",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1281,
        "icon": "file:openrouter.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenRouter Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjOTRBM0I4IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHdpZHRoPSI0MCIgaGVpZ2h0PSI0MCIgdmlld0JveD0iMCAwIDI0IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjx0aXRsZT5PcGVuUm91dGVyPC90aXRsZT48cGF0aCBkPSJNMTYuODA0IDEuOTU3bDcuMjIgNC4xMDV2LjA4N0wxNi43MyAxMC4yMWwuMDE3LTIuMTE3LS44MjEtLjAzYy0xLjA1OS0uMDI4LTEuNjExLjAwMi0yLjI2OC4xMS0xLjA2NC4xNzUtMi4wMzguNTc3LTMuMTQ3IDEuMzUyTDguMzQ1IDExLjAzYy0uMjg0LjE5NS0uNDk1LjMzNi0uNjguNDU1bC0uNTE1LjMyMi0uMzk3LjIzNC4zODUuMjMuNTMuMzM4Yy40NzYuMzE0IDEuMTcuNzk2IDIuNzAxIDEuODY2IDEuMTEuNzc1IDIuMDgzIDEuMTc3IDMuMTQ3IDEuMzUybC4zLjA0NWMuNjk0LjA5MSAxLjM3NS4wOTQgMi44MjUuMDMzbC4wMjItMi4xNTkgNy4yMiA0LjEwNXYuMDg3TDE2LjU4OSAyMmwuMDE0LTEuODYyLS42MzUuMDIyYy0xLjM4Ni4wNDItMi4xMzcuMDAyLTMuMTM4LS4xNjItMS42OTQtLjI4LTMuMjYtLjkyNi00Ljg4MS0yLjA1OWwtMi4xNTgtMS41YTIxLjk5NyAyMS45OTcgMCAwMC0uNzU1LS40OThsLS40NjctLjI4YTU1LjkyNyA1NS45MjcgMCAwMC0uNzYtLjQzQzIuOTA4IDE0LjczLjU2MyAxNC4xMTYgMCAxNC4xMTZWOS44ODhsLjE0LjAwNGMuNTY0LS4wMDcgMi45MS0uNjIyIDMuODA5LTEuMTI0bDEuMDE2LS41OC40MzgtLjI3NGMuNDI4LS4yOCAxLjA3Mi0uNzI2IDIuNjg2LTEuODUzIDEuNjIxLTEuMTMzIDMuMTg2LTEuNzggNC44ODEtMi4wNTkgMS4xNTItLjE5IDEuOTc0LS4yMTMgMy44MTQtLjEzOGwuMDItMS45MDd6Ij48L3BhdGg+PC9zdmc+Cg=="
        },
        "displayName": "OpenRouter Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 5,
        "name": "Engineering"
      },
      {
        "id": 49,
        "name": "AI Summarization"
      }
    ],
    "image": []
  }
}