{
  "id": 2180,
  "slug": "2180",
  "title": "Scrape and summarize posts of a news site without RSS feed using AI and save them to a NocoDB",
  "description": "The [News Site](https://www.colt.net/resources/type/news/) from Colt, a telecom company, does not offer an RSS feed, therefore web scraping is the choice to extract and process the news.\n\nThe goal is to get only the newest posts, a summary of each post and their respective (technical) keywords.\n\nNote that the news site offers the links to each news post, but not the individual news. We collect first the links and dates of each post before extracting the newest ones.\n\nThe result is sent to a SQL database, in this case a NocoDB database.\n\nThis process happens each week thru a cron job.\n\n**Requirements**:\n- Basic understanding of CSS selectors and how to get them via browser (usually: right click &rarr; inspect)\n- ChatGPT API account - normal account is not sufficient\n- A NocoDB database - of course you may choose any type of output target\n\n**Assumptions**:\n- CSS selectors work on the news site\n- The post has a date with own CSS selector - meaning date is not part of the news content\n\n**\"Warnings\"**\n- Not every site likes to be scraped, especially not in high frequency\n- Each website is structured in different ways, the workflow may then need several adaptations.",
  "featuredImage": "/data/workflows/2180/2180.webp",
  "author": {
    "id": 101,
    "slug": "askans",
    "name": "Askan",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 29636,
  "downloads": 2963,
  "createdAt": "2024-03-17T20:13:47.141Z",
  "updatedAt": "2026-01-16T08:23:27.003Z",
  "publishedAt": "2024-03-17T20:13:47.141Z",
  "nodes": 36,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2180"
}