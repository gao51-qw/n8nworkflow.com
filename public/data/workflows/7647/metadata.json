{
  "id": 7647,
  "slug": "7647",
  "title": "Build a self-updating RAG system with OpenAI, Google Gemini, Qdrant and Google Drive",
  "description": "This workflow implements a **Retrieval-Augmented Generation (RAG) system** that integrates **Google Drive and Qdrant**.\n\nThis setup creates a powerful, **self-updating knowledge base** that provides accurate, context-aware answers to user queries.\n\n---\n\n###  Key Advantages\n\n* **Automated Knowledge Base Updates**\n  No manual intervention is required—documents in Google Drive are automatically synchronized with Qdrant.\n\n* **Efficient Search and Retrieval**\n  Vector embeddings enable fast and precise retrieval of relevant information.\n\n* **Scalable and Flexible**\n  Works with multiple documents and supports continuous growth of your dataset.\n\n* **Seamless AI Integration**\n  Combines **OpenAI embeddings** for vectorization and **Google Gemini** for high-quality natural language answers.\n\n* **Metadata-Enhanced Storage**\n  Each document stores metadata (file ID and name), making it easy to manage and track document versions.\n\n* **End-to-End RAG Pipeline**\n  From document ingestion to AI-powered Q\\&A, everything is handled inside one n8n workflow.\n\n---\n\n### **How It Works**  \nThis workflow implements a **Retrieval-Augmented Generation (RAG)** system that automatically processes, stores, and retrieves document information for AI-powered question answering. Here’s how it functions:\n\n1. **Document Processing & Vectorization**:\n   - The system monitors a specified **Google Drive folder** for new or updated files.\n   - When a file is added or modified, it is downloaded and split into manageable chunks using a **Recursive Character Text Splitter**.\n   - Each chunk is converted into vector embeddings using **OpenAI's embedding model**.\n   - These vectors, along with metadata (file ID, file name), are stored in a **Qdrant vector database**.\n\n2. **Automatic Updates**:\n   - The workflow includes a mechanism to **delete old vectors** associated with an updated file before inserting the new ones, ensuring the knowledge base remains current.\n\n3. **Query Handling & Response Generation**:\n   - When a user sends a chat message (via a chat trigger), the system:\n     - Retrieves the most relevant document chunks from **Qdrant** based on the query's semantic similarity.\n     - Uses a **Google Gemini** language model to generate a context-aware answer grounded in the retrieved documents.\n   - This provides accurate, source-based responses instead of relying solely on the AI's internal knowledge.\n\n4. **Initial Setup & Maintenance**:\n   - The workflow can be triggered manually to **create the Qdrant collection** or **clear all existing data**.\n   - It processes all existing files in the Drive folder during initial setup, populating the vector store.\n\n---\n\n### **Set Up Steps**  \nTo configure this workflow, follow these steps:\n\n**STEP 1: Create Qdrant Collection**\n- Replace `QDRANTURL` in the **\"Create collection\"** and **\"Clear collection\"** nodes with your Qdrant instance URL (e.g., `http://your-qdrant-host:6333`).\n- Replace `COLLECTION` with your desired collection name.\n- Ensure the Qdrant API credentials are correctly set in the respective HTTP Request nodes.\n\n**STEP 2: Configure Google Drive Access**\n- Set up OAuth credentials for **Google Drive** to allow the workflow to:\n  - Read files from a specific folder .\n  - Download files for processing.\n- Update the **Folder ID** in the **\"Search files\"** and **\"Update?\"** trigger nodes to point to your target Google Drive folder.\n\n**STEP 3: Set Up AI Models**\n- Configure the **OpenAI API** credentials in the **Embeddings** nodes for generating text embeddings.\n- Configure the **Google Gemini (PaLM) API** credentials in the **Google Gemini Chat Model** node for generating answers.\n\n**STEP 4: Configure Metadata**\n- The system automatically attaches metadata (`file_id`, `file_name`) to each document chunk. This is set in the **Default Data Loader** nodes.\n- This metadata is crucial for identifying the source of information and for the update mechanism.\n\n**STEP 5: Test the RAG System**\n- The workflow includes a chat trigger (**\"When chat message received\"**) for testing.\n- Send a query to test the retrieval and answer generation process.\n\n---\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
  "featuredImage": "/data/workflows/7647/7647.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "AI RAG",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1284,
  "downloads": 128,
  "createdAt": "2025-08-20T13:56:39.197Z",
  "updatedAt": "2026-01-16T08:51:34.590Z",
  "publishedAt": "2025-08-20T13:56:39.197Z",
  "nodes": 32,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7647"
}