{
  "id": 4300,
  "slug": "4300",
  "title": "Extract and structure Thai documents to Google Sheets using Typhoon OCR and Llama 3.1",
  "description": "![20250522_93100.png](fileId:1356)\n⚠️ **Note:** This template requires a community node and works **only on self-hosted** n8n installations. It uses the Typhoon OCR Python package and custom command execution. Make sure to install required dependencies locally.\n\n---\n\n## Who is this for?\n\nThis template is for developers, operations teams, and automation builders in Thailand (or any Thai-speaking environment) who regularly process PDFs or scanned documents in Thai and want to extract structured text into a Google Sheet.\n\n### It is ideal for:\n* Local government document processing\n* Thai-language enterprise paperwork\n* AI automation pipelines requiring Thai OCR\n\n---\n\n## What problem does this solve?\n\nTyphoon OCR is one of the most accurate OCR tools for Thai text. However, integrating it into an end-to-end workflow usually requires manual scripting and data wrangling.\n\n### This template solves that by:\n* Running Typhoon OCR on PDF files\n* Using AI to extract structured data fields\n* Automatically storing results in Google Sheets\n\n---\n\n## What this workflow does\n\n1. **Trigger**: Run manually or from any automation source\n2. **Read Files**: Load local PDF files from a `doc/` folder\n3. **Execute Command**: Run Typhoon OCR on each file using a Python command\n4. **LLM Extraction**: Send the OCR markdown to an AI model (e.g., GPT-4 or OpenRouter) to extract fields\n5. **Code Node**: Parse the LLM output as JSON\n6. **Google Sheets**: Append structured data into a spreadsheet\n\n---\n\n##  Setup\n\n### 1. **Install Requirements**\n\n* Python 3.10+\n* `typhoon-ocr`: `pip install typhoon-ocr`\n* Install [Poppler](https://github.com/oschwartz10612/poppler-windows/releases/) and add to system PATH (needed for `pdftoppm`, `pdfinfo`)\n\n### 2. **Create folders**\n\n* Create a folder called `doc` in the same directory where n8n runs (or mount it via Docker)\n\n### 3. **Google Sheet**\n\nCreate a Google Sheet with the following column headers:\n\n| book\\_id | date | subject | detail | signed\\_by | signed\\_by2 | contact | download\\_url |\n| -------- | ---- | ------- | ------ | ---------- | ----------- | ------- | ------------- |\n\nYou can use this [example Google Sheet](https://docs.google.com/spreadsheets/d/1h70cJyLj5i2j0Ag5kqp93ccZjjhJnqpLmz-ee5r4brU) as a reference.\n\n### 4. **API Key**\n\nExport your `TYPHOON_OCR_API_KEY` and `OPENAI_API_KEY` in your environment (or set inside the command string in `Execute Command` node).\n\n---\n\n## How to customize this workflow\n\n* Replace the LLM provider in the `Basic LLM Chain` node (currently supports OpenRouter)\n* Change output fields to match your data structure (adjust the prompt and Google Sheet headers)\n* Add trigger nodes (e.g., Dropbox Upload, Webhook) to automate input\n\n---\n\n## About Typhoon OCR\n\n[Typhoon](https://docs.opentyphoon.ai/en/) is a multilingual LLM and toolkit optimized for Thai NLP. It includes `typhoon-ocr`, a Python OCR library designed for Thai-centric documents. It is open-source, highly accurate, and works well in automation pipelines. Perfect for government paperwork, PDF reports, and multilingual documents in Southeast Asia.\n\n---",
  "featuredImage": "/data/workflows/4300/4300.webp",
  "author": {
    "id": 101,
    "slug": "jaruphatj",
    "name": "Jaruphat J.",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI Summarization"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 3265,
  "downloads": 326,
  "createdAt": "2025-05-22T02:34:50.107Z",
  "updatedAt": "2026-01-16T08:33:45.937Z",
  "publishedAt": "2025-05-22T02:34:50.107Z",
  "nodes": 8,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4300"
}