{
  "workflow": {
    "id": 8787,
    "name": "Build an intelligent Q&A bot with Lookio Knowledge Base and GPT",
    "views": 361,
    "recentViews": 0,
    "totalViews": 361,
    "createdAt": "2025-09-20T19:53:32.637Z",
    "description": "Build a powerful AI chatbot that provides precise answers from your own company's knowledge base. This template provides a smart AI agent that connects to **Lookio**, a platform where you can easily upload your documents (from Notion, Jira, Slack, etc.) to create a dedicated knowledge source.\n\nWhat makes this agent \"smart\" is its efficiency. It's configured to handle simple greetings and small talk on its own, only using its powerful (and paid) knowledge retrieval tool when a user asks a genuine question. This cost-saving logic makes it perfect for building production-ready internal helpdesks, customer support bots, or any application where you need accurate, source-based answers.\n\n## **Who is this for?**\n\n* **Customer support teams:** Build internal bots that help agents find answers instantly from your support documentation and knowledge bases.\n* **Product & engineering teams:** Create a chatbot that can answer technical questions based on your product documentation or internal wikis.\n* **HR departments:** Deploy an internal assistant that can answer employee questions based on company handbooks, policies, and procedures.\n* **Any business with a knowledge base:** Provide an interactive, conversational way for employees or customers to access information locked away in your documents.\n\n## **What problem does this solve?**\n\n* **Provides accurate, grounded answers:** Ensures the AI agent's responses are based on your trusted, private documents, not the open internet, which prevents factual errors and \"hallucinations.\"\n* **Makes your knowledge accessible:** Transforms your static documents and knowledge bases into an interactive, 24/7 conversational resource.\n* **Optimizes for cost and efficiency:** The agent is intelligent enough to handle simple small talk without making unnecessary API calls to your knowledge base, saving you credits and money.\n* **Simplifies RAG setup:** Provides a ready-to-use template for a common RAG (Retrieval-Augmented Generation) pattern, with the complexities of document management and retrieval handled by the Lookio platform.\n\n\n## **How it works**\n\n1.  **First, build your knowledge base in Lookio:** The process starts on the [Lookio](https://www.lookio.app/) platform. You upload your documents (from Notion, Jira, PDFs, etc.) and create an \"assistant\" which becomes your secure, queryable knowledge base.\n2.  **A user asks a question:** The n8n workflow begins when a user sends a message via the **Chat Trigger**.\n3.  **The agent makes a decision:** The **AI Knowledge Agent**, guided by its system prompt, analyzes the user's message. If it's a simple greeting like \"hi,\" it will respond directly. If it's a substantive question that requires specific knowledge, it decides to use its \"Query knowledge base\" tool.\n4.  **Query the Lookio knowledge base:** The agent passes the user's question to the **HTTP Request Tool**. This tool securely calls the Lookio API with your specific Assistant ID and API key.\n5.  **Deliver the fact-based answer:** Lookio searches your documents, synthesizes a precise answer, and sends it back to the workflow. The n8n agent then presents this answer to the user in the chat interface.\n\n## Architectural Approaches to RAG in n8n with Lookio\n\nFrom a workflow perspective, integrating **RAG** natively in n8n involves orchestrating multiple nodes for data handling, embedding, and vector searches. This method provides high visibility and control over each step. \n\nAn alternative architectural pattern is to use an external [RAG service like Lookio](https://www.lookio.app/), which consolidates these steps into a single HTTP Request node. This simplifies the workflow's structure by abstracting the multi-stage RAG process into one API endpoint.\n\n\n\n## **Setup**\n\n1.  **Set up your Lookio assistant (Prerequisite):** First, go to [Lookio](https://www.lookio.app/), sign up (you get 50 free credits), create an assistant with your documents, and from your settings, copy your **API Key** and **Assistant ID**.\n2.  **Configure the Lookio tool:** In the **Query knowledge base** (HTTP Request Tool) node:\n    * Replace the `&lt;your-assistant-id&gt;` placeholder with your actual Assistant ID.\n    * Replace the `&lt;your-lookio-api-key&gt;` placeholder with your actual API Key.\n3.  **Connect your AI model:** In the **OpenAI Chat Model** node, connect your AI provider credentials.\n4.  **Activate the workflow.** Your smart knowledge base agent is now live and ready to chat!\n\n## **Taking it further**\n\n* **Adjust retrieval quality:** In the **Query knowledge base** node, you can change the `query_mode` from `flash` (fastest) to `deep` for higher quality but slightly slower answers, depending on your needs.\n* **Add more tools:** Enhance your agent by giving it other tools, like a web search for when the internal knowledge base doesn't have an answer, or a calculator for performing computations.\n* **Deploy it anywhere:** Swap the **Chat Trigger** for a **Slack** or **Discord** trigger to deploy your agent right where your team works.\n\n",
    "workflow": {
      "nodes": [
        {
          "id": "f4ead8e8-e78b-490d-9cf0-03907fc6e16f",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            -464,
            16
          ],
          "webhookId": "eef2977c-81d7-4102-8edf-d771d9da2118",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.3
        },
        {
          "id": "4cf321ba-b749-4223-aabd-e9a12e78caf5",
          "name": "Simple Memory",
          "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
          "position": [
            -80,
            336
          ],
          "parameters": {},
          "typeVersion": 1.3
        },
        {
          "id": "fa2f423c-e98b-459d-8613-1d5c5a2db2ac",
          "name": "OpenAI Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            -368,
            384
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4.1-mini"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "7607267f-91b6-4a36-87bb-3e1d753bbd71",
          "name": "AI Knowledge Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            -184,
            16
          ],
          "parameters": {
            "options": {
              "systemMessage": "=You are a helpful assistant that answers the user based on a knowledge base.\n\nWhenever the user query requires specific knowledge (most queries except empty queries like \"hi\"), call the tool \"Query knowledge base\" with a question to have it output an answer based on the knowledge base.\n\nIf the output from the knowledge base tool indicates that the knowledge base doesn't contain enough insights to answer, communicate this to the user transparently."
            }
          },
          "typeVersion": 2.2
        },
        {
          "id": "2cde1ec6-7d21-4955-acbe-4434cfdb9c7c",
          "name": "Query knowledge base",
          "type": "n8n-nodes-base.httpRequestTool",
          "position": [
            240,
            352
          ],
          "parameters": {
            "url": "https://api.lookio.app/webhook/query",
            "method": "POST",
            "options": {},
            "sendBody": true,
            "sendHeaders": true,
            "bodyParameters": {
              "parameters": [
                {
                  "name": "query",
                  "value": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters0_Value', `The query to the knowledge base, in the form of a question`, 'string') }}"
                },
                {
                  "name": "assistant_id",
                  "value": "<your-assistant-id>"
                },
                {
                  "name": "query_mode",
                  "value": "flash"
                }
              ]
            },
            "toolDescription": "Call this tool when the knowledge base is required to answer the user query.",
            "headerParameters": {
              "parameters": [
                {
                  "name": "api_key",
                  "value": "<your-lookio-api-key>"
                }
              ]
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "a79ec48e-1888-477f-b299-2fe05fe509c6",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            112,
            320
          ],
          "parameters": {
            "color": 6,
            "width": 336,
            "height": 400,
            "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Lookio tool\n\nThe agent calls this tool to get answers based on the knowledge base you've built in Lookio.\n- Add your [Lookio](https://www.lookio.app/) API key\n- Specify the ID of the Lookio assistant to query"
          },
          "typeVersion": 1
        },
        {
          "id": "f2b01dab-f1d3-4947-b6c1-7c8390aca275",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -512,
            320
          ],
          "parameters": {
            "color": 5,
            "width": 336,
            "height": 400,
            "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## AI model\n\nThe core AI model of your agent. Connect your OpenAI API key or switch to your favorite LLM provider."
          },
          "typeVersion": 1
        },
        {
          "id": "fda124c2-4fd0-4682-b619-78139b0f4b8b",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -240,
            -224
          ],
          "parameters": {
            "color": 4,
            "width": 336,
            "height": 400,
            "content": "## The agent\n\nThis agent will distribute the relevant questions to Lookio via the \"Query knowledge base\" tool. Feel free to provide more context in its system message and add instructions when it comes to the format or style of responses?"
          },
          "typeVersion": 1
        },
        {
          "id": "54e7d0d6-2bec-4363-bdba-da6dadd72163",
          "name": "Sticky Note3",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -1088,
            -224
          ],
          "parameters": {
            "width": 496,
            "height": 944,
            "content": "# AI Agent for Your Lookio Knowledge Base\n\nThis agent intelligently answers questions using a knowledge base you build in Lookio. It's configured to handle simple greetings on its own, and only queries your Lookio knowledge base for real questions to save API credits.\n\n## **How to use**\n\n1.  **Set up in Lookio:** First, create an assistant in **Lookio** with your company documents and get your **API Key** & **Assistant ID**.\n2.  **Configure the Tool:** In the `Query knowledge base` node, replace the placeholder `<your-lookio-api-key>` and `<your-assistant-id>` with your own.\n3.  **Connect your AI Model:** Add your credentials to the `OpenAI Chat Model` node.\n4.  **Activate & Chat!**\n\n\n*A template developed by Guillaume Duvernay*"
          },
          "typeVersion": 1
        }
      ],
      "connections": {
        "Simple Memory": {
          "ai_memory": [
            [
              {
                "node": "AI Knowledge Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "OpenAI Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "AI Knowledge Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Query knowledge base": {
          "ai_tool": [
            [
              {
                "node": "AI Knowledge Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "AI Knowledge Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 9,
      "nodeTypes": {
        "n8n-nodes-base.stickyNote": {
          "count": 4
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "n8n-nodes-base.httpRequestTool": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Guillaume Duvernay",
      "username": "duv",
      "bio": "AI and automation expert",
      "verified": true,
      "links": [
        "https://www.linkedin.com/in/guillaume-duvernay/"
      ],
      "avatar": "https://gravatar.com/avatar/1e93ed2388069da40b3202c5566318982166f1a0b4c4c35c4802c8ca4de79991?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTM2Ljg2NzEgMTYuMzcxOEMzNy43NzQ2IDEzLjY0OCAzNy40NjIxIDEwLjY2NDIgMzYuMDEwOCA4LjE4NjYxQzMzLjgyODIgNC4zODY1MyAyOS40NDA3IDIuNDMxNDkgMjUuMTU1NiAzLjM1MTUxQzIzLjI0OTMgMS4yMDM5NiAyMC41MTA1IC0wLjAxNzMxNDggMTcuNjM5MiAwLjAwMDE4NTUzM0MxMy4yNTkxIC0wLjAwOTgxNDY4IDkuMzcyNzMgMi44MTAyNSA4LjAyNTIgNi45Nzc4M0M1LjIxMTM5IDcuNTU0MSAyLjc4MjU4IDkuMzE1MzggMS4zNjEzIDExLjgxMTdDLTAuODM3NDkzIDE1LjYwMTggLTAuMzM2MjMyIDIwLjM3OTQgMi42MDEzMyAyMy42Mjk0QzEuNjkzODEgMjYuMzUzMiAyLjAwNjMyIDI5LjMzNzEgMy40NTc2IDMxLjgxNDZDNS42NDAxNSAzNS42MTQ3IDEwLjAyNzcgMzcuNTY5NyAxNC4zMTI4IDM2LjY0OTdDMTYuMjE3OSAzOC43OTczIDE4Ljk1NzkgNDAuMDE4NSAyMS44MjkyIDM5Ljk5OThDMjYuMjExOCA0MC4wMTEgMzAuMDk5NCAzNy4xODg1IDMxLjQ0NjkgMzMuMDE3MUMzNC4yNjA4IDMyLjQ0MDkgMzYuNjg5NiAzMC42Nzk2IDM4LjExMDggMjguMTgzM0M0MC4zMDcxIDI0LjM5MzIgMzkuODA0NiAxOS42MTk0IDM2Ljg2ODMgMTYuMzY5M0wzNi44NjcxIDE2LjM3MThaTTIxLjgzMTcgMzcuMzg2QzIwLjA3OCAzNy4zODg1IDE4LjM3OTIgMzYuNzc0NyAxNy4wMzI5IDM1LjY1MDlDMTcuMDk0MSAzNS42MTg0IDE3LjIwMDQgMzUuNTU5NyAxNy4yNjkxIDM1LjUxNzJMMjUuMjM0MyAzMC45MTcxQzI1LjY0MTggMzAuNjg1OCAyNS44OTE4IDMwLjI1MjEgMjUuODg5MyAyOS43ODMzVjE4LjU1NDNMMjkuMjU1NyAyMC40OTgxQzI5LjI5MTkgMjAuNTE1NiAyOS4zMTU3IDIwLjU1MDYgMjkuMzIwNyAyMC41OTA2VjI5Ljg4OTZDMjkuMzE1NyAzNC4wMjQ3IDI1Ljk2NjggMzcuMzc3MiAyMS44MzE3IDM3LjM4NlpNNS43MjY0IDMwLjUwNzFDNC44NDc2MyAyOC45ODk2IDQuNTMxMzcgMjcuMjEwOCA0LjgzMjYzIDI1LjQ4NDVDNC44OTEzOCAyNS41MTk1IDQuOTk1MTMgMjUuNTgzMiA1LjA2ODg4IDI1LjYyNTdMMTMuMDM0MSAzMC4yMjU4QzEzLjQzNzggMzAuNDYyMSAxMy45Mzc4IDMwLjQ2MjEgMTQuMzQyOCAzMC4yMjU4TDI0LjA2NjggMjQuNjEwN1YyOC40OTgzQzI0LjA2OTMgMjguNTM4MyAyNC4wNTA1IDI4LjU3NyAyNC4wMTkzIDI4LjYwMkwxNS45Njc5IDMzLjI1MDlDMTIuMzgxNSAzNS4zMTU5IDcuODAxNDQgMzQuMDg4NCA1LjcyNzY1IDMwLjUwNzFINS43MjY0Wk0zLjYzMDEgMTMuMTIwNUM0LjUwNTEyIDExLjYwMDQgNS44ODY0IDEwLjQzNzkgNy41MzE0NCA5LjgzNDE1QzcuNTMxNDQgOS45MDI5IDcuNTI3NjkgMTAuMDI0MiA3LjUyNzY5IDEwLjEwOTJWMTkuMzEwNkM3LjUyNTE5IDE5Ljc3ODEgNy43NzUxOSAyMC4yMTE5IDguMTgxNDUgMjAuNDQzMUwxNy45MDU0IDI2LjA1N0wxNC41MzkxIDI4LjAwMDhDMTQuNTA1MyAyOC4wMjMzIDE0LjQ2MjggMjguMDI3IDE0LjQyNTMgMjguMDEwOEw2LjM3MjY2IDIzLjM1ODJDMi43OTM4MyAyMS4yODU2IDEuNTY2MzEgMTYuNzA2OCAzLjYyODg1IDEzLjEyMTdMMy42MzAxIDEzLjEyMDVaTTMxLjI4ODIgMTkuNTU2OUwyMS41NjQyIDEzLjk0MTdMMjQuOTMwNiAxMS45OTkyQzI0Ljk2NDMgMTEuOTc2NyAyNS4wMDY4IDExLjk3MjkgMjUuMDQ0MyAxMS45ODkyTDMzLjA5NyAxNi42MzhDMzYuNjgyMSAxOC43MDkzIDM3LjkxMDggMjMuMjk1NyAzNS44Mzk1IDI2Ljg4MDhDMzQuOTYzMyAyOC4zOTgzIDMzLjU4MzIgMjkuNTYwOCAzMS45Mzk1IDMwLjE2NThWMjAuNjg5NEMzMS45NDMyIDIwLjIyMTkgMzEuNjk0NSAxOS43ODk0IDMxLjI4OTQgMTkuNTU2OUgzMS4yODgyWk0zNC42MzgzIDE0LjUxNDJDMzQuNTc5NSAxNC40NzggMzQuNDc1OCAxNC40MTU1IDM0LjQwMiAxNC4zNzNMMjYuNDM2OCA5Ljc3Mjg5QzI2LjAzMzEgOS41MzY2NCAyNS41MzMxIDkuNTM2NjQgMjUuMTI4MSA5Ljc3Mjg5TDE1LjQwNDEgMTUuMzg4VjExLjUwMDRDMTUuNDAxNiAxMS40NjA0IDE1LjQyMDQgMTEuNDIxNyAxNS40NTE2IDExLjM5NjdMMjMuNTAzIDYuNzUxNThDMjcuMDg5NCA0LjY4Mjc5IDMxLjY3NDUgNS45MTQwNiAzMy43NDIgOS41MDE2NEMzNC42MTU4IDExLjAxNjcgMzQuOTMyIDEyLjc5MDUgMzQuNjM1OCAxNC41MTQySDM0LjYzODNaTTEzLjU3NDEgMjEuNDQzMUwxMC4yMDY1IDE5LjQ5OTRDMTAuMTcwMiAxOS40ODE5IDEwLjE0NjUgMTkuNDQ2OCAxMC4xNDE1IDE5LjQwNjhWMTAuMTA3OUMxMC4xNDQgNS45Njc4MSAxMy41MDI4IDIuNjEyNzQgMTcuNjQyOSAyLjYxNTI0QzE5LjM5NDIgMi42MTUyNCAyMS4wODkyIDMuMjMwMjUgMjIuNDM1NSA0LjM1MDI4QzIyLjM3NDMgNC4zODI3OCAyMi4yNjkzIDQuNDQxNTMgMjIuMTk5MiA0LjQ4NDAzTDE0LjIzNDEgOS4wODQxM0MxMy44MjY2IDkuMzE1MzggMTMuNTc2NiA5Ljc0Nzg5IDEzLjU3OTEgMTAuMjE2N0wxMy41NzQxIDIxLjQ0MDZWMjEuNDQzMVpNMTUuNDAyOSAxNy41MDA2TDE5LjczNDIgMTQuOTk5M0wyNC4wNjU1IDE3LjQ5OTNWMjIuNTAwN0wxOS43MzQyIDI1LjAwMDdMMTUuNDAyOSAyMi41MDA3VjE3LjUwMDZaIiBmaWxsPSIjN0Q3RDg3Ii8+Cjwvc3ZnPgo="
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1163,
        "icon": "fa:database",
        "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "For beginners"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Simple Memory"
        },
        "iconData": {
          "icon": "database",
          "type": "icon"
        },
        "displayName": "Simple Memory",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 40,
        "name": "Support Chatbot"
      },
      {
        "id": 48,
        "name": "AI RAG"
      }
    ],
    "image": []
  }
}