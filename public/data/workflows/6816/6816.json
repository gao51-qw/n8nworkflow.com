{
  "workflow": {
    "id": 6816,
    "name": "Create custom reasoning patterns for AI agents with GraphRAG & knowledge ontology",
    "views": 967,
    "recentViews": 0,
    "totalViews": 967,
    "createdAt": "2025-08-01T16:29:18.234Z",
    "description": "## Teach your AI agent HOW to think, not WHAT to think\n\n[![Video tutorial](https://img.youtube.com/vi/jhqBb3nuyAY/sddefault.jpg)](https://www.youtube.com/watch?v=jhqBb3nuyAY)\n\nThis workflow demonstrates how you can build an AI agent in n8n that uses the reasoning logic you define. So an LLM learns a way of thinking, which you can then apply to multiple problems: \n\n- Make an **AI chatbot that knows how to convince anybody** using the \"Getting to Yes\" method\n- Build an **LLM workflow that uses Ray Dalio's principles** to spot investment opportunities\n- Create an AI agent crew of **interdisciplinary thinkers**: e.g. a specialist in psychology who gives an advice on education programmes.\n\n![InfraNodus knowledge graph](https://infranodus.com/images/front/blog/reasoning-knowledge-graph-infranodus.png)\n\n\n## How it works\nThis template uses the n8n AI agent node as an orchestrating agent that has access to a certain reasoning logic defined by an [InfraNodus knowledge graph](https://infranodus.com).\n\nThis graph contains a list of reasoning rules (ontology), which is extracted to provide an advice that is relevant to the original prompt. It uses GraphRAG under the hood to traverse the parts of the graph relevant to the query.\n\nThis advice and the reasoning logic extracted is then used by the AI agent to generate a response that is relevant to the user's query but that uses the reasoning logic provided through the graph.\n\nHere's a description step by step:\n\n- The user submits a question using the AI chatbot (n8n interface, in this case, a web form that can be embedded to any website, or a webhook that can be connected to a Telegram / WhatsApp bot)\n- The AI agent node accesses the Reasoning Logic HTTP InfraNodus nodes. The description of AI agent and the description of the reasoning InfraNodus node provides the agent with an understanding of how to rephrase the original question to retrieve relevant reasoning logic.\n-  The request is sent to the InfraNodus node. It provides a response that contains the reasoning logic needed to answer the question.\n- This reasoning logic is then sent back to an LLM along with the original query to produce the response.\n\n\nInfraNodus uses **[GraphRAG](https://infranodus.com/docs/graph-rag-knowledge-graph)** under the hood: \n- convert user query into graph\n- find the overlap with the reasoning graph (using n=1 or more hops to include more relations)\n- use similarity search to get additional parts of the graph\n- generate a response based on this intersection as well as the context provided\n- provide information about the underlying structure\n\n## How to use\n\nYou need an [InfraNodus account](https://infranodus.com/use-case/ai-knowledge-graphs) to use this workflow. \n\n- Create an InfraNodus account\n- Get the API key at [https://infranodus.com/api-access](https://infranodus.com/api-access) and create a Bearer authorization key for the InfraNodus HTTP nodes.\n- Create a separate knowledge graph for the reasoning logic\n- Use the [AI ontology creator](https://infranodus.com/import/ai-ontologies) to generate an ontology for a certain topic or text using AI. Then augment it with your own data. See our [help article on creating ontologies](https://support.noduslabs.com/hc/en-us/articles/18301655686172-Generate-Knowledge-Graphs-and-Ontologies-in-Plain-Text) for detailed instructions\n- For each graph, go to the workflow, paste the name of the graph into the request JSON `body` `name` field.\n- Change the system prompt in the AI agent node to reflect the nature of your reasoning logic. For instance, if it's an expert in interactions, you specify that, if it's a psychology expert, you need to specify that as well.\n- Change the description of the reasoning node (HTTP tool). Use the InfraNodus `summary` and `Project Notes` &gt; `RAG prompt` buttons to generate a description for the reasoning logic, which you can then reuse in your workflow.\n- add the LLM key to the OpenAI node (or to the model of your choice) and launch the workflow\n\n## Requirements\n\n- An [InfraNodus](https://infranodus.com/use-case/ai-knowledge-graphs) account and API key\n- An OpenAI (or any other LLM) API key\n\n\n## Customizing this workflow\n\nYou can use this same workflow with a Telegram bot, so you can interact with it using Telegram. There are many more customizations available. \n\nCheck out the **complete guide** at [https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts](https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts)\n\nAlso check out the **video tutorial** with a demo:\n\n[![Video tutorial](https://img.youtube.com/vi/jhqBb3nuyAY/sddefault.jpg)](https://www.youtube.com/watch?v=jhqBb3nuyAY)\n\n\n\n\n",
    "workflow": {
      "id": "a31fIa8ZmGBq07CK",
      "meta": {
        "instanceId": "2a26454b0172ffcb8d70ba77c235b1209f92cd71bf06c79ba609c7173b416d68",
        "templateCredsSetupCompleted": true
      },
      "name": "Reasoning Expert with Graph RAG Knowledge Ontology",
      "tags": [],
      "nodes": [
        {
          "id": "aa3aae5b-5652-4bd8-a1bf-986eb9765ab3",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            -480,
            -220
          ],
          "webhookId": "2dfe79eb-bbb0-49ed-83c9-cb3e2a49602f",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.1
        },
        {
          "id": "7c700795-faff-412e-aecb-4624439c1246",
          "name": "OpenAI Chat Model",
          "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
          "position": [
            -360,
            200
          ],
          "parameters": {
            "model": {
              "__rl": true,
              "mode": "list",
              "value": "gpt-4o-mini"
            },
            "options": {}
          },
          "credentials": {
            "openAiApi": {
              "id": "credential-id",
              "name": "openAiApi Credential"
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "4a09a841-6743-4d8f-8cbc-33b64b2d21bb",
          "name": "Simple Memory",
          "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
          "position": [
            -160,
            200
          ],
          "parameters": {},
          "typeVersion": 1.3
        },
        {
          "id": "c388dd69-24a6-422b-a08c-4a2046a75997",
          "name": "Interaction Dynamics Expert",
          "type": "n8n-nodes-base.httpRequestTool",
          "position": [
            200,
            200
          ],
          "parameters": {
            "url": "https://infranodus.com/api/v1/graphAndAdvice?doNotSave=true&addStats=true&optimize=develop&includeStatements=true&includeGraphSummary=true&includeGraph=false",
            "method": "POST",
            "options": {},
            "sendBody": true,
            "authentication": "genericCredentialType",
            "bodyParameters": {
              "parameters": [
                {
                  "name": "name",
                  "value": "eightos_system"
                },
                {
                  "name": "requestMode",
                  "value": "response"
                },
                {
                  "name": "prompt",
                  "value": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters2_Value', `User query to send to the expert`, 'string') }}"
                },
                {
                  "name": "aiTopics",
                  "value": "true"
                }
              ]
            },
            "genericAuthType": "httpBearerAuth",
            "toolDescription": "You are an expert in interaction dynamics who provides advice on the best way to interact with people and situations. You receive information about the dynamics of an interaction and then provide advice for what to do next based on these dynamics.\n\n<MainConcepts>: \n[[escalation]], [[adaptive_strategy]], [[metastability]], [[polysingularity]]\n</MainConcepts>\n\n\n<MainTopics>: \n1. Tension Dynamics: [[escalation]] [[engagement]] [[tension_release]] \n2. Synergistic Growth: [[synergy]] [[assimilation]] [[common_good]] \n3. Ethical Narratives: [[∞os_private_ethics]] [[narrative_activation_formula]] [[environment]] \n4. Chaotic Stability: [[metastability]] [[chaotic_itinerancy]] [[dynamic_stability]] \n5. Adaptive Fluidity: [[adaptive_strategy]] [[fluidity]] [[environmental_input]] \n6. Diverse Governance: [[polysingularity]] [[hedging_preset]] [[holocracy]] \n</MainTopics>\n\n<TopicalGap>: \n4. Chaotic Stability: [[metastability]] [[chaotic_itinerancy]] \n6. Diverse Governance: [[polysingularity]] [[hedging_preset]] \n</TopicalGap>\n\n<ConceptualGateways> \n[[common_good]] [[chaotic_itinerancy]] [[hedging_preset]] [[environmental_input]] [[synergy]] [[narrative_activation_formula]] [[∞os_private_ethics]] [[environment]] [[fluidity]] [[holocracy]] [[assimilation]] [[panarchy]] [[discipline_preset]] \n</ConceptualGateways>\n\n\n<Relations>: \n1) [[dissipation]] [[tension_release]]\n2) [[dissipation]] [[a_r_d_method]]\n3) [[common_good]] [[synergy]]\n4) [[oscillatory_progress]] [[pendulation]]\n5) [[assimilation]] [[energy_absorption]]\n6) [[feedback_escalation]] [[feedback_loop]]\n7) [[metastability]] [[chaotic_itinerancy]]\n8) [[polysingularity]] [[diversity]]\n9) [[oscillatory_pattern]] [[synchronization]]\n10) [[fluidity]] [[adaptive_strategy]]\n11) [[tension_increase]] [[tension_release]]\n12) [[escalation]] [[adaptive_strategy]]\n</Relations>\n\nSentiment (wink):\npositive: 15%, negative: 18%, neutral: 68%\n\n"
          },
          "credentials": {
            "httpBearerAuth": {
              "id": "credential-id",
              "name": "httpBearerAuth Credential"
            }
          },
          "typeVersion": 4.2
        },
        {
          "id": "1bf99f65-00fb-49f3-b576-b21acc14e2ae",
          "name": "Reasoning Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            -200,
            -60
          ],
          "parameters": {
            "options": {
              "systemMessage": "You are a reasoning agent. You have access to a dynamic interaction expert that provides you advice on how to continue your interaction. When you send a request to this expert, you need to give it an interpretation of the previous interaction and its dynamics (your interpretation of the conversation) using the language and concepts that the reasoning agent will understand. \n\nUse the response from the expert as an instruction to improve your response to the user's query. Give the utmost importance to the expert's advice to improve your standard response to the client's original query."
            }
          },
          "typeVersion": 1.9
        },
        {
          "id": "61106e92-7c6a-4e93-8afb-180f00123f2e",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -220,
            -240
          ],
          "parameters": {
            "width": 380,
            "height": 320,
            "content": "## 1. Reasoning Agent \n\nHere you add a system prompt that tell the agent to augment the original prompt using its knowledge about the reasoning ontology. "
          },
          "typeVersion": 1
        },
        {
          "id": "7b409287-758d-46e8-b828-69776ce5f56d",
          "name": "Sticky Note1",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            60,
            120
          ],
          "parameters": {
            "width": 340,
            "height": 560,
            "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 2. Reasoning Ontology\n\nHere you add an [InfraNodus](https://infranodus.com) knowledge graph that will contain the reasoning ontology you want to use. \n\n1. Specify it in the `name` field\n\n2. Add a description and topical summary (generated in `Project Notes` > `prompt augmentation for RAG` on the graph's page)"
          },
          "typeVersion": 1
        },
        {
          "id": "06e7c099-dd74-4f46-bb3b-b7639c3fc3ea",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            400,
            120
          ],
          "parameters": {
            "width": 420,
            "height": 560,
            "content": "\n\n\n\n\n\n\n\n\n\n### Knowledge Graph: Reasoning Ontology\n\nYou can auto-generate the reasoning ontology using the [https://infranodus.com/import/ai-ontologies](https://infranodus.com/import/ai-ontologies) interface and / or edit it manually using the [[wiki links]] for nodes and [tags] for relationship types. \n\n[![InfraNodus knowledge graph](https://infranodus.com/images/front/blog/reasoning-knowledge-graph-infranodus.png)](https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts)\n\n**[Learn more on the InfraNodus support portal](https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts)**\n"
          },
          "typeVersion": 1
        }
      ],
      "active": false,
      "pinData": {},
      "settings": {
        "executionOrder": "v1"
      },
      "versionId": "02353b90-13a1-4624-bc39-391a0dd4a1b0",
      "connections": {
        "Simple Memory": {
          "ai_memory": [
            [
              {
                "node": "Reasoning Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "Reasoning Agent": {
          "main": [
            []
          ]
        },
        "OpenAI Chat Model": {
          "ai_languageModel": [
            [
              {
                "node": "Reasoning Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "Reasoning Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Interaction Dynamics Expert": {
          "ai_tool": [
            [
              {
                "node": "Reasoning Agent",
                "type": "ai_tool",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 8,
      "nodeTypes": {
        "n8n-nodes-base.stickyNote": {
          "count": 3
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "n8n-nodes-base.httpRequestTool": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "InfraNodus",
      "username": "infranodus",
      "bio": "I'm Dmitry, the founder of InfraNodus — an AI text network analysis tool. I'm passionate about networks and data visualization and its ability to reveal what everyone else is missing and to highlight different perspectives. I'm sharing the n8n templates that make use of this unique capability of InfraNodus for multiple scenarios.",
      "verified": true,
      "links": [
        "https://infranodus.com"
      ],
      "avatar": "https://gravatar.com/avatar/2c4026bed17ffbab6bc63bfd88f3a7375e83f7f2b1c92859a092f8bb3abbbc30?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1153,
        "icon": "file:openAiLight.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "OpenAI Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "OpenAI Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1163,
        "icon": "fa:database",
        "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "For beginners"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Simple Memory"
        },
        "iconData": {
          "icon": "database",
          "type": "icon"
        },
        "displayName": "Simple Memory",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 5,
        "name": "Engineering"
      },
      {
        "id": 48,
        "name": "AI RAG"
      }
    ],
    "image": []
  }
}