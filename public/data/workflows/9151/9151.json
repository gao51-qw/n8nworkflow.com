{
  "workflow": {
    "id": 9151,
    "name": "Complete backup solution for n8n workflows & credentials (local/FTP)",
    "views": 1513,
    "recentViews": 1,
    "totalViews": 1513,
    "createdAt": "2025-10-01T12:05:26.763Z",
    "description": "## Automated n8n Workflows & Credentials Backup to Local/Server Disk & FTP\n\nComplete backup solution that saves both workflows and credentials to local/server disk with optional FTP upload for off-site redundancy.\n\n**What makes this workflow different:**\n* Backs up workflows AND credentials together\n* Saves to **local/server** disk (not Git, GitHub, or any cloud services)\n* Optional **FTP upload** for redundancy (disabled by default)\n* Comprehensive error handling and email notifications\n* **Timezone-aware** scheduling\n* Ready to use with minimal configuration\n\n### How it works\n\n**Backup Process (Automated Daily at 4 AM):**\n1. **Initialisation** - Sets up timezone-aware timestamps and configurable backup paths for both local/server disk and FTP destinations\n2. **Folder Creation** - Creates date-stamped backup directories (YYYY-MM-DD format) on local/server disk\n3. **Dual Backup Operations** - Processes credentials and workflows in two separate branches:\n   - **Credentials Branch**:\n     - Exports n8n credentials using the built-in CLI command with backup flag\n     - Lists exported credential files in the credentials folder\n     - Reads each credential file from disk\n     - *Optional*: Uploads to FTP server (disabled by default)\n     - *Optional*: Logs FTP upload results for credentials\n   - **Workflows Branch**:\n     - Retrieves all workflows via n8n API\n     - Cleans workflow names for cross-platform compatibility\n     - Converts workflows to formatted JSON files\n     - Writes files to local/server disk\n     - *Optional*: Uploads to FTP server (disabled by default)\n     - *Optional*: Logs FTP upload results for workflows\n4. **Data Aggregation** - Combines all workflow data with binary attachments for comprehensive reporting\n5. **Results Merging** - Consolidates credentials FTP logs, workflows FTP logs, and aggregated workflow data\n6. **Summary Generation** - Creates detailed backup logs including:\n   - Statistics (file counts, sizes, durations)\n   - Success/failure tracking for local and FTP operations\n   - Error tracking with detailed messages\n   - Timezone-aware timestamps\n7. **Notifications** - Sends comprehensive email reports with log files attached and saves execution logs to disk\n\n### How to use\n\n**Initial Setup:**\n\n1. **Configure the Init Node** - Open the \"Init\" node and customize these key parameters in the \"Workflow Standard Configuration\" section:\n   ```javascript\n   // Admin email for notifications\n   const N8N_ADMIN_EMAIL = $env.N8N_ADMIN_EMAIL || 'youremail@world.com';\n   \n   // Workflow name (auto-detected)\n   const WORKFLOW_NAME = $workflow.name;\n   \n   // Projects root directory on your server\n   const N8N_PROJECTS_DIR = $env.N8N_PROJECTS_DIR || '/files/n8n-projects-data';\n   // projects-root-folder/\n   //   â””â”€â”€ Your-project-folder-name/\n   //       â”œâ”€â”€ logs/\n   //       â”œâ”€â”€ reports/\n   //       â”œâ”€â”€ ...\n   //       â””â”€â”€ [other project files]\n   \n   // Project folder name for this backup workflow\n   const PROJECT_FOLDER_NAME = \"Workflow-backups\";\n   ```\n   \n   Then customize these parameters in the \"Workflow Custom Configuration\" section:\n   ```javascript\n   // Local backup folder (must exist on your server)\n   const BACKUP_FOLDER = $env.N8N_BACKUP_FOLDER || '/files/n8n-backups';\n   \n   // FTP backup folder (root path on your FTP server)\n   const FTP_BACKUP_FOLDER = $env.N8N_FTP_BACKUP_FOLDER || '/n8n-backups';\n   \n   // FTP server name for logging (display purposes only)\n   const FTPName = 'Synology NAS 2To';\n   ```\n   \n   These variables can also be set as environment variables in your n8n configuration.\n\n2. **Set Up Credentials:**\n   - Configure n8n API credentials for the \"Fetch Workflows\" node\n   - Configure SMTP credentials for email notifications\n   - *Optional*: Configure FTP credentials if you want to enable off-site backups\n\n3. **Configure Backup Folder:**\n   - Ensure the backup folder path exists on your server\n   - Verify proper write permissions for the n8n process\n   - If running in Docker, ensure volume mapping is correctly configured\n\n4. **Customize Email Settings:**\n   - Update the \"Send email\" node with your recipient email address or your \"N8N_ADMIN_EMAIL\" environment value\n   - Adjust email subject and body text as needed\n\n**Enabling FTP Upload (Optional):**\n\nBy default, FTP upload nodes are disabled for easier setup. To enable off-site FTP backups:\n\n1. **Simply activate these 4 nodes** (no other changes needed):\n   - \"Upload Credentials To FTP\"\n   - \"FTP Logger (credentials)\"\n   - \"Upload Workflows To FTP\"  \n   - \"FTP Logger (workflows)\"\n\n2. **Configure FTP credentials** in the two upload nodes\n\n3. The workflow will automatically handle FTP operations and include upload status in reports\n\n### Requirements\n- n8n API credentials (for workflow fetching)\n- SMTP server configuration (for email notifications)\n- Adequate disk space for local backup storage\n- Proper file system permissions for backup folder access\n- Docker environment with volume mapping (if running n8n in Docker)\n- *Optional*: FTP server access and credentials (for off-site backups)\n\n### Good to know\n\n- **Security**: Credentials are exported using n8n's secure backup format - actual credential values are not exposed in plain text\n- **Timezone Handling**: All timestamps respect configured timezone settings (defaults to Europe/Paris, configurable in Init node)\n- **File Naming**: Automatic sanitization ensures backup files work across different operating systems (removes forbidden characters, limits length to 180 characters)\n- **FTP Upload**: Disabled by default for easier setup - simply activate 4 nodes to enable off-site backups without any code changes\n- **Connection Resilience**: FTP operations include error handling for timeout and connection issues without failing the entire backup\n- **Graceful Degradation**: If FTP nodes are disabled, the workflow completes successfully with local backups only and indicates FTP status in logs\n- **Error Handling**: Comprehensive error catching with detailed logging and email notifications\n- **Dual Logging**: Creates both JSON logs (for programmatic parsing) and plain text logs (for human readability)\n- **Storage**: Individual workflow JSON files allow for selective restore and easier version control integration\n- **Scalability**: Handles any number of workflows efficiently with detailed progress tracking\n---\n\n*This automated backup workflow saves your n8n data to both local disk and FTP server. To restore your backups, use:*\n- [*\"n8n Restore from Disk - Self-Hosted Solution\" for local/server disk restores*](https://n8n.io/workflows/9154-automated-workflow-and-credential-restoration-system-for-self-hosted-environments/)\n- [*\"n8n Restore from FTP - Remote Backup Solution\" for FTP remote restores*](https://n8n.io/workflows/9156-restore-workflows-and-credentials-from-remote-ftp-backup-storage/)\n",
    "workflow": {
      "meta": {
        "instanceId": "",
        "templateCredsSetupCompleted": true
      },
      "nodes": [
        {
          "id": "",
          "name": "Sticky Note",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -112,
            -1408
          ],
          "parameters": {
            "width": 1264,
            "height": 528,
            "content": "## Backup Worflows & Credentials to Drive\nConfigure \"Init\" node in 2 sections.\n### Workflow Standard Configuration\n```\n// Admin email for notifications\nconst N8N_ADMIN_EMAIL = $env.N8N_ADMIN_EMAIL || 'youremail@world.com';\n   \n// Workflow name (auto-detected)\nconst WORKFLOW_NAME = $workflow.name;\n   \n// Projects root directory on your server (see file structure in node)\nconst N8N_PROJECTS_DIR = $env.N8N_PROJECTS_DIR || '/files/n8n-projects-data';\n   \n// Project folder name for this backup workflow\nconst PROJECT_FOLDER_NAME = \"Workflow-backups\";  // âš ï¸ Your project folder name\n```\n### Workflow Custom Configuration\n```\n// Base backup path using your Docker and FTP volume configuration (folder must exist)\nconst BACKUP_FOLDER = $env.N8N_BACKUP_FOLDER || '/files/n8n-backups'; // âš ï¸ Change the default value for your n8n backup folder\nconst FTP_BACKUP_FOLDER = $env.N8N_FTP_BACKUP_FOLDER || '/n8n-backups';\nconst FTPName = 'Your FTP Server Name'; // FTP server name for logging (display purposes only)\n \nconst credentials_backup_folder = \"n8n-credentials\"; // Credentials backup path\n```"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Sticky Note2",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            -112,
            -816
          ],
          "parameters": {
            "color": 4,
            "width": 624,
            "height": 832,
            "content": "## Initialisation"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Sticky Note3",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            576,
            -816
          ],
          "parameters": {
            "color": 3,
            "width": 1232,
            "height": 272,
            "content": "## Credentialsâ€™ backup & FTP upload"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Sticky Note5",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            576,
            -480
          ],
          "parameters": {
            "color": 5,
            "width": 1232,
            "height": 496,
            "content": "## Workflowsâ€™ backup & FTP upload"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Sticky Note6",
          "type": "n8n-nodes-base.stickyNote",
          "position": [
            1872,
            -816
          ],
          "parameters": {
            "color": 6,
            "width": 816,
            "height": 832,
            "content": "## Finalisation"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Backup Summary",
          "type": "n8n-nodes-base.code",
          "onError": "continueErrorOutput",
          "position": [
            2112,
            -544
          ],
          "parameters": {
            "jsCode": "// Generate backup summary and statistics with binary data for log file\n// âœ… Enhanced to handle both credentials and workflows FTP upload results\n// âœ… Adapted for Aggregate + Merge structure\n// âœ… Handles disabled FTP nodes gracefully\n\n// âš ï¸ CONFIGURE THIS NODE WITH:\n// SETTINGS > ON ERROR > CONTINUE (USING ERROR OUTPUT)\n\nconst allItems = $input.all();\nconst summaryDataInput = $(\"Init\").first().json;\n\nconsole.log('[Backup Summary] Total items received:', allItems.length);\n\n// Separate different data types from Merge\nconst credentialsFtpItems = allItems.filter(item => \n  item.json.credentialsFtpUpload !== undefined\n);\n\nconst workflowsFtpItems = allItems.filter(item => \n  item.json.workflowsFtpUpload !== undefined\n);\n\nconst aggregatedWorkflowItems = allItems.filter(item => \n  item.json.workflows !== undefined\n);\n\nconsole.log('[Backup Summary] Credentials FTP items:', credentialsFtpItems.length);\nconsole.log('[Backup Summary] Workflows FTP items:', workflowsFtpItems.length);\nconsole.log('[Backup Summary] Aggregated workflow items:', aggregatedWorkflowItems.length);\n\n// Get credentials FTP upload data\nconst credentialsFtpData = credentialsFtpItems.length > 0 ? \n  credentialsFtpItems[0].json.credentialsFtpUpload : null;\n\n// Get workflows FTP upload data\nconst workflowsFtpData = workflowsFtpItems.length > 0 ? \n  workflowsFtpItems[0].json.workflowsFtpUpload : null;\n\n// Get aggregated workflows data\nconst workflowsData = aggregatedWorkflowItems.length > 0 ? \n  aggregatedWorkflowItems[0].json.workflows : [];\n\n// Get original workflow count from Fetch Workflows node\nconst workflows = $(\"Fetch Workflows\").all();\nconst totalWorkflows = workflows.length;\n\nconsole.log('[Backup Summary] Total workflows fetched:', totalWorkflows);\nconsole.log('[Backup Summary] Aggregated workflows found:', workflowsData.length);\nconsole.log('[Backup Summary] Credentials FTP data found:', credentialsFtpData !== null);\nconsole.log('[Backup Summary] Workflows FTP data found:', workflowsFtpData !== null);\n\n// Get credentials export result directly from the Export Credentials node\nconst credentialsResult = $(\"Export Credentials\").first()?.json || null;\n\n// Process workflow data from aggregated structure with binary data\nconst successfulWrites = [];\nconst failedWrites = [];\nlet totalSize = 0;\n\n// Get aggregated item with binary data\nconst aggregatedItem = aggregatedWorkflowItems[0];\nconst binaryData = aggregatedItem?.binary || {};\n\n// Since we have aggregated data, we assume all workflows were written successfully\n// (failed writes would have been caught by error handling in previous nodes)\nworkflowsData.forEach((workflowFile, index) => {\n  const fileName = workflowFile.fileName;\n  const workflowName = fileName ? fileName.split('/').pop().replace('.json', '') : `workflow_${index + 1}`;\n  \n  // Try to match with original workflow data to get more details\n  const originalWorkflow = workflows.find(w => {\n    const cleanedName = workflowName.replace(/[^a-zA-Z0-9]/g, '_');\n    return w.json.cleanedFileName === cleanedName || \n           w.json.name === workflowName;\n  });\n  \n  const nodesCount = originalWorkflow ? \n    (originalWorkflow.json.nodes ? originalWorkflow.json.nodes.length : 0) : 0;\n  \n  // Get real file size from binary data\n  let actualSize = 0;\n  const binaryKey = `data_${index}` || `data${index + 1}` || Object.keys(binaryData)[index];\n  \n  if (binaryData[binaryKey] && binaryData[binaryKey].data) {\n    // Calculate size from base64 data (base64 is ~33% larger than original)\n    const base64Data = binaryData[binaryKey].data;\n    actualSize = Math.floor(base64Data.length * 0.75); // Convert base64 length to actual bytes\n  }\n  \n  console.log(`[Backup Summary] Workflow ${workflowName}: ${actualSize} bytes`);\n  \n  successfulWrites.push({\n    fileName: fileName,\n    workflowName: workflowName,\n    filePath: fileName,\n    contentSize: actualSize,\n    nodesCount: nodesCount\n  });\n  \n  totalSize += actualSize;\n});\n\nconsole.log(`[Backup Summary] Processed ${successfulWrites.length} successful workflow writes`);\n\n// Use time data from Init node instead of recalculating\nconst initTimeData = summaryDataInput.timeData;\nconst endTime = new Date();\nconst startTime = new Date(initTimeData.startTime);\nconst durationSeconds = Math.round((endTime.getTime() - startTime.getTime()) / 1000);\n\n// Process credentials export result\nconst credentialsExportSuccess = credentialsResult && \n  credentialsResult.exitCode !== undefined && \n  credentialsResult.exitCode === 0;\n\nconst credentialsExport = {\n  attempted: credentialsResult !== null,\n  success: credentialsExportSuccess,\n  exitCode: credentialsResult?.exitCode,\n  message: credentialsExportSuccess ? \n    'Credentials exported successfully' : \n    `Credentials export failed with exit code ${credentialsResult?.exitCode}`,\n  stdout: credentialsResult?.stdout || '',\n  stderr: credentialsResult?.stderr || ''\n};\n\n// Process credentials FTP upload results with disabled node detection\nconst credentialsFtpSuccess = credentialsFtpData && \n  credentialsFtpData.summary && \n  credentialsFtpData.summary.overallSuccess;\n\nconst credentialsFtpUpload = {\n  attempted: credentialsFtpData !== null,\n  disabled: credentialsFtpData === null,\n  success: credentialsFtpSuccess,\n  totalFiles: credentialsFtpData?.totalFiles || 0,\n  successfulUploads: credentialsFtpData?.successfulUploads || 0,\n  failedUploads: credentialsFtpData?.failedUploads || 0,\n  message: credentialsFtpData === null ? \n    'âš ï¸ Warning: no FTP data received (node likely disabled)' :\n    (credentialsFtpSuccess ? \n      credentialsFtpData.summary.summary :\n      credentialsFtpData?.summary?.summary || 'Credentials FTP upload failed')\n};\n\n// Process workflows FTP upload results with disabled node detection\nconst workflowsFtpSuccess = workflowsFtpData && \n  workflowsFtpData.summary && \n  workflowsFtpData.summary.overallSuccess;\n\nconst workflowsFtpUpload = {\n  attempted: workflowsFtpData !== null,\n  disabled: workflowsFtpData === null,\n  success: workflowsFtpSuccess,\n  totalFiles: workflowsFtpData?.totalFiles || 0,\n  successfulUploads: workflowsFtpData?.successfulUploads || 0,\n  failedUploads: workflowsFtpData?.failedUploads || 0,\n  message: workflowsFtpData === null ? \n    'âš ï¸ Warning: no FTP data received (node likely disabled)' :\n    (workflowsFtpSuccess ? \n      workflowsFtpData.summary.summary :\n      workflowsFtpData?.summary?.summary || 'Workflows FTP upload failed')\n};\n\nconsole.log('[Backup Summary] Credentials export status:', credentialsExport.success ? 'âœ… Success' : 'âŒ Failed');\nconsole.log('[Backup Summary] Credentials FTP status:', credentialsFtpUpload.disabled ? 'âš ï¸ Disabled' : (credentialsFtpUpload.success ? 'âœ… Success' : 'âŒ Failed'));\nconsole.log('[Backup Summary] Workflows FTP status:', workflowsFtpUpload.disabled ? 'âš ï¸ Disabled' : (workflowsFtpUpload.success ? 'âœ… Success' : 'âŒ Failed'));\nconsole.log(`[Backup Summary] Final counts - Successful: ${successfulWrites.length}, Failed: ${failedWrites.length}`);\n\n// Create a backupSummary structure\nconst backupSummary = {\n  totalWorkflows: totalWorkflows,\n  errorCount: failedWrites.length,\n  errors: failedWrites.map(fail => ({\n    workflowName: fail.workflowName,\n    error: fail.error\n  }))\n};\n\n// Determine FTP folder status icon\nconst ftpFolderStatusIcon = (credentialsFtpUpload.disabled || workflowsFtpUpload.disabled) ? \n  'âš ï¸' : \n  ((credentialsFtpUpload.success && workflowsFtpUpload.success) ? 'âœ…' : 'âŒ');\n\n// Create comprehensive backup log using Init variables\nconst backupLog = {\n  timestamp: endTime.toISOString(),\n  localTimestamp: endTime.toLocaleString('en-GB', { timeZone: initTimeData.localTimezone }),\n  localTimezone: initTimeData.localTimezone,\n  backupFolder: summaryDataInput.customConfig.backupFolder,\n  dateFolder: initTimeData.datePrefix,\n  duration: {\n    seconds: durationSeconds,\n    formatted: `${Math.floor(durationSeconds / 60)}m ${durationSeconds % 60}s`,\n    startTime: initTimeData.startTime,\n    endTime: endTime.toISOString()\n  },\n  statistics: {\n    totalWorkflows: backupSummary.totalWorkflows,\n    successfulBackups: successfulWrites.length,\n    failedBackups: failedWrites.length,\n    preparationErrors: backupSummary.errorCount,\n    credentialsExported: credentialsExport.success,\n    credentialsFtpUploaded: credentialsFtpUpload.success,\n    credentialsFtpDisabled: credentialsFtpUpload.disabled,\n    credentialsFtpFiles: credentialsFtpUpload.totalFiles,\n    workflowsFtpUploaded: workflowsFtpUpload.success,\n    workflowsFtpDisabled: workflowsFtpUpload.disabled,\n    workflowsFtpFiles: workflowsFtpUpload.totalFiles,\n    totalSizeMB: Math.round(totalSize / 1024 / 1024 * 100) / 100,\n    averageSizeKB: successfulWrites.length > 0 ? Math.round(totalSize / successfulWrites.length / 1024) : 0\n  },\n  credentialsExport,\n  credentialsFtpUpload,\n  workflowsFtpUpload,\n  successfulFiles: successfulWrites.map(file => ({\n    fileName: file.fileName,\n    workflowName: file.workflowName,\n    contentSize: file.contentSize,\n    nodesCount: file.nodesCount\n  })),\n  failedFiles: failedWrites.map(file => ({\n    fileName: file.fileName,\n    workflowName: file.workflowName,\n    error: file.error\n  })),\n  preparationErrors: backupSummary.errors || [],\n  status: failedWrites.length === 0 && \n          backupSummary.errorCount === 0 && \n          credentialsExport.success && \n          (!credentialsFtpUpload.attempted || credentialsFtpUpload.success) &&\n          (!workflowsFtpUpload.attempted || workflowsFtpUpload.success) ? \n    'success' : 'partial_success',\n  configuration: {\n    backupConfig: summaryDataInput.customConfig.backupConfig,\n    workflowName: summaryDataInput.workflowConfig.WORKFLOW_NAME,\n    adminEmail: summaryDataInput.workflowConfig.N8N_ADMIN_EMAIL\n  },\n  debug: {\n    totalItemsReceived: allItems.length,\n    credentialsFtpItemsFound: credentialsFtpItems.length,\n    workflowsFtpItemsFound: workflowsFtpItems.length,\n    aggregatedWorkflowItemsFound: aggregatedWorkflowItems.length,\n    workflowsInAggregate: workflowsData.length,\n    totalWorkflowsFetched: totalWorkflows,\n    credentialsResultFound: credentialsResult !== null\n  }\n};\n\n// Convert backup log to binary data for Write Files from Disk node\nconst logJsonContent = JSON.stringify(backupLog, null, 2);\nconst logBinaryData = Buffer.from(logJsonContent, 'utf8').toString('base64');\n\n// Create console & email output lines array using Init variables\nconst startTimeLocal = new Date(initTimeData.startTime).toLocaleString('sv-SE', { timeZone: initTimeData.localTimezone });\nconst endTimeLocal = endTime.toLocaleString('sv-SE', { timeZone: initTimeData.localTimezone });\n\n// Determine status text for FTP uploads\nconst credentialsFtpStatus = credentialsFtpUpload.disabled ? 'âš ï¸ Disabled' : \n  (credentialsFtpUpload.success ? 'âœ… Yes' : 'âŒ Failed');\n\nconst workflowsFtpStatus = workflowsFtpUpload.disabled ? 'âš ï¸ Disabled' : \n  (workflowsFtpUpload.success ? 'âœ… Yes' : 'âŒ Failed');\n\nconst consoleLines = [\n  '=================================',\n  'ðŸ“ N8N WORKFLOWS BACKUP SUMMARY',\n  '=================================',\n  `ðŸ“… Date: ${initTimeData.localTimeFormatted}`,\n  `ðŸŒ Timezone: ${initTimeData.localTimezone}`,\n  `â±ï¸ Duration: ${backupLog.duration.formatted}`,\n  `   â€¢ Start time (local): ${startTimeLocal}`,\n  `   â€¢ End time (local): ${endTimeLocal}`,\n  `ðŸ“‚ Backup folder: ${summaryDataInput.customConfig.backupFolder}/${initTimeData.datePrefix} ${successfulWrites.length > 0 ? 'âœ…' : 'âŒ'}`,\n  `ðŸ“¤ FTP folder (${summaryDataInput.customConfig.FTPName || 'FTP Server'}): ${summaryDataInput.customConfig.FTP_BACKUP_FOLDER}/${initTimeData.datePrefix} ${ftpFolderStatusIcon}`,\n  `ðŸ“Š Workflows found: ${backupLog.statistics.totalWorkflows}`,\n  `âœ… Successfully backed up: ${backupLog.statistics.successfulBackups}`,\n  `âŒ Failed backups: ${backupLog.statistics.failedBackups}`,\n  `âš ï¸ Preparation errors: ${backupLog.statistics.preparationErrors}`,\n  `ðŸ” Credentials exported: ${credentialsExport.success ? 'âœ… Yes' : 'âŒ Failed'}`,\n  `ðŸ“¤ Credentials FTP uploaded: ${credentialsFtpStatus}`,\n  `ðŸ“¤ Workflows FTP uploaded: ${workflowsFtpStatus}`,\n  `ðŸ’¾ Total size: ${backupLog.statistics.totalSizeMB} MB`,\n  `ðŸ“ˆ Status: ${backupLog.status.toUpperCase()}`,\n  '================================='\n];\n\n// Console summary - display all lines\nconsoleLines.forEach(line => console.log(line));\n\n// Add error details to console lines if any\nif (failedWrites.length > 0) {\n  console.log('âŒ Failed files:');\n  consoleLines.push('âŒ Failed files:');\n  failedWrites.forEach(fail => {\n    const errorLine = `  - ${fail.fileName}: ${fail.error}`;\n    console.log(errorLine);\n    consoleLines.push(errorLine);\n  });\n}\n\n// Add credentials export details - only show errors, not success details\nif (!credentialsExport.success) {\n  console.log('ðŸ” Credentials export error:');\n  consoleLines.push('ðŸ” Credentials export error:');\n  consoleLines.push(`  - Exit code: ${credentialsExport.exitCode}`);\n  if (credentialsExport.stderr) {\n    consoleLines.push(`  - Error: ${credentialsExport.stderr}`);\n  }\n}\n\n// Add credentials FTP upload details\nif (credentialsFtpUpload.disabled) {\n  console.log('Credentials FTP upload disabled:');\n  consoleLines.push('âš ï¸ Credentials FTP upload:');\n  consoleLines.push(`  - Warning: no FTP data received (node likely disabled)`);\n} else if (!credentialsFtpUpload.success && credentialsFtpUpload.attempted) {\n  console.log('Credentials FTP upload errors:');\n  consoleLines.push('âŒ Credentials FTP upload errors:');\n  consoleLines.push(`  - ${credentialsFtpUpload.message}`);\n  \n  if (credentialsFtpData && credentialsFtpData.uploads) {\n    const failedUploads = credentialsFtpData.uploads.filter(upload => !upload.success);\n    failedUploads.forEach(upload => {\n      const errorLine = `    â€¢ ${upload.fileName}: ${upload.error || 'Upload failed'}`;\n      console.log(errorLine);\n      consoleLines.push(errorLine);\n    });\n  }\n}\n\n// Add workflows FTP upload details\nif (workflowsFtpUpload.disabled) {\n  console.log('Workflows FTP upload disabled:');\n  consoleLines.push('âš ï¸ Workflows FTP upload:');\n  consoleLines.push(`  - Warning: no FTP data received (node likely disabled)`);\n} else if (!workflowsFtpUpload.success && workflowsFtpUpload.attempted) {\n  console.log('Workflows FTP upload errors:');\n  consoleLines.push('âŒ Workflows FTP upload errors:');\n  consoleLines.push(`  - ${workflowsFtpUpload.message}`);\n  \n  if (workflowsFtpData && workflowsFtpData.uploads) {\n    const failedUploads = workflowsFtpData.uploads.filter(upload => !upload.success);\n    failedUploads.forEach(upload => {\n      const errorLine = `    â€¢ ${upload.fileName || upload.workflowName}: ${upload.error || 'Upload failed'}`;\n      console.log(errorLine);\n      consoleLines.push(errorLine);\n    });\n  }\n}\n\n// Create email log file content as plain text\nconst emailLogText = consoleLines.join('\\n');\n\n// Convert execution log to binary data as plain text\nconst emailLogBinaryData = Buffer.from(emailLogText, 'utf8').toString('base64'); \n\n// Create execution log file name using Init variables\nconst emailLogFileName = `${initTimeData.localDateTime}_exec_log.txt`;\nconst emailLogFilePath = `${summaryDataInput.workflowConfig.LOGS_PATH}/${emailLogFileName}`;\n\nconst emailLog = {\n  data: emailLogBinaryData,\n  mimeType: 'text/plain', \n  fileName: emailLogFileName,\n  fileExtension: 'txt'\n}\n\nconst summaryData = {\n  backupLog,\n  emailLogText,\n  logPathFile: summaryDataInput.workflowConfig.logPathFileName,\n  emailLogPath: emailLogFilePath,\n  emailLogFileName: emailLogFileName,\n  backupCompleted: true,\n  workflowStep: 'completed'\n};\n\n// Return with binary data for BOTH log files\nreturn [{\n  json: summaryData,\n  binary: {\n    data: {\n      data: logBinaryData,\n      mimeType: 'application/json',\n      fileName: summaryDataInput.workflowConfig.logFileName,\n      fileExtension: 'json'\n    },\n    emailLog\n  }\n}];"
          },
          "typeVersion": 2
        },
        {
          "id": "",
          "name": "Write Backup Log",
          "type": "n8n-nodes-base.readWriteFile",
          "position": [
            2320,
            -560
          ],
          "parameters": {
            "options": {},
            "fileName": "={{ $json.logPathFile }}",
            "operation": "write"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Send email",
          "type": "n8n-nodes-base.emailSend",
          "position": [
            2528,
            -560
          ],
          "webhookId": "",
          "parameters": {
            "text": "=Workflow:  {{ $workflow.name }}\nWorkflow has executed sucessfully.\n\n{{ $json.emailLogText }}\n\nFind the exported Workflow JSON files attached to this email.",
            "options": {
              "attachments": "data",
              "appendAttribution": false
            },
            "subject": "=n8n SUCCESS: {{ $workflow.name }}",
            "toEmail": "={{ $env.N8N_ADMIN_EMAIL }}",
            "fromEmail": "admin <admin@example.com>",
            "emailFormat": "text"
          },
          "typeVersion": 2.1
        },
        {
          "id": "",
          "name": "Write Email Log",
          "type": "n8n-nodes-base.readWriteFile",
          "position": [
            2320,
            -752
          ],
          "parameters": {
            "options": {},
            "fileName": "={{ $json.emailLogPath }}",
            "operation": "write",
            "dataPropertyName": "emailLog"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Create Date Folder",
          "type": "n8n-nodes-base.executeCommand",
          "position": [
            368,
            -560
          ],
          "parameters": {
            "command": "=mkdir -p \"{{ $json.customConfig.backupFolder }}/{{ $json.customConfig.datePrefix }}\""
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Init",
          "type": "n8n-nodes-base.code",
          "position": [
            160,
            -560
          ],
          "parameters": {
            "jsCode": "// Init Workflow Variables - Local timezone version\n// âœ… All dates/times handled in local timezone\n\n// YOUR_AWS_SECRET_KEY_HERE==\n// ðŸ“… LOCAL DATE/TIME INITIALIZATION\n// YOUR_AWS_SECRET_KEY_HERE==\n\nconst now = new Date();\n\n// YOUR_AWS_SECRET_KEY_HERE==\n// ðŸŒ USER-DEFINED TIMEZONE CONFIGURATION\n// YOUR_AWS_SECRET_KEY_HERE==\n// âš ï¸  IMPORTANT: This code runs on the n8n SERVER, not in your browser!\n// âš ï¸  Configure the timezone where you want executions to be scheduled,\n// âš ï¸  regardless of where your n8n server is physically located.\n//\n// ðŸ“ Common timezone examples:\n// - 'Europe/Paris'       â†’ Central European Time (CET/CEST)\n// - 'America/New_York'   â†’ Eastern Time (EST/EDT)\n// - 'America/Chicago'    â†’ Central Time (CST/CDT)\n// - 'America/Los_Angeles'â†’ Pacific Time (PST/PDT)\n// - 'Asia/Tokyo'         â†’ Japan Standard Time (JST)\n// - 'Asia/Shanghai'      â†’ China Standard Time (CST)\n// - 'Australia/Sydney'   â†’ Australian Eastern Time (AET)\n// - 'UTC'                â†’ Coordinated Universal Time\n//\n// ðŸ”§ TO CONFIGURE FOR YOUR USE CASE:\n// 1. Uncomment and edit the line below with your desired timezone\n// 2. Comment out the automatic detection line\n//\n// To use user-defined timezone instead, UNCOMMENT these lines:\n// const USER_TIMEZONE = 'Europe/Paris';  // ðŸ‘ˆ EDIT THIS for your location\n// const LOCAL_TIMEZONE = USER_TIMEZONE;  // ðŸ‘ˆ EDIT THIS for your location\n//\n// For automatic detection (uses server timezone or environment variable):\nconst LOCAL_TIMEZONE = $env.TZ || 'Europe/Paris';  // ðŸŸ¢ Default fallback\n// To use user-defined timezone instead, comment out the above line\n\n// Local date in YYYY-MM-DD format\nconst localDate = now.toLocaleDateString('sv-SE', { timeZone: LOCAL_TIMEZONE });\n\n// Local datetime in YYYY-MM-DD_HH-MM-SS format\nconst localDateTime = now.toLocaleString('sv-SE', { \n  timeZone: LOCAL_TIMEZONE,\n  year: 'numeric',\n  month: '2-digit',\n  day: '2-digit',\n  hour: '2-digit',\n  minute: '2-digit',\n  second: '2-digit'\n}).replace(' ', '_').replace(/:/g, '-');\n\n// Local formatted time for display\nconst localTimeFormatted = now.toLocaleString('en-GB', { \n  timeZone: LOCAL_TIMEZONE,\n  year: 'numeric',\n  month: '2-digit',\n  day: '2-digit',\n  hour: '2-digit',\n  minute: '2-digit',\n  second: '2-digit'\n});\n\nconst timestampUTC = now.toISOString().replace(/[:.]/g, '-').slice(0, 19); // 2025-01-20T09-30-45\n\nconsole.log('ðŸš€ USER-DEFINE TIMEZONE VARIABLES INITIALISED (Local timezone):');\nconsole.log(`   ðŸŒ Timezone: ${LOCAL_TIMEZONE}`);\nconsole.log(`   ðŸ“… Local date: ${localDate}`);\nconsole.log(`   ðŸ“… Local date/time: ${localDateTime}`);\nconsole.log(`   ðŸ• Local time: ${localTimeFormatted}`);\n\n// Create structure for time data output\nconst timeData = {\n  nowUTC: now.toISOString(),        // UTC for calculations\n  localDate: localDate,             // YYYY-MM-DD format\n  localDateTime: localDateTime,     // YYY-MM-DD_HH-MM-SS format\n  localTimeFormatted: localTimeFormatted, // Human readable\n  localTimezone: LOCAL_TIMEZONE,         // For reference\n  datePrefix: localDate,\n  timestampUTC,\n  startTime: now.toISOString()\n}\n\n// YOUR_AWS_SECRET_KEY_HERE==\n// ðŸ“ WORKFLOW STANDARD CONFIGURATION\n// YOUR_AWS_SECRET_KEY_HERE==\n\nconst N8N_ADMIN_EMAIL = $env.N8N_ADMIN_EMAIL || 'user@example.com';\nconst WORKFLOW_NAME = $workflow.name;\nconst N8N_PROJECTS_DIR = $env.N8N_PROJECTS_DIR || '/files/n8n-projects-data'; // âš ï¸ Your projectsâ€™ ROOT folder here\n// projects-root-folder/\n//   â””â”€â”€ Your-project-folder-name/\n//       â”œâ”€â”€ logs/\n//       â”œâ”€â”€ reports/\n//       â”œâ”€â”€ ...\n//       â””â”€â”€ [other project files]\nconst PROJECT_FOLDER_NAME = \"Workflow-backups\"; // âš ï¸ Your project folder name\nconst PROJECT_ROOT_PATH = `${N8N_PROJECTS_DIR}/${PROJECT_FOLDER_NAME}`;\n// const N8N_MEDIA_ROOT_PATH = $env.N8N_MEDIA_SHARED || '/files/n8n-media-shared'; // âš ï¸ Your public folder, accessible from inet\n// const mediaOutputFolder = \"/output\";\n// const mediaTempFolder = \"/temp\";\n// const N8N_FILE_SERVER_PURL = $env.N8N_FILE_SERVER_PURL || 'https://files.example.com'; // File serve public url\n\nconst LOGS_PATH = `${PROJECT_ROOT_PATH}/logs`;\n// const logFileName = `${localDateTime2}-${WORKFLOW_NAME.replace(/[^a-zA-Z0-9]/g, '_')}_logs.json`;  // âš ï¸ Your log file name\nconst logFileName = `${localDateTime}-backup_logs.json`;  // âš ï¸ Your log file name\nconst logPathFileName = `${LOGS_PATH}/${logFileName}`;\n\n// Configuration for report generation\nconst REPORTS_PATH = `${PROJECT_ROOT_PATH}/reports`;\nconst reportFileName = `${localDateTime}-report.txt`;\nconst reportPathFileName = `${REPORTS_PATH}/${reportFileName}`;\n\n// Console output\nconsole.log('ðŸ§¾ STANDARD WORKFLOW VARIABLES INITIALISED:');\nconsole.log(`   ðŸ“ Admin email: ${N8N_ADMIN_EMAIL}`);\nconsole.log(`   ðŸ“ Workflow name: ${WORKFLOW_NAME}`);\nconsole.log(`   ðŸ“ Projects folder: ${N8N_PROJECTS_DIR}`);\nconsole.log(`   ðŸ“ Project folder name: ${PROJECT_FOLDER_NAME}`);\nconsole.log(`   ðŸ“ Project root path: ${PROJECT_ROOT_PATH}`);\n// console.log(`   ðŸ“ Media root path: ${N8N_MEDIA_ROOT_PATH}`);\n// console.log(`   ðŸ“ File server public URL: ${N8N_FILE_SERVER_PURL}`);\nconsole.log(`   ðŸ“ Log path: ${LOGS_PATH}`);\nconsole.log(`   ðŸ“ Log file name: ${logFileName}`);\nconsole.log(`   ðŸ“ Log file path: ${logPathFileName}`);\nconsole.log(`   ðŸ“ Reports path: ${REPORTS_PATH}`);\nconsole.log(`   ðŸ“ Report file name: ${reportFileName}`);\nconsole.log(`   ðŸ“ Report file path: ${reportPathFileName}`);\n\n// Create structure for workflow configuration output\nconst workflowConfig = {\n  workflowStep: 'init',\n  N8N_ADMIN_EMAIL,\n  WORKFLOW_NAME,\n  N8N_PROJECTS_DIR,\n  PROJECT_FOLDER_NAME,\n  PROJECT_ROOT_PATH,\n  // N8N_MEDIA_ROOT_PATH,\n  // mediaOutputFolder,\n  // mediaTempFolder,\n  // N8N_FILE_SERVER_PURL,\n  LOGS_PATH,\n  logFileName,\n  logPathFileName,\n  REPORTS_PATH,\n  reportFileName,\n  reportPathFileName\n}\n\n// YOUR_AWS_SECRET_KEY_HERE==\n// ðŸ“ WORKFLOW CUSTOM CONFIGURATION\n// YOUR_AWS_SECRET_KEY_HERE==\n// âš ï¸  INSERT HERE: your workflow custom configuration variables\n\n// Base backup path using your Docker and FTP volume configuration (folder must exist)\nconst BACKUP_FOLDER = $env.N8N_BACKUP_FOLDER || '/files/n8n-backups'; // âš ï¸ Change the default value for your n8n backup folder\nconst FTP_BACKUP_FOLDER = $env.N8N_FTP_BACKUP_FOLDER || '/n8n-backups';\nconst FTPName = 'Your FTP Server Name'; // FTP server name for logging (display purposes only)\n\nconst credentials_backup_folder = \"n8n-credentials\"; // Credentials backup path\n\n// Configuration for the backup process\nconst backupConfig = {\n  datePrefix: localDate, // Prefix for all backup files\n  fileNaming: 'name_only', // Options: 'name_only', 'id_only', 'name_and_id'\n  maxRetries: 3,\n  timeout: 30000,\n  includeCredentials: false, // Security: Don't export credential data\n  compression: false // Future enhancement\n};\n\n// Console output\nconsole.log('ðŸ§¾ CUSTOM WORKFLOW VARIABLES INITIALISED:');\nconsole.log(`   ðŸ’¾ Backup folder: ${BACKUP_FOLDER}`);\nconsole.log('      File prefix:', localDate);\nconsole.log('      Timestamp (UTC):', timestampUTC);\n\nconst customConfig = {\n  backupFolder: BACKUP_FOLDER,\n  FTP_BACKUP_FOLDER,\n  FTPName,\n  credentials: credentials_backup_folder,\n  ...backupConfig\n}\n\n// YOUR_AWS_SECRET_KEY_HERE==\n// ðŸ“Š OUTPUT DATA\n// YOUR_AWS_SECRET_KEY_HERE==\n\nconst initData = {\n  timeData,\n  workflowConfig,\n  customConfig\n};\n\nreturn [{ json: initData }];"
          },
          "typeVersion": 2
        },
        {
          "id": "",
          "name": "Daily Backup",
          "type": "n8n-nodes-base.scheduleTrigger",
          "position": [
            -48,
            -560
          ],
          "parameters": {
            "rule": {
              "interval": [
                {
                  "triggerAtHour": 4
                }
              ]
            }
          },
          "typeVersion": 1.2
        },
        {
          "id": "",
          "name": "Convert to File",
          "type": "n8n-nodes-base.convertToFile",
          "position": [
            1040,
            -336
          ],
          "parameters": {
            "mode": "each",
            "options": {
              "format": true,
              "fileName": "={{ $json.name }}"
            },
            "operation": "toJson",
            "binaryPropertyName": "=data"
          },
          "typeVersion": 1.1
        },
        {
          "id": "",
          "name": "Fetch Workflows",
          "type": "n8n-nodes-base.n8n",
          "position": [
            624,
            -336
          ],
          "parameters": {
            "filters": {},
            "requestOptions": {}
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Clean Filename",
          "type": "n8n-nodes-base.code",
          "onError": "continueErrorOutput",
          "position": [
            832,
            -336
          ],
          "parameters": {
            "jsCode": "// YOUR_AWS_SECRET_KEY_HERE==\n// ðŸ§¹ FLEXIBLE FILENAME CLEANER\n// YOUR_AWS_SECRET_KEY_HERE==\n// Purpose: Clean filename for cross-platform compatibility\n// Usage: Can work with current input OR reference another node\n//\n// Recommended Configuration:\n// **Node Settings**:\n// * â˜‘ï¸ **On Error**: Continue (using error output)\n// * â˜‘ï¸ **Error Workflow**: Your notification workflow\n// The node stops at the first error and immediately triggers your notification system! ðŸš¨\n\n// âš™ï¸ CONFIGURATION\nconst SOURCE_FIELD = 'name';           // Field containing the filename\nconst SOURCE_NODE = 'Fetch Workflows';              // Set to node name like 'Fetch Workflows' OR null to use current input\n                                       // Examples: 'Fetch Workflows', 'HTTP Request', 'Set'\n\n// Get input items\nconst inputItems = $input.all();\nconst itemCount = inputItems.length;\n\nconsole.log(`Flexible Filename Cleaner: Processing ${itemCount} item(s)`);\nconsole.log(`Configuration: SOURCE_FIELD=\"${SOURCE_FIELD}\", SOURCE_NODE=${SOURCE_NODE || 'current input'}`);\n\nif (itemCount === 0) {\n  console.error('No items to process');\n  throw new Error('No items to process');\n}\n\nconst outputItems = [];\n\ninputItems.forEach((item, index) => {\n  try {\n    let originalFileName;\n    let sourceDescription;\n    \n    // Determine where to get the filename from\n    if (SOURCE_NODE) {\n      // Get from specified node\n      try {\n        // Use the corresponding item from the source node (same index)\n        const sourceItems = $(SOURCE_NODE).all();\n        if (sourceItems[index]) {\n          originalFileName = sourceItems[index].json[SOURCE_FIELD];\n          sourceDescription = `${SOURCE_NODE}[${index}].${SOURCE_FIELD}`;\n        } else {\n          // Fallback to first item if index doesn't exist\n          originalFileName = $(SOURCE_NODE).first().json[SOURCE_FIELD];\n          sourceDescription = `${SOURCE_NODE}[0].${SOURCE_FIELD} (fallback)`;\n        }\n      } catch (nodeError) {\n        const errorMsg = `Cannot access node '${SOURCE_NODE}': ${nodeError.message}`;\n        console.error(errorMsg);\n        throw new Error(errorMsg);\n      }\n    } else {\n      // Get from current input item\n      originalFileName = item.json[SOURCE_FIELD];\n      sourceDescription = `current_input[${index}].${SOURCE_FIELD}`;\n    }\n    \n    if (!originalFileName) {\n      const errorMsg = `No filename found in ${sourceDescription}`;\n      console.error(errorMsg);\n      throw new Error(errorMsg);\n    }\n    \n    console.log(`Item ${index + 1}/${itemCount}: \"${originalFileName}\" from ${sourceDescription}`);\n    \n    // Clean filename for cross-platform compatibility\n    const cleanedFileName = originalFileName\n      // Remove forbidden characters for Windows/Linux\n      .replace(/[<>:\"/\\\\|?*\\x00-\\x1F\\x7F]/g, '_')\n      // Replace multiple spaces/dots with single underscore\n      .replace(/[\\s.]+/g, '_')\n      // Remove consecutive underscores\n      .replace(/_+/g, '_')\n      // Remove leading/trailing underscores\n      .replace(/^_+|_+$/g, '')\n      // Limit length to 180 chars\n      .substring(0, 180);\n    \n    // Fallback if name becomes empty after cleaning\n    const finalCleanedFileName = cleanedFileName || `file_${index + 1}`;\n    \n    console.log(`âœ… Cleaned: \"${finalCleanedFileName}\"`);\n    \n    // Pass through all original data + add cleaned filename\n    outputItems.push({\n      json: {\n        ...item.json,\n        cleanedFileName: finalCleanedFileName\n      },\n      binary: item.binary || {}\n    });\n    \n  } catch (error) {\n    console.error(`âŒ Error processing item ${index + 1}:`, error.message);\n    \n    // Log error and re-throw to trigger error workflow\n    throw new Error(`Failed to process item ${index + 1}: ${error.message}`);\n  }\n});\n\nconsole.log(`âœ… Successfully processed ${outputItems.length} item(s)`);\nreturn outputItems;"
          },
          "typeVersion": 2
        },
        {
          "id": "",
          "name": "Write Each Workflow To Disk",
          "type": "n8n-nodes-base.readWriteFile",
          "position": [
            1264,
            -240
          ],
          "parameters": {
            "options": {
              "append": false
            },
            "fileName": "={{ $('Init').first().json.customConfig.backupFolder }}/{{ $('Init').first().json.customConfig.datePrefix }}/{{ $('Clean Filename').all()[$itemIndex].json.cleanedFileName }}.json",
            "operation": "write"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "ERROR:â€¯Backup Summary",
          "type": "n8n-nodes-base.stopAndError",
          "position": [
            2336,
            -368
          ],
          "parameters": {
            "errorMessage": "={{ $json.error }}"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "ERROR: Clean Filename",
          "type": "n8n-nodes-base.stopAndError",
          "position": [
            1040,
            -144
          ],
          "parameters": {
            "errorMessage": "={{ $json.error }}"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Read/Write Files from Disk",
          "type": "n8n-nodes-base.readWriteFile",
          "position": [
            1248,
            -736
          ],
          "parameters": {
            "options": {},
            "fileSelector": "={{ $json.localPath }}"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "List Credential Files",
          "type": "n8n-nodes-base.executeCommand",
          "position": [
            832,
            -736
          ],
          "parameters": {
            "command": "=# List all JSON files in credentials backup folder\n# Command for Execute Command node\n\nls -1 \"{{ $('Init').first().json.customConfig.backupFolder }}/{{ $('Init').first().json.customConfig.datePrefix }}/{{ $('Init').first().json.customConfig.credentials }}\"/*.json 2>/dev/null || echo \"No JSON files found\""
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Output Credential Items",
          "type": "n8n-nodes-base.code",
          "position": [
            1040,
            -736
          ],
          "parameters": {
            "jsCode": "// Process file list from Execute Command and create items for each file\n// âœ… Converts file list into individual items for Read Files node\n\n// âš ï¸ CONFIGURE THIS NODE WITH:\n// SETTINGS > ON ERROR > CONTINUE (USING ERROR OUTPUT)\n\nconst initData = $('Init').first().json;\nconst commandResult = $input.first().json;\nconst exportResult = $('Export Credentials').first().json;\n\nconsole.log('[Process File List] Command result:', commandResult);\nconsole.log('[Process File List] Command stdout:', commandResult.stdout);\n\n// Check if command was successful\nif (commandResult.exitCode !== 0) {\n  const errorMsg = `List files command failed with exit code ${commandResult.exitCode}`;\n  console.error(`[Process File List] ${errorMsg}`);\n  console.error(`[Process File List] Command stderr:`, commandResult.stderr);\n  throw new Error(errorMsg);\n}\n\n// Parse the file list from stdout\nconst stdout = commandResult.stdout.trim();\n\nif (!stdout || stdout === \"No JSON files found\") {\n  console.log('[Process File List] No credentials files found');\n  return [{ json: { workflowStep: 'no_credentials_files', message: 'No credentials files found' } }];\n}\n\n// Split file paths and filter out empty lines\nconst filePaths = stdout.split('\\n').filter(path => path.trim().length > 0);\n\nconsole.log(`[Process File List] Found ${filePaths.length} credentials file(s)`);\n\nconst outputItems = filePaths.map((fullPath, index) => {\n  // Extract filename from full path\n  const fileName = fullPath.split('/').pop();\n  \n  // Build FTP remote path\n  const ftpPath = `${initData.customConfig.FTP_BACKUP_FOLDER}/${initData.customConfig.datePrefix}/${initData.customConfig.credentials}/${fileName}`;\n  \n  console.log(`[Process File List] File ${index + 1}: ${fileName}`);\n  console.log(`  Local path: ${fullPath}`);\n  console.log(`  FTP path: ${ftpPath}`);\n  \n  return {\n    json: {\n      fileName: fileName,\n      localPath: fullPath,\n      ftpPath: ftpPath,\n      fileType: 'credentials_file',\n      workflowStep: 'credentials_file_read',\n      fileIndex: index + 1,\n      totalFiles: filePaths.length,\n      exportResult: {\n        exitCode: exportResult.exitCode,\n        stdout: exportResult.stdout,\n        stderr: exportResult.stderr\n      }\n    }\n  };\n});\n\nconsole.log(`[Process File List] âœ… Created ${outputItems.length} items for file reading`);\n\nreturn outputItems;"
          },
          "typeVersion": 2
        },
        {
          "id": "",
          "name": "Aggregate",
          "type": "n8n-nodes-base.aggregate",
          "position": [
            1472,
            -240
          ],
          "parameters": {
            "options": {
              "includeBinaries": true
            },
            "aggregate": "aggregateAllItemData",
            "destinationFieldName": "workflows"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Merge",
          "type": "n8n-nodes-base.merge",
          "position": [
            1920,
            -560
          ],
          "parameters": {
            "numberInputs": 3
          },
          "typeVersion": 3.2
        },
        {
          "id": "",
          "name": "Upload Credentials To FTP",
          "type": "n8n-nodes-base.ftp",
          "onError": "continueRegularOutput",
          "disabled": true,
          "position": [
            1456,
            -736
          ],
          "parameters": {
            "path": "={{ $('Output Credential Items').item.json.ftpPath }}",
            "operation": "upload"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "FTP Logger (credentials)",
          "type": "n8n-nodes-base.code",
          "disabled": true,
          "position": [
            1664,
            -736
          ],
          "parameters": {
            "jsCode": "// FTP Upload Results Logger for Credentials Files\n// âœ… Processes FTP upload results from individual credentials files and creates comprehensive logging data\n// âœ… Enhanced error handling for FTP connection timeouts and server errors\n\n// âš ï¸ CONFIGURE THIS NODE WITH:\n// SETTINGS > ON ERROR > CONTINUE (USING ERROR OUTPUT)\n\nconst allFtpResults = $input.all();\nconst initData = $('Init').first().json;\n\nconsole.log('[FTP Logger] Processing FTP upload results for credentials files...');\nconsole.log(`[FTP Logger] Received ${allFtpResults.length} FTP result item(s)`);\n\nconst ftpUploadResults = {\n  timestamp: new Date().toISOString(),\n  localTimestamp: new Date().toLocaleString('en-GB', { timeZone: initData.timeData.timezone }),\n  totalFiles: allFtpResults.length,\n  successfulUploads: 0,\n  failedUploads: 0,\n  uploads: []\n};\n\n// Process each FTP result\nallFtpResults.forEach((result, index) => {\n  try {\n    // Handle different result structures (success vs error outputs)\n    let uploadData;\n    let isConnectionError = false;\n    let connectionErrorMessage = null;\n    \n    // Check if this is an error result from FTP node\n    if (result.error) {\n      // This comes from the error output of FTP node\n      isConnectionError = true;\n      connectionErrorMessage = result.error;\n      uploadData = result.json || {};\n      console.log(`[FTP Logger] FTP node error detected: ${connectionErrorMessage}`);\n    } else if (result.json && result.json.error) {\n      // Error embedded in JSON response\n      isConnectionError = true;\n      connectionErrorMessage = result.json.error;\n      uploadData = result.json;\n      console.log(`[FTP Logger] FTP JSON error detected: ${connectionErrorMessage}`);\n    } else {\n      // Normal success/failure response\n      uploadData = result.json || {};\n    }\n    \n    // Determine if upload was successful\n    const isSuccess = !isConnectionError && !uploadData.error && uploadData.success !== false;\n    \n    // Extract file information with fallbacks\n    const fileName = uploadData.fileName || uploadData.path || `credentials_file_${index + 1}`;\n    const ftpPath = uploadData.ftpPath || uploadData.path || 'unknown';\n    \n    const uploadLog = {\n      fileName: fileName,\n      fileType: uploadData.fileType || 'credentials_file',\n      localPath: uploadData.localPath || 'unknown',\n      ftpPath: ftpPath,\n      success: isSuccess,\n      uploadTime: new Date().toISOString(),\n      error: connectionErrorMessage || uploadData.error || null,\n      ftpResponse: uploadData.response || null,\n      fileSize: uploadData.fileSize || null,\n      fileIndex: uploadData.fileIndex || index + 1,\n      connectionError: isConnectionError\n    };\n    \n    if (isSuccess) {\n      ftpUploadResults.successfulUploads++;\n      console.log(`[FTP Logger] âœ… Successfully uploaded: ${uploadLog.fileName} (${uploadLog.fileIndex}/${uploadData.totalFiles || ftpUploadResults.totalFiles})`);\n    } else {\n      ftpUploadResults.failedUploads++;\n      if (isConnectionError) {\n        console.error(`[FTP Logger] ðŸ”Œ Connection error for: ${uploadLog.fileName} - ${connectionErrorMessage}`);\n      } else {\n        console.error(`[FTP Logger] âŒ Failed to upload: ${uploadLog.fileName} (${uploadLog.fileIndex}/${uploadData.totalFiles || ftpUploadResults.totalFiles})`);\n      }\n      if (uploadLog.error) {\n        console.error(`[FTP Logger] Error details: ${uploadLog.error}`);\n      }\n    }\n    \n    ftpUploadResults.uploads.push(uploadLog);\n    \n  } catch (error) {\n    console.error(`[FTP Logger] Error processing result ${index + 1}:`, error.message);\n    \n    // Add error entry for processing failures\n    ftpUploadResults.uploads.push({\n      fileName: `unknown_file_${index + 1}`,\n      fileType: 'credentials_file',\n      localPath: 'unknown',\n      ftpPath: 'unknown',\n      success: false,\n      error: `Processing error: ${error.message}`,\n      uploadTime: new Date().toISOString(),\n      fileIndex: index + 1,\n      connectionError: false\n    });\n    \n    ftpUploadResults.failedUploads++;\n  }\n});\n\n// Create simplified summary\nconst connectionErrors = ftpUploadResults.uploads.filter(upload => upload.connectionError);\nconst hasConnectionErrors = connectionErrors.length > 0;\n\n// Create simplified summary\nconst ftpSummary = {\n  overallSuccess: ftpUploadResults.failedUploads === 0,\n  summary: hasConnectionErrors ? \n    `FTP server connection failed - credentials files could not be uploaded due to server connectivity issues` :\n    `${ftpUploadResults.successfulUploads}/${ftpUploadResults.totalFiles} credentials files uploaded successfully`\n};\n\nconsole.log('[FTP Logger] Credentials Upload Summary:');\nconsole.log(`  Total credentials files: ${ftpUploadResults.totalFiles}`);\nconsole.log(`  Successful uploads: ${ftpUploadResults.successfulUploads}`);\nconsole.log(`  Failed uploads: ${ftpUploadResults.failedUploads}`);\n\nif (hasConnectionErrors) {\n  console.log('[FTP Logger] ðŸ”Œ FTP server connection failed');\n}\n\n// Add summary to results\nftpUploadResults.summary = ftpSummary;\n\n// Create output data that will be merged with Backup Summary\nconst credentialsFtpLog = {\n  credentialsFtpUpload: ftpUploadResults\n};\n\nconsole.log('[FTP Logger] âœ… Credentials FTP upload logging completed');\n\nreturn [{ json: credentialsFtpLog }];"
          },
          "typeVersion": 2
        },
        {
          "id": "",
          "name": "FTP Logger (workflows)",
          "type": "n8n-nodes-base.code",
          "disabled": true,
          "position": [
            1472,
            -432
          ],
          "parameters": {
            "jsCode": "// FTP Upload Results Logger for Workflow Files\n// âœ… Processes FTP upload results from workflow files and creates summary for Backup Summary\n// âœ… Enhanced error handling for FTP connection timeouts and server errors\n\n// âš ï¸ CONFIGURE THIS NODE WITH:\n// SETTINGS > ON ERROR > CONTINUE (USING ERROR OUTPUT)\n\nconst allFtpResults = $input.all();\nconst initData = $('Init').first().json;\n\nconsole.log('[FTP Workflow Logger] Processing FTP upload results for workflow files...');\nconsole.log(`[FTP Workflow Logger] Received ${allFtpResults.length} FTP result item(s)`);\n\nconst ftpUploadResults = {\n  timestamp: new Date().toISOString(),\n  localTimestamp: new Date().toLocaleString('en-GB', { timeZone: initData.timeData.localTimezone }),\n  totalFiles: allFtpResults.length,\n  successfulUploads: 0,\n  failedUploads: 0,\n  uploads: []\n};\n\n// Process each FTP result\nallFtpResults.forEach((result, index) => {\n  try {\n    // Handle different result structures (success vs error outputs)\n    let uploadData;\n    let isConnectionError = false;\n    let connectionErrorMessage = null;\n    \n    // Check if this is an error result from FTP node\n    if (result.error) {\n      // This comes from the error output of FTP node\n      isConnectionError = true;\n      connectionErrorMessage = result.error;\n      uploadData = result.json || {};\n      console.log(`[FTP Workflow Logger] FTP node error detected: ${connectionErrorMessage}`);\n    } else if (result.json && result.json.error) {\n      // Error embedded in JSON response\n      isConnectionError = true;\n      connectionErrorMessage = result.json.error;\n      uploadData = result.json;\n      console.log(`[FTP Workflow Logger] FTP JSON error detected: ${connectionErrorMessage}`);\n    } else {\n      // Normal success/failure response\n      uploadData = result.json || {};\n    }\n    \n    // Determine if upload was successful\n    const isSuccess = !isConnectionError && !uploadData.error && uploadData.success !== false;\n    \n    // Extract file information with fallbacks\n    // For workflows, try to get the filename from Clean Filename node (which has both name and cleanedFileName)\n    let originalWorkflowName = `workflow_${index + 1}`;\n    let cleanedFileName = `workflow_${index + 1}`;\n    \n    try {\n      const cleanFilenameItems = $('Clean Filename').all();\n      if (cleanFilenameItems[index]) {\n        originalWorkflowName = cleanFilenameItems[index].json.name || `workflow_${index + 1}`;\n        cleanedFileName = cleanFilenameItems[index].json.cleanedFileName || `workflow_${index + 1}`;\n      }\n    } catch (error) {\n      console.log(`[FTP Workflow Logger] Could not access Clean Filename node for item ${index + 1}, using fallback`);\n    }\n    \n    const fileName = uploadData.fileName || uploadData.path || `${cleanedFileName}.json`;\n    const ftpPath = uploadData.ftpPath || uploadData.path || 'unknown';\n    \n    const uploadLog = {\n      fileName: fileName,\n      workflowName: originalWorkflowName,\n      cleanedFileName: cleanedFileName,\n      fileType: 'workflow_file',\n      localPath: uploadData.localPath || 'unknown',\n      ftpPath: ftpPath,\n      success: isSuccess,\n      uploadTime: new Date().toISOString(),\n      error: connectionErrorMessage || uploadData.error || null,\n      ftpResponse: uploadData.response || null,\n      fileSize: uploadData.fileSize || null,\n      fileIndex: uploadData.fileIndex || index + 1,\n      connectionError: isConnectionError\n    };\n    \n    if (isSuccess) {\n      ftpUploadResults.successfulUploads++;\n      console.log(`[FTP Workflow Logger] âœ… Successfully uploaded: ${originalWorkflowName} (${uploadLog.fileIndex}/${ftpUploadResults.totalFiles})`);\n    } else {\n      ftpUploadResults.failedUploads++;\n      if (isConnectionError) {\n        console.error(`[FTP Workflow Logger] ðŸ”Œ Connection error for: ${originalWorkflowName} - ${connectionErrorMessage}`);\n      } else {\n        console.error(`[FTP Workflow Logger] âŒ Failed to upload: ${originalWorkflowName} (${uploadLog.fileIndex}/${ftpUploadResults.totalFiles})`);\n      }\n      if (uploadLog.error) {\n        console.error(`[FTP Workflow Logger] Error details: ${uploadLog.error}`);\n      }\n    }\n    \n    ftpUploadResults.uploads.push(uploadLog);\n    \n  } catch (error) {\n    console.error(`[FTP Workflow Logger] Error processing result ${index + 1}:`, error.message);\n    \n    // Add error entry for processing failures\n    ftpUploadResults.uploads.push({\n      fileName: `unknown_workflow_${index + 1}`,\n      workflowName: `unknown_workflow_${index + 1}`,\n      fileType: 'workflow_file',\n      localPath: 'unknown',\n      ftpPath: 'unknown',\n      success: false,\n      error: `Processing error: ${error.message}`,\n      uploadTime: new Date().toISOString(),\n      fileIndex: index + 1,\n      connectionError: false\n    });\n    \n    ftpUploadResults.failedUploads++;\n  }\n});\n\n// Check for connection errors specifically\nconst connectionErrors = ftpUploadResults.uploads.filter(upload => upload.connectionError);\nconst hasConnectionErrors = connectionErrors.length > 0;\n\n// Create simplified summary\nconst ftpSummary = {\n  overallSuccess: ftpUploadResults.failedUploads === 0,\n  summary: hasConnectionErrors ? \n    `FTP server connection failed - workflow files could not be uploaded due to server connectivity issues` :\n    `${ftpUploadResults.successfulUploads}/${ftpUploadResults.totalFiles} workflow files uploaded successfully`\n};\n\nconsole.log('[FTP Workflow Logger] Workflow Upload Summary:');\nconsole.log(`  Total workflow files: ${ftpUploadResults.totalFiles}`);\nconsole.log(`  Successful uploads: ${ftpUploadResults.successfulUploads}`);\nconsole.log(`  Failed uploads: ${ftpUploadResults.failedUploads}`);\n\nif (hasConnectionErrors) {\n  console.log('[FTP Workflow Logger] ðŸ”Œ FTP server connection failed');\n}\n\n// Add summary to results\nftpUploadResults.summary = ftpSummary;\n\n// Create output data that will be merged with Backup Summary\nconst workflowsFtpLog = {\n  workflowsFtpUpload: ftpUploadResults\n};\n\nconsole.log('[FTP Workflow Logger] âœ… Workflow FTP upload logging completed');\n\nreturn [{ json: workflowsFtpLog }];"
          },
          "typeVersion": 2
        },
        {
          "id": "",
          "name": "Export Credentials",
          "type": "n8n-nodes-base.executeCommand",
          "position": [
            624,
            -736
          ],
          "parameters": {
            "command": "=# Export des credentials avec backup automatique\nn8n export:credentials --backup --output={{ $('Init').item.json.customConfig.backupFolder }}/{{ $('Init').item.json.customConfig.datePrefix }}/{{ $('Init').item.json.customConfig.credentials }}"
          },
          "typeVersion": 1
        },
        {
          "id": "",
          "name": "Upload Workflows To FTP",
          "type": "n8n-nodes-base.ftp",
          "onError": "continueRegularOutput",
          "disabled": true,
          "position": [
            1264,
            -432
          ],
          "parameters": {
            "path": "={{ $('Init').first().json.customConfig.FTP_BACKUP_FOLDER }}/{{ $('Init').first().json.customConfig.datePrefix }}/{{ $('Clean Filename').all()[$itemIndex].json.cleanedFileName }}.json",
            "operation": "upload"
          },
          "credentials": {
            "ftp": {
              "id": "credential-id",
              "name": "ftp Credential"
            }
          },
          "typeVersion": 1
        }
      ],
      "pinData": {},
      "connections": {
        "Init": {
          "main": [
            [
              {
                "node": "Create Date Folder",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Merge": {
          "main": [
            [
              {
                "node": "Backup Summary",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Aggregate": {
          "main": [
            [
              {
                "node": "Merge",
                "type": "main",
                "index": 2
              }
            ]
          ]
        },
        "Daily Backup": {
          "main": [
            [
              {
                "node": "Init",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Backup Summary": {
          "main": [
            [
              {
                "node": "Write Backup Log",
                "type": "main",
                "index": 0
              },
              {
                "node": "Write Email Log",
                "type": "main",
                "index": 0
              }
            ],
            [
              {
                "node": "ERROR:â€¯Backup Summary",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Clean Filename": {
          "main": [
            [
              {
                "node": "Convert to File",
                "type": "main",
                "index": 0
              }
            ],
            [
              {
                "node": "ERROR: Clean Filename",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Convert to File": {
          "main": [
            [
              {
                "node": "Upload Workflows To FTP",
                "type": "main",
                "index": 0
              },
              {
                "node": "Write Each Workflow To Disk",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Fetch Workflows": {
          "main": [
            [
              {
                "node": "Clean Filename",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Write Backup Log": {
          "main": [
            [
              {
                "node": "Send email",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Create Date Folder": {
          "main": [
            [
              {
                "node": "Fetch Workflows",
                "type": "main",
                "index": 0
              },
              {
                "node": "Export Credentials",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Export Credentials": {
          "main": [
            [
              {
                "node": "List Credential Files",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "List Credential Files": {
          "main": [
            [
              {
                "node": "Output Credential Items",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "FTP Logger (workflows)": {
          "main": [
            [
              {
                "node": "Merge",
                "type": "main",
                "index": 1
              }
            ]
          ]
        },
        "Output Credential Items": {
          "main": [
            [
              {
                "node": "Read/Write Files from Disk",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Upload Workflows To FTP": {
          "main": [
            [
              {
                "node": "FTP Logger (workflows)",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "FTP Logger (credentials)": {
          "main": [
            [
              {
                "node": "Merge",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Upload Credentials To FTP": {
          "main": [
            [
              {
                "node": "FTP Logger (credentials)",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Read/Write Files from Disk": {
          "main": [
            [
              {
                "node": "Upload Credentials To FTP",
                "type": "main",
                "index": 0
              }
            ]
          ]
        },
        "Write Each Workflow To Disk": {
          "main": [
            [
              {
                "node": "Aggregate",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 29,
    "workflowInfo": {
      "nodeCount": 28,
      "nodeTypes": {
        "n8n-nodes-base.ftp": {
          "count": 2
        },
        "n8n-nodes-base.n8n": {
          "count": 1
        },
        "n8n-nodes-base.code": {
          "count": 6
        },
        "n8n-nodes-base.merge": {
          "count": 1
        },
        "n8n-nodes-base.aggregate": {
          "count": 1
        },
        "n8n-nodes-base.emailSend": {
          "count": 1
        },
        "n8n-nodes-base.stickyNote": {
          "count": 5
        },
        "n8n-nodes-base.stopAndError": {
          "count": 2
        },
        "n8n-nodes-base.convertToFile": {
          "count": 1
        },
        "n8n-nodes-base.readWriteFile": {
          "count": 4
        },
        "n8n-nodes-base.executeCommand": {
          "count": 3
        },
        "n8n-nodes-base.scheduleTrigger": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Florent",
      "username": "florent",
      "bio": "IT Business Analyst for 8+ years, I am finding joy in developping again, with the help of n8n and AIs ðŸ¤—",
      "verified": true,
      "links": [
        ""
      ],
      "avatar": "https://gravatar.com/avatar/0ee3705eecc1ae4bcf7711dffac52a361d8a770574abbacab758008a85f440b6?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 11,
        "icon": "fa:envelope",
        "name": "n8n-nodes-base.emailSend",
        "codex": {
          "data": {
            "alias": [
              "SMTP",
              "email",
              "human",
              "form",
              "wait",
              "hitl",
              "approval"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                  "icon": "â˜€ï¸",
                  "label": "2021: The Year to Automate the New You with n8n"
                },
                {
                  "url": "https://n8n.io/blog/build-your-own-virtual-assistant-with-n8n-a-step-by-step-guide/",
                  "icon": "ðŸ‘¦",
                  "label": "Build your own virtual assistant with n8n: A step by step guide"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.sendemail/"
                }
              ],
              "credentialDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/credentials/sendemail/"
                }
              ]
            },
            "categories": [
              "Communication",
              "HITL",
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "HITL": [
                "Human in the Loop"
              ]
            }
          }
        },
        "group": "[\"output\"]",
        "defaults": {
          "name": "Send Email",
          "color": "#00bb88"
        },
        "iconData": {
          "icon": "envelope",
          "type": "icon"
        },
        "displayName": "Send Email",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 6,
            "name": "Communication"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 28,
            "name": "HITL"
          }
        ]
      },
      {
        "id": 13,
        "icon": "fa:terminal",
        "name": "n8n-nodes-base.executeCommand",
        "codex": {
          "data": {
            "alias": [
              "Shell",
              "Command",
              "OS",
              "Bash"
            ],
            "details": "Execute command allows you to run terminal commands on the computer/server hosting your n8n instance. Useful for executing a shell script or interacting with your n8n instance programmatically via the CLI.",
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                  "icon": " ðŸ•¸ï¸",
                  "label": "How uProc scraped a multi-page website with a low-code workflow"
                },
                {
                  "url": "https://n8n.io/blog/why-this-product-manager-loves-workflow-automation-with-n8n/",
                  "icon": "ðŸ§ ",
                  "label": "Why this Product Manager loves workflow automation with n8n"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/"
                }
              ]
            },
            "categories": [
              "Development",
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Execute Command",
          "color": "#886644"
        },
        "iconData": {
          "icon": "terminal",
          "type": "icon"
        },
        "displayName": "Execute Command",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 5,
            "name": "Development"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 24,
        "icon": "file:merge.svg",
        "name": "n8n-nodes-base.merge",
        "codex": {
          "data": {
            "alias": [
              "Join",
              "Concatenate",
              "Wait"
            ],
            "resources": {
              "generic": [
                {
                  "url": "https://n8n.io/blog/how-to-sync-data-between-two-systems/",
                  "icon": "ðŸ¬",
                  "label": "How to synchronize data between two systems (one-way vs. two-way sync"
                },
                {
                  "url": "https://n8n.io/blog/supercharging-your-conference-registration-process-with-n8n/",
                  "icon": "ðŸŽ«",
                  "label": "Supercharging your conference registration process with n8n"
                },
                {
                  "url": "https://n8n.io/blog/migrating-community-metrics-to-orbit-using-n8n/",
                  "icon": "ðŸ“ˆ",
                  "label": "Migrating Community Metrics to Orbit using n8n"
                },
                {
                  "url": "https://n8n.io/blog/build-your-own-virtual-assistant-with-n8n-a-step-by-step-guide/",
                  "icon": "ðŸ‘¦",
                  "label": "Build your own virtual assistant with n8n: A step by step guide"
                },
                {
                  "url": "https://n8n.io/blog/sending-automated-congratulations-with-google-sheets-twilio-and-n8n/",
                  "icon": "ðŸ™Œ",
                  "label": "Sending Automated Congratulations with Google Sheets, Twilio, and n8n "
                },
                {
                  "url": "https://n8n.io/blog/aws-workflow-automation/",
                  "label": "7 no-code workflow automations for Amazon Web Services"
                }
              ],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.merge/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Flow",
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Merge"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "Merge",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 350,
        "icon": "fa:server",
        "name": "n8n-nodes-base.ftp",
        "codex": {
          "data": {
            "alias": [
              "SFTP",
              "FTP",
              "Binary",
              "File",
              "Transfer"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.ftp/"
                }
              ],
              "credentialDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/credentials/ftp/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Data & Storage",
              "Development",
              "Utility"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Files",
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "FTP",
          "color": "#303050"
        },
        "iconData": {
          "icon": "server",
          "type": "icon"
        },
        "displayName": "FTP",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 3,
            "name": "Data & Storage"
          },
          {
            "id": 5,
            "name": "Development"
          },
          {
            "id": 7,
            "name": "Utility"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 528,
        "icon": "fa:exclamation-triangle",
        "name": "n8n-nodes-base.stopAndError",
        "codex": {
          "data": {
            "alias": [
              "Throw error",
              "Error",
              "Exception"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.stopanderror/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Utility"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Flow"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Stop and Error",
          "color": "#ff0000"
        },
        "iconData": {
          "icon": "exclamation-triangle",
          "type": "icon"
        },
        "displayName": "Stop and Error",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 7,
            "name": "Utility"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 565,
        "icon": "fa:sticky-note",
        "name": "n8n-nodes-base.stickyNote",
        "codex": {
          "data": {
            "alias": [
              "Comments",
              "Notes",
              "Sticky"
            ],
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Sticky Note",
          "color": "#FFD233"
        },
        "iconData": {
          "icon": "sticky-note",
          "type": "icon"
        },
        "displayName": "Sticky Note",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 826,
        "icon": "file:n8n.svg",
        "name": "n8n-nodes-base.n8n",
        "codex": {
          "data": {
            "alias": [
              "Workflow",
              "Execution"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.n8n/"
                }
              ],
              "credentialDocumentation": [
                {
                  "url": "https://docs.n8n.io/api/authentication/"
                }
              ]
            },
            "categories": [
              "Development",
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers",
                "Other Trigger Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "n8n"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9Im5vbmUiIHZpZXdCb3g9IjAgMCAyMzAgMTIwIj48cGF0aCBmaWxsPSIjRUE0QjcxIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMDQgNDhjLTExLjE4MyAwLTIwLjU4LTcuNjQ5LTIzLjI0NC0xOGgtMjcuNTA4YTEyIDEyIDAgMCAwLTExLjgzNiAxMC4wMjdsLS45ODcgNS45MTlBMjMuOTQgMjMuOTQgMCAwIDEgMTMyLjYyNiA2MGEyMy45NCAyMy45NCAwIDAgMSA3Ljc5OSAxNC4wNTRsLjk4NyA1LjkxOUExMiAxMiAwIDAgMCAxNTMuMjQ4IDkwaDMuNTA4QzE1OS40MiA3OS42NDkgMTY4LjgxNyA3MiAxODAgNzJjMTMuMjU1IDAgMjQgMTAuNzQ1IDI0IDI0cy0xMC43NDUgMjQtMjQgMjRjLTExLjE4MyAwLTIwLjU4LTcuNjQ5LTIzLjI0NC0xOGgtMy41MDhjLTExLjczMiAwLTIxLjc0NC04LjQ4Mi0yMy42NzMtMjAuMDU0bC0uOTg3LTUuOTE5QTEyIDEyIDAgMCAwIDExNi43NTIgNjZoLTkuNTA4QzEwNC41OCA3Ni4zNTEgOTUuMTgzIDg0IDg0IDg0cy0yMC41OC03LjY0OS0yMy4yNDQtMThINDcuMjQ0QzQ0LjU4IDc2LjM1MSAzNS4xODMgODQgMjQgODQgMTAuNzQ1IDg0IDAgNzMuMjU1IDAgNjBzMTAuNzQ1LTI0IDI0LTI0YzExLjE4MyAwIDIwLjU4IDcuNjQ5IDIzLjI0NCAxOGgxMy41MTJDNjMuNDIgNDMuNjQ5IDcyLjgxNyAzNiA4NCAzNnMyMC41OCA3LjY0OSAyMy4yNDQgMThoOS41MDhhMTIgMTIgMCAwIDAgMTEuODM2LTEwLjAyN2wuOTg3LTUuOTE5QzEzMS41MDQgMjYuNDgyIDE0MS41MTYgMTggMTUzLjI0OCAxOGgyNy41MDhDMTgzLjQyIDcuNjQ5IDE5Mi44MTcgMCAyMDQgMGMxMy4yNTUgMCAyNCAxMC43NDUgMjQgMjRzLTEwLjc0NSAyNC0yNCAyNG0wLTEyYzYuNjI3IDAgMTItNS4zNzMgMTItMTJzLTUuMzczLTEyLTEyLTEyLTEyIDUuMzczLTEyIDEyIDUuMzczIDEyIDEyIDEyTTI0IDcyYzYuNjI3IDAgMTItNS4zNzMgMTItMTJzLTUuMzczLTEyLTEyLTEyLTEyIDUuMzczLTEyIDEyIDUuMzczIDEyIDEyIDEybTcyLTEyYzAgNi42MjctNS4zNzMgMTItMTIgMTJzLTEyLTUuMzczLTEyLTEyIDUuMzczLTEyIDEyLTEyIDEyIDUuMzczIDEyIDEybTk2IDM2YzAgNi42MjctNS4zNzMgMTItMTIgMTJzLTEyLTUuMzczLTEyLTEyIDUuMzczLTEyIDEyLTEyIDEyIDUuMzczIDEyIDEyIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4="
        },
        "displayName": "n8n",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 5,
            "name": "Development"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 834,
        "icon": "file:code.svg",
        "name": "n8n-nodes-base.code",
        "codex": {
          "data": {
            "alias": [
              "cpde",
              "Javascript",
              "JS",
              "Python",
              "Script",
              "Custom Code",
              "Function"
            ],
            "details": "The Code node allows you to execute JavaScript in your workflow.",
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.code/"
                }
              ]
            },
            "categories": [
              "Development",
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Helpers",
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Code"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,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"
        },
        "displayName": "Code",
        "typeVersion": 2,
        "nodeCategories": [
          {
            "id": 5,
            "name": "Development"
          },
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 839,
        "icon": "fa:clock",
        "name": "n8n-nodes-base.scheduleTrigger",
        "codex": {
          "data": {
            "alias": [
              "Time",
              "Scheduler",
              "Polling",
              "Cron",
              "Interval"
            ],
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.scheduletrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0"
          }
        },
        "group": "[\"trigger\",\"schedule\"]",
        "defaults": {
          "name": "Schedule Trigger",
          "color": "#31C49F"
        },
        "iconData": {
          "icon": "clock",
          "type": "icon"
        },
        "displayName": "Schedule Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1233,
        "icon": "file:readWriteFile.svg",
        "name": "n8n-nodes-base.readWriteFile",
        "codex": {
          "data": {
            "alias": [
              "Binary",
              "File",
              "Text",
              "Open",
              "Import",
              "Save",
              "Export",
              "Disk",
              "Transfer"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.readwritefile/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Files"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Read/Write Files from Disk"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgdmlld0JveD0iMCAwIDUxMiA1MTIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxnIGNsaXAtcGF0aD0idXJsKCNjbGlwMF8xMTQxXzE1NDcpIj4KPHBhdGggZD0iTTAgMTJDMCA1LjM3MjU4IDUuMzcyNTggMCAxMiAwSDE1OVYxNTRDMTU5IDE2MC42MjcgMTY0LjM3MyAxNjYgMTcxIDE2NkgzMjVWMjQySDIyOC41NjJDMjEwLjg5NSAyNDIgMTk0LjY1NiAyNTEuNzA1IDE4Ni4yODggMjY3LjI2NEwxMjkuMjAzIDM3My40MDdDMTI1LjEzMSAzODAuOTc4IDEyMyAzODkuNDQgMTIzIDM5OC4wMzdWNDM0SDEyQzUuMzcyNTcgNDM0IDAgNDI4LjYyNyAwIDQyMlYxMloiIGZpbGw9IiM0NEFBNDQiLz4KPHBhdGggZD0iTTMyNSAxMzRWMTI3LjQwMUMzMjUgMTI0LjIyMyAzMjMuNzQgMTIxLjE3NSAzMjEuNDk1IDExOC45MjVMMjA2LjM2OSAzLjUyNDgxQzIwNC4xMTggMS4yNjgyIDIwMS4wNjEgMCAxOTcuODczIDBIMTkxVjEzNEgzMjVaIiBmaWxsPSIjNDRBQTQ0Ii8+CjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMjI4LjU2MyAyNzRDMjIyLjY3NCAyNzQgMjE3LjI2MSAyNzcuMjM1IDIxNC40NzIgMjgyLjQyMUwxNzIuMjExIDM2MUg0OTIuNjRMNDQ0LjY3IDI4MS43MTdDNDQxLjc3MiAyNzYuOTI3IDQzNi41OCAyNzQgNDMwLjk4MSAyNzRIMjI4LjU2M1oiIGZpbGw9IiM0NEFBNDQiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xNTUgNDA5QzE1NSA0MDAuMTYzIDE2Mi4xNjMgMzkzIDE3MSAzOTNINDk2QzUwNC44MzcgMzkzIDUxMiA0MDAuMTYzIDUxMiA0MDlWNDk2QzUxMiA1MDQuODM3IDUwNC44MzcgNTEyIDQ5NiA1MTJIMTcxQzE2Mi4xNjMgNTEyIDE1NSA1MDQuODM3IDE1NSA0OTZWNDA5Wk0zOTcgNDUzQzM5NyA0NjYuMjU1IDM4Ni4yNTUgNDc3IDM3MyA0NzdDMzU5Ljc0NSA0NzcgMzQ5IDQ2Ni4yNTUgMzQ5IDQ1M0MzNDkgNDM5Ljc0NSAzNTkuNzQ1IDQyOSAzNzMgNDI5QzM4Ni4yNTUgNDI5IDM5NyA0MzkuNzQ1IDM5NyA0NTNaTTQ0NSA0NzdDNDU4LjI1NSA0NzcgNDY5IDQ2Ni4yNTUgNDY5IDQ1M0M0NjkgNDM5Ljc0NSA0NTguMjU1IDQyOSA0NDUgNDI5QzQzMS43NDUgNDI5IDQyMSA0MzkuNzQ1IDQyMSA0NTNDNDIxIDQ2Ni4yNTUgNDMxLjc0NSA0NzcgNDQ1IDQ3N1oiIGZpbGw9IiM0NEFBNDQiLz4KPC9nPgo8ZGVmcz4KPGNsaXBQYXRoIGlkPSJjbGlwMF8xMTQxXzE1NDciPgo8cmVjdCB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgZmlsbD0id2hpdGUiLz4KPC9jbGlwUGF0aD4KPC9kZWZzPgo8L3N2Zz4K"
        },
        "displayName": "Read/Write Files from Disk",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1234,
        "icon": "file:convertToFile.svg",
        "name": "n8n-nodes-base.convertToFile",
        "codex": {
          "data": {
            "alias": [
              "CSV",
              "Spreadsheet",
              "Excel",
              "xls",
              "xlsx",
              "ods",
              "tabular",
              "encode",
              "encoding",
              "Move Binary Data",
              "Binary",
              "File",
              "JSON",
              "HTML",
              "ICS",
              "iCal",
              "RTF",
              "64",
              "Base64"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.converttofile/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Files",
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"input\"]",
        "defaults": {
          "name": "Convert to File"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTEzLjc2MTkgMkMxMy4yNDM3IDIgMTIuODIzNiAyLjQyMDA5IDEyLjgyMzYgMi45MzgzMVYxNS4yNTI2QzEzLjMxOTkgMTUuNDY0MyAxMy43ODUxIDE1Ljc3MiAxNC4xOTEgMTYuMTc1N0wyMS4yMjgzIDIzLjE3MzlDMjIuMDU0OCAyMy45OTU4IDIyLjUxOTUgMjUuMTEzMiAyMi41MTk1IDI2LjI3ODhDMjIuNTE5NSAyNy40NDQzIDIyLjA1NDggMjguNTYxOCAyMS4yMjgzIDI5LjM4MzdMMTQuMTkxIDM2LjM4MTlDMTMuNzg1IDM2Ljc4NTYgMTMuMzE5OSAzNy4wOTMyIDEyLjgyMzYgMzcuMzA1VjM3LjM1MjdDMTIuODIzNiAzNy44NzA5IDEzLjI0MzcgMzguMjkxIDEzLjc2MTkgMzguMjkxSDM5LjA2MTdDMzkuNTc5OSAzOC4yOTEgNDAgMzcuODcwOSA0MCAzNy4zNTI3TDQwIDE1Ljc5NEgyNy4xNDQzQzI2LjYyNjEgMTUuNzk0IDI2LjIwNiAxNS4zNzM5IDI2LjIwNiAxNC44NTU3VjJIMTMuNzYxOVoiIGZpbGw9IiMzQTQyRTkiLz4KPHBhdGggZD0iTTI4Ljg2NDUgMkMyOC43NzgxIDIgMjguNzA4MSAyLjA3MDAyIDI4LjcwODEgMi4xNTYzOVYxMi44MjI3QzI4LjcwODEgMTMuMDgxOCAyOC45MTgyIDEzLjI5MTkgMjkuMTc3MyAxMy4yOTE5SDM5Ljg0MzZDMzkuOTMgMTMuMjkxOSA0MCAxMy4yMjE5IDQwIDEzLjEzNTVMNDAgMTIuNjI2M0M0MCAxMi4zNzc4IDM5LjkwMTQgMTIuMTM5NSAzOS43MjYgMTEuOTYzNkwzMC4wNjEgMi4yNzU2MUMyOS44ODUgMi4wOTkxNiAyOS42NDYgMiAyOS4zOTY3IDJIMjguODY0NVoiIGZpbGw9IiMzQTQyRTkiLz4KPHBhdGggZD0iTTkuNzcyNjggMzQuNjAwM0M5LjA0MTg2IDMzLjg2NTQgOS4wNDUxNyAzMi42NzcyIDkuNzgwMDcgMzEuOTQ2NEwxMy42MzE1IDI4LjExNjNMMC45MzgzMTEgMjguMTE2M0MwLjQyMDA5NiAyOC4xMTYzIC0yLjI2NTE5ZS0wOCAyNy42OTYyIDAgMjcuMTc4TDguMjAyOTdlLTA4IDI1LjMwMTRDMS4wNDY4MmUtMDcgMjQuNzgzMiAwLjQyMDA5NSAyNC4zNjMxIDAuOTM4MzExIDI0LjM2MzFIMTMuNTUyOUw5Ljc4MDA3IDIwLjYxMTJDOS4wNDUxNyAxOS44ODA0IDkuMDQxODYgMTguNjkyMiA5Ljc3MjY4IDE3Ljk1NzNDMTAuNTAzNSAxNy4yMjI0IDExLjY5MTcgMTcuMjE5MSAxMi40MjY2IDE3Ljk0OTlMMTkuNDYzOSAyNC45NDgxQzE5LjgxODEgMjUuMzAwNCAyMC4wMTczIDI1Ljc3OTMgMjAuMDE3MyAyNi4yNzg4QzIwLjAxNzMgMjYuNzc4MyAxOS44MTgxIDI3LjI1NzIgMTkuNDYzOSAyNy42MDk1TDEyLjQyNjYgMzQuNjA3N0MxMS42OTE3IDM1LjMzODUgMTAuNTAzNSAzNS4zMzUyIDkuNzcyNjggMzQuNjAwM1oiIGZpbGw9IiMzQTQyRTkiLz4KPC9zdmc+Cg=="
        },
        "displayName": "Convert to File",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      },
      {
        "id": 1236,
        "icon": "file:aggregate.svg",
        "name": "n8n-nodes-base.aggregate",
        "codex": {
          "data": {
            "alias": [
              "Aggregate",
              "Combine",
              "Flatten",
              "Transform",
              "Array",
              "List",
              "Item"
            ],
            "details": "",
            "resources": {
              "generic": [],
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.aggregate/"
                }
              ]
            },
            "categories": [
              "Core Nodes"
            ],
            "nodeVersion": "1.0",
            "codexVersion": "1.0",
            "subcategories": {
              "Core Nodes": [
                "Data Transformation"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Aggregate"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1MTIiIGhlaWdodD0iNTEyIiBmaWxsPSJub25lIj48ZyBmaWxsPSIjRkY2RDVBIiBjbGlwLXBhdGg9InVybCgjYSkiPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgZD0iTTMyIDE0OGMwLTYuNjI3IDUuMzczLTEyIDEyLTEyaDE0NmM2LjYyNyAwIDEyIDUuMzczIDEyIDEydjI0YzAgNi42MjctNS4zNzMgMTItMTIgMTJINDRjLTYuNjI3IDAtMTItNS4zNzMtMTItMTJ6bTAgOTZjMC02LjYyNyA1LjM3My0xMiAxMi0xMmgxNDZjNi42MjcgMCAxMiA1LjM3MyAxMiAxMnYyNGMwIDYuNjI3LTUuMzczIDEyLTEyIDEySDQ0Yy02LjYyNyAwLTEyLTUuMzczLTEyLTEyem0wIDk2YzAtNi42MjcgNS4zNzMtMTIgMTItMTJoMTQ2YzYuNjI3IDAgMTIgNS4zNzMgMTIgMTJ2MjRjMCA2LjYyNy01LjM3MyAxMi0xMiAxMkg0NGMtNi42MjcgMC0xMi01LjM3My0xMi0xMnoiIGNsaXAtcnVsZT0iZXZlbm9kZCIvPjxwYXRoIGQ9Ik03NCA3NmMwIDYuNjI3IDUuMzczIDEyIDEyIDEyaDExNi4yMTdjMTcuNjczIDAgMzIgMTQuMzI3IDMyIDMydjU2YzAgMjYuOTc4IDEwLjI3MiA1MS41NTcgMjcuMTE5IDcwLjAzOSA1LjA1NSA1LjU0NSA1LjA1NSAxNC4zNzcgMCAxOS45MjItMTYuODQ3IDE4LjQ4Mi0yNy4xMTkgNDMuMDYxLTI3LjExOSA3MC4wMzl2NTZjMCAxNy42NzMtMTQuMzI3IDMyLTMyIDMySDg2Yy02LjYyNyAwLTEyIDUuMzczLTEyIDEydjI0YzAgNi42MjcgNS4zNzMgMTIgMTIgMTJoMTE2LjIxN2M0NC4xODMgMCA4MC0zNS44MTcgODAtODB2LTU2YzAtMzAuOTI4IDI1LjA3Mi01NiA1Ni01NmE1Ljc4MyA1Ljc4MyAwIDAgMCA1Ljc4My01Ljc4M3YtMzYuNDM0YTUuNzgzIDUuNzgzIDAgMCAwLTUuNzgzLTUuNzgzYy0zMC45MjggMC01Ni0yNS4wNzItNTYtNTZ2LTU2YzAtNDQuMTgzLTM1LjgxNy04MC04MC04MEg4NmMtNi42MjcgMC0xMiA1LjM3My0xMiAxMnoiLz48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0zNzYgMjQ0YzAtNi42MjcgNS4zNzMtMTIgMTItMTJoMTEyYzYuNjI3IDAgMTIgNS4zNzMgMTIgMTJ2MjRjMCA2LjYyNy01LjM3MyAxMi0xMiAxMkgzODhjLTYuNjI3IDAtMTItNS4zNzMtMTItMTJ6IiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L2c+PGRlZnM+PGNsaXBQYXRoIGlkPSJhIj48cGF0aCBmaWxsPSIjZmZmIiBkPSJNMCAwaDUxMnY1MTJIMHoiLz48L2NsaXBQYXRoPjwvZGVmcz48L3N2Zz4="
        },
        "displayName": "Aggregate",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 16,
        "name": "DevOps"
      }
    ],
    "image": []
  }
}