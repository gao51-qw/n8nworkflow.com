{
  "id": 4400,
  "slug": "4400",
  "title": "Build a PDF Document RAG System with Mistral OCR, Qdrant and Gemini AI",
  "description": "This workflow is designed to **process PDF documents** using **Mistral's OCR** capabilities, store the extracted text in a Qdrant vector database, and enable Retrieval-Augmented Generation (**RAG**) for answering questions. Here’s how it functions:  \n\nOnce configured, the workflow automates document ingestion, vectorization, and intelligent querying, enabling powerful RAG applications.\n\n---\n\n### **Benefits**\n\n* **End-to-End Automation**\n  No manual interaction is needed: documents are read, processed, and made queryable with minimal setup.\n\n* **Scalable and Modular**\n  The workflow uses subflows and batching, making it easy to scale and customize.\n\n* **Multi-Model Support**\n  Combines Mistral for OCR, OpenAI for embeddings, and Gemini for intelligent answering—taking advantage of the strengths of each.\n\n* **Real-Time Q\\&A**\n  With RAG integration, users can query document content through natural language and receive accurate responses grounded in the PDF data.\n\n* **Light or Full Mode**\n  Users can choose to index full page content or only summarized text, optimizing for either performance or richness.\n\n---\n\n### **How It Works** \n\n1. **PDF Processing with Mistral OCR**:  \n   - The workflow starts by uploading a PDF file to Mistral's API, which performs OCR to extract text and metadata.  \n   - The extracted content is split into manageable chunks (e.g., pages or sections) for further processing.  \n\n2. **Vector Storage in Qdrant**:  \n   - The extracted text is converted into embeddings using OpenAI's embedding model.  \n   - These embeddings are stored in a Qdrant vector database, enabling efficient similarity searches for RAG.  \n\n3. **Question-Answering with RAG**:  \n   - When a user submits a question via a chat interface, the workflow retrieves relevant text chunks from Qdrant using vector similarity.  \n   - A language model (Google Gemini) generates answers based on the retrieved context, providing accurate and context-aware responses.  \n\n4. **Optional Summarization**:  \n   - The workflow includes an optional summarization step using Google Gemini to condense the extracted text for faster processing or lighter RAG usage.  \n\n---\n\n### **Set Up Steps**  \nTo deploy this workflow in n8n, follow these steps:  \n\n1. **Configure Qdrant Database**:  \n   - Replace `QDRANTURL` and `COLLECTION` in the \"Create collection\" and \"Refresh collection\" nodes with your Qdrant instance details.  \n   - Ensure the Qdrant collection is configured with the correct vector size (e.g., 1536 for OpenAI embeddings) and distance metric (e.g., Cosine).  \n\n2. **Set Up Credentials**:  \n   - Add credentials for:  \n     - **Mistral Cloud API** (for OCR processing).  \n     - **OpenAI API** (for embeddings).  \n     - **Google Gemini API** (for chat and summarization).  \n     - **Google Drive** (if sourcing PDFs from Drive).  \n     - **Qdrant API** (for vector storage).  \n\n3. **PDF Source Configuration**:  \n   - If using Google Drive, specify the folder ID in the \"Search PDFs\" node.  \n   - Alternatively, modify the workflow to accept PDFs from other sources (e.g., direct uploads or external APIs).  \n\n4. **Customize Text Processing**:  \n   - Adjust chunk size and overlap in the \"Token Splitter\" node to optimize for your document type.  \n   - Choose between raw text or summarized content for RAG by toggling between the \"Set page\" and \"Summarization Chain\" nodes.  \n\n5. **Test the RAG**:  \n   - Trigger the workflow manually or via a chat message to verify OCR, embedding, and Qdrant storage.  \n   - Use the \"Question and Answer Chain\" node to test query responses.  \n\n6. **Optional Sub-Workflows**:  \n   - The workflow supports execution as a sub-workflow for batch processing (e.g., handling multiple PDFs).  \n\n----\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/). ",
  "featuredImage": "/data/workflows/4400/4400.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 41620,
  "downloads": 4162,
  "createdAt": "2025-05-26T12:28:14.350Z",
  "updatedAt": "2026-01-16T08:34:11.605Z",
  "publishedAt": "2025-05-26T12:28:14.350Z",
  "nodes": 34,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4400"
}