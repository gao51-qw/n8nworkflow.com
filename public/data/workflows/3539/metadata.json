{
  "id": 3539,
  "slug": "3539",
  "title": "Extract & summarize Wikipedia data with Bright Data and Gemini AI",
  "description": "### Who this is for?\nThis workflow automates the process of Wikipedia data extraction using the Bright Data Web Unlocker, parsing and cleaning the data, and then sending the results to a specified webhook URL for downstream processing, reporting, or integration.\n\n### What problem is this workflow solving?\n\n- Researchers who need structured information from Wikipedia pages regularly.\n\n- Data Engineers building knowledge bases or enriching datasets with factual data.\n\n- Digital Marketers or Content Writers automating fact-checking or content sourcing.\n\n- Automation Enthusiasts who want to trigger external systems with rich context from Wikipedia.\n\n### What this workflow does\n\nThis workflow addresses the challenges of manually retrieving, structuring, and using data from Wikipedia at scale.\n\n#### Workflow Breakdown\n\n**Trigger**\n- Type: Scheduled or Manual\n- Purpose: Starts the workflow either on a fixed schedule (e.g., daily) or on-demand via a manual trigger or incoming webhook.\n\n**Bright Data Wikipedia Scraping**\n- Tool Used: Bright Data Web Unlocker\n- Action: Scrape the HTML content of one or multiple Wikipedia article URLs.\n\n**Parse & Extract Structured Data**\n- The Basic LLM Chain node is responsible for producing a human readable content.\n\n**Summarization**\n- Summarize the Wikipedia content by utilizing the Summarization Chain node.\n\n**Send to Webhook**\n- Initiates a Webhook notification to the specified URL as part of the \"**Summary Webhook Notifier**\" node.\n\n### Setup\n\n- Sign up at [Bright Data](https://brightdata.com/).\n- Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n- In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n![Header Authentication.png](fileId:1239)\nThe Value field should be set with the\n**Bearer XXXXXXXXXXXXXX**. The XXXXXXXXXXXXXX should be replaced by the Web Unlocker Token.\n- In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).\n- Update the **Set Wikipedia URL with Bright Data Zone** node with the Wikipedia URL and Bright Data Zone.\n- Update the **Summary Webhook Notifier** node with the Webhook endpoint of your choice.\n\n### How to customize this workflow to your needs\n\n1. **Update Wikipedia URL**\n- Replace with your own Wikipedia URL of your interest.\n- Make sure to set the Wikipedia URL as part of the \"**Set Wikipedia URL with Bright Data Zone**\" node.\n2. **Modify Data Extraction Logic**\n- Extract entire article content or just specific sections by extending the \"**LLM Data Extractor**\" node prompt.\n3. **Extend AI Summarization**\n- Extract key bullet points or entities.\n- Create short-form summaries by extending the \"**Concise Summary Generator**\" node.\n4. **Extend Summary Webhook Notifier**\n- Send to Slack, Discord, Telegram, MS Teams via the Webhook notification mechanism.\n- Connect to your internal database/API via the Webhook notification mechanism.",
  "featuredImage": "/data/workflows/3539/3539.webp",
  "author": {
    "id": 101,
    "slug": "ranjancse",
    "name": "Ranjan Dailata",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 562,
  "downloads": 56,
  "createdAt": "2025-04-13T10:36:32.089Z",
  "updatedAt": "2026-01-16T08:30:14.750Z",
  "publishedAt": "2025-04-13T10:36:32.089Z",
  "nodes": 12,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3539"
}