{
  "id": 5258,
  "slug": "5258",
  "title": "Enrich LinkedIn profiles in NocoDB CRM with Apify scraper",
  "description": "# Introduction\n**Manual LinkedIn data collection is time-consuming, error-prone, and results\n  in inconsistent data quality across CRM/database records.**\n\n This workflow is great for organizations that struggle with:\n  - Incomplete contact records with only LinkedIn URLs but missing profile\n  details\n  - Hours spent manually copying LinkedIn information into databases\n  - Inconsistent data formats due to copy-paste from LinkedIn (emojis, styled\n  text, special characters)\n  - Outdated profile information that doesn't reflect current roles/companies\n  - No systematic way to enrich contacts at scale\n\n## Primary Users\n1.   Sales & Marketing Teams\n2.   Event Organizers & Conference Managers for event materials\n4.   Recruitment & HR Professionals\n5.   CRM Administrators\n\n## Specific Problems Addressed\n\n  1. Data Completeness: Automatically fills missing profile fields (headline,\n  bio, skills, experience)\n  2. Data Quality: Sanitizes problematic characters that break\n  databases/exports\n  3. Time Efficiency: Reduces hours of manual data entry to automated monthly\n  updates\n  4. Error Handling: Gracefully manages invalid/deleted LinkedIn profiles\n  5. Scalability: Processes multiple profiles in batch without manual\n  intervention\n  6. Standardization: Ensures consistent data format across all records\n\n## Cost\nEach URL scraped by Apify costs $0.01 to get all the data above. Apify charges per scrape, regardless of how much dta or fields you extract/use.\n\n# Setup Instructions\n\n## Prerequisites\n\n  1. **n8n Instance:** Access to a running n8n instance (self-hosted or cloud)\n  2. **NocoDB Account:** Database with a table containing LinkedIn URLs\n  3. **Apify Account:** Free or paid account for LinkedIn scraping\n\n## Required fields in NocoDB table\n\n### Input:\n* single LinkedIn URL\n\n*NocoDB Field name*\n```\nLinkedIn\n```\n\n### Output:\n* first/last/full name\n* e-mail\n* bio\n* headline\n* profile pic URL\n* current role\n* country\n* skills\n* current employer\n* employer URL\n* experiences (all previous jobs)\n* personal website\n* publications (articles)\n\n\n*NocoDB Field names*\n```\nlinkedin_full_name\nlinkedin_first_name: \nlinkedin_headline:\nlinkedin_email:\nlinkedin_bio:\nlinkedin_profile_pic\nlinkedin_current_role\nlinkedin_current_company\nlinkedin_country\nlinkedin_skills\nlinkedin_company_website\nlinkedin_experiences\nlinkedin_personal_website\nlinkedin_publications\nlinkedin_scrape_error_reason\nlinkedin_scrape_last_attempt\nlinkedin_scrape_status\nlinkedin_last_modified\n```\n\nTechnically you also need an Id field, but that is always there so no need to add it :)\n\n\n## n8n Setup\n\n###   1. Import the Workflow\n    - Copy the workflow JSON from the template\n    - In n8n, click \"Add workflow\" → \"Import from JSON\"\n    - Paste the workflow and click \"Import\"\n###   2. Configure NocoDB Connection\n    - Click on any NocoDB node in the workflow\n    - Add new credentials → \"NocoDB Token account\"\n    - Enter your NocoDB API token (found in NocoDB → User Settings → API\n  Tokens)\n    - Update the projectId and table parameters in all NocoDB nodes\n###   3. Set Up Apify Integration\n    - Create an Apify account at apify.com\n    - Generate an API token (Settings → Integrations → API)\n    - In the workflow, update the Apify token in the \"Get Scraper Results\"\n  node\n    - Configure HTTP Query Auth credentials with your token\n###   4. Map Your Database Fields\n    - Review the \"Transform & Sanitize Data\" node\n    - Update field mappings to match your NocoDB table structure\n    - Ensure these fields exist in your table:\n        - LinkedIn (URL field)\n      - linkedin_headline, linkedin_full_name, linkedin_bio, etc.\n      - linkedin_scrape_status, linkedin_last_modified\n###   5. Configure the Filter\n    - In \"Get Guests with LinkedIn\" node\n    - Adjust the filter to match your requirements\n    - Default: (LinkedIn,isnot,null)~and(linkedin_headline,is,null)\n###   6. Test the Workflow\n    - Click \"Execute Workflow\" with Manual Trigger\n    - Monitor execution for any errors\n    - Verify data is properly updated in NocoDB\n###   7. Activate Automated Schedule\n    - Configure the Schedule Trigger node (default: monthly)\n    - Toggle the workflow to \"Active\"\n    - Monitor executions in n8n dashboard\n\n# Customization Options\n\n## 1. Data Source Modifications\n  - Different Database: Replace NocoDB nodes with Airtable, Google Sheets, or\n  PostgreSQL\n  - Multiple Tables: Add parallel branches to process different contact tables\n  - Custom Filters: Modify the WHERE clause to target specific record subsets\n\n## 2. Enrichment Fields\n\n  - Add Fields: Include additional LinkedIn data like education,\n  certifications, or recommendations\n  - Remove Fields: Simplify by removing unnecessary fields (publications,\n  skills)\n  - Custom Transformations: Add business logic for field calculations or\n  formatting\n\n## 3. Scheduling Options\n  - Frequency: Change from monthly to daily, weekly, or hourly\n  - Time-based: Set specific times for different timezones\n  - Event-triggered: Replace with webhook trigger for on-demand processing\n\n**4. Error Handling Enhancement**\n  - Notifications: Add email/Slack nodes to alert on failures\n  - Retry Logic: Implement wait and retry for temporary failures\n  - Logging: Add database logging for audit trails\n\n## 5. Data Quality Rules\n\n  - Validation: Add IF nodes to validate data before updates\n  - Duplicate Detection: Check for existing records before creating new ones\n  - Data Standardization: Add custom sanitization rules for industry-specific\n  needs\n\n## 6. Integration Extensions\n\n  - CRM Sync: Add nodes to push data to Salesforce, HubSpot, or Pipedrive\n  - AI Enhancement: Use OpenAI to summarize bios or extract key skills\n  - Image Processing: Download and store profile pictures locally\n\n## 7. Performance Optimization\n\n  - Batch Size: Adjust the number of profiles processed per run\n  - Rate Limiting: Add delays between API calls to avoid limits\n  - Parallel Processing: Split large datasets across multiple workflow\n  executions\n\n## 8. Compliance Additions\n\n  - GDPR Compliance: Add consent checking before processing\n  - Data Retention: Implement automatic cleanup of old records\n  - Audit Logging: Track who accessed what data and when\n\nThese customizations allow the workflow to adapt from simple contact enrichment to complex data pipeline scenarios across various industries and use cases.",
  "featuredImage": "/data/workflows/5258/5258.webp",
  "author": {
    "id": 101,
    "slug": "gxjansen",
    "name": "Guido X Jansen",
    "avatar": ""
  },
  "categories": [
    "Lead Generation"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 934,
  "downloads": 93,
  "createdAt": "2025-06-24T22:20:44.285Z",
  "updatedAt": "2026-01-16T08:38:36.863Z",
  "publishedAt": "2025-06-24T22:20:44.285Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5258"
}