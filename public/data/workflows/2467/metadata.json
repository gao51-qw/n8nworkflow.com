{
  "id": 2467,
  "slug": "2467",
  "title": "Narrating over a video using multimodal AI",
  "description": "This n8n template takes a video and extracts frames from it which are used with a multimodal LLM to generate a script. The script is then passed to the same multimodal LLM to generate a voiceover clip.\n\nThis template was inspired by [Processing and narrating a video with GPT's visual capabilities and the TTS API](https://cookbook.openai.com/examples/gpt_with_vision_for_video_understanding)\n\n## How it works\n* Video is downloaded using the HTTP node.\n* Python code node is used to extract the frames using OpenCV.\n* Loop node is used o batch the frames for the LLM to generate partial scripts.\n* All partial scripts are combined to form the full script which is then sent to OpenAI to generate audio from it.\n* The finished voiceover clip is uploaded to Google Drive.\n\nSample the finished product here: [https://drive.google.com/file/d/1-XCoii0leGB2MffBMPpCZoxboVyeyeIX/view?usp=sharing](https://drive.google.com/file/d/1-XCoii0leGB2MffBMPpCZoxboVyeyeIX/view?usp=sharing)\n\n## Requirements\n\n* OpenAI for LLM\n* Ideally, a mid-range (16GB RAM) machine for acceptable performance!\n\n## Customising this workflow\n\n* For larger videos, consider splitting into smaller clips for better performance\n* Use a multimodal LLM which supports fully video such as Google's Gemini.\n",
  "featuredImage": "/data/workflows/2467/2467.webp",
  "author": {
    "id": 101,
    "slug": "jimleuk",
    "name": "Jimleuk",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 9667,
  "downloads": 966,
  "createdAt": "2024-10-17T10:45:39.624Z",
  "updatedAt": "2026-01-16T08:24:56.735Z",
  "publishedAt": "2024-10-17T10:45:39.624Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2467"
}