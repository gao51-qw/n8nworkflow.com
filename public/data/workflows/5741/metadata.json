{
  "id": 5741,
  "slug": "5741",
  "title": "Generate cinematic videos from text prompts with GPT-4o, Fal.AI Seedance & Audio",
  "description": "### Who’s it for?\n\nThis workflow is built for:\n- **AI storytellers**, **content creators**, **YouTubers**, and **short-form video marketers**\n- Anyone looking to transform text prompts into **cinematic AI-generated videos** fully automatically\n- **Educators**, **trainers**, or **agencies** creating story-based visual content at scale\n\n---\n\n###  What It Does\n\nThis n8n workflow allows you to automatically turn a **simple text prompt** into a **multi-scene cinematic video**, using the powerful **Fal.AI Seedance V1.0** model (developed by **ByteDance** — the creators of TikTok).\n\nIt combines the creativity of **GPT-4o**, the motion synthesis of **Seedance**, and the automation power of **n8n** to generate AI videos with ambient sound and publish-ready format.\n\n---\n\n### How It Works\n\n1. Accepts a prompt from **Google Sheets** (configurable fields like duration, aspect ratio, resolution, scene count)\n2. Uses **OpenAI GPT-4o** to write a vivid cinematic **narrative**\n3. Splits the story into **n separate scenes**\n4. For each scene:\n   - GPT generates a structured cinematic description (characters, camera, movement, sound)\n   - The **Seedance V1.0 model (via Fal.AI API)** renders a 5s animated video\n   - Optional: Adds ambient **audio via Fal’s MM-Audio model**\n5. Finally:\n   - Merges all scene videos using **Fal’s FFmpeg API**\n   - Optionally **uploads to YouTube automatically**\n\n---\n\n###  Why This Is Special\n\n- **Fal.AI Seedance V1.0** is a highly advanced motion video model developed by ByteDance, capable of generating expressive, stylized 5–6 second cinematic clips from text.\n- This workflow supports full looping, scene count validation, and wait-polling for long render jobs.\n- The entire story, breakdown, and scene design are AI-generated — no manual effort needed.\n- Output is export-ready: MP4 with sound, ideal for YouTube Shorts, Reels, or TikTok.\n\n---\n\n### Requirements\n\n- n8n (Self-hosted recommended)\n- API Keys:\n  -  `Fal.AI` (https://fal.ai)\n  -  `OpenAI` (GPT-4o or 3.5)\n  -  `Google Sheets` [Example Google Sheet](https://docs.google.com/spreadsheets/d/1FuDdvkzq5TZ3Evs92BxUxD4qOK0EDLAzB-SayKwpAdw)\n\n---\n\n### How to Set It Up\n\n1. Clone the template into your n8n instance\n2. Configure credentials:\n   - Fal.AI Header Token\n   - OpenAI API Key\n   - Google Sheets OAuth2\n   - (Optional) YouTube API OAuth\n3. Prepare a Google Sheet with these columns:\n   - `story` (short prompt)\n   - `number_of_scene`\n   - `duration` (per clip)\n   - `aspect_ratio`, `resolution`, `model`\n4. Run manually or trigger on Sheet update.\n\n---\n\n### How to Customize\n\n- Modify the storytelling tone in GPT prompts (e.g., switch to fantasy, horror, sci-fi)\n- Change Seedance model params like style or seed\n- Add subtitles or branding overlays to final video\n- Integrate LINE, Notion, or Telegram for auto-sharing\n\n---\n\n### Example Output\n\n**Prompt**: *“A rabbit flies to the moon on a dragonfly and eats watermelon together”*  \n→ Result: 3 scenes, each 5s, cinematic camera pans, soft ambient audio, auto-uploaded to YouTube\n[Result](https://youtu.be/_PKvi0Sfs84)\n",
  "featuredImage": "/data/workflows/5741/5741.webp",
  "author": {
    "id": 101,
    "slug": "jaruphatj",
    "name": "Jaruphat J.",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 18134,
  "downloads": 1813,
  "createdAt": "2025-07-07T09:21:49.644Z",
  "updatedAt": "2026-01-16T08:41:12.126Z",
  "publishedAt": "2025-07-07T09:21:49.644Z",
  "nodes": 38,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5741"
}