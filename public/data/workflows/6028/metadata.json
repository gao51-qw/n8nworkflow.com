{
  "id": 6028,
  "slug": "6028",
  "title": "Scrape Upwork job listings & generate daily email reports with Apify & Google Sheets",
  "description": "This automated n8n workflow scrapes job listings from Upwork using Apify, processes and cleans the data, and generates daily email reports with job summaries. The system uses Google Sheets for data storage and keyword management, providing a comprehensive solution for tracking relevant job opportunities and market trends.\n\n## **What is Apify?**\nApify is a web scraping and automation platform that provides reliable APIs for extracting data from websites like Upwork. It handles the complexities of web scraping including rate limiting, proxy management, and data extraction while maintaining compliance with website terms of service.\n\n## **Good to Know**\n* Apify API calls may incur costs based on usage; check Apify pricing for details\n* Google Sheets access must be properly authorized to avoid data sync issues\n* The workflow includes data cleaning and deduplication to ensure high-quality results\n* Email reports provide structured summaries for easy review and decision-making\n* Keyword management through Google Sheets allows for flexible job targeting\n\n## **How It Works**\n\nThe workflow is organized into three main phases:\n\n**Phase 1: Job Scraping & Initial Processing**\nThis phase handles the core data collection and initial storage:\n1. **Trigger Manual Run** - Manually starts the workflow for on-demand job scraping\n2. **Fetch Keywords from Google Sheet** - Reads the list of job-related keywords from the All Keywords sheet\n3. **Loop Through Keywords** - Iterates over each keyword to trigger Apify scraping\n4. **Trigger Apify Scraper** - Sends HTTP request to start Apify actor for job scraping\n5. **Wait for Apify Completion** - Waits for the Apify actor to finish execution\n6. **Delay Before Dataset Read** - Waits a few seconds to ensure dataset is ready for processing\n7. **Fetch Scraped Job Dataset** - Fetches the latest dataset from Apify\n8. **Process Raw Job Data** - Filters jobs posted in the last 24 hours and formats the data\n9. **Save Jobs to Daily Sheet** - Appends new job data to the daily Google Sheet\n10. **Update Keyword Job Count** - Updates job count in the All Keywords summary sheet\n\n**Phase 2: Data Cleaning & Deduplication**\nThis phase ensures data quality and removes duplicates:\n1. **Load Today's Daily Jobs** - Loads all jobs added in today's sheet for processing\n2. **Remove Duplicates by Title/Desc** - Removes duplicates based on title and description matching\n3. **Save Clean Job Data** - Saves the cleaned, unique entries back to the sheet\n4. **Clear Old Daily Sheet Data** - Deletes old or duplicate entries from the sheet\n5. **Reload Clean Job Data** - Loads clean data again after deletion for final processing\n\n**Phase 3: Daily Summary & Email Report**\nThis phase generates summaries and delivers the final report:\n1. **Generate Keyword Summary Stats** - Counts job totals per keyword for analysis\n2. **Update Summary Sheet** - Updates the summary sheet with keyword statistics\n3. **Fetch Final Summary Data** - Reads the summary sheet for reporting purposes\n4. **Build Email Body** - Formats email with statistics and sheet link\n5. **Send Daily Report Email** - Sends the structured daily summary email to recipients\n\n## **Data Sources**\nThe workflow utilizes Google Sheets for data management:\n\n1. **AI Keywords Sheet** - Contains keyword management data with columns:\n   - Keyword (text) - Job search terms\n   - Job Count (number) - Number of jobs found for each keyword\n   - Status (text) - Active/Inactive status\n   - Last Updated (timestamp) - When keyword was last processed\n\n2. **Daily Jobs Sheet** - Contains scraped job data with columns:\n   - Job Title (text) - Title of the job posting\n   - Description (text) - Job description content\n   - Budget (text) - Job budget or hourly rate\n   - Client Rating (number) - Client's rating on Upwork\n   - Posted Date (timestamp) - When job was posted\n   - Job URL (text) - Direct link to the job posting\n   - Keyword (text) - Which keyword found this job\n   - Scraped At (timestamp) - When data was collected\n\n3. **Summary Sheet** - Contains daily statistics with columns:\n   - Date (date) - Report date\n   - Total Jobs (number) - Total jobs found\n   - Keywords Processed (number) - Number of keywords searched\n   - Top Keyword (text) - Most productive keyword\n   - Average Budget (currency) - Average job budget\n   - Report Generated (timestamp) - When summary was created\n\n## **How to Use**\n* Import the workflow into n8n\n* Configure Apify API credentials and Google Sheets API access\n* Set up email credentials for daily report delivery\n* Create three Google Sheets with the specified column structures\n* Add relevant job keywords to the AI Keywords sheet\n* Test with sample keywords and adjust as needed\n\n## **Requirements**\n1. Apify API credentials and actor access\n2. Google Sheets API access\n3. Email service credentials (Gmail, SMTP, etc.)\n4. Upwork job search keywords for targeting\n\n## **Customizing This Workflow**\nModify the Process Raw Job Data node to filter jobs by additional criteria like budget range, client rating, or job type. Adjust the email report format to include more detailed statistics or add visual aids, such as charts. Customize the data cleaning logic to better handle duplicate detection based on your specific requirements, or add additional data sources beyond Upwork for comprehensive job market analysis.",
  "featuredImage": "/data/workflows/6028/6028.webp",
  "author": {
    "id": 101,
    "slug": "oneclick-ai",
    "name": "Oneclick AI Squad",
    "avatar": ""
  },
  "categories": [
    "Market Research"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 741,
  "downloads": 74,
  "createdAt": "2025-07-15T14:21:31.160Z",
  "updatedAt": "2026-01-16T08:42:46.975Z",
  "publishedAt": "2025-07-15T14:21:31.160Z",
  "nodes": 23,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6028"
}