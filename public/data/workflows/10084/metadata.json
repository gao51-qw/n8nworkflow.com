{
  "id": 10084,
  "slug": "10084",
  "title": "Monitor emails & send AI-generated auto-replies with Ollama & Telegram alerts",
  "description": "\n## Workflow Overview\n\nThis advanced n8n workflow provides intelligent email automation with AI-generated responses. It combines four core functions:\n1. Monitors incoming emails via IMAP (e.g., SOGo)\n2. Sends instant Telegram notifications for all new emails\n3. Uses AI (Ollama LLM) to generate contextual, personalized auto-replies\n4. Sends confirmation notifications when auto-replies are sent\n\nUnlike traditional auto-responders, this workflow analyzes email content and creates unique, relevant responses for each message.\n\n---\n\n## Setup Instructions\n\n### Prerequisites\n\nBefore setting up this workflow, ensure you have:\n- An n8n instance (self-hosted or cloud) with AI/LangChain nodes enabled\n- IMAP email account credentials (e.g., SOGo, Gmail, Outlook)\n- SMTP server access for sending emails\n- Telegram Bot API credentials\n- Telegram Chat ID where notifications will be sent\n- Ollama installed locally or accessible via network (for AI model)\n- The llama3.1 model downloaded in Ollama\n\n### Step 1: Install and Configure Ollama\n\n#### Local Installation\n\n1. Install Ollama on your system:\n   - Visit https://ollama.ai and download the installer for your OS\n   - Follow installation instructions for your platform\n\n2. Download the llama3.1 model:\n   ```bash\n   ollama pull llama3.1\n   ```\n\n3. Verify the model is available:\n   ```bash\n   ollama list\n   ```\n\n4. Start Ollama service (if not already running):\n   ```bash\n   ollama serve\n   ```\n\n5. Test the model:\n   ```bash\n   ollama run llama3.1 \"Hello, world!\"\n   ```\n\n#### Remote Ollama Instance\n\nIf using a remote Ollama server:\n- Note the server URL (e.g., http://192.168.1.100:11434)\n- Ensure network connectivity between n8n and Ollama server\n- Verify firewall allows connections on port 11434\n\n### Step 2: Configure IMAP Credentials\n\n1. Navigate to n8n Credentials section\n2. Create a new IMAP credential with the following information:\n   - Host: Your IMAP server address\n   - Port: Usually 993 for SSL/TLS\n   - Username: Your email address\n   - Password: Your email password or app-specific password\n   - Enable SSL/TLS: Yes (recommended)\n   - Security: Use STARTTLS or SSL/TLS\n\n### Step 3: Configure SMTP Credentials\n\n1. Create a new SMTP credential in n8n\n2. Enter the following details:\n   - Host: Your SMTP server address (e.g., Postfix server)\n   - Port: Usually 587 (STARTTLS) or 465 (SSL)\n   - Username: Your email address\n   - Password: Your email password or app-specific password\n   - Secure connection: Enable based on your server configuration\n   - Allow unauthorized certificates: Enable if using self-signed certificates\n\n### Step 4: Configure Telegram Bot\n\n1. Create a Telegram bot via BotFather:\n   - Open Telegram and search for @BotFather\n   - Send `/newbot` command\n   - Follow instructions to create your bot\n   - Save the API token provided by BotFather\n\n2. Obtain your Chat ID:\n   - Method 1: Send a message to your bot, then visit:\n     `https://api.telegram.org/bot&lt;YOUR_BOT_TOKEN&gt;/getUpdates`\n   - Method 2: Use a Telegram Chat ID bot like @userinfobot\n   - Method 3: For group chats, add the bot to the group and check the updates\n   - Note: Group chat IDs are negative numbers (e.g., -1234567890123)\n\n3. Add Telegram API credential in n8n:\n   - Credential Type: Telegram API\n   - Access Token: Your bot token from BotFather\n\n### Step 5: Configure Ollama API Credential\n\n1. In n8n Credentials section, create a new Ollama API credential\n2. Configure based on your setup:\n   - For local Ollama: Base URL is usually `http://localhost:11434`\n   - For remote Ollama: Enter the server URL (e.g., `http://192.168.1.100:11434`)\n3. Test the connection to ensure n8n can reach Ollama\n\n### Step 6: Import and Configure Workflow\n\n1. Import the workflow JSON into your n8n instance\n2. Update the following nodes with your specific information:\n\n#### Check Incoming Emails Node\n- Verify IMAP credentials are connected\n- Configure polling interval (optional):\n  - Default behavior checks on workflow trigger schedule\n  - Can be set to check every N minutes\n- Set mailbox folder if needed (default is INBOX)\n\n#### Send Notification from Incoming Email Node\n- Update `chatId` parameter with your Telegram Chat ID\n- Replace `-1234567890123` with your actual chat ID\n- Customize notification message template if desired\n- Current format includes: Sender, Subject, Date-Time\n\n#### Dedicate Filtering As No-Response Node\n- Review spam filter conditions:\n  - Blocks emails from addresses containing \"noreply\" or \"no-reply\"\n  - Blocks emails with \"newsletter\" in subject line (case-insensitive)\n- Add additional filtering rules as needed:\n  - Block specific domains\n  - Filter by keywords\n  - Whitelist/blacklist specific senders\n\n#### Ollama Model Node\n- Verify Ollama API credential is connected\n- Confirm model name: `llama3.1:bf230501` (or adjust to your installed version)\n- Context window set to 4096 tokens (sufficient for most emails)\n- Can be adjusted based on your needs and hardware capabilities\n\n#### Basic LLM Chain Node\n- Review the AI prompt engineering (pre-configured but customizable)\n- Current prompt instructs the AI to:\n  - Read the email content\n  - Identify main topic in 2-4 words\n  - Generate a professional acknowledgment response\n  - Keep responses consistent and concise\n- Modify prompt if you want different response styles\n\n#### Send Auto-Response in SMTP Node\n- Verify SMTP credentials are connected\n- Check `fromEmail` uses correct email address:\n  - Currently set to `{{ $('Check Incoming Emails - IMAP (example: SOGo)').item.json.to }}`\n  - This automatically uses the recipient address (your mailbox)\n- Subject automatically includes \"Re: \" prefix with original subject\n- Message text comes from AI-generated content\n\n#### Send Notification from Response Node\n- Update `chatId` parameter (same as first notification node)\n- This sends confirmation that auto-reply was sent\n- Includes original email details and the AI-generated response text\n\n### Step 7: Test the Workflow\n\n1. Perform initial configuration test:\n   - Test Ollama connectivity: `curl http://localhost:11434/api/tags`\n   - Verify all credentials are properly configured\n   - Check n8n has access to required network endpoints\n\n2. Execute a test run:\n   - Click \"Execute Workflow\" button in n8n\n   - Send a test email to your monitored inbox\n   - Use a clear subject and body for better AI response\n\n3. Verify workflow execution:\n   - First Telegram notification received (incoming email alert)\n   - AI processes the email content\n   - Auto-reply is sent to the original sender\n   - Second Telegram notification received (confirmation with AI response)\n   - Check n8n execution log for any errors\n\n4. Verify email delivery:\n   - Check if auto-reply arrived at sender's inbox\n   - Verify it's not marked as spam\n   - Review AI-generated content for appropriateness\n\n### Step 8: Fine-Tune AI Responses\n\n1. Send various types of test emails:\n   - Different topics (inquiry, complaint, information request)\n   - Various email lengths (short, medium, long)\n   - Different languages if applicable\n\n2. Review AI-generated responses:\n   - Check if topic identification is accurate\n   - Verify response appropriateness\n   - Ensure tone is professional\n\n3. Adjust the prompt if needed:\n   - Modify topic word count (currently 2-4 words)\n   - Change response template\n   - Add language-specific instructions\n   - Include custom sign-offs or branding\n\n### Step 9: Activate the Workflow\n\n1. Once testing is successful and AI responses are satisfactory:\n   - Toggle the workflow to \"Active\" state\n   - The workflow will now run automatically on the configured schedule\n\n2. Monitor initial production runs:\n   - Review first few auto-replies carefully\n   - Check Telegram notifications for any issues\n   - Verify SMTP delivery rates\n\n3. Set up monitoring:\n   - Enable n8n workflow error notifications\n   - Monitor Ollama resource usage\n   - Check email server logs periodically\n\n---\n\n## How to Use\n\n### Normal Operation\n\nOnce activated, the workflow operates fully automatically:\n\n1. **Email Monitoring**: The workflow continuously checks your IMAP inbox for new messages based on the configured polling interval or trigger schedule.\n\n2. **Immediate Incoming Notification**: When a new email arrives, you receive an instant Telegram notification containing:\n   - Sender's email address\n   - Email subject line\n   - Date and time received\n   - Note indicating it's from IMAP mailbox\n\n3. **Intelligent Filtering**: The workflow evaluates each email against spam filter criteria:\n   - Emails from \"noreply\" or \"no-reply\" addresses are filtered out\n   - Emails with \"newsletter\" in the subject line are filtered out\n   - Filtered emails receive notification but no auto-reply\n   - Legitimate emails proceed to AI response generation\n\n4. **AI Response Generation**: For emails that pass the filter:\n   - The AI reads the full email content\n   - Analyzes the main topic or purpose\n   - Generates a personalized acknowledgment\n   - Creates a professional response that:\n     - Thanks the sender\n     - References the specific topic\n     - Promises a personal follow-up\n     - Maintains professional tone\n\n5. **Automatic Reply Delivery**: The AI-generated response is sent via SMTP to the original sender with:\n   - Subject line: \"Re: [Original Subject]\"\n   - From address: Your monitored mailbox\n   - Body: AI-generated contextual message\n\n6. **Response Confirmation**: After the auto-reply is sent, you receive a second Telegram notification showing:\n   - Original email details (sender, subject, date)\n   - The complete AI-generated response text\n   - Confirmation of successful delivery\n\n### Understanding AI Response Generation\n\nThe AI analyzes emails intelligently:\n\n**Example 1: Business Inquiry**\n```\nIncoming Email: \"I'm interested in your consulting services for our Q4 project...\"\nAI Topic Identification: \"consulting services\"\nGenerated Response: \"Dear Correspondent! Thank you for your message regarding consulting services. I will respond with a personal message as soon as possible. Have a nice day!\"\n```\n\n**Example 2: Technical Support**\n```\nIncoming Email: \"We're experiencing issues with the API integration...\"\nAI Topic Identification: \"API integration issues\"\nGenerated Response: \"Dear Correspondent! Thank you for your message regarding API integration issues. I will respond with a personal message as soon as possible. Have a nice day!\"\n```\n\n**Example 3: General Question**\n```\nIncoming Email: \"Could you provide more information about pricing?\"\nAI Topic Identification: \"pricing information\"\nGenerated Response: \"Dear Correspondent! Thank you for your message regarding pricing information. I will respond with a personal message as soon as possible. Have a nice day!\"\n```\n\n### Customizing Filter Rules\n\nTo modify which emails receive AI-generated auto-replies:\n\n1. Open the \"Dedicate Filtering As No-Response\" node\n2. Modify existing conditions or add new ones:\n\n**Block specific domains:**\n```javascript\n{{ $json.from.value[0].address }}\nOperation: does not contain\nValue: @spam-domain.com\n```\n\n**Whitelist VIP senders (only respond to specific people):**\n```javascript\n{{ $json.from.value[0].address }}\nOperation: contains\nValue: @important-client.com\n```\n\n**Filter by subject keywords:**\n```javascript\n{{ $json.subject.toLowerCase() }}\nOperation: does not contain\nValue: unsubscribe\n```\n\n**Combine multiple conditions:**\n- Use AND logic (all must be true) for stricter filtering\n- Use OR logic (any can be true) for more permissive filtering\n\n### Customizing AI Prompt\n\nTo change how the AI generates responses:\n\n1. Open the \"Basic LLM Chain\" node\n2. Modify the prompt text in the \"text\" parameter\n3. Current structure:\n   - Context setting (read email, identify topic)\n   - Output format specification\n   - Rules for AI behavior\n\n**Example modifications:**\n\n**Add company branding:**\n```\nReturn only this response, filling in the [TOPIC]:\n\nDear Correspondent! \nThank you for reaching out to [Your Company Name] regarding [TOPIC]. \nI will respond with a personal message as soon as possible. \nBest regards,\n[Your Name]\n[Your Company Name]\n```\n\n**Make it more casual:**\n```\nReturn only this response, filling in the [TOPIC]:\n\nHi there! \nThanks for your email about [TOPIC]. \nI'll get back to you personally soon. \nCheers!\n```\n\n**Add urgency classification:**\n```\nRead the email and classify urgency (Low/Medium/High).\nIdentify the main topic.\n\nReturn:\n\nDear Correspondent!\nThank you for your message regarding [TOPIC].\nPriority: [URGENCY]\nI will respond with a personal message as soon as possible.\n```\n\n### Customizing Telegram Notifications\n\n**Incoming Email Notification:**\n1. Open \"Send Notification from Incoming Email\" node\n2. Modify the \"text\" parameter\n3. Available variables:\n   - `{{ $json.from }}` - Full sender info\n   - `{{ $json.from.value[0].address }}` - Sender email only\n   - `{{ $json.from.value[0].name }}` - Sender name (if available)\n   - `{{ $json.subject }}` - Email subject\n   - `{{ $json.date }}` - Date received\n   - `{{ $json.textPlain }}` - Email body (use cautiously for privacy)\n   - `{{ $json.to }}` - Recipient address\n\n**Response Confirmation Notification:**\n1. Open \"Send Notification from Response\" node\n2. Modify to include additional information\n3. Reference AI response: `{{ $('Basic LLM Chain').item.json.text }}`\n\n### Monitoring and Maintenance\n\n#### Daily Monitoring\n\n- **Check Telegram Notifications**: Review incoming email alerts and response confirmations\n- **Verify AI Quality**: Spot-check AI-generated responses for appropriateness\n- **Email Delivery**: Confirm auto-replies are being delivered (not caught in spam)\n\n#### Weekly Maintenance\n\n- **Review Execution Logs**: Check n8n execution history for errors or warnings\n- **Ollama Performance**: Monitor resource usage (CPU, RAM, disk space)\n- **Filter Effectiveness**: Assess if spam filters are working correctly\n- **Response Quality**: Review multiple AI responses for consistency\n\n#### Monthly Maintenance\n\n- **Update Ollama Model**: Check for new llama3.1 versions or alternative models\n- **Prompt Optimization**: Refine AI prompt based on response quality observations\n- **Credential Rotation**: Update passwords and API tokens for security\n- **Backup Configuration**: Export workflow and credentials (securely)\n\n### Advanced Usage\n\n#### Multi-Language Support\n\nIf you receive emails in multiple languages:\n\n1. Modify the AI prompt to detect language:\n```\nDetect the email language.\nGenerate response in the SAME language as the email.\n\nIf English: [English template]\nIf Hungarian: [Hungarian template]\nIf German: [German template]\n```\n\n2. Or use language-specific conditions in the filtering node\n\n#### Priority-Based Responses\n\nGenerate different responses based on sender importance:\n\n1. Add an IF node after filtering to check sender domain\n2. Route VIP emails to a different LLM chain with priority messaging\n3. Standard emails use the normal AI chain\n\n#### Response Logging\n\nTo maintain a record of all AI interactions:\n\n1. Add a database node (PostgreSQL, MySQL, etc.) after the auto-reply node\n2. Store: timestamp, sender, subject, AI response, delivery status\n3. Use for compliance, analytics, or training data\n\n#### A/B Testing AI Prompts\n\nTest different prompt variations:\n\n1. Create multiple LLM Chain nodes with different prompts\n2. Use a randomizer or round-robin approach\n3. Compare response quality and user feedback\n4. Optimize based on results\n\n### Troubleshooting\n\n#### Notifications Not Received\n\n**Problem**: Telegram notifications not appearing\n\n**Solutions**:\n- Verify Chat ID is correct (positive for personal chats, negative for groups)\n- Check if bot has permissions to send messages\n- Ensure bot wasn't blocked or removed from group\n- Test Telegram API credential independently\n- Review n8n execution logs for Telegram API errors\n\n#### AI Responses Not Generated\n\n**Problem**: Auto-replies sent but content is empty or error messages\n\n**Solutions**:\n- Check Ollama service is running: `ollama list`\n- Verify llama3.1 model is downloaded: `ollama list`\n- Test Ollama directly: `ollama run llama3.1 \"Test message\"`\n- Review Ollama API credential URL in n8n\n- Check network connectivity between n8n and Ollama\n- Increase context window if emails are very long\n- Monitor Ollama logs for errors\n\n#### Poor Quality AI Responses\n\n**Problem**: AI generates irrelevant or inappropriate responses\n\n**Solutions**:\n- Review and refine the prompt engineering\n- Add more specific rules and constraints\n- Provide examples in the prompt of good vs bad responses\n- Adjust topic word count (increase from 2-4 to 3-6 words)\n- Test with different Ollama models (e.g., llama3.1:70b for better quality)\n- Ensure email content is being passed correctly to AI\n\n#### Auto-Replies Not Sent\n\n**Problem**: Workflow executes but emails not delivered\n\n**Solutions**:\n- Verify SMTP credentials and server connectivity\n- Check fromEmail address is correct\n- Review SMTP server logs for errors\n- Test SMTP sending independently\n- Ensure \"Allow unauthorized certificates\" is enabled if needed\n- Check if emails are being filtered by spam filters\n- Verify SPF/DKIM records for your domain\n\n#### High Resource Usage\n\n**Problem**: Ollama consuming excessive CPU/RAM\n\n**Solutions**:\n- Reduce context window size (from 4096 to 2048)\n- Use a smaller model variant (llama3.1:8b instead of default)\n- Limit concurrent workflow executions in n8n\n- Add delay/throttling between email processing\n- Consider using a remote Ollama instance with better hardware\n- Monitor email volume and processing time\n\n#### IMAP Connection Failures\n\n**Problem**: Workflow can't connect to email server\n\n**Solutions**:\n- Verify IMAP credentials are correct\n- Check if IMAP is enabled on email account\n- Ensure SSL/TLS settings match server requirements\n- For Gmail: enable \"Less secure app access\" or use App Passwords\n- Check firewall allows outbound connections on IMAP port (993)\n- Test IMAP connection using email client (Thunderbird, Outlook)\n\n#### Workflow Not Triggering\n\n**Problem**: Workflow doesn't execute automatically\n\n**Solutions**:\n- Verify workflow is in \"Active\" state\n- Check trigger node configuration and schedule\n- Review n8n system logs for scheduler issues\n- Ensure n8n instance has sufficient resources\n- Test manual execution to isolate trigger issues\n- Check if n8n workflow execution queue is backed up\n\n---\n\n## Workflow Architecture\n\n### Node Descriptions\n\n1. **Check Incoming Emails - IMAP**: Polls email server at regular intervals to retrieve new messages from the configured mailbox.\n\n2. **Send Notification from Incoming Email**: Immediately sends formatted notification to Telegram for every new email detected, regardless of spam status.\n\n3. **Dedicate Filtering As No-Response**: Evaluates emails against spam filter criteria to determine if AI processing should occur.\n\n4. **No Operation**: Placeholder node for filtered emails that should not receive an auto-reply (spam, newsletters, automated messages).\n\n5. **Ollama Model**: Provides the AI language model (llama3.1) used for natural language processing and response generation.\n\n6. **Basic LLM Chain**: Executes the AI prompt against the email content to generate contextual auto-reply text.\n\n7. **Send Auto-Response in SMTP**: Sends the AI-generated acknowledgment email back to the original sender via SMTP server.\n\n8. **Send Notification from Response**: Sends confirmation to Telegram showing the auto-reply was successfully sent, including the AI-generated content.\n\n### AI Processing Pipeline\n\n1. **Email Content Extraction**: Email body text is extracted from IMAP data\n2. **Context Loading**: Email content is passed to LLM with prompt instructions\n3. **Topic Analysis**: AI identifies main subject or purpose in 2-4 words\n4. **Template Population**: AI fills response template with identified topic\n5. **Output Formatting**: Response is formatted and cleaned for email delivery\n6. **Quality Assurance**: n8n validates response before sending\n\n",
  "featuredImage": "/data/workflows/10084/10084.webp",
  "author": {
    "id": 101,
    "slug": "vighsandor",
    "name": "Vigh Sandor",
    "avatar": ""
  },
  "categories": [
    "Ticket Management",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 249,
  "downloads": 24,
  "createdAt": "2025-10-23T13:26:24.976Z",
  "updatedAt": "2026-01-16T09:03:20.443Z",
  "publishedAt": "2025-10-23T13:26:24.976Z",
  "nodes": 17,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10084"
}