{
  "workflow": {
    "id": 4972,
    "name": "Monitor AI chat interactions with Gemini 2.5 and Langfuse tracing",
    "views": 1096,
    "recentViews": 0,
    "totalViews": 1096,
    "createdAt": "2025-06-16T14:01:56.103Z",
    "description": "This workflow contains community nodes that are only compatible with the self-hosted version of n8n.\n\n# How it works\n\nThis workflow is a simple AI Agent that connects to Langfuse so send tracing data to help monitor LLM interactions.\n\nThe main idea is to create a custom LLM model that allows the configuration of callbacks, which are used by langchain to connect applications such Langfuse.\n\nThis is achieves by using the \"langchain code\" node:\n- Connects a LLM model sub-node to obtain the model variables (model name, temp and provider) - Creates a generic langchain initChatModel with the model parameters.\n- Return the LLM to be used by the AI Agent node.\n\n\n## üìã Prerequisites\n- Langfuse instance (cloud or self-hosted) with API credentials\n- LLM API key (Gemini, OpenAI, Anthropic, etc.)\n- n8n &gt;= 1.98.0 (required for LangChain code node support in AI Agent)\n\n## ‚öôÔ∏è Setup\n\n1. Add these to your n8n instance:\n```bash\n# Langfuse configuration\nLANGFUSE_SECRET_KEY=your_secret_key\nLANGFUSE_PUBLIC_KEY=your_public_key\nLANGFUSE_BASEURL=https://cloud.langfuse.com  # or your self-hosted URL\n\n# LLM API key (example for Gemini)\nGOOGLE_API_KEY=your_api_key\n```\n\nAlternative: Configure these directly in the LangChain code node if you prefer not to use environment variables\n\n2. Import the workflow JSON\n\n3. Connect your preferred LLM model node\n\n4. Send a test message to verify tracing appears in Langfuse\n",
    "workflow": {
      "meta": {
        "instanceId": "b1926f93e76612afd634dd6dc19dbaa8cf351113b4888b572f3e1d29a5bec617",
        "templateCredsSetupCompleted": true
      },
      "nodes": [
        {
          "id": "c26d363f-53d2-446b-98db-d68a4b947bc5",
          "name": "When chat message received",
          "type": "@n8n/n8n-nodes-langchain.chatTrigger",
          "position": [
            880,
            540
          ],
          "webhookId": "3917af54-131f-41c5-a250-b32e0ff9dc5f",
          "parameters": {
            "options": {}
          },
          "typeVersion": 1.1
        },
        {
          "id": "01f4841f-2e4d-4beb-8f19-258cb4e8f988",
          "name": "gemini-2.5",
          "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
          "position": [
            1188,
            960
          ],
          "parameters": {
            "options": {
              "temperature": 0.4
            },
            "modelName": "models/gemini-2.5-flash-preview-05-20"
          },
          "credentials": {
            "googlePalmApi": {
              "id": "credential-id",
              "name": "googlePalmApi Credential"
            }
          },
          "typeVersion": 1
        },
        {
          "id": "f63d8101-0b24-4917-9126-ceccc926cb3c",
          "name": "mem",
          "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
          "position": [
            1396,
            760
          ],
          "parameters": {
            "contextWindowLength": 100
          },
          "typeVersion": 1.3
        },
        {
          "id": "c5c637fd-962d-4c2c-bb7a-c35faae85ee1",
          "name": "Langfuse LLM",
          "type": "@n8n/n8n-nodes-langchain.code",
          "position": [
            1100,
            762.5
          ],
          "parameters": {
            "code": {
              "supplyData": {
                "code": "const { CallbackHandler } = require(\"langfuse-langchain\");\nconst { initChatModel } = require(\"langchain/chat_models/universal\");\n\n// Get connected model\nconst model = await this.getInputConnectionData(\"ai_languageModel\", 0);\nconst modelProvider = model.lc_namespace[2].replace(\"_\", \"-\");\nconst modelName = model.model;\nconst temperature = model.temperature;\n\n// Initialize Langfuse callback handler\nconst sessionId = $input.item.json.sessionId;\nconst langfuseHandler = new CallbackHandler({\n  sessionId,\n});\n\nconst llm = await initChatModel(modelName, {\n  temperature,\n  modelProvider,\n  callbacks: [langfuseHandler],\n});\n\nreturn llm;\n"
              }
            },
            "inputs": {
              "input": [
                {
                  "type": "ai_languageModel",
                  "required": true,
                  "maxConnections": 1
                }
              ]
            },
            "outputs": {
              "output": [
                {
                  "type": "ai_languageModel"
                }
              ]
            }
          },
          "typeVersion": 1
        },
        {
          "id": "c5f53fbe-5603-4384-b4fa-076a69a1f6aa",
          "name": "AI Agent",
          "type": "@n8n/n8n-nodes-langchain.agent",
          "position": [
            1204,
            540
          ],
          "parameters": {
            "options": {}
          },
          "typeVersion": 2
        }
      ],
      "pinData": {},
      "connections": {
        "mem": {
          "ai_memory": [
            [
              {
                "node": "AI Agent",
                "type": "ai_memory",
                "index": 0
              }
            ]
          ]
        },
        "AI Agent": {
          "main": [
            []
          ]
        },
        "gemini-2.5": {
          "ai_languageModel": [
            [
              {
                "node": "Langfuse LLM",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "Langfuse LLM": {
          "ai_languageModel": [
            [
              {
                "node": "AI Agent",
                "type": "ai_languageModel",
                "index": 0
              }
            ]
          ]
        },
        "When chat message received": {
          "main": [
            [
              {
                "node": "AI Agent",
                "type": "main",
                "index": 0
              }
            ]
          ]
        }
      }
    },
    "lastUpdatedBy": 51,
    "workflowInfo": {
      "nodeCount": 5,
      "nodeTypes": {
        "@n8n/n8n-nodes-langchain.code": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.agent": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.chatTrigger": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.lmChatGoogleGemini": {
          "count": 1
        },
        "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
          "count": 1
        }
      }
    },
    "status": "published",
    "user": {
      "name": "Eduardo Hales",
      "username": "ehales",
      "bio": "Full Stack Developer with 8+ years building web applications, now focused on AI engineering and cybersecurity. I integrate LLMs into production systems, conduct security audits, and help teams build safer, smarter software. Particularly interested in making AI applications both powerful and secure.",
      "verified": false,
      "links": [
        ""
      ],
      "avatar": "https://gravatar.com/avatar/e66357d2e395080b10b4bce9323106ba84f3e31da6a305badee6159c7cc77127?r=pg&d=retro&size=200"
    },
    "nodes": [
      {
        "id": 1119,
        "icon": "fa:robot",
        "name": "@n8n/n8n-nodes-langchain.agent",
        "codex": {
          "data": {
            "alias": [
              "LangChain",
              "Chat",
              "Conversational",
              "Plan and Execute",
              "ReAct",
              "Tools"
            ],
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Agents",
                "Root Nodes"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "AI Agent",
          "color": "#404040"
        },
        "iconData": {
          "icon": "robot",
          "type": "icon"
        },
        "displayName": "AI Agent",
        "typeVersion": 3,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1127,
        "icon": "fa:code",
        "name": "@n8n/n8n-nodes-langchain.code",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Miscellaneous"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "LangChain Code"
        },
        "iconData": {
          "icon": "code",
          "type": "icon"
        },
        "displayName": "LangChain Code",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1163,
        "icon": "fa:database",
        "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Memory"
              ],
              "Memory": [
                "For beginners"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Simple Memory"
        },
        "iconData": {
          "icon": "database",
          "type": "icon"
        },
        "displayName": "Simple Memory",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1247,
        "icon": "fa:comments",
        "name": "@n8n/n8n-nodes-langchain.chatTrigger",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
                }
              ]
            },
            "categories": [
              "Core Nodes",
              "Langchain"
            ]
          }
        },
        "group": "[\"trigger\"]",
        "defaults": {
          "name": "When chat message received"
        },
        "iconData": {
          "icon": "comments",
          "type": "icon"
        },
        "displayName": "Chat Trigger",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 9,
            "name": "Core Nodes"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      },
      {
        "id": 1262,
        "icon": "file:google.svg",
        "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "codex": {
          "data": {
            "resources": {
              "primaryDocumentation": [
                {
                  "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
                }
              ]
            },
            "categories": [
              "AI",
              "Langchain"
            ],
            "subcategories": {
              "AI": [
                "Language Models",
                "Root Nodes"
              ],
              "Language Models": [
                "Chat Models (Recommended)"
              ]
            }
          }
        },
        "group": "[\"transform\"]",
        "defaults": {
          "name": "Google Gemini Chat Model"
        },
        "iconData": {
          "type": "file",
          "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
        },
        "displayName": "Google Gemini Chat Model",
        "typeVersion": 1,
        "nodeCategories": [
          {
            "id": 25,
            "name": "AI"
          },
          {
            "id": 26,
            "name": "Langchain"
          }
        ]
      }
    ],
    "categories": [
      {
        "id": 5,
        "name": "Engineering"
      },
      {
        "id": 47,
        "name": "AI Chatbot"
      }
    ],
    "image": []
  }
}