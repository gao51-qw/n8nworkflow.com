{
  "id": 2292,
  "slug": "2292",
  "title": "Talk to your SQLite database with a LangChain AI Agent ğŸ§ ğŸ’¬  ",
  "description": "This n8n workflow demonstrates how to create an agent using LangChain and SQLite. The agent can understand natural language queries and interact with a SQLite database to provide accurate answers. ğŸ’ª  \n  \n## ğŸš€ Setup  \n  \nRun the top part of the workflow once.  \nIt downloads the example SQLite database, extracts from a ZIP file and saves locally (`chinook.db`).  \n  \n## ğŸ—£ï¸ Chatting with Your Data  \n  \n1. Send a message in a chat window.  \n2. Locally saved SQLite database loads automatically.  \n3. User's chat input is combined with the binary data.  \n4. The LangChain Agend node gets both data and begins to work.  \n  \nThe AI Agent will process the user's message, perform necessary SQL queries, and generate a response based on the database information. ğŸ—„ï¸  \n  \n## ğŸŒŸ Example Queries  \n  \nTry these sample queries to see the AI Agent in action:  \n  \n1. \"Please describe the database\" - Get a high-level overview of the database structure, only one or two queries are needed.  \n2. \"What are the revenues by genre?\" - Retrieve revenue information grouped by genre, LangChain agent iterates several time before producing the answer.  \n  \nThe AI Agent will store the final answer in its memory, allowing for context-aware conversations. ğŸ’¬ \n \nRead the full article: ğŸ‘‰ https://blog.n8n.io/ai-agents/\n",
  "featuredImage": "/data/workflows/2292/2292.webp",
  "author": {
    "id": 101,
    "slug": "yulia",
    "name": "Yulia",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 26460,
  "downloads": 2646,
  "createdAt": "2024-06-14T11:38:57.461Z",
  "updatedAt": "2026-01-16T08:23:51.464Z",
  "publishedAt": "2024-06-14T11:38:57.461Z",
  "nodes": 13,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2292",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Talk to your SQLite database with a LangChain AI Agent ğŸ§ ğŸ’¬  ",
    "workflowName": "Talk to your SQLite database with a LangChain AI Agent ğŸ§ ğŸ’¬  ",
    "description": "This n8n workflow demonstrates how to create an agent using LangChain and SQLite. The agent can understand natural language queries and interact with a SQLite database to provide accurate answers. ğŸ’ª  \n  \n## ğŸš€ Setup  \n  \nRun the top part of the workflow once.  \nIt downloads the example SQLite database, extracts from a ZIP file and saves locally (`chinook.db`).  \n  \n## ğŸ—£ï¸ Chatting with Your Data  \n  \n1. Send a message in a chat window.  \n2. Locally saved SQLite database loads automatically.  \n3. User's chat input is combined with the binary data.  \n4. The LangChain Agend node gets both data and begins to work.  \n  \nThe AI Agent will process the user's message, perform necessary SQL queries, and generate a response based on the database information. ğŸ—„ï¸  \n  \n## ğŸŒŸ Example Queries  \n  \nTry these sample queries to see the AI Agent in action:  \n  \n1. \"Please describe the database\" - Get a high-level overview of the database structure, only one or two queries are needed.  \n2. \"What are the revenues by genre?\" - Retrieve revenue information grouped by genre, LangChain agent iterates several time before producing the answer.  \n  \nThe AI Agent will store the final answer in its memory, allowing for context-aware conversations. ğŸ’¬ \n \nRead the full article: ğŸ‘‰ https://blog.n8n.io/ai-agents/",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking \"Test workflow\"",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Get chinook.zip example",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Extract zip file",
      "type": "n8n-nodes-base.compression",
      "role": "compression",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Save chinook.db locally",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Load local chinook.db",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Combine chat input with the binary",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Chat Trigger",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1"
    }
  ]
}