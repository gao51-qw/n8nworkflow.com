{
  "id": 3326,
  "slug": "3326",
  "title": "Build custom AI agent with LangChain & Gemini (self-hosted)",
  "description": "## Overview  \nThis workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).  \n![截屏20250327 17.53.50.png](fileId:1063)\n\n## Setup Instructions  \n1. **Configure Gemini Credentials**: Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.  \n2. **Interaction Methods**:  \n   - Test directly in the workflow editor using the \"Chat\" button  \n   - Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node  \n\n## Customization Options  \n1. **Interface Settings**: Configure chat UI elements (e.g., title) in the `When Chat Message Received` node  \n2. **Prompt Engineering**:  \n   - Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable  \n   - ⚠️ Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation  \n3. **Model Selection**: Swap language models through the `language model` input field in `Construct & Execute LLM Prompt`  \n4. **Memory Control**: Adjust conversation history length in the `Store Conversation History` node  \n\n## Requirements:  \n⚠️ This workflow uses the **LangChain Code node**, which only works on **self-hosted n8n**.  \n*(Refer to [LangChain Code node docs](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/))*\n",
  "featuredImage": "/data/workflows/3326/3326.webp",
  "author": {
    "id": 101,
    "slug": "shepard",
    "name": "shepard",
    "avatar": ""
  },
  "categories": [
    "Miscellaneous",
    "AI Chatbot"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 5680,
  "downloads": 568,
  "createdAt": "2025-03-26T01:02:38.093Z",
  "updatedAt": "2026-01-16T08:29:10.810Z",
  "publishedAt": "2025-03-26T01:02:38.093Z",
  "nodes": 9,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3326",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build custom AI agent with LangChain & Gemini (self-hosted)",
    "workflowName": "Build custom AI agent with LangChain & Gemini (self-hosted)",
    "description": "This workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).  \n![截屏20250327 17.53.50.png](fileId:1063)\n\n## Setup Instructions  \n1. **Configure Gemini Credentials**: Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.  \n2. **Interaction Methods**:  \n   - Test directly in the workflow editor using the \"Chat\" button  \n   - Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node  \n\n## Customization Options  \n1. **Interface Settings**: Configure chat UI elements (e.g., title) in the `When Chat Message Received` node  \n2. **Prompt Engineering**:  \n   - Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable  \n   - ⚠️ Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation  \n3. **Model Selection**: Swap language models through the `language model` input field in `Construct & Execute LLM Prompt`  \n4. **Memory Control**: Adjust conversation history length in the `Store Conversation History` node  \n\n## Requirements:  \n⚠️ This workflow uses the **LangChain Code node**, which only works on **self-hosted n8n**.  \n*(Refer to [LangChain Code node docs](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/))*",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Store conversation history",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Construct & Execute LLM Prompt",
      "type": "@n8n/n8n-nodes-langchain.code",
      "role": "code",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}