{
  "id": 5807,
  "slug": "5807",
  "title": "Document Q&A system with OpenAI GPT, Pinecone Vector DB & Google Drive integration",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n# ü§ñ AI-Powered Document QA System using Webhook, Pinecone + OpenAI + n8n\n\nThis project demonstrates how to build a Retrieval-Augmented Generation (RAG) system using n8n, and create a simple Question Answer system using Webhook to connect with User Interface (created using Lovable):\n\nüßæ Downloads the pdf file format documents from Google Drive (contract document, user manual, HR policy document etc...) \n\nüìö Converts them into vector embeddings using OpenAI\n\nüîç Stores and searches them in Pinecone Vector DB\n\nüí¨ Allows natural language querying of contracts using AI Agents\n\n## üìÇ Flow 1: Document Loading & RAG Setup\nThis flow automates:\n\nReading documents from a Google Drive folder\n\nVectorizing using text-embedding-3-small\n\nUploading vectors into Pinecone for later semantic search\n\n### üß± Workflow Structure\n  A [Manual Trigger] --&gt; B[Google Drive Search]\n  B --&gt; C[Google Drive Download]\n  C --&gt; D[Pinecone Vector Store]\n  D --&gt; E[Default Data Loader]\n  E --&gt; F[Recursive Character Text Splitter]\n  E --&gt; G[OpenAI Embedding]\n\n#### ü™ú Steps\nManual Trigger: Kickstarts the workflow on demand for loading new documents.\n\nGoogle Drive Search & Download\n\nNode: Google Drive (Search: file/folder)\n\nDownloads PDF documents\n\n#### Apply Recursive Text Splitter: Breaks long documents into overlapping chunks\nSettings:\nChunk Size: 1000\nChunk Overlap: 100\n\n#### OpenAI Embedding\nModel: text-embedding-3-small\nUsed for creating document vectors\n\n#### Pinecone Vector Store\nHost: url\nIndex: index\nBatch Size: 200\n\n#### Pinecone Settings:\nType: Dense\nRegion: us-east-1\nMode: Insert Documents\n\n## üí¨ Flow 2: Chat-Based Q&A Agent\nThis flow enables chat-style querying of stored documents using OpenAI-powered agents with vector memory.\n\n### üß± Workflow Diagram\n\n  A[Webhook (chat message)] --&gt; B[AI Agent]\n  B --&gt; C[OpenAI Chat Model]\n  B --&gt; D[Simple Memory]\n  B --&gt; E[Answer with Vector Store]\n  E --&gt; F[Pinecone Vector Store]\n  F --&gt; G[Embeddings OpenAI]\n\n### ü™ú Components\nChat (Trigger): Receives incoming chat queries\n\nAI Agent Node\n\n#### Handles query flow using:\n\nChat Model: OpenAI GPT\n\nMemory: Simple Memory\n\nTool: Question Answer with Vector Store\n\nPinecone Vector Store: Connected via same embedding index as Flow 1\n\nEmbeddings: Ensures document chunks are retrievable using vector similarity\n\nResponse Node: Returns final AI response to user via webhook\n\n## üåê Flow 3: UI-Based Query with Lovable\nThis flow uses a web UI built using Lovable to query contracts directly from a form interface.\n\n### üì• Webhook Setup for Lovable\nWebhook Node\n\nMethod: POST\nURL:url\nResponse: Using 'Respond to Webhook' Node\n\n### üß± Workflow Logic\n  A[Webhook (Lovable Form)] --&gt; B[AI Agent]\n  B --&gt; C[OpenAI Chat Model]\n  B --&gt; D[Simple Memory]\n  B --&gt; E[Answer with Vector Store]\n  E --&gt; F[Pinecone Vector Store]\n  F --&gt; G[Embeddings OpenAI]\n  B --&gt; H[Respond to Webhook]\n\n### üí° Lovable UI\nUsers can submit:\n\nFull Name\nEmail\nDepartment\nFreeform Query: User can enter any freeform query. \n![image.png](fileId:1715)\nData is sent via webhook to n8n and responded with the answer from contract content.\n\n### üîç Use Cases\nContract Querying for Legal/HR teams\n\nProcurement & Vendor Agreement QA\n\nCustomer Support Automation (based on terms)\n\nRAG Systems for private document knowledge\n\n### ‚öôÔ∏è Tools & Tech Stack\n![image.png](fileId:1714)\n\nüìå Final Notes\nPinecone Index: package1536\n\nDimension: 1536\n\nChunk Size: 1000, Overlap: 100\n\nEmbedding Model: text-embedding-3-small\n\nFeel free to fork the workflow or request the full JSON export.\nLooking forward to your suggestions and improvements!\n\n",
  "featuredImage": "/data/workflows/5807/5807.webp",
  "author": {
    "id": 101,
    "slug": "mohan",
    "name": "Mohan Gopal",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 954,
  "downloads": 95,
  "createdAt": "2025-07-09T07:49:31.272Z",
  "updatedAt": "2026-01-16T08:41:31.076Z",
  "publishedAt": "2025-07-09T07:49:31.272Z",
  "nodes": 30,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5807",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Document Q&A system with OpenAI GPT, Pinecone Vector DB & Google Drive integration",
    "workflowName": "Document Q&A system with OpenAI GPT, Pinecone Vector DB & Google Drive integration",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n# ü§ñ AI-Powered Document QA System using Webhook, Pinecone + OpenAI + n8n\n\nThis project demonstrates how to build a Retrieval-Augmented Generation (RAG) system using n8n, and create a simple Question Answer system using Webhook to connect with User Interface (created using Lovable):\n\nüßæ Downloads the pdf file format documents from Google Drive (contract document, user manual, HR policy document etc...) \n\nüìö Converts them into vector embeddings using OpenAI\n\nüîç Stores and searches them in Pinecone Vector DB\n\nüí¨ Allows natural language querying of contracts using AI Agents\n\n## üìÇ Flow 1: Document Loading & RAG Setup\nThis flow automates:\n\nReading documents from a Google Drive folder\n\nVectorizing using text-embedding-3-small\n\nUploading vectors into Pinecone for later semantic search\n\n### üß± Workflow Structure\n  A [Manual Trigger] --&gt; B[Google Drive Search]\n  B --&gt; C[Google Drive Download]\n  C --&gt; D[Pinecone Vector Store]\n  D --&gt; E[Default Data Loader]\n  E --&gt; F[Recursive Character Text Splitter]\n  E --&gt; G[OpenAI Embedding]\n\n#### ü™ú Steps\nManual Trigger: Kickstarts the workflow on demand for loading new documents.\n\nGoogle Drive Search & Download\n\nNode: Google Drive (Search: file/folder)\n\nDownloads PDF documents\n\n#### Apply Recursive Text Splitter: Breaks long documents into overlapping chunks\nSettings:\nChunk Size: 1000\nChunk Overlap: 100\n\n#### OpenAI Embedding\nModel: text-embedding-3-small\nUsed for creating document vectors\n\n#### Pinecone Vector Store\nHost: url\nIndex: index\nBatch Size: 200\n\n#### Pinecone Settings:\nType: Dense\nRegion: us-east-1\nMode: Insert Documents\n\n## üí¨ Flow 2: Chat-Based Q&A Agent\nThis flow enables chat-style querying of stored documents using OpenAI-powered agents with vector memory.\n\n### üß± Workflow Diagram\n\n  A[Webhook (chat message)] --&gt; B[AI Agent]\n  B --&gt; C[OpenAI Chat Model]\n  B --&gt; D[Simple Memory]\n  B --&gt; E[Answer with Vector Store]\n  E --&gt; F[Pinecone Vector Store]\n  F --&gt; G[Embeddings OpenAI]\n\n### ü™ú Components\nChat (Trigger): Receives incoming chat queries\n\nAI Agent Node\n\n#### Handles query flow using:\n\nChat Model: OpenAI GPT\n\nMemory: Simple Memory\n\nTool: Question Answer with Vector Store\n\nPinecone Vector Store: Connected via same embedding index as Flow 1\n\nEmbeddings: Ensures document chunks are retrievable using vector similarity\n\nResponse Node: Returns final AI response to user via webhook\n\n## üåê Flow 3: UI-Based Query with Lovable\nThis flow uses a web UI built using Lovable to query contracts directly from a form interface.\n\n### üì• Webhook Setup for Lovable\nWebhook Node\n\nMethod: POST\nURL:url\nResponse: Using 'Respond to Webhook' Node\n\n### üß± Workflow Logic\n  A[Webhook (Lovable Form)] --&gt; B[AI Agent]\n  B --&gt; C[OpenAI Chat Model]\n  B --&gt; D[Simple Memory]\n  B --&gt; E[Answer with Vector Store]\n  E --&gt; F[Pinecone Vector Store]\n  F --&gt; G[Embeddings OpenAI]\n  B --&gt; H[Respond to Webhook]\n\n### üí° Lovable UI\nUsers can submit:\n\nFull Name\nEmail\nDepartment\nFreeform Query: User can enter any freeform query. \n![image.png](fileId:1715)\nData is sent via webhook to n8n and responded with the answer from contract content.\n\n### üîç Use Cases\nContract Querying for Legal/HR teams\n\nProcurement & Vendor Agreement QA\n\nCustomer Support Automation (based on terms)\n\nRAG Systems for private document knowledge\n\n### ‚öôÔ∏è Tools & Tech Stack\n![image.png](fileId:1714)\n\nüìå Final Notes\nPinecone Index: package1536\n\nDimension: 1536\n\nChunk Size: 1000, Overlap: 100\n\nEmbedding Model: text-embedding-3-small\n\nFeel free to fork the workflow or request the full JSON export.\nLooking forward to your suggestions and improvements!",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‚ÄòExecute workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Drive",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Google Drive1",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Answer questions with a vector store",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "role": "toolVectorStore",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Pinecone Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2"
    },
    {
      "name": "AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "OpenAI Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Simple Memory1",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Answer questions with a vector store1",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "role": "toolVectorStore",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Pinecone Vector Store2",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings OpenAI2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model3",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.4"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}