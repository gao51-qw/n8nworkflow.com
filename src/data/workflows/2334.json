{
  "id": 2334,
  "slug": "2334",
  "title": "Organise your local file directories with AI",
  "description": "If you have a shared or personal drive location with a high frequency of files created by humans, it can become difficult to organise. This may not matter... until you need to search for something!\n\nThis n8n workflow works with the local filesystem to target the messy folder and categorise as well as organise its files into sub directories automatically.\n\n## Disclaimer\nUnfortunately due to the intended use-case, this workflow will not work on n8n Cloud and a self-hosted version of n8n is required.\n\n## How it works\n* Uses the local file trigger to activate once a new file is introduced to the directory\n* The new file's filename and filetype are analysed using AI to determine the best location to move this file.\n* The AI assess the current subdirectories as to not create duplicates. If a relevant subdirectory is not found, a new subdirectory is suggested.\n* Finally, an Execute Command node uses the AI's suggestions to move the new file into the correct location.\n\n## Requirements\n* Self-hosted version of n8n. The nodes used in this workflow only work in the self-hosted version.\n* If you are using docker, you must create a [bind mount](https://docs.docker.com/storage/bind-mounts/) to a host directory.\n* Mistral.ai account for LLM model\n\n## Customise this workflow\n\nIf the frequency of files created is high enough, you may not want the trigger to active on every new file created event. Switch to a timer to avoid concurrency issues.\n\n## Want to go fully local?\n\nA version of this workflow is available which uses Ollama instead. You can download this template here:\nhttps://drive.google.com/file/d/1iqJ_zCGussXpfaUBYGrN5opziEFAEQMu/view?usp=sharing",
  "featuredImage": "/data/workflows/2334/2334.webp",
  "author": {
    "id": 101,
    "slug": "jimleuk",
    "name": "Jimleuk",
    "avatar": ""
  },
  "categories": [
    "File Management",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 16926,
  "downloads": 1692,
  "createdAt": "2024-07-10T14:46:38.909Z",
  "updatedAt": "2026-01-16T08:24:06.072Z",
  "publishedAt": "2024-07-10T14:46:38.909Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2334",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Organise your local file directories with AI",
    "workflowName": "Organise your local file directories with AI",
    "description": "If you have a shared or personal drive location with a high frequency of files created by humans, it can become difficult to organise. This may not matter... until you need to search for something!\n\nThis n8n workflow works with the local filesystem to target the messy folder and categorise as well as organise its files into sub directories automatically.\n\n## Disclaimer\nUnfortunately due to the intended use-case, this workflow will not work on n8n Cloud and a self-hosted version of n8n is required.\n\n## How it works\n* Uses the local file trigger to activate once a new file is introduced to the directory\n* The new file's filename and filetype are analysed using AI to determine the best location to move this file.\n* The AI assess the current subdirectories as to not create duplicates. If a relevant subdirectory is not found, a new subdirectory is suggested.\n* Finally, an Execute Command node uses the AI's suggestions to move the new file into the correct location.\n\n## Requirements\n* Self-hosted version of n8n. The nodes used in this workflow only work in the self-hosted version.\n* If you are using docker, you must create a [bind mount](https://docs.docker.com/storage/bind-mounts/) to a host directory.\n* Mistral.ai account for LLM model\n\n## Customise this workflow\n\nIf the frequency of files created is high enough, you may not want the trigger to active on every new file created event. Switch to a timer to avoid concurrency issues.\n\n## Want to go fully local?\n\nA version of this workflow is available which uses Ollama instead. You can download this template here:\nhttps://drive.google.com/file/d/1iqJ_zCGussXpfaUBYGrN5opziEFAEQMu/view?usp=sharing",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Local File Trigger",
      "type": "n8n-nodes-base.localFileTrigger",
      "role": "localFileTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Files and Folders",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "Files and Folders to Array",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Mistral Cloud Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Set Variables",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Move Files into Folders",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "If Has Target Files...",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Suggestions to List",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "AI File Manager",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.4"
    }
  ]
}