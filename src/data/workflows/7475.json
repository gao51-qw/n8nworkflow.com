{
  "id": 7475,
  "slug": "7475",
  "title": "Optimize unstructured data for RAG with Blockify IdeaBlocks technology",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n## Blockify® Data Optimization Workflow\n\n### Blockify Optimizes Data for RAG - Giving Structure to Unstructured Data for ~78X Accuracy, when pairing Blockify Ingest and Blockify Distill\n\n### Learn more at [https://iternal.ai/blockify](https://iternal.ai/blockify)\n\n#### Get Free Demo API Access here: [https://api.blockify.ai/register](https://api.blockify.ai/register)\n\n#### Read the Technical Whitepaper here: [https://iternal.ai/blockify-results](https://iternal.ai/blockify-results)\n\n#### See example Accuracy Comparison here: [https://iternal.ai/case-studies/medical-accuracy/](https://iternal.ai/case-studies/medical-accuracy/)\n\nBlockify is a data optimization tool that takes messy, unstructured text, like hundreds of sales‑meeting transcripts or long proposals, and intelligently optimizes the data into small, easy‑to‑understand \"IdeaBlocks.\" Each IdeaBlock is just a couple of sentences in length that capture one clear idea, plus a built‑in contextualized question and answer.\n\nWith this approach, Blockify improves accuracy of LLMs (Large Language Models) by an average aggregate 78X, while shrinking the original mountain of text to about 2.5% of its size while keeping (and even improving) the important information.\n\nWhen Blockify's IdeaBlocks are compared with the usual method of breaking text into equal‑sized chunks, the results are dramatic. Answers pulled from the distilled IdeaBlocks are roughly 40X more accurate, and user searches return the right information about 52% more accurate. In short, Blockify lets you store less data, spend less on computing, and still get better answers- turning huge documents into a concise, high‑quality knowledge base that anyone can search quickly.\n\nBlockify works by processing chunks of text to create structured data from an unstructured data source.\n\nBlockify® replaces the traditional \"dump‑and‑chunk\" approach with an end‑to‑end pipeline that cleans and organizes content before it ever hits a vector store.\n\nAdmins first define who should see what, then the system ingests any file type—Word, PDF, slides, images—inside public cloud, private cloud, or on‑prem. A ​context‑aware splitter finds natural breaks, and a series of specially developed Blockify LLM model turns each segment into a draft IdeaBlock.\n\nGenAI systems fed with this curated data return sharper answers, hallucinate far less, and comply with security policies out of the box.\n\nThe result: higher trust, lower operating cost, and a clear path to enterprise‑scale RAG without the cleanup headaches that stall most AI rollouts.",
  "featuredImage": "/data/workflows/7475/7475.webp",
  "author": {
    "id": 101,
    "slug": "iternal",
    "name": "Iternal Technologies",
    "avatar": ""
  },
  "categories": [
    "AI RAG",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 205,
  "downloads": 20,
  "createdAt": "2025-08-16T13:49:43.039Z",
  "updatedAt": "2026-01-16T08:50:32.513Z",
  "publishedAt": "2025-08-16T13:49:43.039Z",
  "nodes": 22,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7475",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Optimize unstructured data for RAG with Blockify IdeaBlocks technology",
    "workflowName": "Optimize unstructured data for RAG with Blockify IdeaBlocks technology",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n## Blockify® Data Optimization Workflow\n\n### Blockify Optimizes Data for RAG - Giving Structure to Unstructured Data for ~78X Accuracy, when pairing Blockify Ingest and Blockify Distill\n\n### Learn more at [https://iternal.ai/blockify](https://iternal.ai/blockify)\n\n#### Get Free Demo API Access here: [https://api.blockify.ai/register](https://api.blockify.ai/register)\n\n#### Read the Technical Whitepaper here: [https://iternal.ai/blockify-results](https://iternal.ai/blockify-results)\n\n#### See example Accuracy Comparison here: [https://iternal.ai/case-studies/medical-accuracy/](https://iternal.ai/case-studies/medical-accuracy/)\n\nBlockify is a data optimization tool that takes messy, unstructured text, like hundreds of sales‑meeting transcripts or long proposals, and intelligently optimizes the data into small, easy‑to‑understand \"IdeaBlocks.\" Each IdeaBlock is just a couple of sentences in length that capture one clear idea, plus a built‑in contextualized question and answer.\n\nWith this approach, Blockify improves accuracy of LLMs (Large Language Models) by an average aggregate 78X, while shrinking the original mountain of text to about 2.5% of its size while keeping (and even improving) the important information.\n\nWhen Blockify's IdeaBlocks are compared with the usual method of breaking text into equal‑sized chunks, the results are dramatic. Answers pulled from the distilled IdeaBlocks are roughly 40X more accurate, and user searches return the right information about 52% more accurate. In short, Blockify lets you store less data, spend less on computing, and still get better answers- turning huge documents into a concise, high‑quality knowledge base that anyone can search quickly.\n\nBlockify works by processing chunks of text to create structured data from an unstructured data source.\n\nBlockify® replaces the traditional \"dump‑and‑chunk\" approach with an end‑to‑end pipeline that cleans and organizes content before it ever hits a vector store.\n\nAdmins first define who should see what, then the system ingests any file type—Word, PDF, slides, images—inside public cloud, private cloud, or on‑prem. A ​context‑aware splitter finds natural breaks, and a series of specially developed Blockify LLM model turns each segment into a draft IdeaBlock.\n\nGenAI systems fed with this curated data return sharper answers, hallucinate far less, and comply with security policies out of the box.\n\nThe result: higher trust, lower operating cost, and a clear path to enterprise‑scale RAG without the cleanup headaches that stall most AI rollouts.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Query Data Tool",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.2"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "RAG Chatbot",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Chunk Text",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over Chunks",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Simple IdeaBlock Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embed Individual IdeaBlocks (Already Separated)",
      "type": "@n8n/n8n-nodes-langchain.textSplitterCharacterTextSplitter",
      "role": "textSplitterCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract Text from .TXT File",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Download .TXT File for Ingest",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Blockify Ingest API",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Extract IdeaBlocks from API Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    }
  ]
}