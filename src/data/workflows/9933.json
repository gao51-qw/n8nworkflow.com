{
  "id": 9933,
  "slug": "9933",
  "title": "Multi-format document processing for RAG chatbot with Google Drive & Supabase",
  "description": "This n8n workflow is the data ingestion pipeline for the \"RAG System V2\" chatbot. It automatically monitors a specific Google Drive folder for new files, processes them based on their type, and inserts their content into a Supabase vector database to make it searchable for the RAG agent.\n\nKey Features & Workflow:\n\nGoogle Drive Trigger: The workflow starts automatically when a new file is created in a designated folder (named \"DOCUMENTS\" in this template).\n\nSmart File Handling: A Switch node routes the file based on its MIME type (e.g., PDF, Excel, Google Doc, Word Doc) for correct processing.\n\nMulti-Format Extraction:\n\nPDF: Text is extracted directly using the Extract PDF Text node.\n\nGoogle Docs: Files are downloaded and converted to plain text (text/plain) and processed by the Extract from Text File node.\n\nExcel: Data is extracted, aggregated, and concatenated into a single text block for embedding.\n\nWord (.doc/.docx): Word files are automatically converted into Google Docs format using an HTTP Request. This newly created Google Doc will then trigger the entire workflow again, ensuring it's processed correctly.\n\nChunking & Metadata Enrichment: The extracted text is split into manageable chunks using the Recursive Character Text Splitter (set to 2000-character chunks). The Enhanced Default Data Loader then enriches these chunks with crucial metadata from the original file, such as file_name, creator, and created_at.\n\nVectorization & Storage: Finally, the workflow uses OpenAI Embeddings to create vector representations of the text chunks and inserts them into the Supabase Vector Store.",
  "featuredImage": "/data/workflows/9933/9933.webp",
  "author": {
    "id": 101,
    "slug": "edsan",
    "name": "edisantosa",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 491,
  "downloads": 49,
  "createdAt": "2025-10-20T11:24:21.434Z",
  "updatedAt": "2026-01-16T09:02:40.342Z",
  "publishedAt": "2025-10-20T11:24:21.434Z",
  "nodes": 18,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9933",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Multi-format document processing for RAG chatbot with Google Drive & Supabase",
    "workflowName": "Multi-format document processing for RAG chatbot with Google Drive & Supabase",
    "description": "This n8n workflow is the data ingestion pipeline for the \"RAG System V2\" chatbot. It automatically monitors a specific Google Drive folder for new files, processes them based on their type, and inserts their content into a Supabase vector database to make it searchable for the RAG agent.\n\nKey Features & Workflow:\n\nGoogle Drive Trigger: The workflow starts automatically when a new file is created in a designated folder (named \"DOCUMENTS\" in this template).\n\nSmart File Handling: A Switch node routes the file based on its MIME type (e.g., PDF, Excel, Google Doc, Word Doc) for correct processing.\n\nMulti-Format Extraction:\n\nPDF: Text is extracted directly using the Extract PDF Text node.\n\nGoogle Docs: Files are downloaded and converted to plain text (text/plain) and processed by the Extract from Text File node.\n\nExcel: Data is extracted, aggregated, and concatenated into a single text block for embedding.\n\nWord (.doc/.docx): Word files are automatically converted into Google Docs format using an HTTP Request. This newly created Google Doc will then trigger the entire workflow again, ensuring it's processed correctly.\n\nChunking & Metadata Enrichment: The extracted text is split into manageable chunks using the Recursive Character Text Splitter (set to 2000-character chunks). The Enhanced Default Data Loader then enriches these chunks with crucial metadata from the original file, such as file_name, creator, and created_at.\n\nVectorization & Storage: Finally, the workflow uses OpenAI Embeddings to create vector representations of the text chunks and inserts them into the Supabase Vector Store.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Aggregate1",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Summarize1",
      "type": "n8n-nodes-base.summarize",
      "role": "summarize",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract PDF Text",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from Excel",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Convert to Google Doc1",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.1"
    },
    {
      "name": "Delete File",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Set File ID1",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Download File1",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Enhanced Default Data Loader1",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "File Created",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from Text File",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Switch2",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3"
    },
    {
      "name": "Insert into Supabase Vectorstore1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}