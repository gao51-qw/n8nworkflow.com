{
  "id": 10077,
  "slug": "10077",
  "title": "Automate a 'Chat with your PDF' Bot on Telegram with Google Gemini & Pinecone",
  "description": "## This n8n template from [Intuz](https://www.intuz.com/) provides a complete solution to automate a powerful, AI-driven 'Chat with your PDF' bot on Telegram.\n\nIt uses Retrieval-Augmented Generation (RAG) to allow users to upload documents, which are then indexed into a vector database, enabling the bot to answer questions based only on the provided content.\n\n## Who's this workflow for?\n- Researchers & Students\n- Legal & Compliance Teams\n- Business Analysts & Financial Advisors\n- Anyone needing to quickly find information within large documents\n\n## How it works\nThis workflow has two primary functions: indexing a new document and answering questions about it.\n\n**1. Uploading & Indexing a Document:**\n- A user sends a PDF file to the Telegram bot.\n- n8n downloads the document, extracts the text, and splits it into small, manageable chunks.\n- Using Google Gemini, each text chunk is converted into a numerical representation (an \"embedding\").\n- These embeddings are stored in a Pinecone vector database, making the document's content searchable.\n- The bot sends a confirmation message to the user that the document has been successfully saved.\n\n**2. Asking a Question (RAG):**\n- A user sends a regular text message (a question) to the bot.\n- n8n converts the user's question into an embedding using Google Gemini.\n- It then searches the Pinecone database to find the most relevant text chunks from the uploaded PDF that match the question.\n- These relevant chunks (the \"context\") are sent to the Gemini chat model along with the original question.\n- Gemini generates a new, accurate answer based only on the provided context and sends it back to the user in Telegram.\n\n## Key Requirements to Use This Template\n\n**1. n8n Instance & Required Nodes:**\n- An active n8n account (Cloud or self-hosted).\n- This workflow uses the official n8n LangChain integration (@n8n/n8n-nodes-langchain). If you are using a self-hosted version of n8n, please ensure this package is installed.\n\n**2. Telegram Account:**\n- A Telegram bot created via the BotFather, along with its API token.\n\n**3. Google Gemini AI Account:**\n- A Google Cloud account with the Vertex AI API enabled and an associated API Key.\n\n**4. Pinecone Account:**\n- A Pinecone account with an API key.\n- You must have a vector index created in Pinecone. For use with Google Gemini's embedding-001 model, the index must be configured with 768 dimensions.\n\n## Setup Instructions\n**1. Telegram Configuration:**\n- In the \"Telegram Message Trigger\" node, create a new credential and add your Telegram bot's API token.\n- Do the same for the \"Telegram Response\" and \"Telegram Response about Database\" nodes.\n\n**2. Pinecone Configuration:**\n- In both \"Pinecone Vector Store\" nodes, create a new credential and add your Pinecone API key.\n- In the \"Index\" field of both nodes, enter the name of your pre-configured Pinecone index (e.g., telegram).\n\n**3. Google Gemini Configuration:**\n- In all three Google Gemini nodes (Embeddings Google Gemini, Embeddings Google Gemini1, and Google Gemini Chat Model), create a new credential and add your Google Gemini (Palm) API key.\n\n**4. Activate and Use:**\n- Save the workflow and toggle the \"Active\" switch to ON.\n- To use: First, send a PDF document to your bot. Wait for the confirmation message. Then, you can start asking questions about the content of that PDF.\n\n## Connect with us\n- Website: https://www.intuz.com/services\n- Email: getstarted@intuz.com\n- LinkedIn: https://www.linkedin.com/company/intuz\n- Get Started: https://n8n.partnerlinks.io/intuz\n\n## For Custom Workflow Automation\nClick here- [Get Started](https://www.intuz.com/get-started)",
  "featuredImage": "/data/workflows/10077/10077.webp",
  "author": {
    "id": 101,
    "slug": "intuz",
    "name": "Intuz ",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 561,
  "downloads": 56,
  "createdAt": "2025-10-23T07:08:33.118Z",
  "updatedAt": "2026-01-16T09:03:15.808Z",
  "publishedAt": "2025-10-23T07:08:33.118Z",
  "nodes": 25,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10077",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Automate a 'Chat with your PDF' Bot on Telegram with Google Gemini & Pinecone",
    "workflowName": "Automate a 'Chat with your PDF' Bot on Telegram with Google Gemini & Pinecone",
    "description": "## This n8n template from [Intuz](https://www.intuz.com/) provides a complete solution to automate a powerful, AI-driven 'Chat with your PDF' bot on Telegram.\n\nIt uses Retrieval-Augmented Generation (RAG) to allow users to upload documents, which are then indexed into a vector database, enabling the bot to answer questions based only on the provided content.\n\n## Who's this workflow for?\n- Researchers & Students\n- Legal & Compliance Teams\n- Business Analysts & Financial Advisors\n- Anyone needing to quickly find information within large documents\n\n## How it works\nThis workflow has two primary functions: indexing a new document and answering questions about it.\n\n**1. Uploading & Indexing a Document:**\n- A user sends a PDF file to the Telegram bot.\n- n8n downloads the document, extracts the text, and splits it into small, manageable chunks.\n- Using Google Gemini, each text chunk is converted into a numerical representation (an \"embedding\").\n- These embeddings are stored in a Pinecone vector database, making the document's content searchable.\n- The bot sends a confirmation message to the user that the document has been successfully saved.\n\n**2. Asking a Question (RAG):**\n- A user sends a regular text message (a question) to the bot.\n- n8n converts the user's question into an embedding using Google Gemini.\n- It then searches the Pinecone database to find the most relevant text chunks from the uploaded PDF that match the question.\n- These relevant chunks (the \"context\") are sent to the Gemini chat model along with the original question.\n- Gemini generates a new, accurate answer based only on the provided context and sends it back to the user in Telegram.\n\n## Key Requirements to Use This Template\n\n**1. n8n Instance & Required Nodes:**\n- An active n8n account (Cloud or self-hosted).\n- This workflow uses the official n8n LangChain integration (@n8n/n8n-nodes-langchain). If you are using a self-hosted version of n8n, please ensure this package is installed.\n\n**2. Telegram Account:**\n- A Telegram bot created via the BotFather, along with its API token.\n\n**3. Google Gemini AI Account:**\n- A Google Cloud account with the Vertex AI API enabled and an associated API Key.\n\n**4. Pinecone Account:**\n- A Pinecone account with an API key.\n- You must have a vector index created in Pinecone. For use with Google Gemini's embedding-001 model, the index must be configured with 768 dimensions.\n\n## Setup Instructions\n**1. Telegram Configuration:**\n- In the \"Telegram Message Trigger\" node, create a new credential and add your Telegram bot's API token.\n- Do the same for the \"Telegram Response\" and \"Telegram Response about Database\" nodes.\n\n**2. Pinecone Configuration:**\n- In both \"Pinecone Vector Store\" nodes, create a new credential and add your Pinecone API key.\n- In the \"Index\" field of both nodes, enter the name of your pre-configured Pinecone index (e.g., telegram).\n\n**3. Google Gemini Configuration:**\n- In all three Google Gemini nodes (Embeddings Google Gemini, Embeddings Google Gemini1, and Google Gemini Chat Model), create a new credential and add your Google Gemini (Palm) API key.\n\n**4. Activate and Use:**\n- Save the workflow and toggle the \"Active\" switch to ON.\n- To use: First, send a PDF document to your bot. Wait for the confirmation message. Then, you can start asking questions about the content of that PDF.\n\n## Connect with us\n- Website: https://www.intuz.com/services\n- Email: getstarted@intuz.com\n- LinkedIn: https://www.linkedin.com/company/intuz\n- Get Started: https://n8n.partnerlinks.io/intuz\n\n## For Custom Workflow Automation\nClick here- [Get Started](https://www.intuz.com/get-started)",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Stop and Error",
      "type": "n8n-nodes-base.stopAndError",
      "role": "stopAndError",
      "configDescription": "Version 1"
    },
    {
      "name": "Question and Answer Chain",
      "type": "@n8n/n8n-nodes-langchain.chainRetrievalQa",
      "role": "chainRetrievalQa",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Vector Store Retriever",
      "type": "@n8n/n8n-nodes-langchain.retrieverVectorStore",
      "role": "retrieverVectorStore",
      "configDescription": "Version 1"
    },
    {
      "name": "Pinecone Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1"
    },
    {
      "name": "Check If is a document",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2"
    },
    {
      "name": "Change to application/pdf",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Telegram get File",
      "type": "n8n-nodes-base.telegram",
      "role": "telegram",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Telegram Response",
      "type": "n8n-nodes-base.telegram",
      "role": "telegram",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Telegram Response about Database",
      "type": "n8n-nodes-base.telegram",
      "role": "telegram",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Stop and Error1",
      "type": "n8n-nodes-base.stopAndError",
      "role": "stopAndError",
      "configDescription": "Version 1"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1"
    },
    {
      "name": "Limit to 1",
      "type": "n8n-nodes-base.limit",
      "role": "limit",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Google Gemini",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Google Gemini1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Telegram Message Trigger",
      "type": "n8n-nodes-base.telegramTrigger",
      "role": "telegramTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}