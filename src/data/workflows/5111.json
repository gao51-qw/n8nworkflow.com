{
  "id": 5111,
  "slug": "5111",
  "title": "Create adaptive RAG chat agent with Google Gemini and Qdrant",
  "description": "Unlock adaptive, context-aware AI chat in your automations‚Äîno coding required!\n\nThis template is a plug-and-play n8n workflow that transforms how your chatbots, support agents, and knowledge systems respond to users. Powered by Google Gemini and a Qdrant vector database, it automatically classifies every incoming query and applies a tailor-made strategy for Factual, Analytical, Opinion, or Contextual requests‚Äîdelivering the right answer, every time.\n\nüõ†Ô∏è Key Features\nAutomatic Query Classification:\nSeamlessly detects whether the user wants facts, a deep analysis, opinions, or context‚Äîthen routes each input to the best answering strategy.\n\nFour Dynamic Retrieval Modes:\n1) Factual: Delivers precise, accurate information\n2) Analytical: Breaks down complex topics for deep dives\n3) Opinion: Surfaces diverse viewpoints and perspectives\n4) Contextual: Connects the dots using implied or user-specific context\n\nEnd-to-End RAG Pipeline:\nUses Gemini to classify and answer, while Qdrant powers fast, smart knowledge retrieval.\n\nNo-Code Visual Editing:\nImport into n8n, connect your LLM and vector database credentials, and you‚Äôre live‚Äîcustomize, extend, and scale with zero backend code.\n\nReusable in Any Project:\nPerfect for customer support, research, onboarding bots, internal knowledgebases, or any adaptive AI chat interface.\n\nüöÄ How it Works\n1) User submits a query (via chat or API)\n2) Query is auto-classified as Factual, Analytical, Opinion, or Contextual\n3) Adaptive retrieval strategy is triggered\n(each with its own prompt logic and memory buffer)\n4) Smart knowledge search is performed using Gemini and Qdrant\n5) Response is generated and sent back to the user‚Äîtailored to the query type!\n\nüß© What‚Äôs Included\n- Full n8n workflow (.json)\n- Step-by-step setup instructions\n- Sample prompts and system messages for each strategy\n- Lifetime updates (as the workflow evolves)\n\nüí° Use Cases\n- Chatbots that adapt to every user‚Äôs intent\n- Internal/external FAQ and helpdesk automations\n- AI research and summarization agents\n- Product support and onboarding flows\n\nAny scenario where smarter, more relevant answers = better user experience\n\nReady to build smarter automations? Import this template, connect your Gemini & Qdrant accounts, and let your AI agent adapt to every conversation.",
  "featuredImage": "/data/workflows/5111/5111.webp",
  "author": {
    "id": 101,
    "slug": "brandononchain",
    "name": "Brandon Crenshaw",
    "avatar": ""
  },
  "categories": [
    "Support Chatbot",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 4868,
  "downloads": 486,
  "createdAt": "2025-06-22T04:11:54.325Z",
  "updatedAt": "2026-01-16T08:37:44.736Z",
  "publishedAt": "2025-06-22T04:11:54.325Z",
  "nodes": 40,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5111",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Create adaptive RAG chat agent with Google Gemini and Qdrant",
    "workflowName": "Create adaptive RAG chat agent with Google Gemini and Qdrant",
    "description": "Unlock adaptive, context-aware AI chat in your automations‚Äîno coding required!\n\nThis template is a plug-and-play n8n workflow that transforms how your chatbots, support agents, and knowledge systems respond to users. Powered by Google Gemini and a Qdrant vector database, it automatically classifies every incoming query and applies a tailor-made strategy for Factual, Analytical, Opinion, or Contextual requests‚Äîdelivering the right answer, every time.\n\nüõ†Ô∏è Key Features\nAutomatic Query Classification:\nSeamlessly detects whether the user wants facts, a deep analysis, opinions, or context‚Äîthen routes each input to the best answering strategy.\n\nFour Dynamic Retrieval Modes:\n1) Factual: Delivers precise, accurate information\n2) Analytical: Breaks down complex topics for deep dives\n3) Opinion: Surfaces diverse viewpoints and perspectives\n4) Contextual: Connects the dots using implied or user-specific context\n\nEnd-to-End RAG Pipeline:\nUses Gemini to classify and answer, while Qdrant powers fast, smart knowledge retrieval.\n\nNo-Code Visual Editing:\nImport into n8n, connect your LLM and vector database credentials, and you‚Äôre live‚Äîcustomize, extend, and scale with zero backend code.\n\nReusable in Any Project:\nPerfect for customer support, research, onboarding bots, internal knowledgebases, or any adaptive AI chat interface.\n\nüöÄ How it Works\n1) User submits a query (via chat or API)\n2) Query is auto-classified as Factual, Analytical, Opinion, or Contextual\n3) Adaptive retrieval strategy is triggered\n(each with its own prompt logic and memory buffer)\n4) Smart knowledge search is performed using Gemini and Qdrant\n5) Response is generated and sent back to the user‚Äîtailored to the query type!\n\nüß© What‚Äôs Included\n- Full n8n workflow (.json)\n- Step-by-step setup instructions\n- Sample prompts and system messages for each strategy\n- Lifetime updates (as the workflow evolves)\n\nüí° Use Cases\n- Chatbots that adapt to every user‚Äôs intent\n- Internal/external FAQ and helpdesk automations\n- AI research and summarization agents\n- Product support and onboarding flows\n\nAny scenario where smarter, more relevant answers = better user experience\n\nReady to build smarter automations? Import this template, connect your Gemini & Qdrant accounts, and let your AI agent adapt to every conversation.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Query Classification",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Factual Strategy - Focus on Precision",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Analytical Strategy - Comprehensive Coverage",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Opinion Strategy - Diverse Perspectives",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Contextual Strategy - User Context Integration",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Chat",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Factual Prompt and Output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Contextual Prompt and Output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Opinion Prompt and Output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Analytical Prompt and Output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Gemini Classification",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Gemini Factual",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Gemini Analytical",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Chat Buffer Memory Analytical",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Chat Buffer Memory Factual",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Gemini Opinion",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Chat Buffer Memory Opinion",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Gemini Contextual",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Chat Buffer Memory Contextual",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Concatenate Context",
      "type": "n8n-nodes-base.summarize",
      "role": "summarize",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Retrieve Documents from Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Set Prompt and Output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Gemini Answer",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Answer",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Chat Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When Executed by Another Workflow",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "role": "executeWorkflowTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Combined Fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note9",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}