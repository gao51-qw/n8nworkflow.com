{
  "id": 7026,
  "slug": "7026",
  "title": "Analyze images, videos, documents & audio with Gemini Tools and Qwen LLM Agent",
  "description": "### üìÅ Analyze uploaded images, videos, audio, and documents with specialized tools ‚Äî powered by a lightweight language-only agent.\n\n---\n\n## üß≠ What It Does\n\nThis workflow enables **multimodal file analysis** using **Google Gemini tools** connected to a **text-only LLM agent**. Users can upload images, videos, audio files, or documents via a chat interface. The workflow will:\n\n* Upload each file to Google Gemini and obtain an accessible URL.\n* Dynamically generate contextual prompts based on the file(s) and user message.\n* Allow the agent to invoke Gemini tools for specific media types as needed.\n* Return a concise, helpful response based on the analysis.\n\n---\n\n## üöÄ Use Cases\n\n* **Customer support**: Let users upload screenshots, documents, or recordings and get helpful insights or summaries.\n* **Multimedia QA**: Review visual, audio, or video content for correctness or compliance.\n* **Educational agents**: Interpret content from PDFs, diagrams, or audio recordings on the fly.\n* **Low-cost multimodal assistants**: Achieve multimodal functionality **without relying on large vision-language models**.\n\n---\n\n## üéØ Why This Architecture Matters\n\nUnlike end-to-end multimodal LLMs (like Gemini 1.5 or GPT-4o), this template:\n\n* Uses a **text-only LLM (Qwen 32B via Groq)** for reasoning.\n* Delegates **media analysis to specialized Gemini tools**.\n\n### ‚úÖ Advantages\n\n| Feature                 | Benefit                                                               |\n| ----------------------- | --------------------------------------------------------------------- |\n| üß© Modular              | LLM + Tools are decoupled; can update them independently              |\n| üí∏ Cost-Efficient       | No need to pay for full multimodal models; only use tools when needed |\n| üîß Tool-based Reasoning | Agent invokes tools on demand, just like OpenAI‚Äôs Toolformer setup    |\n| ‚ö° Fast                  | Groq LLMs offer ultra-fast responses with low latency                 |\n| üìö Memory               | Includes context buffer for multi-turn chats (15 messages)            |\n\n---\n\n## üß™ How It Works\n\n### üîπ Input via Chat\n\n* Users submit a message and (optionally) files via the `chatTrigger`.\n\n### üîπ File Handling\n\n* If no files: prompt is passed directly to the agent.\n* If files are included:\n\n  * Files are split, uploaded to Gemini (to get public URLs).\n  * Metadata (name, type, URL) is collected and embedded into the prompt.\n\n### üîπ Prompt Construction\n\n* A new `chatInput` is dynamically generated:\n\n  ```\n  User message\n  Media: [array of file data]\n  ```\n\n### üîπ Agent Reasoning\n\n* The `Langchain Agent` receives:\n\n  * The enriched prompt\n  * File URLs\n  * Memory context (15 turns)\n  * Access to 4 Gemini tools:\n\n    * `IMG`: analyze image\n    * `VIDEO`: analyze video\n    * `AUDIO`: analyze audio\n    * `DOCUMENT`: analyze document\n\nThe agent autonomously decides whether and how to use tools, then responds with concise output.\n\n---\n\n## üß± Nodes & Services\n\n| Category        | Node / Tool                  | Purpose                               |\n| --------------- | ---------------------------- | ------------------------------------- |\n| Chat Input      | `chatTrigger`                | User interface with file support      |\n| File Processing | `splitOut`, `splitInBatches` | Process each uploaded file            |\n| Upload          | `googleGemini`               | Uploads each file to Gemini, gets URL |\n| Metadata        | `set`, `aggregate`           | Builds structured file info           |\n| AI Agent        | `Langchain Agent`            | Receives context + file data          |\n| Tools           | `googleGeminiTool`           | Analyze media with Gemini             |\n| LLM             | `lmChatGroq` (Qwen 32B)      | Text reasoning, high-speed            |\n| Memory          | `memoryBufferWindow`         | Maintains session context             |\n\n---\n\n## ‚öôÔ∏è Setup Instructions\n\n### 1. üîë Required Credentials\n\n* **Groq API key** (for Qwen 32B model)\n* **Google Gemini API key** (Palm / Gemini 1.5 tools)\n\n### 2. üß© Nodes That Need Setup\n\n* Replace existing credentials on:\n\n  * `Upload a file`\n  * Each `GeminiTool` (IMG, VIDEO, AUDIO, DOCUMENT)\n  * `lmChatGroq`\n\n### 3. ‚ö†Ô∏è File Size & Format Considerations\n\n* Some Gemini tools have file size or format restrictions.\n* You may add validation nodes before uploading if needed.\n\n---\n\n## üõ†Ô∏è Optional Improvements\n\n* Add logging and error handling (e.g., for upload failures).\n* Add MIME-type filtering to choose the right tool explicitly.\n* Extend to include OCR or transcription services pre-analysis.\n* Integrate with Slack, Telegram, or WhatsApp for chat delivery.\n\n---\n\n## üß™ Example Use Case\n\n&gt; \"Hola, ¬øqu√© dice este PDF?\"\n\nUploads a document ‚Üí Agent routes it to Gemini DOCUMENT tool ‚Üí Receives extracted content ‚Üí LLM summarizes it in Spanish.\n\n---\n\n## üß∞ Tags\n\n```\nmultimodal, agent, langchain, groq, gemini, image analysis, audio analysis, document parsing, video analysis, file uploader, chat assistant, LLM tools, memory, AI tools\n```\n\n---\n\n## üìÇ Files\n\n* This template is ready to use as-is in n8n.\n* No external webhooks or integrations required.\n",
  "featuredImage": "/data/workflows/7026/7026.webp",
  "author": {
    "id": 101,
    "slug": "rckflr",
    "name": "Mauricio Perera",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 3456,
  "downloads": 345,
  "createdAt": "2025-08-05T20:58:56.935Z",
  "updatedAt": "2026-01-16T08:48:14.223Z",
  "publishedAt": "2025-08-05T20:58:56.935Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7026",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Analyze images, videos, documents & audio with Gemini Tools and Qwen LLM Agent",
    "workflowName": "Analyze images, videos, documents & audio with Gemini Tools and Qwen LLM Agent",
    "description": "### üìÅ Analyze uploaded images, videos, audio, and documents with specialized tools ‚Äî powered by a lightweight language-only agent.\n\n---\n\n## üß≠ What It Does\n\nThis workflow enables **multimodal file analysis** using **Google Gemini tools** connected to a **text-only LLM agent**. Users can upload images, videos, audio files, or documents via a chat interface. The workflow will:\n\n* Upload each file to Google Gemini and obtain an accessible URL.\n* Dynamically generate contextual prompts based on the file(s) and user message.\n* Allow the agent to invoke Gemini tools for specific media types as needed.\n* Return a concise, helpful response based on the analysis.\n\n---\n\n## üöÄ Use Cases\n\n* **Customer support**: Let users upload screenshots, documents, or recordings and get helpful insights or summaries.\n* **Multimedia QA**: Review visual, audio, or video content for correctness or compliance.\n* **Educational agents**: Interpret content from PDFs, diagrams, or audio recordings on the fly.\n* **Low-cost multimodal assistants**: Achieve multimodal functionality **without relying on large vision-language models**.\n\n---\n\n## üéØ Why This Architecture Matters\n\nUnlike end-to-end multimodal LLMs (like Gemini 1.5 or GPT-4o), this template:\n\n* Uses a **text-only LLM (Qwen 32B via Groq)** for reasoning.\n* Delegates **media analysis to specialized Gemini tools**.\n\n### ‚úÖ Advantages\n\n| Feature                 | Benefit                                                               |\n| ----------------------- | --------------------------------------------------------------------- |\n| üß© Modular              | LLM + Tools are decoupled; can update them independently              |\n| üí∏ Cost-Efficient       | No need to pay for full multimodal models; only use tools when needed |\n| üîß Tool-based Reasoning | Agent invokes tools on demand, just like OpenAI‚Äôs Toolformer setup    |\n| ‚ö° Fast                  | Groq LLMs offer ultra-fast responses with low latency                 |\n| üìö Memory               | Includes context buffer for multi-turn chats (15 messages)            |\n\n---\n\n## üß™ How It Works\n\n### üîπ Input via Chat\n\n* Users submit a message and (optionally) files via the `chatTrigger`.\n\n### üîπ File Handling\n\n* If no files: prompt is passed directly to the agent.\n* If files are included:\n\n  * Files are split, uploaded to Gemini (to get public URLs).\n  * Metadata (name, type, URL) is collected and embedded into the prompt.\n\n### üîπ Prompt Construction\n\n* A new `chatInput` is dynamically generated:\n\n  ```\n  User message\n  Media: [array of file data]\n  ```\n\n### üîπ Agent Reasoning\n\n* The `Langchain Agent` receives:\n\n  * The enriched prompt\n  * File URLs\n  * Memory context (15 turns)\n  * Access to 4 Gemini tools:\n\n    * `IMG`: analyze image\n    * `VIDEO`: analyze video\n    * `AUDIO`: analyze audio\n    * `DOCUMENT`: analyze document\n\nThe agent autonomously decides whether and how to use tools, then responds with concise output.\n\n---\n\n## üß± Nodes & Services\n\n| Category        | Node / Tool                  | Purpose                               |\n| --------------- | ---------------------------- | ------------------------------------- |\n| Chat Input      | `chatTrigger`                | User interface with file support      |\n| File Processing | `splitOut`, `splitInBatches` | Process each uploaded file            |\n| Upload          | `googleGemini`               | Uploads each file to Gemini, gets URL |\n| Metadata        | `set`, `aggregate`           | Builds structured file info           |\n| AI Agent        | `Langchain Agent`            | Receives context + file data          |\n| Tools           | `googleGeminiTool`           | Analyze media with Gemini             |\n| LLM             | `lmChatGroq` (Qwen 32B)      | Text reasoning, high-speed            |\n| Memory          | `memoryBufferWindow`         | Maintains session context             |\n\n---\n\n## ‚öôÔ∏è Setup Instructions\n\n### 1. üîë Required Credentials\n\n* **Groq API key** (for Qwen 32B model)\n* **Google Gemini API key** (Palm / Gemini 1.5 tools)\n\n### 2. üß© Nodes That Need Setup\n\n* Replace existing credentials on:\n\n  * `Upload a file`\n  * Each `GeminiTool` (IMG, VIDEO, AUDIO, DOCUMENT)\n  * `lmChatGroq`\n\n### 3. ‚ö†Ô∏è File Size & Format Considerations\n\n* Some Gemini tools have file size or format restrictions.\n* You may add validation nodes before uploading if needed.\n\n---\n\n## üõ†Ô∏è Optional Improvements\n\n* Add logging and error handling (e.g., for upload failures).\n* Add MIME-type filtering to choose the right tool explicitly.\n* Extend to include OCR or transcription services pre-analysis.\n* Integrate with Slack, Telegram, or WhatsApp for chat delivery.\n\n---\n\n## üß™ Example Use Case\n\n&gt; \"Hola, ¬øqu√© dice este PDF?\"\n\nUploads a document ‚Üí Agent routes it to Gemini DOCUMENT tool ‚Üí Receives extracted content ‚Üí LLM summarizes it in Spanish.\n\n---\n\n## üß∞ Tags\n\n```\nmultimodal, agent, langchain, groq, gemini, image analysis, audio analysis, document parsing, video analysis, file uploader, chat assistant, LLM tools, memory, AI tools\n```\n\n---\n\n## üìÇ Files\n\n* This template is ready to use as-is in n8n.\n* No external webhooks or integrations required.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Split Out Files",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "IMG",
      "type": "@n8n/n8n-nodes-langchain.googleGeminiTool",
      "role": "googleGeminiTool",
      "configDescription": "Version 1"
    },
    {
      "name": "VIDEO",
      "type": "@n8n/n8n-nodes-langchain.googleGeminiTool",
      "role": "googleGeminiTool",
      "configDescription": "Version 1"
    },
    {
      "name": "AUDIO",
      "type": "@n8n/n8n-nodes-langchain.googleGeminiTool",
      "role": "googleGeminiTool",
      "configDescription": "Version 1"
    },
    {
      "name": "DOCUMENT",
      "type": "@n8n/n8n-nodes-langchain.googleGeminiTool",
      "role": "googleGeminiTool",
      "configDescription": "Version 1"
    },
    {
      "name": "Input",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "If Not Files",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Upload a file",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "role": "googleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "File data",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Update Input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Generate chat Input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "role": "lmChatGroq",
      "configDescription": "Version 1"
    },
    {
      "name": "Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}