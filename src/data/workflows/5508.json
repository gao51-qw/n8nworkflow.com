{
  "id": 5508,
  "slug": "5508",
  "title": "Create a private document Q&A system with Llama3, Postgres, Qdrant and Google Drive",
  "description": "## ‚öôÔ∏è How It Works: LocalRAG.AI\n\n‚ö†Ô∏è Note: This system only works for self-hosted n8n instances. It will not function on n8n.cloud or other remote setups.\nLocalRAG.AI is a private, on-prem AI assistant that uses your own documents to answer questions intelligently. It combines LangChain, Ollama, Qdrant, and Postgres into a powerful AI pipeline ‚Äî all running locally for maximum data privacy.\n\n## üîÑ What It Does\nMonitors Your Google Drive Folders for new or updated files.\nDownloads the file, extracts the text, and prepares it.\nGenerates Embeddings using your local Ollama model (e.g., LLaMA 3).\nStores them in Qdrant, your local vector database.\nDuring a chat, it:\nUses vector search to retrieve relevant chunks.\nCombines them with chat history stored in Postgres.\nResponds via a LangChain AI agent using your local model.\nüõ†Ô∏è Setup Steps (Self-hosted Only)\nInstall and Self-host n8n (e.g., via Docker).\nSet up your Ollama instance locally and load your desired LLM (e.g., llama3).\nDeploy Qdrant locally for vector storage.\nConnect a Postgres DB to store chat history.\nCreate and import the workflow in n8n.\nAuthenticate Google Drive to monitor folders.\nConnect credentials for Ollama, Qdrant, Postgres in the n8n workflow.\nStart chatting through the Webhook Trigger or custom UI.\nüß† Perfect For:\nResearch teams handling confidential data\nInternal documentation Q&A\nAI chatbots that don‚Äôt rely on OpenAI or cloud\n",
  "featuredImage": "/data/workflows/5508/5508.webp",
  "author": {
    "id": 101,
    "slug": "dae221",
    "name": "David Olusola",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 3032,
  "downloads": 303,
  "createdAt": "2025-07-01T07:42:55.735Z",
  "updatedAt": "2026-01-16T08:40:03.569Z",
  "publishedAt": "2025-07-01T07:42:55.735Z",
  "nodes": 20,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5508",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Create a private document Q&A system with Llama3, Postgres, Qdrant and Google Drive",
    "workflowName": "Create a private document Q&A system with Llama3, Postgres, Qdrant and Google Drive",
    "description": "## ‚öôÔ∏è How It Works: LocalRAG.AI\n\n‚ö†Ô∏è Note: This system only works for self-hosted n8n instances. It will not function on n8n.cloud or other remote setups.\nLocalRAG.AI is a private, on-prem AI assistant that uses your own documents to answer questions intelligently. It combines LangChain, Ollama, Qdrant, and Postgres into a powerful AI pipeline ‚Äî all running locally for maximum data privacy.\n\n## üîÑ What It Does\nMonitors Your Google Drive Folders for new or updated files.\nDownloads the file, extracts the text, and prepares it.\nGenerates Embeddings using your local Ollama model (e.g., LLaMA 3).\nStores them in Qdrant, your local vector database.\nDuring a chat, it:\nUses vector search to retrieve relevant chunks.\nCombines them with chat history stored in Postgres.\nResponds via a LangChain AI agent using your local model.\nüõ†Ô∏è Setup Steps (Self-hosted Only)\nInstall and Self-host n8n (e.g., via Docker).\nSet up your Ollama instance locally and load your desired LLM (e.g., llama3).\nDeploy Qdrant locally for vector storage.\nConnect a Postgres DB to store chat history.\nCreate and import the workflow in n8n.\nAuthenticate Google Drive to monitor folders.\nConnect credentials for Ollama, Qdrant, Postgres in the n8n workflow.\nStart chatting through the Webhook Trigger or custom UI.\nüß† Perfect For:\nResearch teams handling confidential data\nInternal documentation Q&A\nAI chatbots that don‚Äôt rely on OpenAI or cloud",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Ollama Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "role": "lmChatOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Postgres Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "role": "memoryPostgresChat",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Ollama Model",
      "type": "@n8n/n8n-nodes-langchain.lmOllama",
      "role": "lmOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Ollama",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "role": "embeddingsOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Answer questions with a vector store",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "role": "toolVectorStore",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "File Created",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "File Updated",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Set File ID",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Download File",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Extract Document Text",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Ollama1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "role": "embeddingsOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Qdrant Vector Store Insert",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}