{
  "id": 3303,
  "slug": "3303",
  "title": "AI-powered research assistant for platform questions with GPT-4o and MCP",
  "description": " ## Description\n\nThis workflow empowers you to effortlessly get answers to your n8n platform questions through an AI-powered assistant. Simply send your query, and the assistant will search documentation, forum posts, and example workflows to provide comprehensive, accurate responses tailored to your specific needs.\n\n&gt; **Note:** This workflow uses community nodes (n8n-nodes-mcp.mcpClientTool) and will only work on self-hosted n8n instances. You'll need to install the required community nodes before importing this workflow.\n\n!![image.png](fileId:1035)\n\n## What does this workflow do?\n\nThis workflow streamlines the information retrieval process by automatically researching n8n platform documentation, community forums, and example workflows, providing you with relevant answers to your questions.\n\n## Who is this for?\n\n- **New n8n Users**: Quickly get answers to basic platform questions and learn how to use n8n effectively\n- **Experienced Developers**: Find solutions to specific technical issues or discover advanced workflows\n- **Teams**: Boost productivity by automating the research process for n8n platform questions\n- **Anyone** looking to leverage AI for efficient and accurate n8n platform knowledge retrieval\n\n## Benefits\n\n- **Effortless Research**: Automate the research process across n8n documentation, forum posts, and example workflows\n- **AI-Powered Intelligence**: Leverage the power of LLMs to understand context and generate helpful responses\n- **Increased Efficiency**: Save time and resources by automating the research process\n- **Quick Solutions**: Get immediate answers to your n8n platform questions\n- **Enhanced Learning**: Discover new workflows, features, and best practices to improve your n8n experience\n\n## How It Works\n\n1. **Receive Request**: The workflow starts when a chat message is received containing your n8n-related question\n2. **AI Processing**: The AI agent powered by OpenAI GPT-4o analyzes your question\n3. **Research and Information Gathering**: The system searches across multiple sources:\n   - Official n8n documentation for general knowledge and how-to guides\n   - Community forums for bug reports and specific issues\n   - Example workflow repository for relevant implementations\n4. **Response Generation**: The AI agent compiles the research and generates a clear, comprehensive answer\n5. **Output**: The workflow provides you with the relevant information and step-by-step guidance when applicable\n\n## n8n Nodes Used\n\n- When chat message received (Chat Trigger)\n- OpenAI Chat Model (GPT-4o mini)\n- N8N AI Agent\n- n8n-assistant tools (MCP Client Tool - Community Node)\n- n8n-assistant execute (MCP Client Tool - Community Node)\n\n## Prerequisites\n\n- Self-hosted n8n instance\n- OpenAI API credentials\n- MCP client community node installed\n- MCP server configured to search n8n resources\n\n## Setup\n\n1. Import the workflow JSON into your n8n instance\n2. Configure the OpenAI credentials\n3. Configure your MCP client API credentials\n4. In the n8n-assistant execute node, ensure the parameter is set to \"specific\" (corrected from \"spesific\")\n5. Test the workflow by sending a message with an n8n-related question\n\n## MCP Server Connection\n\nTo connect to the MCP server that powers this assistant's research capabilities, you need to use the following URL:\nhttps://smithery.ai/server/@onurpolat05/n8n-assistant\n\nThis MCP server is specifically designed to search across three types of n8n resources:\n1. Official documentation for general platform information and workflow creation guidance\n2. Community forums for bug-related issues and troubleshooting\n3. Example workflow repositories for reference implementations\n\nConfigure this URL in your MCP client credentials to enable the assistant to retrieve relevant information based on user queries.\n\nThis workflow combines the convenience of chat with the power of AI to provide a seamless n8n platform research experience. Start getting instant answers to your n8n questions today!",
  "featuredImage": "/data/workflows/3303/3303.webp",
  "author": {
    "id": 101,
    "slug": "onurpolat05",
    "name": "Onur",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 18128,
  "downloads": 1812,
  "createdAt": "2025-03-24T09:42:01.239Z",
  "updatedAt": "2026-01-16T08:29:07.418Z",
  "publishedAt": "2025-03-24T09:42:01.239Z",
  "nodes": 5,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3303",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "AI-powered research assistant for platform questions with GPT-4o and MCP",
    "workflowName": "AI-powered research assistant for platform questions with GPT-4o and MCP",
    "description": "## Description\n\nThis workflow empowers you to effortlessly get answers to your n8n platform questions through an AI-powered assistant. Simply send your query, and the assistant will search documentation, forum posts, and example workflows to provide comprehensive, accurate responses tailored to your specific needs.\n\n&gt; **Note:** This workflow uses community nodes (n8n-nodes-mcp.mcpClientTool) and will only work on self-hosted n8n instances. You'll need to install the required community nodes before importing this workflow.\n\n!![image.png](fileId:1035)\n\n## What does this workflow do?\n\nThis workflow streamlines the information retrieval process by automatically researching n8n platform documentation, community forums, and example workflows, providing you with relevant answers to your questions.\n\n## Who is this for?\n\n- **New n8n Users**: Quickly get answers to basic platform questions and learn how to use n8n effectively\n- **Experienced Developers**: Find solutions to specific technical issues or discover advanced workflows\n- **Teams**: Boost productivity by automating the research process for n8n platform questions\n- **Anyone** looking to leverage AI for efficient and accurate n8n platform knowledge retrieval\n\n## Benefits\n\n- **Effortless Research**: Automate the research process across n8n documentation, forum posts, and example workflows\n- **AI-Powered Intelligence**: Leverage the power of LLMs to understand context and generate helpful responses\n- **Increased Efficiency**: Save time and resources by automating the research process\n- **Quick Solutions**: Get immediate answers to your n8n platform questions\n- **Enhanced Learning**: Discover new workflows, features, and best practices to improve your n8n experience\n\n## How It Works\n\n1. **Receive Request**: The workflow starts when a chat message is received containing your n8n-related question\n2. **AI Processing**: The AI agent powered by OpenAI GPT-4o analyzes your question\n3. **Research and Information Gathering**: The system searches across multiple sources:\n   - Official n8n documentation for general knowledge and how-to guides\n   - Community forums for bug reports and specific issues\n   - Example workflow repository for relevant implementations\n4. **Response Generation**: The AI agent compiles the research and generates a clear, comprehensive answer\n5. **Output**: The workflow provides you with the relevant information and step-by-step guidance when applicable\n\n## n8n Nodes Used\n\n- When chat message received (Chat Trigger)\n- OpenAI Chat Model (GPT-4o mini)\n- N8N AI Agent\n- n8n-assistant tools (MCP Client Tool - Community Node)\n- n8n-assistant execute (MCP Client Tool - Community Node)\n\n## Prerequisites\n\n- Self-hosted n8n instance\n- OpenAI API credentials\n- MCP client community node installed\n- MCP server configured to search n8n resources\n\n## Setup\n\n1. Import the workflow JSON into your n8n instance\n2. Configure the OpenAI credentials\n3. Configure your MCP client API credentials\n4. In the n8n-assistant execute node, ensure the parameter is set to \"specific\" (corrected from \"spesific\")\n5. Test the workflow by sending a message with an n8n-related question\n\n## MCP Server Connection\n\nTo connect to the MCP server that powers this assistant's research capabilities, you need to use the following URL:\nhttps://smithery.ai/server/@onurpolat05/n8n-assistant\n\nThis MCP server is specifically designed to search across three types of n8n resources:\n1. Official documentation for general platform information and workflow creation guidance\n2. Community forums for bug-related issues and troubleshooting\n3. Example workflow repositories for reference implementations\n\nConfigure this URL in your MCP client credentials to enable the assistant to retrieve relevant information based on user queries.\n\nThis workflow combines the convenience of chat with the power of AI to provide a seamless n8n platform research experience. Start getting instant answers to your n8n questions today!",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "n8n Research AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.8"
    },
    {
      "name": "n8n-assistant Tool Lookup",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "n8n-assistant Execute Tool",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenAI Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    }
  ]
}