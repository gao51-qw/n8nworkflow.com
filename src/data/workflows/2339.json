{
  "id": 2339,
  "slug": "2339",
  "title": "Breakdown documents into study notes using templating MistralAI and Qdrant",
  "description": "This n8n workflow takes in a document such as a research paper, marketing or sales deck or company filings, and breaks them down into 3 templates: study guide, briefing doc and timeline.\n\nThese templates are designed to help a student, associate or clerk quickly summarise, learn and understand the contents to be more productive.\n\n* Study guide - a short quiz of questions and answered generated by the AI Agent using the contents of the document.\n* Briefing Doc - key information and insights are extracted by the AI into a digestable form.\n* Timeline - key events, durations and people are identified and listed into a simple to understand timeline by the AI\n\n## How it works\n* A local file trigger watches a local network directory for new documents.\n* New documents are imported into the workflow, its contents extracted and vectorised into a Qdrant vector store to build a mini-knowledgebase.\n* The document then passes through a series of template generating prompts where the AI will perform \"research\" on the knowledgebase to generate the template contents.\n* Generated study guide, briefing and timeline documents are exported to a designated folder for the user.\n\n## Requirements\n* Self-hosted version of n8n.\n* Qdrant instance for knowledgebase.\n* Mistral.ai account for embeddings and AI model.\n\n## Customising your workflow\n\nTry adding your own templates or adjusting the existing templates to suit your unique use-case. Anything is quite possible and limited only by your imagination!\n\n## Want to go fully local?\n\nA version of this workflow is available which uses Ollama instead. You can download this template here: https://drive.google.com/file/d/1VV5R2nW-IhVcFP_k8uEks4LsLRZrHSNG/view?usp=sharing",
  "featuredImage": "/data/workflows/2339/2339.webp",
  "author": {
    "id": 101,
    "slug": "jimleuk",
    "name": "Jimleuk",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 28014,
  "downloads": 2801,
  "createdAt": "2024-07-11T09:13:39.718Z",
  "updatedAt": "2026-01-16T08:24:09.280Z",
  "publishedAt": "2024-07-11T09:13:39.718Z",
  "nodes": 42,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2339",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Breakdown documents into study notes using templating MistralAI and Qdrant",
    "workflowName": "Breakdown documents into study notes using templating MistralAI and Qdrant",
    "description": "This n8n workflow takes in a document such as a research paper, marketing or sales deck or company filings, and breaks them down into 3 templates: study guide, briefing doc and timeline.\n\nThese templates are designed to help a student, associate or clerk quickly summarise, learn and understand the contents to be more productive.\n\n* Study guide - a short quiz of questions and answered generated by the AI Agent using the contents of the document.\n* Briefing Doc - key information and insights are extracted by the AI into a digestable form.\n* Timeline - key events, durations and people are identified and listed into a simple to understand timeline by the AI\n\n## How it works\n* A local file trigger watches a local network directory for new documents.\n* New documents are imported into the workflow, its contents extracted and vectorised into a Qdrant vector store to build a mini-knowledgebase.\n* The document then passes through a series of template generating prompts where the AI will perform \"research\" on the knowledgebase to generate the template contents.\n* Generated study guide, briefing and timeline documents are exported to a designated folder for the user.\n\n## Requirements\n* Self-hosted version of n8n.\n* Qdrant instance for knowledgebase.\n* Mistral.ai account for embeddings and AI model.\n\n## Customising your workflow\n\nTry adding your own templates or adjusting the existing templates to suit your unique use-case. Anything is quite possible and limited only by your imagination!\n\n## Want to go fully local?\n\nA version of this workflow is available which uses Ollama instead. You can download this template here: https://drive.google.com/file/d/1VV5R2nW-IhVcFP_k8uEks4LsLRZrHSNG/view?usp=sharing",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Local File Trigger",
      "type": "n8n-nodes-base.localFileTrigger",
      "role": "localFileTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Mistral Cloud",
      "type": "@n8n/n8n-nodes-langchain.embeddingsMistralCloud",
      "role": "embeddingsMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Prep Incoming Doc",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Settings",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Get Doc Types",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Split Out Doc Types",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "For Each Doc Type...",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Item List Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserItemList",
      "role": "outputParserItemList",
      "configDescription": "Version 1"
    },
    {
      "name": "Vector Store Retriever",
      "type": "@n8n/n8n-nodes-langchain.retrieverVectorStore",
      "role": "retrieverVectorStore",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Mistral Cloud1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsMistralCloud",
      "role": "embeddingsMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Qdrant Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model3",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Discover",
      "type": "@n8n/n8n-nodes-langchain.chainRetrievalQa",
      "role": "chainRetrievalQa",
      "configDescription": "Version 1.3"
    },
    {
      "name": "2secs",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Get Generated Documents",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Generate",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.4"
    },
    {
      "name": "Prep For AI",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.3"
    },
    {
      "name": "To Binary",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Export to Folder",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Get FileType",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3"
    },
    {
      "name": "Import File",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from PDF",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from DOCX",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from TEXT",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Summarization Chain",
      "type": "@n8n/n8n-nodes-langchain.chainSummarization",
      "role": "chainSummarization",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Interview",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.4"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}