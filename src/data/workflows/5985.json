{
  "id": 5985,
  "slug": "5985",
  "title": "Automated SEO content engine with Claude AI, Scrapeless, and competitor analysis",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n### How it works\n\nThis n8n workflow helps you build a fully automated **SEO content engine** using [Scrapeless](https://www.scrapeless.com/?utm_source=n8n&utm_campaign=seo-engine) and AI. It‚Äôs designed for teams running international websites‚Äîsuch as SaaS products, e-commerce platforms, or content-driven businesses‚Äîwho want to grow **targeted search traffic** through **high-conversion content**, without relying on manual research or hit-or-miss topics.\n\nThe flow runs in **three key phases**:\n\n#### üîç Phase 1: Topic Discovery  \nAutomatically find **high-potential long-tail keywords** based on a seed keyword using Google Trends via Scrapeless. Each keyword is analyzed for trend strength and categorized by priority (P0‚ÄìP3) with the help of an AI agent.\n\n#### üß† Phase 2: Competitor Research  \nFor each P0‚ÄìP2 keyword, the flow performs a Google Search (via [Deep SerpAPI](https://www.scrapeless.com/en/product/deep-serp-api?utm_source=n8n&utm_campaign=seo-engine)) and extracts the top 3 organic results. Scrapeless then crawls each result to extract full article content in clean Markdown. This gives you a structured, comparable view of how competitors are writing about each topic.\n\n#### ‚úçÔ∏è Phase 3: AI Article Generation  \nUsing AI (OpenAI or other LLM), the workflow generates a **complete SEO article draft**, including:\n- SEO title\n- Slug\n- Meta description\n- Trend-based strategy summary\n- Structured JSON-based article body with H2/H3 blocks\n\nFinally, the article is stored in **Supabase** (or any other supported DB), making it ready for review, API-based publishing, or further automation.\n\n### Set up steps\n\nThis flow requires intermediate familiarity with n8n and API key setup. Full configuration may take **30‚Äì60 minutes**.\n\n#### ‚úÖ Prerequisites\n\n- **Scrapeless** account (for Google Trends and web crawling)\n- **LLM provider** (e.g. OpenAI or Claude)\n- **Supabase** or **Google Sheets** (to store keywords & article output)\n\n#### üß© Required Credentials in n8n\n\n- `Scrapeless API Key`\n- `OpenAI (or other LLM)` credentials\n- `Supabase` or `Google Sheets` credentials\n\n---\n\n#### üîß Setup Instructions (Simplified)\n\n1. **Input Seed Keyword**  \n   Edit the ‚ÄúSet Seed Keyword‚Äù node to define your niche, e.g., `\"project management\"`.\n\n2. **Google Trends via Scrapeless**  \n   Use Scrapeless to retrieve ‚Äúrelated queries‚Äù and their interest-over-time data.\n\n3. **Trend Analysis with AI Agent**  \n   AI evaluates each keyword's trend strength and assigns a priority (P0‚ÄìP3).\n\n4. **Filter & Store Keyword Data**  \n   Group and sort keywords by priority, then store them in Google Sheets.\n\n5. **Competitor Research**  \n   Use Deep SerpAPI to get top 3 Google results. Crawl each using Scrapeless.\n\n6. **AI Content Generation**  \n   Feed competitor content + trend data into AI. Output a structured SEO blog article.\n\n7. **Store Final Article**  \n   Save full article JSON (title, meta, slug, content) to Supabase.",
  "featuredImage": "/data/workflows/5985/5985.webp",
  "author": {
    "id": 101,
    "slug": "scrapelessofficial",
    "name": "scrapeless official",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1294,
  "downloads": 129,
  "createdAt": "2025-07-14T08:34:53.156Z",
  "updatedAt": "2026-01-16T08:42:31.481Z",
  "publishedAt": "2025-07-14T08:34:53.156Z",
  "nodes": 26,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5985",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Automated SEO content engine with Claude AI, Scrapeless, and competitor analysis",
    "workflowName": "Automated SEO content engine with Claude AI, Scrapeless, and competitor analysis",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n### How it works\n\nThis n8n workflow helps you build a fully automated **SEO content engine** using [Scrapeless](https://www.scrapeless.com/?utm_source=n8n&utm_campaign=seo-engine) and AI. It‚Äôs designed for teams running international websites‚Äîsuch as SaaS products, e-commerce platforms, or content-driven businesses‚Äîwho want to grow **targeted search traffic** through **high-conversion content**, without relying on manual research or hit-or-miss topics.\n\nThe flow runs in **three key phases**:\n\n#### üîç Phase 1: Topic Discovery  \nAutomatically find **high-potential long-tail keywords** based on a seed keyword using Google Trends via Scrapeless. Each keyword is analyzed for trend strength and categorized by priority (P0‚ÄìP3) with the help of an AI agent.\n\n#### üß† Phase 2: Competitor Research  \nFor each P0‚ÄìP2 keyword, the flow performs a Google Search (via [Deep SerpAPI](https://www.scrapeless.com/en/product/deep-serp-api?utm_source=n8n&utm_campaign=seo-engine)) and extracts the top 3 organic results. Scrapeless then crawls each result to extract full article content in clean Markdown. This gives you a structured, comparable view of how competitors are writing about each topic.\n\n#### ‚úçÔ∏è Phase 3: AI Article Generation  \nUsing AI (OpenAI or other LLM), the workflow generates a **complete SEO article draft**, including:\n- SEO title\n- Slug\n- Meta description\n- Trend-based strategy summary\n- Structured JSON-based article body with H2/H3 blocks\n\nFinally, the article is stored in **Supabase** (or any other supported DB), making it ready for review, API-based publishing, or further automation.\n\n### Set up steps\n\nThis flow requires intermediate familiarity with n8n and API key setup. Full configuration may take **30‚Äì60 minutes**.\n\n#### ‚úÖ Prerequisites\n\n- **Scrapeless** account (for Google Trends and web crawling)\n- **LLM provider** (e.g. OpenAI or Claude)\n- **Supabase** or **Google Sheets** (to store keywords & article output)\n\n#### üß© Required Credentials in n8n\n\n- `Scrapeless API Key`\n- `OpenAI (or other LLM)` credentials\n- `Supabase` or `Google Sheets` credentials\n\n---\n\n#### üîß Setup Instructions (Simplified)\n\n1. **Input Seed Keyword**  \n   Edit the ‚ÄúSet Seed Keyword‚Äù node to define your niche, e.g., `\"project management\"`.\n\n2. **Google Trends via Scrapeless**  \n   Use Scrapeless to retrieve ‚Äúrelated queries‚Äù and their interest-over-time data.\n\n3. **Trend Analysis with AI Agent**  \n   AI evaluates each keyword's trend strength and assigns a priority (P0‚ÄìP3).\n\n4. **Filter & Store Keyword Data**  \n   Group and sort keywords by priority, then store them in Google Sheets.\n\n5. **Competitor Research**  \n   Use Deep SerpAPI to get top 3 Google results. Crawl each using Scrapeless.\n\n6. **AI Content Generation**  \n   Feed competitor content + trend data into AI. Output a structured SEO blog article.\n\n7. **Store Final Article**  \n   Save full article JSON (title, meta, slug, content) to Supabase.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‚ÄòExecute workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Trends",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Crawl",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "Split Out2",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Search",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "Set seed keywords",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Google Trends-Get heat data",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Anthropic Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "role": "lmChatAnthropic",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Filter out topics with priority above P2",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Filter TOP3 competitor links",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Extract competitor content Markdown",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Senior SEO content writer",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Code1",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Append or update row in sheet",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Split Out1",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Get row(s) in sheet",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Anthropic Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "role": "lmChatAnthropic",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Create a row",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    }
  ]
}