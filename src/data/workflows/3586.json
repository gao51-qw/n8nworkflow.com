{
  "id": 3586,
  "slug": "3586",
  "title": "AI-powered WhatsApp chatbot ü§ñüì≤ for text, voice, images & PDFs with memory üß†",
  "description": "This workflow is a highly advanced **multimodal AI assistant** designed to operate through **WhatsApp**. It can **understand and respond** to text, images, voice messages, and PDF documents by combining **OpenAI models** with smart logic to adapt to the content received.\n\n---\n\n### üéØ **Core Features**\n\n#### üì• 1. **Automatic Message Type Detection**\nUsing the `Input type` node, the bot detects whether the user has sent:\n- Text\n- Voice messages\n- Images\n- Files (PDF)\n- Other unsupported content\n\n#### üí¨ 2. **Smart Text Message Handling**\n- Text messages are processed by an **OpenAI GPT-4o-mini agent** with a customized system prompt.\n- Replies are concise, accurate, and formatted for mobile readability.\n\n#### üñºÔ∏è 3. **Image Analysis & Description**\n- Images are downloaded, converted to base64, and analyzed by an **image-aware AI model**.\n- The output is a rich, structured description, designed for visually impaired users or visual content interpretation.\n\n#### üéôÔ∏è 4. **Voice Message Transcription & Reply**\n- Audio messages are downloaded and transcribed using OpenAI Whisper.\n- The transcribed text is analyzed and answered by the AI.\n- Optionally, the AI reply can be **converted back to voice** using **OpenAI's text-to-speech**, and sent as an audio message.\n\n#### üìÑ 5. **PDF Document Extraction & Summary**\n- Only PDFs are allowed (filtered via MIME type).\n- The document‚Äôs content is extracted and combined with the user's message.\n- The AI then provides a relevant summary or answer.\n\n#### üß† 6. **Contextual Memory**\n- Each user has a personalized session ID with a memory window of 10 interactions.\n- This ensures a more natural and contextual conversation flow.\n\n\n---\n\n### **How It Works**  \n\nThisworkflow is designed to handle incoming WhatsApp messages and process different types of inputs (**text, audio, images, and PDF documents**) using **AI-powered analysis**. Here‚Äôs how it functions:  \n\n- **Trigger**: The workflow starts with the **WhatsApp Trigger** node, which listens for incoming messages (text, audio, images, or documents).  \n- **Input Routing**: The **Input type** (Switch node) checks the message type and routes it to the appropriate processing branch:  \n  - **Text**: Directly forwards the message to the AI agent for response generation.  \n  - **Audio**: Downloads the audio file, transcribes it using OpenAI, and sends the transcription to the AI agent.  \n  - **Image**: Downloads the image, analyzes it with OpenAI‚Äôs GPT-4 model, and generates a detailed description.  \n  - **PDF Document**: Downloads the file, extracts text, and processes it with the AI agent.  \n  - **Unsupported Formats**: Sends an error message if the input is not supported.  \n- **AI Processing**: The **AI Agent1** node, powered by OpenAI, processes the input (text, transcribed audio, image description, or PDF content) and generates a response.  \n- **Response Handling**:  \n  - For **audio inputs**, the AI‚Äôs response is converted back into speech (using OpenAI‚Äôs TTS) and sent as a voice message.  \n  - For **other inputs**, the response is sent as a text message via WhatsApp.  \n- **Memory**: The **Simple Memory** node maintains conversation context for follow-up interactions.  \n\n###  **Setup Steps**  \nTo deploy this workflow in n8n, follow these steps:  \n\n1. **Configure WhatsApp API Credentials**:  \n   - Set up **WhatsApp Business API** credentials (Meta Developer Account).  \n   - Add the credentials in the **WhatsApp Trigger**, **Get Image/Audio/File URL**, and **Send Message** nodes.  \n\n**Set Up OpenAI Integration**:  \n   - Provide an **OpenAI API key** in the **Analyze Image**, **Transcribe Audio**, **Generate Audio Response**, and **AI Agent1** nodes.  \n\n **Adjust Input Handling (Optional)**:  \n   - Modify the **Switch node (\"Input type\")** to handle additional message types if needed.  \n   - Update the **\"Only PDF File\" IF node** to support other document formats.  \n\n**Test & Deploy**:  \n   - Activate the workflow and test with different message types (text, audio, image, PDF).  \n   - Ensure responses are correctly generated and sent back via WhatsApp.  \n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/). ",
  "featuredImage": "/data/workflows/3586/3586.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "Support Chatbot",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 122473,
  "downloads": 12247,
  "createdAt": "2025-04-17T14:22:12.162Z",
  "updatedAt": "2026-01-16T08:30:28.923Z",
  "publishedAt": "2025-04-17T14:22:12.162Z",
  "nodes": 32,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3586",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "AI-powered WhatsApp chatbot ü§ñüì≤ for text, voice, images & PDFs with memory üß†",
    "workflowName": "AI-powered WhatsApp chatbot ü§ñüì≤ for text, voice, images & PDFs with memory üß†",
    "description": "This workflow is a highly advanced **multimodal AI assistant** designed to operate through **WhatsApp**. It can **understand and respond** to text, images, voice messages, and PDF documents by combining **OpenAI models** with smart logic to adapt to the content received.\n\n---\n\n### üéØ **Core Features**\n\n#### üì• 1. **Automatic Message Type Detection**\nUsing the `Input type` node, the bot detects whether the user has sent:\n- Text\n- Voice messages\n- Images\n- Files (PDF)\n- Other unsupported content\n\n#### üí¨ 2. **Smart Text Message Handling**\n- Text messages are processed by an **OpenAI GPT-4o-mini agent** with a customized system prompt.\n- Replies are concise, accurate, and formatted for mobile readability.\n\n#### üñºÔ∏è 3. **Image Analysis & Description**\n- Images are downloaded, converted to base64, and analyzed by an **image-aware AI model**.\n- The output is a rich, structured description, designed for visually impaired users or visual content interpretation.\n\n#### üéôÔ∏è 4. **Voice Message Transcription & Reply**\n- Audio messages are downloaded and transcribed using OpenAI Whisper.\n- The transcribed text is analyzed and answered by the AI.\n- Optionally, the AI reply can be **converted back to voice** using **OpenAI's text-to-speech**, and sent as an audio message.\n\n#### üìÑ 5. **PDF Document Extraction & Summary**\n- Only PDFs are allowed (filtered via MIME type).\n- The document‚Äôs content is extracted and combined with the user's message.\n- The AI then provides a relevant summary or answer.\n\n#### üß† 6. **Contextual Memory**\n- Each user has a personalized session ID with a memory window of 10 interactions.\n- This ensures a more natural and contextual conversation flow.\n\n\n---\n\n### **How It Works**  \n\nThisworkflow is designed to handle incoming WhatsApp messages and process different types of inputs (**text, audio, images, and PDF documents**) using **AI-powered analysis**. Here‚Äôs how it functions:  \n\n- **Trigger**: The workflow starts with the **WhatsApp Trigger** node, which listens for incoming messages (text, audio, images, or documents).  \n- **Input Routing**: The **Input type** (Switch node) checks the message type and routes it to the appropriate processing branch:  \n  - **Text**: Directly forwards the message to the AI agent for response generation.  \n  - **Audio**: Downloads the audio file, transcribes it using OpenAI, and sends the transcription to the AI agent.  \n  - **Image**: Downloads the image, analyzes it with OpenAI‚Äôs GPT-4 model, and generates a detailed description.  \n  - **PDF Document**: Downloads the file, extracts text, and processes it with the AI agent.  \n  - **Unsupported Formats**: Sends an error message if the input is not supported.  \n- **AI Processing**: The **AI Agent1** node, powered by OpenAI, processes the input (text, transcribed audio, image description, or PDF content) and generates a response.  \n- **Response Handling**:  \n  - For **audio inputs**, the AI‚Äôs response is converted back into speech (using OpenAI‚Äôs TTS) and sent as a voice message.  \n  - For **other inputs**, the response is sent as a text message via WhatsApp.  \n- **Memory**: The **Simple Memory** node maintains conversation context for follow-up interactions.  \n\n###  **Setup Steps**  \nTo deploy this workflow in n8n, follow these steps:  \n\n1. **Configure WhatsApp API Credentials**:  \n   - Set up **WhatsApp Business API** credentials (Meta Developer Account).  \n   - Add the credentials in the **WhatsApp Trigger**, **Get Image/Audio/File URL**, and **Send Message** nodes.  \n\n**Set Up OpenAI Integration**:  \n   - Provide an **OpenAI API key** in the **Analyze Image**, **Transcribe Audio**, **Generate Audio Response**, and **AI Agent1** nodes.  \n\n **Adjust Input Handling (Optional)**:  \n   - Modify the **Switch node (\"Input type\")** to handle additional message types if needed.  \n   - Update the **\"Only PDF File\" IF node** to support other document formats.  \n\n**Test & Deploy**:  \n   - Activate the workflow and test with different message types (text, audio, image, PDF).  \n   - Ensure responses are correctly generated and sent back via WhatsApp.  \n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "WhatsApp Trigger",
      "type": "n8n-nodes-base.whatsAppTrigger",
      "role": "whatsAppTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Download Image",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Analyze Image",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Download Audio",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Transcribe Audio",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Download File",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Extract from File",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Get File Url",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Only PDF File",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Fix mimeType for Audio",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Send message",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Send audio",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Incorrect format",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Text",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Audio",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Image",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "File",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Not supported",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Image Url",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Audio Url",
      "type": "n8n-nodes-base.whatsApp",
      "role": "whatsApp",
      "configDescription": "Version 1"
    },
    {
      "name": "Generate Audio Response",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "From audio to audio?",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Input type",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}