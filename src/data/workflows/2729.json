{
  "id": 2729,
  "slug": "2729",
  "title": "ğŸ”ğŸ¦™ğŸ¤– Private & local Ollama self-hosted AI assistant",
  "description": "Transform your local N8N instance into a powerful chat interface using any local & private Ollama model, with zero cloud dependencies â˜ï¸. This workflow creates a structured chat experience that processes messages locally through a language model chain and returns formatted responses ğŸ’¬.\n\n## How it works ğŸ”„\n- ğŸ’­ Chat messages trigger the workflow\n- ğŸ§  Messages are processed through Llama 3.2 via Ollama (or any other Ollama compatible model)\n- ğŸ“Š Responses are formatted as structured JSON\n- âš¡ Error handling ensures robust operation\n\n## Set up steps ğŸ› ï¸\n- ğŸ“¥ Install N8N and Ollama\n- âš™ï¸ Download Ollama 3.2 model (or other model)\n- ğŸ”‘ Configure Ollama API credentials\n- âœ¨ Import and activate workflow\n\nThis template provides a foundation for building AI-powered chat applications while maintaining full control over your data and infrastructure ğŸš€.\n",
  "featuredImage": "/data/workflows/2729/2729.webp",
  "author": {
    "id": 101,
    "slug": "joe",
    "name": "Joseph LePage",
    "avatar": ""
  },
  "categories": [
    "Personal Productivity",
    "AI Chatbot"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 60225,
  "downloads": 6022,
  "createdAt": "2025-01-15T05:39:06.856Z",
  "updatedAt": "2026-01-16T08:26:10.503Z",
  "publishedAt": "2025-01-15T05:39:06.856Z",
  "nodes": 14,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2729",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "ğŸ”ğŸ¦™ğŸ¤– Private & local Ollama self-hosted AI assistant",
    "workflowName": "ğŸ”ğŸ¦™ğŸ¤– Private & local Ollama self-hosted AI assistant",
    "description": "Transform your local N8N instance into a powerful chat interface using any local & private Ollama model, with zero cloud dependencies â˜ï¸. This workflow creates a structured chat experience that processes messages locally through a language model chain and returns formatted responses ğŸ’¬.\n\n## How it works ğŸ”„\n- ğŸ’­ Chat messages trigger the workflow\n- ğŸ§  Messages are processed through Llama 3.2 via Ollama (or any other Ollama compatible model)\n- ğŸ“Š Responses are formatted as structured JSON\n- âš¡ Error handling ensures robust operation\n\n## Set up steps ğŸ› ï¸\n- ğŸ“¥ Install N8N and Ollama\n- âš™ï¸ Download Ollama 3.2 model (or other model)\n- ğŸ”‘ Configure Ollama API credentials\n- âœ¨ Import and activate workflow\n\nThis template provides a foundation for building AI-powered chat applications while maintaining full control over your data and infrastructure ğŸš€.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Basic LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.5"
    },
    {
      "name": "Ollama Model",
      "type": "@n8n/n8n-nodes-langchain.lmOllama",
      "role": "lmOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Error Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "JSON to Object",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    }
  ]
}