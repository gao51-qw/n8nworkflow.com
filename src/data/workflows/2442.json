{
  "id": 2442,
  "slug": "2442",
  "title": "ðŸš€ Local multi-LLM testing & performance tracker",
  "description": "### ðŸš€ **Local Multi-LLM Testing & Performance Tracker**\n\nThis workflow is perfect for developers, researchers, and data scientists benchmarking multiple LLMs with LM Studio. It dynamically fetches active models, tests prompts, and tracks metrics like word count, readability, and response time, logging results into Google Sheets. Easily adjust **temperature** ðŸ”¥ and **top P** ðŸŽ¯ for flexible model testing.\n\n---\n\n### **Level of Effort**:  \nðŸŸ¢ Easy â€“ Minimal setup with customizable options.\n\n---\n\n### **Setup Steps**:\n1. Install LM Studio and configure models.\n2. Update IP to connect to LM Studio.\n3. Create a Google Sheet for result tracking.\n\n---\n\n### **Key Outcomes**:\n- Benchmark LLM performance.\n- Automate results in Google Sheets for easy comparison.\n\n\nVersion 1.0",
  "featuredImage": "/data/workflows/2442/2442.webp",
  "author": {
    "id": 101,
    "slug": "davidmoneil",
    "name": "Wildkick",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 4339,
  "downloads": 433,
  "createdAt": "2024-09-28T19:28:58.189Z",
  "updatedAt": "2026-01-16T08:24:47.200Z",
  "publishedAt": "2024-09-28T19:28:58.189Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2442",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "ðŸš€ Local multi-LLM testing & performance tracker",
    "workflowName": "ðŸš€ Local multi-LLM testing & performance tracker",
    "description": "### ðŸš€ **Local Multi-LLM Testing & Performance Tracker**\n\nThis workflow is perfect for developers, researchers, and data scientists benchmarking multiple LLMs with LM Studio. It dynamically fetches active models, tests prompts, and tracks metrics like word count, readability, and response time, logging results into Google Sheets. Easily adjust **temperature** ðŸ”¥ and **top P** ðŸŽ¯ for flexible model testing.\n\n---\n\n### **Level of Effort**:  \nðŸŸ¢ Easy â€“ Minimal setup with customizable options.\n\n---\n\n### **Setup Steps**:\n1. Install LM Studio and configure models.\n2. Update IP to connect to LM Studio.\n3. Create a Google Sheet for result tracking.\n\n---\n\n### **Key Outcomes**:\n- Benchmark LLM performance.\n- Automate results in Google Sheets for easy comparison.\n\n\nVersion 1.0",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Models",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Get timeDifference",
      "type": "n8n-nodes-base.dateTime",
      "role": "dateTime",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Run Model with Dunamic Inputs",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Analyze LLM Response Metrics",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Save Results to Google Sheets",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.5"
    },
    {
      "name": "Capture End Time",
      "type": "n8n-nodes-base.dateTime",
      "role": "dateTime",
      "configDescription": "Version 2"
    },
    {
      "name": "Capture Start Time",
      "type": "n8n-nodes-base.dateTime",
      "role": "dateTime",
      "configDescription": "Version 2"
    },
    {
      "name": "Prepare Data for Analysis",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Extract Model IDsto Run Separately",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Add System Prompt",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "LLM Response Analysis",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.4"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}