{
  "id": 8944,
  "slug": "8944",
  "title": "My solution for the \"Agentic Arena Community Contest\" (RAG, Qdrant, Mistral OCR)",
  "description": "ðŸ¤–ðŸ“ˆ This workflow is **my personal solution** for the **Agentic Arena Community Contest**, where the goal is to build a Retrieval-Augmented Generation (RAG) AI agent capable of answering questions based on a provided PDF knowledge base.\n\n\n---\n\n### Key Advantages\n\n* âœ… **End-to-End RAG Implementation**\n  Fully automates the ingestion, processing, and retrieval of knowledge from PDFs into a vector database.\n\n* âœ… **Accuracy through Multi-Layered Retrieval**\n  Combines embeddings, Qdrant search, and Cohere reranking to ensure the agent retrieves the most relevant policy information.\n\n* âœ… **Robust Evaluation System**\n  Includes an automated correctness evaluation pipeline powered by GPT-4.1 as a judge, ensuring transparent scoring and continuous improvement.\n\n* âœ… **Citation-Driven Compliance**\n  The AI agent is instructed to provide **citations for every answer**, making it suitable for high-stakes use cases like policy compliance.\n\n* âœ… **Scalability and Modularity**\n  Can easily integrate with different data sources (Google Drive, APIs, other storage systems) and be extended to new use cases.\n\n* âœ… **Seamless Collaboration with Google Sheets**\n  Both the evaluation set and the results are integrated with Google Sheets, enabling easy monitoring, iteration, and reporting.\n\n* âœ… **Cloud and Self-Hosted Flexibility**\n  Works with self-hosted **Qdrant** on Hetzner, Mistral Cloud for OCR, and OpenAI/Cohere APIs, combining local control with powerful cloud AI services.\n\n---\n### **How it Works**\n\n1.  **Knowledge Base Ingestion (The \"Setup\" Execution):**\n    *   When started manually, the workflow first clears an existing Qdrant vector database collection.\n    *   It then searches a specified Google Drive folder for PDF files. For each PDF found, it performs the following steps:\n        *   **Uploads the file** to the Mistral AI API.\n        *   **Processes the PDF** using Mistral's OCR service to extract text and convert it into a structured markdown format.\n        *   **Splits the text** into manageable chunks.\n        *   **Generates embeddings** for each text chunk using OpenAI's model.\n        *   **Stores the embeddings** in the Qdrant vector store, creating a searchable knowledge base.\n\n2.  **Agent Evaluation (The \"Testing\" Execution):**\n    *   The workflow is triggered by an evaluation Google Sheet containing questions and correct answers.\n    *   For each question, the core **AI Agent** is activated. This agent:\n        *   Uses the **RAG tool** to search the pre-populated Qdrant vector store for relevant information from the PDFs.\n        *   Employs a **Cohere reranker** to refine the search results for the highest quality context.\n        *   Leverages a **GPT-4.1 model** to generate an answer based strictly on the retrieved context.\n    *   The agent's answer is then passed to an **\"LLM as a Judge\"** (another GPT-4.1 instance), which compares it to the ground truth answer from the evaluation sheet.\n    *   The judge provides a detailed score (1-5) based on factual correctness and citation accuracy.\n    *   Finally, both the agent's answer and the correctness score are saved back to a Google Sheet for review.\n\n---\n\n### **Set up Steps**\n\nTo implement this solution, you need to configure the following components and credentials:\n\n1.  **Configure Core AI Services:**\n    *   **OpenAI API Credentials:** Required for the main AI agent, the judge LLM, and generating embeddings.\n    *   **Mistral AI API Credentials:** Necessary for the OCR service that processes PDF files.\n    *   **Cohere API Credentials:** Used for the reranker node that improves retrieval quality.\n    *   **Google Service Accounts:** Set up OAuth for Google Sheets (to read questions and save results) and Google Drive (to access the PDF source files).\n\n2.  **Set up the Vector Database (Qdrant):**\n    *   This workflow uses a self-hosted Qdrant instance. You must deploy and configure your own Qdrant server.\n    *   Update the **Qdrant Vector Store** and **RAG** nodes with the correct API endpoint URL and credentials for your Qdrant instance.\n    *   Ensure the collection name (`agentic-arena`) is created or matches your setup.\n\n3.  **Connect Data Sources:**\n    *   **PDF Source:** In the **\"Search PDFs\"** node, update the `folderId` parameter to point to your own Google Drive folder containing the contest PDFs.\n    *   **Evaluation Sheet:** In the **\"Eval Set\"** node, update the `documentId` to point to your own copy of the evaluation Google Sheet containing the test questions and answers.\n    *   **Results Sheet:** In the **\"Save Eval\"** node, update the `documentId` to point to the Google Sheet where you want to save the evaluation results.\n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
  "featuredImage": "/data/workflows/8944/8944.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 681,
  "downloads": 68,
  "createdAt": "2025-09-26T09:12:39.109Z",
  "updatedAt": "2026-01-16T08:58:29.380Z",
  "publishedAt": "2025-09-26T09:12:39.109Z",
  "nodes": 41,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/8944",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "My solution for the \"Agentic Arena Community Contest\" (RAG, Qdrant, Mistral OCR)",
    "workflowName": "My solution for the \"Agentic Arena Community Contest\" (RAG, Qdrant, Mistral OCR)",
    "description": "ðŸ¤–ðŸ“ˆ This workflow is **my personal solution** for the **Agentic Arena Community Contest**, where the goal is to build a Retrieval-Augmented Generation (RAG) AI agent capable of answering questions based on a provided PDF knowledge base.\n\n\n---\n\n### Key Advantages\n\n* âœ… **End-to-End RAG Implementation**\n  Fully automates the ingestion, processing, and retrieval of knowledge from PDFs into a vector database.\n\n* âœ… **Accuracy through Multi-Layered Retrieval**\n  Combines embeddings, Qdrant search, and Cohere reranking to ensure the agent retrieves the most relevant policy information.\n\n* âœ… **Robust Evaluation System**\n  Includes an automated correctness evaluation pipeline powered by GPT-4.1 as a judge, ensuring transparent scoring and continuous improvement.\n\n* âœ… **Citation-Driven Compliance**\n  The AI agent is instructed to provide **citations for every answer**, making it suitable for high-stakes use cases like policy compliance.\n\n* âœ… **Scalability and Modularity**\n  Can easily integrate with different data sources (Google Drive, APIs, other storage systems) and be extended to new use cases.\n\n* âœ… **Seamless Collaboration with Google Sheets**\n  Both the evaluation set and the results are integrated with Google Sheets, enabling easy monitoring, iteration, and reporting.\n\n* âœ… **Cloud and Self-Hosted Flexibility**\n  Works with self-hosted **Qdrant** on Hetzner, Mistral Cloud for OCR, and OpenAI/Cohere APIs, combining local control with powerful cloud AI services.\n\n---\n### **How it Works**\n\n1.  **Knowledge Base Ingestion (The \"Setup\" Execution):**\n    *   When started manually, the workflow first clears an existing Qdrant vector database collection.\n    *   It then searches a specified Google Drive folder for PDF files. For each PDF found, it performs the following steps:\n        *   **Uploads the file** to the Mistral AI API.\n        *   **Processes the PDF** using Mistral's OCR service to extract text and convert it into a structured markdown format.\n        *   **Splits the text** into manageable chunks.\n        *   **Generates embeddings** for each text chunk using OpenAI's model.\n        *   **Stores the embeddings** in the Qdrant vector store, creating a searchable knowledge base.\n\n2.  **Agent Evaluation (The \"Testing\" Execution):**\n    *   The workflow is triggered by an evaluation Google Sheet containing questions and correct answers.\n    *   For each question, the core **AI Agent** is activated. This agent:\n        *   Uses the **RAG tool** to search the pre-populated Qdrant vector store for relevant information from the PDFs.\n        *   Employs a **Cohere reranker** to refine the search results for the highest quality context.\n        *   Leverages a **GPT-4.1 model** to generate an answer based strictly on the retrieved context.\n    *   The agent's answer is then passed to an **\"LLM as a Judge\"** (another GPT-4.1 instance), which compares it to the ground truth answer from the evaluation sheet.\n    *   The judge provides a detailed score (1-5) based on factual correctness and citation accuracy.\n    *   Finally, both the agent's answer and the correctness score are saved back to a Google Sheet for review.\n\n---\n\n### **Set up Steps**\n\nTo implement this solution, you need to configure the following components and credentials:\n\n1.  **Configure Core AI Services:**\n    *   **OpenAI API Credentials:** Required for the main AI agent, the judge LLM, and generating embeddings.\n    *   **Mistral AI API Credentials:** Necessary for the OCR service that processes PDF files.\n    *   **Cohere API Credentials:** Used for the reranker node that improves retrieval quality.\n    *   **Google Service Accounts:** Set up OAuth for Google Sheets (to read questions and save results) and Google Drive (to access the PDF source files).\n\n2.  **Set up the Vector Database (Qdrant):**\n    *   This workflow uses a self-hosted Qdrant instance. You must deploy and configure your own Qdrant server.\n    *   Update the **Qdrant Vector Store** and **RAG** nodes with the correct API endpoint URL and credentials for your Qdrant instance.\n    *   Ensure the collection name (`agentic-arena`) is created or matches your setup.\n\n3.  **Connect Data Sources:**\n    *   **PDF Source:** In the **\"Search PDFs\"** node, update the `folderId` parameter to point to your own Google Drive folder containing the contest PDFs.\n    *   **Evaluation Sheet:** In the **\"Eval Set\"** node, update the `documentId` to point to your own copy of the evaluation Google Sheet containing the test questions and answers.\n    *   **Results Sheet:** In the **\"Save Eval\"** node, update the `documentId` to point to the Google Sheet where you want to save the evaluation results.\n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Only if we are evaluating",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Eval Input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Eval Set",
      "type": "n8n-nodes-base.evaluationTrigger",
      "role": "evaluationTrigger",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Respond to Chat",
      "type": "@n8n/n8n-nodes-langchain.chat",
      "role": "chat",
      "configDescription": "Version 1"
    },
    {
      "name": "Filter Empty Rows",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Save Eval",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Run Evaluation",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "LLM as a Judge",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking â€˜Execute workflowâ€™",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Upload",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Mistral Signed URL",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Mistral DOC OCR",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Refresh collection",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Loop Over Items1",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "When Executed by Another Workflow",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "role": "executeWorkflowTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Create collection",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Set page",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Search PDFs",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Get PDF",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterCharacterTextSplitter",
      "role": "textSplitterCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Reranker Cohere",
      "type": "@n8n/n8n-nodes-langchain.rerankerCohere",
      "role": "rerankerCohere",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "RAG",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Call 'Agent Arena'",
      "type": "n8n-nodes-base.executeWorkflow",
      "role": "executeWorkflow",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Get File ID",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    }
  ]
}