{
  "id": 7430,
  "slug": "7430",
  "title": "Extract context from voice notes with OpenRouter AI & Milvus for RAG systems",
  "description": "# Voice Note Context Extraction Pipeline with AI Agent & Vector Storage\n\n\n### This n8n template demonstrates how to automatically extract and store contextual information from voice notes using AI agents and vector databases for future retrieval.\n\n\n### How it works\n\n- **Webhook trigger** receives voice note data including title, transcript, and timestamp from external services (example here: voicenotes.com)\n- **Field extraction** isolates the key data fields (title, transcript, timestamp) for processing\n- **AI Context Agent** processes the transcript to extract meaningful context while:\n  - Correcting speech-to-text errors\n  - Converting first-person references to third-person facts\n  - Filtering out casual conversation and focusing on significant information\n- **Output formatting** structures the extracted context with timestamps for embedding\n- **File conversion** prepares the context data for vector storage\n- **Vector embedding** uses OpenAI embeddings to create searchable representations\n- **Milvus storage** stores the embedded context for future retrieval in RAG applications\n\n### How to use\n\n- Configure the webhook endpoint to receive data from your voice note service\n- Set up credentials for OpenRouter (LLM), OpenAI (embeddings), and Milvus (vector storage)\n- Customize the AI agent's system prompt to match your context extraction needs\n- The workflow automatically processes incoming voice notes and stores extracted context\n\n### Requirements\n\n- OpenRouter account for LLM access\n- OpenAI API key for embeddings\n- Milvus vector database (cloud or self-hosted)\n- Voice note service with webhook capabilities (e.g., Voicenotes.com)\n\n### Customizing this workflow\n\n- **Modify the context extraction prompt** to focus on specific types of information (preferences, facts, relationships)\n- **Add filtering logic** to process only voice notes with specific tags or keywords\n- **Integrate with other storage** systems like Pinecone, Weaviate, or local vector databases\n- **Connect to RAG systems** to use the stored context for enhanced AI conversations\n- **Add notification nodes** to confirm successful context extraction and storage\n\n### Use cases\n\n- **Personal AI assistant** that remembers your preferences and context from voice notes\n- **Knowledge management** system for capturing insights from recorded thoughts\n- **Content creation** pipeline that extracts key themes from voice recordings\n- **Research assistant** that builds context from interview transcripts or meeting notes",
  "featuredImage": "/data/workflows/7430/7430.webp",
  "author": {
    "id": 101,
    "slug": "danielrosehill",
    "name": "Daniel Rosehill",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 546,
  "downloads": 54,
  "createdAt": "2025-08-15T12:25:09.656Z",
  "updatedAt": "2026-01-16T08:50:21.231Z",
  "publishedAt": "2025-08-15T12:25:09.656Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7430",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Extract context from voice notes with OpenRouter AI & Milvus for RAG systems",
    "workflowName": "Extract context from voice notes with OpenRouter AI & Milvus for RAG systems",
    "description": "# Voice Note Context Extraction Pipeline with AI Agent & Vector Storage\n\n\n### This n8n template demonstrates how to automatically extract and store contextual information from voice notes using AI agents and vector databases for future retrieval.\n\n\n### How it works\n\n- **Webhook trigger** receives voice note data including title, transcript, and timestamp from external services (example here: voicenotes.com)\n- **Field extraction** isolates the key data fields (title, transcript, timestamp) for processing\n- **AI Context Agent** processes the transcript to extract meaningful context while:\n  - Correcting speech-to-text errors\n  - Converting first-person references to third-person facts\n  - Filtering out casual conversation and focusing on significant information\n- **Output formatting** structures the extracted context with timestamps for embedding\n- **File conversion** prepares the context data for vector storage\n- **Vector embedding** uses OpenAI embeddings to create searchable representations\n- **Milvus storage** stores the embedded context for future retrieval in RAG applications\n\n### How to use\n\n- Configure the webhook endpoint to receive data from your voice note service\n- Set up credentials for OpenRouter (LLM), OpenAI (embeddings), and Milvus (vector storage)\n- Customize the AI agent's system prompt to match your context extraction needs\n- The workflow automatically processes incoming voice notes and stores extracted context\n\n### Requirements\n\n- OpenRouter account for LLM access\n- OpenAI API key for embeddings\n- Milvus vector database (cloud or self-hosted)\n- Voice note service with webhook capabilities (e.g., Voicenotes.com)\n\n### Customizing this workflow\n\n- **Modify the context extraction prompt** to focus on specific types of information (preferences, facts, relationships)\n- **Add filtering logic** to process only voice notes with specific tags or keywords\n- **Integrate with other storage** systems like Pinecone, Weaviate, or local vector databases\n- **Connect to RAG systems** to use the stored context for enhanced AI conversations\n- **Add notification nodes** to confirm successful context extraction and storage\n\n### Use cases\n\n- **Personal AI assistant** that remembers your preferences and context from voice notes\n- **Knowledge management** system for capturing insights from recorded thoughts\n- **Content creation** pipeline that extracts key themes from voice recordings\n- **Research assistant** that builds context from interview transcripts or meeting notes",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2"
    },
    {
      "name": "Edit Fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "OpenRouter Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "role": "lmChatOpenRouter",
      "configDescription": "Version 1"
    },
    {
      "name": "Edit Fields1",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Convert to File",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Milvus Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreMilvus",
      "role": "vectorStoreMilvus",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}