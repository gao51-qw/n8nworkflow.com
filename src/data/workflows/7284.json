{
  "id": 7284,
  "slug": "7284",
  "title": "Automated AWS S3 / Azure / Google to local MinIO object backup with scheduling",
  "description": "# Automated AWS S3 / Azure / Google to local MinIO Object Backup with Scheduling\n\n## What this workflow does ?\n\nThis workflow performs automated, periodic backups of objects from an AWS S3 bucket, an Azure Container or a Google Storage Space to a MinIO S3 bucket running locally or on a dedicated container/VM/server. It can also work if the MinIO bucket is running on a remote cloud provider's infrastructure; you just need to change the URL and keys.\n\n## Who's this intended for ?\n\nStorage administrators, cloud architects, or DevOps who need a simple and scalable solution for retrieving data from AWS, Azure or GCP.\n\n## How it works\n\nThis workflow uses the official AWS S3 API to list and download objects from a specific bucket, or the Azure BLOB one, then send them to MinIO using their version of the S3 API.  \n\n\n## Requirements\n\nNone, just a source Bucket on your Cloud Storage Provider and a destination one on MinIO. You'll also need to get MinIO running. \n\nYou're using Proxmox VE ? Create a MinIO LXC Container : https://community-scripts.github.io/ProxmoxVE/scripts?id=minio\n\n## Need a Backup from another Cloud Storage Provider ?\n\nNeed automated backup from another Cloud Storage Provider ?\n\n$\\mapsto$ Check out our templates, we've done it with AWS, Azure, and GCP, and we even have a version for FTP/SFTP servers!\n\nFor a dedicated source Cloud Storage Provider, please contact us !\n\n$\\odot$ These workflow can be integrated to bigger ones and modified to best suit your needs ! You can, for example, replace the MinIO node to another S3 Bucket from another Cloud Storage Provider (Backblaze, Wasabi, Scaleway, OVH, ...)\n",
  "featuredImage": "/data/workflows/7284/7284.webp",
  "author": {
    "id": 101,
    "slug": "sienna",
    "name": "SIENNA",
    "avatar": ""
  },
  "categories": [
    "File Management",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 537,
  "downloads": 53,
  "createdAt": "2025-08-12T10:23:40.922Z",
  "updatedAt": "2026-01-16T08:49:31.387Z",
  "publishedAt": "2025-08-12T10:23:40.922Z",
  "nodes": 19,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7284",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Automated AWS S3 / Azure / Google to local MinIO object backup with scheduling",
    "workflowName": "Automated AWS S3 / Azure / Google to local MinIO object backup with scheduling",
    "description": "# Automated AWS S3 / Azure / Google to local MinIO Object Backup with Scheduling\n\n## What this workflow does ?\n\nThis workflow performs automated, periodic backups of objects from an AWS S3 bucket, an Azure Container or a Google Storage Space to a MinIO S3 bucket running locally or on a dedicated container/VM/server. It can also work if the MinIO bucket is running on a remote cloud provider's infrastructure; you just need to change the URL and keys.\n\n## Who's this intended for ?\n\nStorage administrators, cloud architects, or DevOps who need a simple and scalable solution for retrieving data from AWS, Azure or GCP.\n\n## How it works\n\nThis workflow uses the official AWS S3 API to list and download objects from a specific bucket, or the Azure BLOB one, then send them to MinIO using their version of the S3 API.  \n\n\n## Requirements\n\nNone, just a source Bucket on your Cloud Storage Provider and a destination one on MinIO. You'll also need to get MinIO running. \n\nYou're using Proxmox VE ? Create a MinIO LXC Container : https://community-scripts.github.io/ProxmoxVE/scripts?id=minio\n\n## Need a Backup from another Cloud Storage Provider ?\n\nNeed automated backup from another Cloud Storage Provider ?\n\n$\\mapsto$ Check out our templates, we've done it with AWS, Azure, and GCP, and we even have a version for FTP/SFTP servers!\n\nFor a dedicated source Cloud Storage Provider, please contact us !\n\n$\\odot$ These workflow can be integrated to bigger ones and modified to best suit your needs ! You can, for example, replace the MinIO node to another S3 Bucket from another Cloud Storage Provider (Backblaze, Wasabi, Scaleway, OVH, ...)",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Sticky Note37",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Path Extraction",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Schedule Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "List Objects",
      "type": "n8n-nodes-base.awsS3",
      "role": "awsS3",
      "configDescription": "Version 2"
    },
    {
      "name": "Download Objects",
      "type": "n8n-nodes-base.awsS3",
      "role": "awsS3",
      "configDescription": "Version 2"
    },
    {
      "name": "Upload Objects to MinIO",
      "type": "n8n-nodes-base.s3",
      "role": "s3",
      "configDescription": "Version 1"
    },
    {
      "name": "BLOB Listing",
      "type": "n8n-nodes-base.azureStorage",
      "role": "azureStorage",
      "configDescription": "Version 1"
    },
    {
      "name": "Path extraction",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "BLOB Download",
      "type": "n8n-nodes-base.azureStorage",
      "role": "azureStorage",
      "configDescription": "Version 1"
    },
    {
      "name": "MinIO BLOB Upload",
      "type": "n8n-nodes-base.s3",
      "role": "s3",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Object Listing",
      "type": "n8n-nodes-base.googleCloudStorage",
      "role": "googleCloudStorage",
      "configDescription": "Version 1"
    },
    {
      "name": "Upload on MinIO",
      "type": "n8n-nodes-base.s3",
      "role": "s3",
      "configDescription": "Version 1"
    },
    {
      "name": "Download Objects Data",
      "type": "n8n-nodes-base.googleCloudStorage",
      "role": "googleCloudStorage",
      "configDescription": "Version 1"
    },
    {
      "name": "Path extraction1",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}