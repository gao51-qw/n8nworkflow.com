{
  "id": 2165,
  "slug": "2165",
  "title": "Chat with PDF docs using AI (quoting sources)",
  "description": "This workflow allows you to ask questions about a PDF document. The answers are provided by an AI model of your choice, and the answer includes a citation pointing to the information it used.\n\nYou can use n8n’s built-in chat interface to ask the questions, or you could customise this workflow to use another one (e.g. Slack, Teams, etc.)\n\n### Example\n\nThe workflow is set up with the Bitcoin whitepaper. So you could ask things like:\n\n*Question: “Which email provider does the creator of Bitcoin use?“*\n*Answer: “GMX [Bitcoin whitepaper.pdf, lines 1-35]”*\n\n### Requirements\n\n1. A Pinecone account (they have a free tier at the time of writing that is easily enough for this workflow)\n2. Access to a large language model (e.g. an OpenAI account)\n\n### Customizing this workflow\n\nThe workflow only reads in one document, but you could customise it to read in all the documents in a folder (or more).\n\nThe workflow is set up to use GPT 3.5, but you could swap that out for any other model (including self-hosted ones).",
  "featuredImage": "/data/workflows/2165/2165.webp",
  "author": {
    "id": 101,
    "slug": "davidn8n",
    "name": "David Roberts",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 113346,
  "downloads": 11334,
  "createdAt": "2024-03-05T17:31:20.648Z",
  "updatedAt": "2026-01-16T08:23:22.522Z",
  "publishedAt": "2024-03-05T17:31:20.648Z",
  "nodes": 22,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2165",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Chat with PDF docs using AI (quoting sources)",
    "workflowName": "Chat with PDF docs using AI (quoting sources)",
    "description": "This workflow allows you to ask questions about a PDF document. The answers are provided by an AI model of your choice, and the answer includes a citation pointing to the information it used.\n\nYou can use n8n’s built-in chat interface to ask the questions, or you could customise this workflow to use another one (e.g. Slack, Teams, etc.)\n\n### Example\n\nThe workflow is set up with the Bitcoin whitepaper. So you could ask things like:\n\n*Question: “Which email provider does the creator of Bitcoin use?“*\n*Answer: “GMX [Bitcoin whitepaper.pdf, lines 1-35]”*\n\n### Requirements\n\n1. A Pinecone account (they have a free tier at the time of writing that is easily enough for this workflow)\n2. Access to a large language model (e.g. an OpenAI account)\n\n### Customizing this workflow\n\nThe workflow only reads in one document, but you could customise it to read in all the documents in a folder (or more).\n\nThe workflow is set up to use GPT 3.5, but you could swap that out for any other model (including self-hosted ones).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking \"Execute Workflow\"",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "OpenAI Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Set file URL in Google Drive",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Download file",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Set max chunks to send to model",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Get top chunks matching query",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1"
    },
    {
      "name": "Prepare chunks",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Answer the query based on chunks",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1"
    },
    {
      "name": "Compose citations",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Generate response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    }
  ]
}