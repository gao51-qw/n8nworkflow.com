{
  "id": 10097,
  "slug": "10097",
  "title": "Ai website scraper & company intelligence",
  "description": "#  AI Website Scraper & Company Intelligence\n\n## **Description**\n\nThis workflow automates the process of transforming any website URL into a **structured, intelligent company profile**.  \nIt's triggered by a form, allowing a user to submit a website and choose between a **\"basic\"** or **\"deep\"** scrape.\n\nThe workflow extracts key information (mission, services, contacts, SEO keywords), stores it in a structured **Supabase** database, and archives a full JSON backup to **Google Drive**.  \nIt also features a secondary AI agent that automatically finds and saves competitors for each company, building a rich, interconnected database of company intelligence.\n\n---\n\n## **Quick Implementation Steps**\n\n1. **Import the Workflow:** Import the provided JSON file into your **n8n instance**.\n2. **Install Custom Community Node:**  \n   You must install the community node from:  \n  [https://www.npmjs.com/package/n8n-nodes-crawl-and-scrape](https://www.npmjs.com/package/n8n-nodes-crawl-and-scrape)\n**FIRECRAWL  N8N Documentation**\n  [https://docs.firecrawl.dev/developer-guides/workflow-automation/n8n](https://docs.firecrawl.dev/developer-guides/workflow-automation/n8n)\n\n\n3. **Install Additional Nodes:**  \n   `n8n-nodes-crawl-and-scrape` and `n8n-nodes-mcp` fire crawl mcp   .\n4. **Set up Credentials:**  \n   Create credentials in n8n for  **FIRE CRAWL API**,**Supabase**, **Mistral AI**, and **Google Drive**.\n5. **Configure API Key (CRITICAL):**  \n   - Open the **Web Search tool node**.  \n   - Go to **Parameters → Headers** and replace the hardcoded **Tavily AI API key** with your own.\n6. **Configure Supabase Nodes:**  \n   - Assign your Supabase credential to all Supabase nodes.  \n   - Ensure table names (e.g., `companies`, `competitors`) match your schema.\n7. **Configure Google Drive Nodes:**  \n   - Assign your Google Drive credential to the `Google Drive2` and `save to Google Drive1` nodes.  \n   - Select the correct **Folder ID**.\n8. **Activate Workflow:**  \n   Turn on the workflow and open the **Webhook URL** in the “On form submission” node to access the form.\n\n---\n\n## **What It Does**\n\n### **Form Trigger**\nCaptures user input: “Website URL” and “Scraping Type” (basic or deep).\n\n### **Scraping Router**\nA **Switch node** routes the flow:\n- **Deep Scraping →** AI-based MCP Firecrawler agent.  \n- **Basic Scraping →** Crawlee node.\n\n### **Deep Scraping (Firecrawl AI Agent)**\n- Uses **Firecrawl** and **Tavily Web Search**.\n- Extracts a detailed JSON profile: mission, services, contacts, SEO keywords, etc.\n\n### **Basic Scraping (Crawlee)**\n- Uses `Crawl and Scrape` node to collect raw text.  \n- A **Mistral-based AI extractor** structures the data into JSON.\n\n### **Data Storage**\n- Stores structured data in Supabase tables (`companies`, `company_basicprofiles`).\n- Archives a full JSON backup to **Google Drive**.\n\n### **Automated Competitor Analysis**\n- Runs after a deep scrape.\n- Uses Tavily web search to find competitors (e.g., from **Crunchbase**).\n- Saves competitor data to Supabase, linked by `company_id`.\n\n---\n\n## **Who's It For**\n\n- **Sales & Marketing Teams:** Enrich leads with deep company info.  \n- **Market Researchers:** Build structured, searchable company databases.  \n- **B2B Data Providers:** Automate company intelligence collection.  \n- **Developers:** Use as a base for RAG or enrichment pipelines.\n\n---\n\n## **Requirements**\n\n- **n8n instance** (self-hosted or cloud)\n- **Supabase Account:** With tables like `companies`, `competitors`, `social_links`, etc.\n- **Mistral AI API Key**\n- **Google Drive Credentials**\n- **Tavily AI API Key**\n- *(Optional)* **Custom Nodes:**  \n  - `n8n-nodes-crawl-and-scrape`  \n \n\n---\n\n## **How It Works**\n\n### **Flow Summary**\n1. **Form Trigger:** Captures “Website URL” and “Scraping Type”.\n2. **Switch Node:**  \n   - `deep` → MCP Firecrawler (AI Agent).  \n   - `basic` → Crawl and Scrape node.\n3. **Scraping & Extraction:**  \n   - Deep path: Firecrawler → JSON structure.  \n   - Basic path: Crawlee → Mistral extractor → JSON.\n4. **Storage:**  \n   - Save JSON to Supabase.  \n   - Archive in Google Drive.\n5. **Competitor Analysis (Deep Only):**  \n   - Finds competitors via Tavily.  \n   - Saves to Supabase `competitors` table.\n6. **End:** Finishes with a `No Operation` node.\n\n---\n\n## **How To Set Up**\n\n1. Import workflow JSON.\n2. Install community nodes (especially `n8n-nodes-crawl-and-scrape` from npm).\n3. Configure credentials (Supabase, Mistral AI, Google Drive).\n4. Add your **Tavily API key**.\n5. Connect Supabase and Drive nodes properly.\n6. Fix disconnected “basic” path if needed.\n7. Activate workflow.\n8. Test via the webhook form URL.\n\n---\n\n## **How To Customize**\n\n- **Change LLMs:** Swap Mistral for OpenAI or Claude.  \n- **Edit Scraper Prompts:** Modify system prompts in AI agent nodes.  \n- **Change Extraction Schema:** Update JSON Schema in extractor nodes.  \n- **Fix Relational Tables:** Add `Items` node before Supabase inserts for arrays (social links, keywords).  \n- **Enhance Automation:** Add email/slack notifications, or replace form trigger with a Google Sheets trigger.\n\n---\n\n## **Add-ons**\n\n- **Automated Trigger:** Run on new sheet rows.  \n- **Notifications:** Email or Slack alerts after completion.  \n- **RAG Integration:** Use the Supabase database as a chatbot knowledge source.\n\n---\n\n## **Use Case Examples**\n\n- **Sales Lead Enrichment:** Instantly get company + competitor data from a URL.  \n- **Market Research:** Collect and compare companies in a niche.  \n- **B2B Database Creation:** Build a proprietary company dataset.\n\n---\n\n## WORKFLOW IMAGE \n![Screenshot_22102025_152855_localhost.jpeg](fileId:3139)\n---\n## **Troubleshooting Guide**\n\n| Issue | Possible Cause | Solution |\n|-------|----------------|-----------|\n| **Form Trigger 404** | Workflow not active | Activate the workflow |\n| **Web Search Tool fails** | Missing Tavily API key | Replace the placeholder key |\n| **FIRECRAWLER / find competitor fails** | Missing MCP node | Install `n8n-nodes-mcp` |\n| **Basic scrape does nothing** | Switch node path disconnected | Reconnect “basic” output |\n| **Supabase node error** | Wrong table/column names | Match schema exactly |\n\n---\n\n###  **Need Help or More Workflows?**\nWant to customize this workflow for your business or integrate it with your existing tools?  \nOur team at **Digital Biz Tech** can tailor it precisely to your use case  from automation logic to AI-powered enhancements.  \n\n **Contact:** [shilpa.raju@digitalbiz.tech](mailto:shilpa.raju@digitalbiz.tech)  \n **For more such offerings, visit us:** [https://www.digitalbiz.tech](https://www.digitalbiz.tech)\n\n---",
  "featuredImage": "/data/workflows/10097/10097.webp",
  "author": {
    "id": 101,
    "slug": "dbt",
    "name": "DIGITAL BIZ TECH",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 847,
  "downloads": 84,
  "createdAt": "2025-10-24T01:38:47.520Z",
  "updatedAt": "2026-01-16T09:03:22.960Z",
  "publishedAt": "2025-10-24T01:38:47.520Z",
  "nodes": 35,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10097",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Ai website scraper & company intelligence",
    "workflowName": "Ai website scraper & company intelligence",
    "description": "#  AI Website Scraper & Company Intelligence\n\n## **Description**\n\nThis workflow automates the process of transforming any website URL into a **structured, intelligent company profile**.  \nIt's triggered by a form, allowing a user to submit a website and choose between a **\"basic\"** or **\"deep\"** scrape.\n\nThe workflow extracts key information (mission, services, contacts, SEO keywords), stores it in a structured **Supabase** database, and archives a full JSON backup to **Google Drive**.  \nIt also features a secondary AI agent that automatically finds and saves competitors for each company, building a rich, interconnected database of company intelligence.\n\n---\n\n## **Quick Implementation Steps**\n\n1. **Import the Workflow:** Import the provided JSON file into your **n8n instance**.\n2. **Install Custom Community Node:**  \n   You must install the community node from:  \n  [https://www.npmjs.com/package/n8n-nodes-crawl-and-scrape](https://www.npmjs.com/package/n8n-nodes-crawl-and-scrape)\n**FIRECRAWL  N8N Documentation**\n  [https://docs.firecrawl.dev/developer-guides/workflow-automation/n8n](https://docs.firecrawl.dev/developer-guides/workflow-automation/n8n)\n\n\n3. **Install Additional Nodes:**  \n   `n8n-nodes-crawl-and-scrape` and `n8n-nodes-mcp` fire crawl mcp   .\n4. **Set up Credentials:**  \n   Create credentials in n8n for  **FIRE CRAWL API**,**Supabase**, **Mistral AI**, and **Google Drive**.\n5. **Configure API Key (CRITICAL):**  \n   - Open the **Web Search tool node**.  \n   - Go to **Parameters → Headers** and replace the hardcoded **Tavily AI API key** with your own.\n6. **Configure Supabase Nodes:**  \n   - Assign your Supabase credential to all Supabase nodes.  \n   - Ensure table names (e.g., `companies`, `competitors`) match your schema.\n7. **Configure Google Drive Nodes:**  \n   - Assign your Google Drive credential to the `Google Drive2` and `save to Google Drive1` nodes.  \n   - Select the correct **Folder ID**.\n8. **Activate Workflow:**  \n   Turn on the workflow and open the **Webhook URL** in the “On form submission” node to access the form.\n\n---\n\n## **What It Does**\n\n### **Form Trigger**\nCaptures user input: “Website URL” and “Scraping Type” (basic or deep).\n\n### **Scraping Router**\nA **Switch node** routes the flow:\n- **Deep Scraping →** AI-based MCP Firecrawler agent.  \n- **Basic Scraping →** Crawlee node.\n\n### **Deep Scraping (Firecrawl AI Agent)**\n- Uses **Firecrawl** and **Tavily Web Search**.\n- Extracts a detailed JSON profile: mission, services, contacts, SEO keywords, etc.\n\n### **Basic Scraping (Crawlee)**\n- Uses `Crawl and Scrape` node to collect raw text.  \n- A **Mistral-based AI extractor** structures the data into JSON.\n\n### **Data Storage**\n- Stores structured data in Supabase tables (`companies`, `company_basicprofiles`).\n- Archives a full JSON backup to **Google Drive**.\n\n### **Automated Competitor Analysis**\n- Runs after a deep scrape.\n- Uses Tavily web search to find competitors (e.g., from **Crunchbase**).\n- Saves competitor data to Supabase, linked by `company_id`.\n\n---\n\n## **Who's It For**\n\n- **Sales & Marketing Teams:** Enrich leads with deep company info.  \n- **Market Researchers:** Build structured, searchable company databases.  \n- **B2B Data Providers:** Automate company intelligence collection.  \n- **Developers:** Use as a base for RAG or enrichment pipelines.\n\n---\n\n## **Requirements**\n\n- **n8n instance** (self-hosted or cloud)\n- **Supabase Account:** With tables like `companies`, `competitors`, `social_links`, etc.\n- **Mistral AI API Key**\n- **Google Drive Credentials**\n- **Tavily AI API Key**\n- *(Optional)* **Custom Nodes:**  \n  - `n8n-nodes-crawl-and-scrape`  \n \n\n---\n\n## **How It Works**\n\n### **Flow Summary**\n1. **Form Trigger:** Captures “Website URL” and “Scraping Type”.\n2. **Switch Node:**  \n   - `deep` → MCP Firecrawler (AI Agent).  \n   - `basic` → Crawl and Scrape node.\n3. **Scraping & Extraction:**  \n   - Deep path: Firecrawler → JSON structure.  \n   - Basic path: Crawlee → Mistral extractor → JSON.\n4. **Storage:**  \n   - Save JSON to Supabase.  \n   - Archive in Google Drive.\n5. **Competitor Analysis (Deep Only):**  \n   - Finds competitors via Tavily.  \n   - Saves to Supabase `competitors` table.\n6. **End:** Finishes with a `No Operation` node.\n\n---\n\n## **How To Set Up**\n\n1. Import workflow JSON.\n2. Install community nodes (especially `n8n-nodes-crawl-and-scrape` from npm).\n3. Configure credentials (Supabase, Mistral AI, Google Drive).\n4. Add your **Tavily API key**.\n5. Connect Supabase and Drive nodes properly.\n6. Fix disconnected “basic” path if needed.\n7. Activate workflow.\n8. Test via the webhook form URL.\n\n---\n\n## **How To Customize**\n\n- **Change LLMs:** Swap Mistral for OpenAI or Claude.  \n- **Edit Scraper Prompts:** Modify system prompts in AI agent nodes.  \n- **Change Extraction Schema:** Update JSON Schema in extractor nodes.  \n- **Fix Relational Tables:** Add `Items` node before Supabase inserts for arrays (social links, keywords).  \n- **Enhance Automation:** Add email/slack notifications, or replace form trigger with a Google Sheets trigger.\n\n---\n\n## **Add-ons**\n\n- **Automated Trigger:** Run on new sheet rows.  \n- **Notifications:** Email or Slack alerts after completion.  \n- **RAG Integration:** Use the Supabase database as a chatbot knowledge source.\n\n---\n\n## **Use Case Examples**\n\n- **Sales Lead Enrichment:** Instantly get company + competitor data from a URL.  \n- **Market Research:** Collect and compare companies in a niche.  \n- **B2B Database Creation:** Build a proprietary company dataset.\n\n---\n\n## WORKFLOW IMAGE \n![Screenshot_22102025_152855_localhost.jpeg](fileId:3139)\n---\n## **Troubleshooting Guide**\n\n| Issue | Possible Cause | Solution |\n|-------|----------------|-----------|\n| **Form Trigger 404** | Workflow not active | Activate the workflow |\n| **Web Search Tool fails** | Missing Tavily API key | Replace the placeholder key |\n| **FIRECRAWLER / find competitor fails** | Missing MCP node | Install `n8n-nodes-mcp` |\n| **Basic scrape does nothing** | Switch node path disconnected | Reconnect “basic” output |\n| **Supabase node error** | Wrong table/column names | Match schema exactly |\n\n---\n\n###  **Need Help or More Workflows?**\nWant to customize this workflow for your business or integrate it with your existing tools?  \nOur team at **Digital Biz Tech** can tailor it precisely to your use case  from automation logic to AI-powered enhancements.  \n\n **Contact:** [shilpa.raju@digitalbiz.tech](mailto:shilpa.raju@digitalbiz.tech)  \n **For more such offerings, visit us:** [https://www.digitalbiz.tech](https://www.digitalbiz.tech)\n\n---",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Supabase",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model3",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "list tools",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "execute tools",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "find competitor",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Supabase4",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Crawl and Scrape",
      "type": "n8n-nodes-crawl-and-scrape.crawleeNode",
      "role": "crawleeNode",
      "configDescription": "Version 1"
    },
    {
      "name": "On form submission",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "basic web scraper",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "social media db",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "keywords",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model5",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Information Extractor1",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Mistral Cloud Chat Model6",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Drive2",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Firecrawl tools1",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "Mistral Cloud Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Firecrawl list1",
      "type": "n8n-nodes-mcp.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser1",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Web Search tool",
      "type": "@n8n/n8n-nodes-langchain.toolHttpRequest",
      "role": "toolHttpRequest",
      "configDescription": "Version 1.1"
    },
    {
      "name": "No Operation, do nothing",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "MCP based scraper FIRECRAWLER",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Convert to File  for storage",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Convert to File  for storage1",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "save to Google Drive1",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "save to Supabase",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}