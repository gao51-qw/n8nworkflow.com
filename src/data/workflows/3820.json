{
  "id": 3820,
  "slug": "3820",
  "title": "Dynamically switch between LLMs for AI agents using LangChain code",
  "description": "# Dynamically switch between LLMs for AI Agents using LangChain Code\n\n## Purpose\n\nThis example workflow demonstrates a way to connect multiple LLMs to a single AI Agent/LangChain Node and programmatically use one – or in this case loop through them.\n\n## What it does\n\nThis AI workflow takes in customer complaints and generates a response that is being validated before returned. If the answer was not satisfactory, the response will be generated again with a more capable model.\n\n## How it works\n\n- A LangChain Code Node allows multiple LLMs to be connected to a single Basic LLM Chain. On every call only one LLM is actually being connected to the Basic LLM Chain, which is determined by the index defined in a previous Node.\n- The AI output is later validated by a Sentiment Analysis Node\n- If the result was not satisfactory, it loops back to the beginning and executes the same query with the next available LLM\n- The loop ends either when the result passed the requirements or when all LLMs have been used before.\n\n## Setup\n- Clone the workflow and select the belonging credentials. You'll need an OpenAI Account, alternatively you can swap the LLM nodes with ones from a different provider like Anthropic after the import.\n\n## How to use\n\n*Beware that the order of the used LLMs is determined by the order they have been added to the workflow, not by the position on the canvas.*\n\nAfter cloning this workflow into your environment, open the chat and send this example message:\n\n&gt; I really *love* waiting two weeks just to get a keyboard that doesn’t even work. Great job. Any chance I could actually use the thing I paid for sometime this month?\n\nMost likely you will see that the first validation fails, causing it to loop back to the generation node and try again with the next available LLM.\n\n*Since AI responses are unpredictable, the results and number of tries will differ for each run.*\n\n## Disclaimer\nPlease note, that this workflow can only run on self-hosted n8n instances, since it requires the LangChain Code Node.",
  "featuredImage": "/data/workflows/3820/3820.webp",
  "author": {
    "id": 101,
    "slug": "octionic",
    "name": "Mario",
    "avatar": ""
  },
  "categories": [
    "Support Chatbot",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 5269,
  "downloads": 526,
  "createdAt": "2025-05-01T12:28:53.112Z",
  "updatedAt": "2026-01-16T08:31:37.945Z",
  "publishedAt": "2025-05-01T12:28:53.112Z",
  "nodes": 22,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3820",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Dynamically switch between LLMs for AI agents using LangChain code",
    "workflowName": "Dynamically switch between LLMs for AI agents using LangChain code",
    "description": "# Dynamically switch between LLMs for AI Agents using LangChain Code\n\n## Purpose\n\nThis example workflow demonstrates a way to connect multiple LLMs to a single AI Agent/LangChain Node and programmatically use one – or in this case loop through them.\n\n## What it does\n\nThis AI workflow takes in customer complaints and generates a response that is being validated before returned. If the answer was not satisfactory, the response will be generated again with a more capable model.\n\n## How it works\n\n- A LangChain Code Node allows multiple LLMs to be connected to a single Basic LLM Chain. On every call only one LLM is actually being connected to the Basic LLM Chain, which is determined by the index defined in a previous Node.\n- The AI output is later validated by a Sentiment Analysis Node\n- If the result was not satisfactory, it loops back to the beginning and executes the same query with the next available LLM\n- The loop ends either when the result passed the requirements or when all LLMs have been used before.\n\n## Setup\n- Clone the workflow and select the belonging credentials. You'll need an OpenAI Account, alternatively you can swap the LLM nodes with ones from a different provider like Anthropic after the import.\n\n## How to use\n\n*Beware that the order of the used LLMs is determined by the order they have been added to the workflow, not by the position on the canvas.*\n\nAfter cloning this workflow into your environment, open the chat and send this example message:\n\n&gt; I really *love* waiting two weeks just to get a keyboard that doesn’t even work. Great job. Any chance I could actually use the thing I paid for sometime this month?\n\nMost likely you will see that the first validation fails, causing it to loop back to the generation node and try again with the next available LLM.\n\n*Since AI responses are unpredictable, the results and number of tries will differ for each run.*\n\n## Disclaimer\nPlease note, that this workflow can only run on self-hosted n8n instances, since it requires the LangChain Code Node.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Switch Model",
      "type": "@n8n/n8n-nodes-langchain.code",
      "role": "code",
      "configDescription": "Version 1"
    },
    {
      "name": "Set LLM index",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Increase LLM index",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "No Operation, do nothing",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Check for expected error",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Loop finished without results",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Unexpected error",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Return result",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "OpenAI 4o-mini",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI 4o",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI o1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Validate response",
      "type": "@n8n/n8n-nodes-langchain.sentimentAnalysis",
      "role": "sentimentAnalysis",
      "configDescription": "Version 1"
    },
    {
      "name": "Generate response",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}