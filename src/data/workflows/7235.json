{
  "id": 7235,
  "slug": "7235",
  "title": "Dynamic search interface with Elasticsearch and automated report generation",
  "description": "# Dynamic Search Interface with Elasticsearch and Automated Report Generation\n\n## üéØ What this workflow does\n\nThis template creates a comprehensive data search and reporting system that allows users to query large datasets through an intuitive web form interface. The system performs real-time searches against Elasticsearch, processes results, and automatically generates structured reports in multiple formats for data analysis and business intelligence.\n\n**Key Features:**\n- üîç Interactive web form for dynamic data querying\n- ‚ö° Real-time Elasticsearch data retrieval with complex filtering\n- üìä Auto-generated reports (Text & CSV formats) with custom formatting\n- üíæ Automatic file storage system for data persistence\n- üéØ Configurable search parameters (amounts, time ranges, entity filters)\n- üîß Scalable architecture for handling large datasets\n\n## üõ†Ô∏è Setup requirements\n\n### Prerequisites\n- **Elasticsearch cluster** running on `https://localhost:9220`\n- **Transaction dataset** indexed in `bank_transactions` index\n- **Sample dataset**: Download from [Bank Transaction Dataset](https://github.com/dataminexcode/n8n-workflow/blob/main/Dynamic%20Search%20Interface%20with%20Elasticsearch%20and%20Automated%20Report%20Generation/data)\n- **File system access** to `/tmp/` directory for report storage\n- **HTTP Basic Authentication** credentials for Elasticsearch\n\n### Required Elasticsearch Index Structure\nThis template uses the **Bank Transaction Dataset** from GitHub: https://github.com/dataminexcode/n8n-workflow/blob/main/Dynamic%20Search%20Interface%20with%20Elasticsearch%20and%20Automated%20Report%20Generation/data\n\nYou can use this python script for importing the csv file into elasticsearch: [Python script for importing data](https://github.com/dataminexcode/n8n-workflow/blob/main/Dynamic%20Search%20Interface%20with%20Elasticsearch%20and%20Automated%20Report%20Generation/python_scripts/import_to_elasticsearch.py)\n\nYour `bank_transactions` index should contain documents with these fields:\n```json\n{\n  \"transaction_id\": \"TXN_123456789\",\n  \"customer_id\": \"CUST_000001\", \n  \"amount\": 5000,\n  \"merchant_category\": \"grocery_net\",\n  \"timestamp\": \"2025-08-10T15:30:00Z\"\n}\n```\n\n**Dataset Info**: This dataset contains realistic financial transaction data perfect for testing search algorithms and report generation, with over 1 million transaction records including various transaction patterns and data types.\n\n### Credentials Setup\n1. Create HTTP Basic Auth credentials in n8n\n2. Configure with your Elasticsearch username/password\n3. Assign to the \"Search Elasticsearch\" node\n\n## ‚öôÔ∏è Configuration\n\n### 1. Form Customization\n- **Webhook Path**: Update the webhook ID if needed\n- **Form Fields**: Modify amounts, time ranges, or add new filters\n- **Validation**: Adjust required fields based on your needs\n\n### 2. Elasticsearch Configuration\n- **URL**: Change `localhost:9220` to your ES cluster endpoint\n- **Index Name**: Update `bank_transactions` to your index name\n- **Query Logic**: Modify search criteria in \"Build Search Query\" node\n- **Result Limit**: Adjust the `size: 100` parameter for more/fewer results\n\n### 3. File Storage\n- **Directory**: Change `/tmp/` to your preferred storage location\n- **Filename Pattern**: Modify `fraud_report_YYYY-MM-DD.{ext}` format\n- **Permissions**: Ensure n8n has write access to the target directory\n\n### 4. Report Formatting\n- **CSV Headers**: Customize column names in the Format Report node\n- **Text Layout**: Modify the report template for your organization\n- **Data Fields**: Add/remove transaction fields as needed\n\n## üöÄ How to use\n\n### For Administrators:\n1. **Import** this workflow template\n2. **Configure** Elasticsearch credentials\n3. **Activate** the workflow\n4. **Share** the webhook URL with data analysts\n\n### For Data Analysts:\n1. **Access** the search interface via the webhook URL\n2. **Set parameters**: Minimum amount, time range, entity filter\n3. **Choose format**: Text report or CSV export\n4. **Submit** form to generate instant data report\n5. **Review** results in the generated file\n\n### Sample Use Cases:\n- **Data analysis**: Search for transactions &gt; $10,000 in last 24 hours\n- **Entity investigation**: Filter all activity for specific customer ID  \n- **Pattern analysis**: Quick analysis of transaction activity patterns\n- **Business reporting**: Generate CSV exports for business intelligence\n- **Dataset testing**: Perfect for testing with the transaction dataset\n\n## üìä Sample Output\n\n### Text Report Format:\n```\nDATA ANALYSIS REPORT\n====================\n\nSearch Criteria:\n- Minimum Amount: $10000\n- Time Range: Last 24 Hours  \n- Customer: All\n\nResults: 3 transactions found\n\nTRANSACTIONS:\n=============\n\n1. Transaction ID: TXN_123456789\n   Customer: CUST_000001\n   Amount: $15000\n   Merchant: grocery_net\n   Time: 2025-08-10T15:30:00Z\n```\n\n### CSV Export Format:\n```csv\nTransaction_ID,Customer_ID,Amount,Merchant_Category,Timestamp\n\"TXN_123456789\",\"CUST_000001\",15000,\"grocery_net\",\"2025-08-10T15:30:00Z\"\n```\n\n## üîß Customization ideas\n\n### Enhanced Analytics Features:\n- Add data validation and quality checks\n- Implement statistical analysis (averages, trends, patterns)\n- Include data visualization charts and graphs\n- Generate summary metrics and KPIs\n\n### Advanced Search Capabilities:\n- Multi-field search with complex boolean logic\n- Fuzzy search and text matching algorithms\n- Date range filtering with custom periods\n- Aggregation queries for data grouping\n\n### Integration Options:\n- **Email notifications**: Alert teams of significant data findings\n- **Slack integration**: Post analytics results to team channels  \n- **Dashboard updates**: Push metrics to business intelligence systems\n- **API endpoints**: Expose search functionality as REST API\n\n### Report Enhancements:\n- **PDF generation**: Create formatted PDF analytics reports\n- **Data visualization**: Add charts, graphs, and trending analysis\n- **Executive summaries**: Include key metrics and business insights\n- **Export formats**: Support for Excel, JSON, and other data formats\n\n## üè∑Ô∏è Tags\n`elasticsearch`, `data-search`, `reporting`, `analytics`, `automation`, `business-intelligence`, `data-processing`, `csv-export`\n\n## üìà Use cases\n- **Business Intelligence**: Organizations analyzing transaction patterns and trends\n- **E-commerce Analytics**: Detecting payment patterns and customer behavior analysis\n- **Data Science**: Real-time data exploration and pattern recognition systems\n- **Operations Teams**: Automated reporting and data monitoring workflows\n- **Research & Development**: Testing search algorithms and data processing techniques\n- **Training & Education**: Learning Elasticsearch integration with realistic datasets\n- **Financial Technology**: Transaction data analysis and business reporting systems\n\n## ‚ö†Ô∏è Important notes\n\n### Security Considerations:\n- Never expose Elasticsearch credentials in logs or form data\n- Implement proper access controls for the webhook URL\n- Consider encryption for sensitive data processing\n- Regular audit of generated reports and access logs\n\n### Performance Tips:\n- Index optimization improves search response times\n- Consider pagination for large result sets\n- Monitor Elasticsearch cluster performance under load\n- Archive old reports to manage disk usage\n\n### Data Management:\n- Ensure data retention policies align with business requirements\n- Implement audit trails for all search operations\n- Consider data privacy requirements when processing datasets\n- Document all configuration changes for maintenance\n\n---\n\n*This template provides a production-ready data search and reporting system that can be easily customized for various data analysis needs. The modular design allows for incremental enhancements while maintaining core search and reporting functionality.*",
  "featuredImage": "/data/workflows/7235/7235.webp",
  "author": {
    "id": 101,
    "slug": "dataminex",
    "name": "DataMinex",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "Multimodal AI"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 589,
  "downloads": 58,
  "createdAt": "2025-08-11T07:59:00.003Z",
  "updatedAt": "2026-01-16T08:49:10.912Z",
  "publishedAt": "2025-08-11T07:59:00.003Z",
  "nodes": 11,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7235",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Dynamic search interface with Elasticsearch and automated report generation",
    "workflowName": "Dynamic search interface with Elasticsearch and automated report generation",
    "description": "# Dynamic Search Interface with Elasticsearch and Automated Report Generation\n\n## üéØ What this workflow does\n\nThis template creates a comprehensive data search and reporting system that allows users to query large datasets through an intuitive web form interface. The system performs real-time searches against Elasticsearch, processes results, and automatically generates structured reports in multiple formats for data analysis and business intelligence.\n\n**Key Features:**\n- üîç Interactive web form for dynamic data querying\n- ‚ö° Real-time Elasticsearch data retrieval with complex filtering\n- üìä Auto-generated reports (Text & CSV formats) with custom formatting\n- üíæ Automatic file storage system for data persistence\n- üéØ Configurable search parameters (amounts, time ranges, entity filters)\n- üîß Scalable architecture for handling large datasets\n\n## üõ†Ô∏è Setup requirements\n\n### Prerequisites\n- **Elasticsearch cluster** running on `https://localhost:9220`\n- **Transaction dataset** indexed in `bank_transactions` index\n- **Sample dataset**: Download from [Bank Transaction Dataset](https://github.com/dataminexcode/n8n-workflow/blob/main/Dynamic%20Search%20Interface%20with%20Elasticsearch%20and%20Automated%20Report%20Generation/data)\n- **File system access** to `/tmp/` directory for report storage\n- **HTTP Basic Authentication** credentials for Elasticsearch\n\n### Required Elasticsearch Index Structure\nThis template uses the **Bank Transaction Dataset** from GitHub: https://github.com/dataminexcode/n8n-workflow/blob/main/Dynamic%20Search%20Interface%20with%20Elasticsearch%20and%20Automated%20Report%20Generation/data\n\nYou can use this python script for importing the csv file into elasticsearch: [Python script for importing data](https://github.com/dataminexcode/n8n-workflow/blob/main/Dynamic%20Search%20Interface%20with%20Elasticsearch%20and%20Automated%20Report%20Generation/python_scripts/import_to_elasticsearch.py)\n\nYour `bank_transactions` index should contain documents with these fields:\n```json\n{\n  \"transaction_id\": \"TXN_123456789\",\n  \"customer_id\": \"CUST_000001\", \n  \"amount\": 5000,\n  \"merchant_category\": \"grocery_net\",\n  \"timestamp\": \"2025-08-10T15:30:00Z\"\n}\n```\n\n**Dataset Info**: This dataset contains realistic financial transaction data perfect for testing search algorithms and report generation, with over 1 million transaction records including various transaction patterns and data types.\n\n### Credentials Setup\n1. Create HTTP Basic Auth credentials in n8n\n2. Configure with your Elasticsearch username/password\n3. Assign to the \"Search Elasticsearch\" node\n\n## ‚öôÔ∏è Configuration\n\n### 1. Form Customization\n- **Webhook Path**: Update the webhook ID if needed\n- **Form Fields**: Modify amounts, time ranges, or add new filters\n- **Validation**: Adjust required fields based on your needs\n\n### 2. Elasticsearch Configuration\n- **URL**: Change `localhost:9220` to your ES cluster endpoint\n- **Index Name**: Update `bank_transactions` to your index name\n- **Query Logic**: Modify search criteria in \"Build Search Query\" node\n- **Result Limit**: Adjust the `size: 100` parameter for more/fewer results\n\n### 3. File Storage\n- **Directory**: Change `/tmp/` to your preferred storage location\n- **Filename Pattern**: Modify `fraud_report_YYYY-MM-DD.{ext}` format\n- **Permissions**: Ensure n8n has write access to the target directory\n\n### 4. Report Formatting\n- **CSV Headers**: Customize column names in the Format Report node\n- **Text Layout**: Modify the report template for your organization\n- **Data Fields**: Add/remove transaction fields as needed\n\n## üöÄ How to use\n\n### For Administrators:\n1. **Import** this workflow template\n2. **Configure** Elasticsearch credentials\n3. **Activate** the workflow\n4. **Share** the webhook URL with data analysts\n\n### For Data Analysts:\n1. **Access** the search interface via the webhook URL\n2. **Set parameters**: Minimum amount, time range, entity filter\n3. **Choose format**: Text report or CSV export\n4. **Submit** form to generate instant data report\n5. **Review** results in the generated file\n\n### Sample Use Cases:\n- **Data analysis**: Search for transactions &gt; $10,000 in last 24 hours\n- **Entity investigation**: Filter all activity for specific customer ID  \n- **Pattern analysis**: Quick analysis of transaction activity patterns\n- **Business reporting**: Generate CSV exports for business intelligence\n- **Dataset testing**: Perfect for testing with the transaction dataset\n\n## üìä Sample Output\n\n### Text Report Format:\n```\nDATA ANALYSIS REPORT\n====================\n\nSearch Criteria:\n- Minimum Amount: $10000\n- Time Range: Last 24 Hours  \n- Customer: All\n\nResults: 3 transactions found\n\nTRANSACTIONS:\n=============\n\n1. Transaction ID: TXN_123456789\n   Customer: CUST_000001\n   Amount: $15000\n   Merchant: grocery_net\n   Time: 2025-08-10T15:30:00Z\n```\n\n### CSV Export Format:\n```csv\nTransaction_ID,Customer_ID,Amount,Merchant_Category,Timestamp\n\"TXN_123456789\",\"CUST_000001\",15000,\"grocery_net\",\"2025-08-10T15:30:00Z\"\n```\n\n## üîß Customization ideas\n\n### Enhanced Analytics Features:\n- Add data validation and quality checks\n- Implement statistical analysis (averages, trends, patterns)\n- Include data visualization charts and graphs\n- Generate summary metrics and KPIs\n\n### Advanced Search Capabilities:\n- Multi-field search with complex boolean logic\n- Fuzzy search and text matching algorithms\n- Date range filtering with custom periods\n- Aggregation queries for data grouping\n\n### Integration Options:\n- **Email notifications**: Alert teams of significant data findings\n- **Slack integration**: Post analytics results to team channels  \n- **Dashboard updates**: Push metrics to business intelligence systems\n- **API endpoints**: Expose search functionality as REST API\n\n### Report Enhancements:\n- **PDF generation**: Create formatted PDF analytics reports\n- **Data visualization**: Add charts, graphs, and trending analysis\n- **Executive summaries**: Include key metrics and business insights\n- **Export formats**: Support for Excel, JSON, and other data formats\n\n## üè∑Ô∏è Tags\n`elasticsearch`, `data-search`, `reporting`, `analytics`, `automation`, `business-intelligence`, `data-processing`, `csv-export`\n\n## üìà Use cases\n- **Business Intelligence**: Organizations analyzing transaction patterns and trends\n- **E-commerce Analytics**: Detecting payment patterns and customer behavior analysis\n- **Data Science**: Real-time data exploration and pattern recognition systems\n- **Operations Teams**: Automated reporting and data monitoring workflows\n- **Research & Development**: Testing search algorithms and data processing techniques\n- **Training & Education**: Learning Elasticsearch integration with realistic datasets\n- **Financial Technology**: Transaction data analysis and business reporting systems\n\n## ‚ö†Ô∏è Important notes\n\n### Security Considerations:\n- Never expose Elasticsearch credentials in logs or form data\n- Implement proper access controls for the webhook URL\n- Consider encryption for sensitive data processing\n- Regular audit of generated reports and access logs\n\n### Performance Tips:\n- Index optimization improves search response times\n- Consider pagination for large result sets\n- Monitor Elasticsearch cluster performance under load\n- Archive old reports to manage disk usage\n\n### Data Management:\n- Ensure data retention policies align with business requirements\n- Implement audit trails for all search operations\n- Consider data privacy requirements when processing datasets\n- Document all configuration changes for maintenance\n\n---\n\n*This template provides a production-ready data search and reporting system that can be easily customized for various data analysis needs. The modular design allows for incremental enhancements while maintaining core search and reporting functionality.*",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Search Form",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Build Search Query",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Search Elasticsearch",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.1"
    },
    {
      "name": "Format Report",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Read/Write Files from Disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}