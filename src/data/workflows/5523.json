{
  "id": 5523,
  "slug": "5523",
  "title": "Evaluate tool usage accuracy in multi-agent AI workflows using evaluation nodes",
  "description": "Who's it for\n------------\n\nThis workflow is ideal for AI developers running multi-agent systems in n8n who need to quantitatively evaluate tool usage behavior. If you're building autonomous agents and want to verify their decisions against ground-truth expectations, this workflow gives you plug-and-play observability.\n\nWhat it does\n------------\n\nThis template uses n8n's built-in Evaluation Trigger and Evaluation nodes to assess whether an AI agent correctly used all the expected tools. It supports:\n\n-   Dataset-driven testing of agent behavior\n\n-   Logging actual tools to compare them with the expected tools\n\n-   Assigning performance metrics (tool_called = true/false)\n\n-   Persisting output back to Google Sheets for further debugging\n\nThe workflow can be triggered by either the chat input or the dataset row evaluation. It routes through a multi-tool agent node powered by the best LLMs. The agent has access to tools such as web search, calculator, vector search, and summarizer tools. The workflow then aims to validate tool use decisions by extracting the intermediate steps from the agent (i.e., action + observation) and comparing the tools that were called with the expected tools. If the tools that were called during the workflow execution match, then it's a pass; otherwise, it's documented as a fail. The evaluation nodes take care of that process. \n\nHow to set it up\n----------------\n\n1.  Connect your Google Sheets OAuth2 credential. Replace the document with your own test dataset.\n\n2.  Set your desired models and configure the different agent tools, such as the summarizer and vector store. The default vector store used is Qdrant, so the user must create this vector store with a few samples of queries + web search results.\n\n3.  Run from either the chat trigger or the evaluation trigger to test.\n\nRequirements\n------------\n\n-   Google Sheets OAuth2 credential\n\n-   OpenRouter / OpenAI credentials for AI agents and embeddings\n\n-   Firecrawl and Qdrant credentials for web + vector search\n\nHow to customize\n----------------\n\n-   Edit the Search Agent system message to define tool selection behavior\n\n-   Add more metric columns in the Evaluation node for complex scoring\n\n-   Add new tool nodes and link them to the agent block\n\n-   Swap in your own summarizer",
  "featuredImage": "/data/workflows/5523/5523.webp",
  "author": {
    "id": 101,
    "slug": "djangelic",
    "name": "Angel Menendez",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 13322,
  "downloads": 1332,
  "createdAt": "2025-07-01T17:12:40.342Z",
  "updatedAt": "2026-01-16T08:40:06.394Z",
  "publishedAt": "2025-07-01T17:12:40.342Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5523",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Evaluate tool usage accuracy in multi-agent AI workflows using evaluation nodes",
    "workflowName": "Evaluate tool usage accuracy in multi-agent AI workflows using evaluation nodes",
    "description": "Who's it for\n------------\n\nThis workflow is ideal for AI developers running multi-agent systems in n8n who need to quantitatively evaluate tool usage behavior. If you're building autonomous agents and want to verify their decisions against ground-truth expectations, this workflow gives you plug-and-play observability.\n\nWhat it does\n------------\n\nThis template uses n8n's built-in Evaluation Trigger and Evaluation nodes to assess whether an AI agent correctly used all the expected tools. It supports:\n\n-   Dataset-driven testing of agent behavior\n\n-   Logging actual tools to compare them with the expected tools\n\n-   Assigning performance metrics (tool_called = true/false)\n\n-   Persisting output back to Google Sheets for further debugging\n\nThe workflow can be triggered by either the chat input or the dataset row evaluation. It routes through a multi-tool agent node powered by the best LLMs. The agent has access to tools such as web search, calculator, vector search, and summarizer tools. The workflow then aims to validate tool use decisions by extracting the intermediate steps from the agent (i.e., action + observation) and comparing the tools that were called with the expected tools. If the tools that were called during the workflow execution match, then it's a pass; otherwise, it's documented as a fail. The evaluation nodes take care of that process. \n\nHow to set it up\n----------------\n\n1.  Connect your Google Sheets OAuth2 credential. Replace the document with your own test dataset.\n\n2.  Set your desired models and configure the different agent tools, such as the summarizer and vector store. The default vector store used is Qdrant, so the user must create this vector store with a few samples of queries + web search results.\n\n3.  Run from either the chat trigger or the evaluation trigger to test.\n\nRequirements\n------------\n\n-   Google Sheets OAuth2 credential\n\n-   OpenRouter / OpenAI credentials for AI agents and embeddings\n\n-   Firecrawl and Qdrant credentials for web + vector search\n\nHow to customize\n----------------\n\n-   Edit the Search Agent system message to define tool selection behavior\n\n-   Add more metric columns in the Evaluation node for complex scoring\n\n-   Add new tool nodes and link them to the agent block\n\n-   Swap in your own summarizer",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Calculator",
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "role": "toolCalculator",
      "configDescription": "Version 1"
    },
    {
      "name": "Check if tool called",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Match chat format",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Return chat response",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "When fetching a dataset row",
      "type": "n8n-nodes-base.evaluationTrigger",
      "role": "evaluationTrigger",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Evaluation",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Evaluating?",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Set Outputs",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Search Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.9"
    },
    {
      "name": "Summarizer",
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "role": "toolWorkflow",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Web search",
      "type": "n8n-nodes-base.httpRequestTool",
      "role": "httpRequestTool",
      "configDescription": "Version 4.2"
    },
    {
      "name": "OpenRouter Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "role": "lmChatOpenRouter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Search_db",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.3"
    }
  ]
}