{
  "id": 3062,
  "slug": "3062",
  "title": "Avoid Asking Redundant Questions with Dynamically Generated Forms using OpenAI ",
  "description": "# Avoid Asking Redundant Questions with Dynamically Generated Forms using OpenAI \n## Target Audience\nThis workflow has been built for those who require a form to capture as much data as possible as well as the answers to predefined questions, whilst optimising the user experience by avoiding asking redundant questions.\n## Use Case\nWhen creating a form to capture information, it can be useful to give the user an opportunity to input a long answer to a large, open-ended question. We then want to drill down to answer specific questions that we require the answer to. When doing this, we don't want to ask duplicate questions. This particular scenario imagines an AI consultancy capturing leads.\n## What it Does\nThis workflow requires users to input basic information and then answer an open ended question. The specific questions on the next page will only be those that weren't answered in the open-ended question.\n## How it Works\n1. The open-ended question (and relevant basic information) is analysed by an LLM to determine which specific questions have not been answered. Chain-of-thought reasoning is utilised and the output structure is specified with the **Structured Output Parser**.\n2. Those questions that have already been answered are filtered out nodes. The remaining items are then used to generate the last page of the form.\n3. Once the user has filled in the final page of the form, they are shown a form completion page.\n## Setup\n1. Add your **OpenAI** credentials\n2. Go to the **Get Basic Information** node and click **Test Step**\n3. Complete the form to test the generic use case\n4. Modify the prompt in **Analyse Response** to fit your use case\n## Next Steps\n- Add additional nodes to send an email to the form owner\n- Add a subsequent LLM call to analyse the form response - those that are qualified should be given the opportunity to book an appointment",
  "featuredImage": "/data/workflows/3062/3062.webp",
  "author": {
    "id": 101,
    "slug": "chriscarr",
    "name": "Chris Carr",
    "avatar": ""
  },
  "categories": [
    "Lead Generation",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 3049,
  "downloads": 304,
  "createdAt": "2025-03-02T17:16:14.512Z",
  "updatedAt": "2026-01-16T08:27:53.687Z",
  "publishedAt": "2025-03-02T17:16:14.512Z",
  "nodes": 19,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3062",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Avoid Asking Redundant Questions with Dynamically Generated Forms using OpenAI ",
    "workflowName": "Avoid Asking Redundant Questions with Dynamically Generated Forms using OpenAI ",
    "description": "# Avoid Asking Redundant Questions with Dynamically Generated Forms using OpenAI \n## Target Audience\nThis workflow has been built for those who require a form to capture as much data as possible as well as the answers to predefined questions, whilst optimising the user experience by avoiding asking redundant questions.\n## Use Case\nWhen creating a form to capture information, it can be useful to give the user an opportunity to input a long answer to a large, open-ended question. We then want to drill down to answer specific questions that we require the answer to. When doing this, we don't want to ask duplicate questions. This particular scenario imagines an AI consultancy capturing leads.\n## What it Does\nThis workflow requires users to input basic information and then answer an open ended question. The specific questions on the next page will only be those that weren't answered in the open-ended question.\n## How it Works\n1. The open-ended question (and relevant basic information) is analysed by an LLM to determine which specific questions have not been answered. Chain-of-thought reasoning is utilised and the output structure is specified with the **Structured Output Parser**.\n2. Those questions that have already been answered are filtered out nodes. The remaining items are then used to generate the last page of the form.\n3. Once the user has filled in the final page of the form, they are shown a form completion page.\n## Setup\n1. Add your **OpenAI** credentials\n2. Go to the **Get Basic Information** node and click **Test Step**\n3. Complete the form to test the generic use case\n4. Modify the prompt in **Analyse Response** to fit your use case\n## Next Steps\n- Add additional nodes to send an email to the form owner\n- Add a subsequent LLM call to analyse the form response - those that are qualified should be given the opportunity to book an appointment",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Clarification Questions",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Basic Information",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Get Business Overview",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 1"
    },
    {
      "name": "End Form",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Remove Already Answered Questions",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Analyse Response",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.5"
    },
    {
      "name": "Split Out Analysis",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Prepare For Form Generation",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Aggregate For Form Generation",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}