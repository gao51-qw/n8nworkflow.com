{
  "id": 10837,
  "slug": "10837",
  "title": "Chat with GitHub issues using OpenAI and Redis vector search",
  "description": "# Chat with Your GitHub Issues Using AI ðŸ¤–\n\nEver wanted to just *ask* your repository what's going on instead of scrolling through endless issue lists? This workflow lets you do exactly that.\n\n## What Does It Do?\n\nTurn any GitHub repo into a conversational knowledge base. Ask questions in plain English, get smart answers powered by AI and vector search.\n\n* **\"Show me recent authentication bugs\"** â†’ AI finds and explains them\n* **\"What issues are blocking the release?\"** â†’ Instant context-aware answers\n* **\"Are there any similar problems to #247?\"** â†’ Semantic search finds connections you'd miss\n\n## The Magic âœ¨\n\n1. **Slurp up issues** from your GitHub repo (with all the metadata goodness)\n2. **Vectorize everything** using OpenAI embeddings and store in Redis\n3. **Chat naturally** with an AI agent that searches your issue database\n4. **Get smart answers** with full conversation memory\n\n## Quick Start\n\n**You'll need:**\n- OpenAI API key (for the AI brain)\n- Redis 8.x (for vector search magic)\n- GitHub repo URL (optional: API token for speed)\n\n**Get it running:**\n1. Drop in your credentials\n2. Point it at your repo (edit the `owner` and `repository` params)\n3. Run the ingestion flow once to populate the database\n4. Start chatting!\n\n## Tinker Away ðŸ”§\n\nThis is your playground. Here are some ideas:\n\n- **Swap the data source**: Jira tickets? Linear issues? Notion docs? Go wild.\n- **Change the AI model**: Try different GPT models or even local LLMs\n- **Add custom filters**: Filter by labels, assignees, or whatever matters to you\n- **Tune the search**: Adjust how many results come back, tweak relevance scores\n- **Make it public**: Share the chat interface with your team or users\n- **Auto-update**: Hook it up to webhooks for real-time issue indexing\n\nBuilt with n8n, Redis, and OpenAI. No vendor lock-in, fully hackable, 100% yours to customize.\n\n",
  "featuredImage": "/data/workflows/10837/10837.webp",
  "author": {
    "id": 101,
    "slug": "tishun",
    "name": "Tihomir Mateev",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 163,
  "downloads": 16,
  "createdAt": "2025-11-14T14:52:15.096Z",
  "updatedAt": "2026-01-16T09:06:30.616Z",
  "publishedAt": "2025-11-14T14:52:15.096Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10837",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Chat with GitHub issues using OpenAI and Redis vector search",
    "workflowName": "Chat with GitHub issues using OpenAI and Redis vector search",
    "description": "# Chat with Your GitHub Issues Using AI ðŸ¤–\n\nEver wanted to just *ask* your repository what's going on instead of scrolling through endless issue lists? This workflow lets you do exactly that.\n\n## What Does It Do?\n\nTurn any GitHub repo into a conversational knowledge base. Ask questions in plain English, get smart answers powered by AI and vector search.\n\n* **\"Show me recent authentication bugs\"** â†’ AI finds and explains them\n* **\"What issues are blocking the release?\"** â†’ Instant context-aware answers\n* **\"Are there any similar problems to #247?\"** â†’ Semantic search finds connections you'd miss\n\n## The Magic âœ¨\n\n1. **Slurp up issues** from your GitHub repo (with all the metadata goodness)\n2. **Vectorize everything** using OpenAI embeddings and store in Redis\n3. **Chat naturally** with an AI agent that searches your issue database\n4. **Get smart answers** with full conversation memory\n\n## Quick Start\n\n**You'll need:**\n- OpenAI API key (for the AI brain)\n- Redis 8.x (for vector search magic)\n- GitHub repo URL (optional: API token for speed)\n\n**Get it running:**\n1. Drop in your credentials\n2. Point it at your repo (edit the `owner` and `repository` params)\n3. Run the ingestion flow once to populate the database\n4. Start chatting!\n\n## Tinker Away ðŸ”§\n\nThis is your playground. Here are some ideas:\n\n- **Swap the data source**: Jira tickets? Linear issues? Notion docs? Go wild.\n- **Change the AI model**: Try different GPT models or even local LLMs\n- **Add custom filters**: Filter by labels, assignees, or whatever matters to you\n- **Tune the search**: Adjust how many results come back, tweak relevance scores\n- **Make it public**: Share the chat interface with your team or users\n- **Auto-update**: Hook it up to webhooks for real-time issue indexing\n\nBuilt with n8n, Redis, and OpenAI. No vendor lock-in, fully hackable, 100% yours to customize.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking â€˜Execute workflowâ€™",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.4"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Redis Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryRedisChat",
      "role": "memoryRedisChat",
      "configDescription": "Version 1.5"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Fetch issues from GitHub",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Vectorize and store in Redis",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreRedis",
      "role": "vectorStoreRedis",
      "configDescription": "Version 1.3"
    },
    {
      "name": "AI Agent using RAG",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3"
    },
    {
      "name": "Augment with results from Redis",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreRedis",
      "role": "vectorStoreRedis",
      "configDescription": "Version 1.3"
    }
  ]
}