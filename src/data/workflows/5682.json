{
  "id": 5682,
  "slug": "5682",
  "title": "Simulate debates between AI agents using Mistral to optimize answers",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.* \n\n# AI Arena - Debate of AI Agents to Optimize Answers and Simulate Diverse Scenarios\n\n## Overview \nVersion: 1.0\n\nThe AI Arena Workflow is designed to facilitate a refined answer generation process by enabling a structured debate among multiple AI agents. This workflow allows for diverse perspectives to be considered before arriving at a final output, enhancing the quality and depth of the generated responses.\n\n## ‚ú® Features\n- **Multi-Agent Debate Simulation**: Engage multiple AI agents in a debate to generate nuanced responses.\n- **Configurable Rounds and Agents**: Easily adjust the number of debate rounds and participating agents to fit your needs.\n- **Contextualized AI Responses**: Each agent operates based on predefined roles and characteristics, ensuring relevant and focused discussions.\n- **JSON Output**: The final output is structured in JSON format, making it easy to integrate with other systems or workflows.\n\n## üë§ Who is this for?\nThis workflow is ideal for developers, data scientists, content creators, and businesses looking to leverage AI for decision-making, content generation, or any scenario requiring diverse viewpoints. It is particularly useful for those who need to synthesize information from multiple personalities or perspectives.\n\n## üí° What problem does this solve?\nThe workflow addresses the challenge of generating nuanced responses by simulating a debate among AI agents. This approach ensures that multiple perspectives are considered, reducing bias and enhancing the overall quality of the output. Use-Case examples:\n- üóìÔ∏è Meeting/Interview Simulation\n- ‚úîÔ∏è Quality Assurance\n- üìñ Storywriter Test Environment\n- üèõÔ∏è Forum/Conference/Symposium Simulation\n\n## üîç What this workflow does\nThe workflow orchestrates a debate among AI agents, allowing them to discuss, critique, and suggest rewrites for a given input based on their roles and predefined characteristics. This collaborative process leads to a more refined and comprehensive final output.\n\n## üîÑ Workflow Steps\n1. **Input & Setup**: The initial input is provided, and the AI environment is configured with necessary parameters.\n2. **Round Execution**: AI agents execute their roles, providing replies and actions based on the input and their individual characteristics.\n3. **Round Results**: The results of each round are aggregated, and a summary is created to capture the key points discussed by the agents.\n4. **Continue to Next Round**: If more rounds are defined, the process repeats until the specified number of rounds is completed.\n5. **Final Output**: The final output is generated based on the agents' discussions and suggestions, providing a cohesive response.\n\n## ‚ö° How to Use/Setup\n### üîê Credentials\n- Obtain an API key for the Mistral API or another LLM API. This key is necessary for the AI agents to function properly.\n\n### üîß Configuration\n- Set up the workflow in n8n, ensuring all nodes are correctly configured according to the workflow requirements. This includes setting the appropriate input parameters and defining the roles of each AI agent.\n- This workflow uses a custom node for Global Variables called 'n8n-nodes-globals.' Alternatively, you can use the 'Edit Field (Set)' node to achieve the same functionality.\n\n### ‚úèÔ∏è Customizing this workflow\n- To customize the workflow, adjust the AI agent parameters in the JSON configuration. This includes defining their roles, personalities, and preferences, which will influence how they interact during the debate.\nOne of the notes includes a ready-to-use example of how to customize the agents and the environment. You can simply edit it and insert it as your credential in the Global Variables node.\n\n## üìå Example\n\n![printscreen1.png](fileId:1680)\n\n![printscreen2.png](fileId:1679)\n\n![printscreen3.png](fileId:1681)\n\nAn example with both input and final output is provided in a note within the workflow.\n\n\n## üõ†Ô∏è Tools Used\n\n- n8n: A workflow automation tool that allows users to connect various applications and services.\n- Mistral API: A powerful language model API used for generating AI responses. (You can replace it with any LLM API of your choice)\n- Podman: A container management tool that allows users to create, manage, and run containers without requiring a daemon. (It serves as an alternative to Docker for container orchestration.)\n\n\n## ‚öôÔ∏è n8n Setup Used\n- **n8n Version**: 1.100.1\n- **n8n-nodes-globals**: 1.1.0\n- **Running n8n via**: Podman 4.3.1\n- **Operating System**: Linux\n\n\n## ‚ö†Ô∏è Notes, Assumptions & Warnings\n\n- Ensure that the AI agents are configured with clear roles to maximize the effectiveness of the debate. Each agent's characteristics should align with the overall goals of the workflow.\n- The workflow can be adapted for various use cases, including meeting simulations, content generation, and brainstorming sessions.\n- This workflow assumes that users have a basic understanding of n8n and JSON configuration.\n- This workflow assumes that users have access to the necessary API keys and permissions to utilize the Mistral API or other LLM APIs.\n- Ensure that the input provided to the AI agents is clear and concise to avoid confusion in the debate process. Ambiguous inputs may lead to unclear or irrelevant outputs.\n- Monitor the output for relevance and accuracy, as AI-generated content may require human oversight to ensure it meets standards and expectations before being used in production.\n\n## ‚ÑπÔ∏è About Us\n\nThis workflow was developed by the Hybroht team of AI enthusiasts and developers dedicated to enhancing the capabilities of AI through collaborative processes. Our goal is to create tools that harness the possibilities of AI technology and more.\n\n\n\n",
  "featuredImage": "/data/workflows/5682/5682.webp",
  "author": {
    "id": 101,
    "slug": "hybroht",
    "name": "Hybroht",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1572,
  "downloads": 157,
  "createdAt": "2025-07-04T19:59:57.854Z",
  "updatedAt": "2026-01-16T08:40:53.608Z",
  "publishedAt": "2025-07-04T19:59:57.854Z",
  "nodes": 38,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5682",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Simulate debates between AI agents using Mistral to optimize answers",
    "workflowName": "Simulate debates between AI agents using Mistral to optimize answers",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.* \n\n# AI Arena - Debate of AI Agents to Optimize Answers and Simulate Diverse Scenarios\n\n## Overview \nVersion: 1.0\n\nThe AI Arena Workflow is designed to facilitate a refined answer generation process by enabling a structured debate among multiple AI agents. This workflow allows for diverse perspectives to be considered before arriving at a final output, enhancing the quality and depth of the generated responses.\n\n## ‚ú® Features\n- **Multi-Agent Debate Simulation**: Engage multiple AI agents in a debate to generate nuanced responses.\n- **Configurable Rounds and Agents**: Easily adjust the number of debate rounds and participating agents to fit your needs.\n- **Contextualized AI Responses**: Each agent operates based on predefined roles and characteristics, ensuring relevant and focused discussions.\n- **JSON Output**: The final output is structured in JSON format, making it easy to integrate with other systems or workflows.\n\n## üë§ Who is this for?\nThis workflow is ideal for developers, data scientists, content creators, and businesses looking to leverage AI for decision-making, content generation, or any scenario requiring diverse viewpoints. It is particularly useful for those who need to synthesize information from multiple personalities or perspectives.\n\n## üí° What problem does this solve?\nThe workflow addresses the challenge of generating nuanced responses by simulating a debate among AI agents. This approach ensures that multiple perspectives are considered, reducing bias and enhancing the overall quality of the output. Use-Case examples:\n- üóìÔ∏è Meeting/Interview Simulation\n- ‚úîÔ∏è Quality Assurance\n- üìñ Storywriter Test Environment\n- üèõÔ∏è Forum/Conference/Symposium Simulation\n\n## üîç What this workflow does\nThe workflow orchestrates a debate among AI agents, allowing them to discuss, critique, and suggest rewrites for a given input based on their roles and predefined characteristics. This collaborative process leads to a more refined and comprehensive final output.\n\n## üîÑ Workflow Steps\n1. **Input & Setup**: The initial input is provided, and the AI environment is configured with necessary parameters.\n2. **Round Execution**: AI agents execute their roles, providing replies and actions based on the input and their individual characteristics.\n3. **Round Results**: The results of each round are aggregated, and a summary is created to capture the key points discussed by the agents.\n4. **Continue to Next Round**: If more rounds are defined, the process repeats until the specified number of rounds is completed.\n5. **Final Output**: The final output is generated based on the agents' discussions and suggestions, providing a cohesive response.\n\n## ‚ö° How to Use/Setup\n### üîê Credentials\n- Obtain an API key for the Mistral API or another LLM API. This key is necessary for the AI agents to function properly.\n\n### üîß Configuration\n- Set up the workflow in n8n, ensuring all nodes are correctly configured according to the workflow requirements. This includes setting the appropriate input parameters and defining the roles of each AI agent.\n- This workflow uses a custom node for Global Variables called 'n8n-nodes-globals.' Alternatively, you can use the 'Edit Field (Set)' node to achieve the same functionality.\n\n### ‚úèÔ∏è Customizing this workflow\n- To customize the workflow, adjust the AI agent parameters in the JSON configuration. This includes defining their roles, personalities, and preferences, which will influence how they interact during the debate.\nOne of the notes includes a ready-to-use example of how to customize the agents and the environment. You can simply edit it and insert it as your credential in the Global Variables node.\n\n## üìå Example\n\n![printscreen1.png](fileId:1680)\n\n![printscreen2.png](fileId:1679)\n\n![printscreen3.png](fileId:1681)\n\nAn example with both input and final output is provided in a note within the workflow.\n\n\n## üõ†Ô∏è Tools Used\n\n- n8n: A workflow automation tool that allows users to connect various applications and services.\n- Mistral API: A powerful language model API used for generating AI responses. (You can replace it with any LLM API of your choice)\n- Podman: A container management tool that allows users to create, manage, and run containers without requiring a daemon. (It serves as an alternative to Docker for container orchestration.)\n\n\n## ‚öôÔ∏è n8n Setup Used\n- **n8n Version**: 1.100.1\n- **n8n-nodes-globals**: 1.1.0\n- **Running n8n via**: Podman 4.3.1\n- **Operating System**: Linux\n\n\n## ‚ö†Ô∏è Notes, Assumptions & Warnings\n\n- Ensure that the AI agents are configured with clear roles to maximize the effectiveness of the debate. Each agent's characteristics should align with the overall goals of the workflow.\n- The workflow can be adapted for various use cases, including meeting simulations, content generation, and brainstorming sessions.\n- This workflow assumes that users have a basic understanding of n8n and JSON configuration.\n- This workflow assumes that users have access to the necessary API keys and permissions to utilize the Mistral API or other LLM APIs.\n- Ensure that the input provided to the AI agents is clear and concise to avoid confusion in the debate process. Ambiguous inputs may lead to unclear or irrelevant outputs.\n- Monitor the output for relevance and accuracy, as AI-generated content may require human oversight to ensure it meets standards and expectations before being used in production.\n\n## ‚ÑπÔ∏è About Us\n\nThis workflow was developed by the Hybroht team of AI enthusiasts and developers dedicated to enhancing the capabilities of AI through collaborative processes. Our goal is to create tools that harness the possibilities of AI technology and more.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Sticky Note12",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Schedule",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note13",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note14",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Configure Workflow Args",
      "type": "n8n-nodes-globals.globalConstants",
      "role": "globalConstants",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking ‚ÄòExecute workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Email Trigger (IMAP)",
      "type": "n8n-nodes-base.emailReadImap",
      "role": "emailReadImap",
      "configDescription": "Version 2"
    },
    {
      "name": "Mistral Cloud Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Prepare Input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Update Input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Split Out AI Agents",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "JSON Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "If No More Rounds",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "End of Debate",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Debate Loop",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Round Loop",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Debate Actor Abstraction",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Debate Environment",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Guarantee Input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Mistral Cloud Chat Model 2",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "JSON Output Parser 2",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Simple Memory 2",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Wait Before Sending Agents",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Wait 1",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Wait 2",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note15",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note16",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}