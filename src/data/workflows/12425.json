{
  "id": 12425,
  "slug": "12425",
  "title": "Generate highly expressive audio üéôÔ∏è using ElevenLabs v3 TTS Audio Tags",
  "description": "This workflow is an **AI-powered text-to-speech production pipeline** designed to generate highly expressive audio using **ElevenLabs v3**.\nIt automates the entire process from raw text input to final audio distribution and upload the mp3 file to Google Drive and an FTP space.\n\n---\n\n\n### Key Advantages\n\n#### 1. ‚úÖ Cinematic-quality audio output\n\nBy combining AI-driven emotional tagging with ElevenLabs v3, the workflow produces audio that feels **acted**, not simply read.\n\n#### 2. ‚úÖ Fully automated pipeline\n\nFrom raw text to hosted audio file, everything is handled automatically:\n\n* No manual tagging\n* No manual uploads\n* No post-processing\n\n#### 3. ‚úÖ Multi-input flexibility\n\nThe workflow supports:\n\n* Manual testing\n* Chat-based usage\n* API/Webhook integrations\n  This makes it ideal for **apps, CMSs, games, and content platforms**.\n\n#### 4. ‚úÖ Language-agnostic\n\nThe agent preserves the **original language** of the input text and applies tags accordingly, making it suitable for **international projects**.\n\n#### 5.‚úÖ  Consistent and correct tagging\n\nThe use of **Context7** ensures that all audio tags follow the **official ElevenLabs v3 specifications**, reducing errors and incompatibilities.\n\n#### 6. ‚úÖ Scalable and production-ready\n\nAutomatic uploads to Drive and FTP make this workflow ready for:\n\n* Large content volumes\n* CDN delivery\n* Team collaboration\n\n#### 7.‚úÖ  Perfect for storytelling and media\n\nThe workflow is especially effective for:\n\n* Horror and cinematic storytelling\n* Audiobooks and podcasts\n* Games and immersive narratives\n* Voiceovers with emotional depth\n\n---\n\n\n\n### How it Works\n\n1. **Text Input & Processing**: The workflow accepts text input through multiple triggers - manual execution via \"Set text\" node, webhook POST requests, or chat message inputs. This text is passed to the Audio Tagger Agent.\n\n2. **AI-Powered Audio Tagging**: The Audio Tagger Agent uses Claude Sonnet 4.5 to analyze the input text and intelligently insert ElevenLabs v3 audio tags. The agent follows strict rules: maintaining original meaning, adding tags for pauses, rhythm, emphasis, emotional tones, breathing, laughter, and delivery variations while keeping the output in the original language.\n\n3. **Reference Validation**: During tagging, the agent consults the Context7 MCP tool, which provides access to the official ElevenLabs v3 audio tags guide to ensure correct and consistent tag usage.\n\n4. **Text-to-Speech Conversion**: The tagged text is sent to ElevenLabs' v3 (alpha) model, which converts it into speech using a specific voice with customized voice settings including stability, similarity boost, style, speaker boost, and speed controls.\n\n5. **Dual Output Distribution**: The generated audio file is simultaneously uploaded to two destinations: Google Drive (in a specified \"Elevenlabs\" folder) and an FTP server (BunnyCDN), ensuring the file is stored in both cloud storage platforms.\n---\n\n\n### Set Up Steps\n\n1. **Prerequisite Configuration**:\n   - Configure Anthropic API credentials for Claude Sonnet access\n   - Set up [ElevenLabs API](https://try.elevenlabs.io/ahkbf00hocnu) credentials with access to v3 (alpha) models\n   - Configure Google Drive OAuth2 credentials with access to the target folder\n   - Set up FTP credentials for BunnyCDN or alternative storage\n   - Configure Context7 MCP tool with appropriate authentication headers\n\n2. **Workflow-Specific Setup**:\n   - In the \"Set text\" node, replace \"YOUR TEXT\" with the default text you want to process (for manual execution)\n   - In the \"Upload to FTP\" node, update the path from \"/YOUR_PATH/\" to your actual FTP directory structure\n   - Verify the Google Drive folder ID points to your intended destination folder\n   - Ensure the webhook path is correctly configured for external integrations\n   - Adjust voice parameters in the ElevenLabs node if different voice characteristics are desired\n\n3. **Execution Options**:\n   - For one-time processing: Use the manual trigger and set text in the \"Set text\" node\n   - For API integration: Use the webhook endpoint to receive text via POST requests\n   - For chat-based interaction: Use the chat trigger for conversational text input\n\n---\n\nüëâ [Subscribe to my new **YouTube channel**](https://youtube.com/@n3witalia). Here I‚Äôll share videos and Shorts with practical tutorials and **FREE templates for n8n**.\n\n[![image](https://n3wstorage.b-cdn.net/n3witalia/youtube-n8n-cover.jpg)](https://youtube.com/@n3witalia)\n\n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/). \n",
  "featuredImage": "/data/workflows/12425/12425.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 29,
  "downloads": 2,
  "createdAt": "2026-01-03T16:39:27.230Z",
  "updatedAt": "2026-01-16T09:12:25.634Z",
  "publishedAt": "2026-01-03T16:39:27.230Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/12425",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Generate highly expressive audio üéôÔ∏è using ElevenLabs v3 TTS Audio Tags",
    "workflowName": "Generate highly expressive audio üéôÔ∏è using ElevenLabs v3 TTS Audio Tags",
    "description": "This workflow is an **AI-powered text-to-speech production pipeline** designed to generate highly expressive audio using **ElevenLabs v3**.\nIt automates the entire process from raw text input to final audio distribution and upload the mp3 file to Google Drive and an FTP space.\n\n---\n\n\n### Key Advantages\n\n#### 1. ‚úÖ Cinematic-quality audio output\n\nBy combining AI-driven emotional tagging with ElevenLabs v3, the workflow produces audio that feels **acted**, not simply read.\n\n#### 2. ‚úÖ Fully automated pipeline\n\nFrom raw text to hosted audio file, everything is handled automatically:\n\n* No manual tagging\n* No manual uploads\n* No post-processing\n\n#### 3. ‚úÖ Multi-input flexibility\n\nThe workflow supports:\n\n* Manual testing\n* Chat-based usage\n* API/Webhook integrations\n  This makes it ideal for **apps, CMSs, games, and content platforms**.\n\n#### 4. ‚úÖ Language-agnostic\n\nThe agent preserves the **original language** of the input text and applies tags accordingly, making it suitable for **international projects**.\n\n#### 5.‚úÖ  Consistent and correct tagging\n\nThe use of **Context7** ensures that all audio tags follow the **official ElevenLabs v3 specifications**, reducing errors and incompatibilities.\n\n#### 6. ‚úÖ Scalable and production-ready\n\nAutomatic uploads to Drive and FTP make this workflow ready for:\n\n* Large content volumes\n* CDN delivery\n* Team collaboration\n\n#### 7.‚úÖ  Perfect for storytelling and media\n\nThe workflow is especially effective for:\n\n* Horror and cinematic storytelling\n* Audiobooks and podcasts\n* Games and immersive narratives\n* Voiceovers with emotional depth\n\n---\n\n\n\n### How it Works\n\n1. **Text Input & Processing**: The workflow accepts text input through multiple triggers - manual execution via \"Set text\" node, webhook POST requests, or chat message inputs. This text is passed to the Audio Tagger Agent.\n\n2. **AI-Powered Audio Tagging**: The Audio Tagger Agent uses Claude Sonnet 4.5 to analyze the input text and intelligently insert ElevenLabs v3 audio tags. The agent follows strict rules: maintaining original meaning, adding tags for pauses, rhythm, emphasis, emotional tones, breathing, laughter, and delivery variations while keeping the output in the original language.\n\n3. **Reference Validation**: During tagging, the agent consults the Context7 MCP tool, which provides access to the official ElevenLabs v3 audio tags guide to ensure correct and consistent tag usage.\n\n4. **Text-to-Speech Conversion**: The tagged text is sent to ElevenLabs' v3 (alpha) model, which converts it into speech using a specific voice with customized voice settings including stability, similarity boost, style, speaker boost, and speed controls.\n\n5. **Dual Output Distribution**: The generated audio file is simultaneously uploaded to two destinations: Google Drive (in a specified \"Elevenlabs\" folder) and an FTP server (BunnyCDN), ensuring the file is stored in both cloud storage platforms.\n---\n\n\n### Set Up Steps\n\n1. **Prerequisite Configuration**:\n   - Configure Anthropic API credentials for Claude Sonnet access\n   - Set up [ElevenLabs API](https://try.elevenlabs.io/ahkbf00hocnu) credentials with access to v3 (alpha) models\n   - Configure Google Drive OAuth2 credentials with access to the target folder\n   - Set up FTP credentials for BunnyCDN or alternative storage\n   - Configure Context7 MCP tool with appropriate authentication headers\n\n2. **Workflow-Specific Setup**:\n   - In the \"Set text\" node, replace \"YOUR TEXT\" with the default text you want to process (for manual execution)\n   - In the \"Upload to FTP\" node, update the path from \"/YOUR_PATH/\" to your actual FTP directory structure\n   - Verify the Google Drive folder ID points to your intended destination folder\n   - Ensure the webhook path is correctly configured for external integrations\n   - Adjust voice parameters in the ElevenLabs node if different voice characteristics are desired\n\n3. **Execution Options**:\n   - For one-time processing: Use the manual trigger and set text in the \"Set text\" node\n   - For API integration: Use the webhook endpoint to receive text via POST requests\n   - For chat-based interaction: Use the chat trigger for conversational text input\n\n---\n\nüëâ [Subscribe to my new **YouTube channel**](https://youtube.com/@n3witalia). Here I‚Äôll share videos and Shorts with practical tutorials and **FREE templates for n8n**.\n\n[![image](https://n3wstorage.b-cdn.net/n3witalia/youtube-n8n-cover.jpg)](https://youtube.com/@n3witalia)\n\n\n---\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‚ÄòExecute workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Anthropic Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "role": "lmChatAnthropic",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Convert text to speech",
      "type": "@elevenlabs/n8n-nodes-elevenlabs.elevenLabs",
      "role": "elevenLabs",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.4"
    },
    {
      "name": "Context7",
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Audio Tagger Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Upload to FTP",
      "type": "n8n-nodes-base.ftp",
      "role": "ftp",
      "configDescription": "Version 1"
    },
    {
      "name": "Set text",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Upload file to Drive",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}