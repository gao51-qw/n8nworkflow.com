{
  "id": 10287,
  "slug": "10287",
  "title": "Multi-AI agent router: compare OpenAI, Anthropic & Groq responses with webhooks",
  "description": "## Introduction\nThis workflow connects to OpenAI, Anthropic, and Groq, processing requests in parallel with automatic performance metrics. Ideal for testing speed, cost, and quality across models.\n## How It Works\nWebhooks trigger parameter extraction and routing. Three AI agents run simultaneously with memory and parsing. Responses merge with detailed metrics.\n## Workflow Template\nWebhook → Extract Parameters → Router\n├→ OpenAI Agent\n├→ Anthropic Agent\n├→ Groq Agent\n→ Merge → Metrics → Respond\n## Workflow Steps\n1. Webhook receives POST with prompt and settings.\n2. Parameters extracted and validated.\n3. Router directs by cost, latency, or type.\n4. AI agents run in parallel.\n5. Results merged with metadata.\n6. Metrics compute time, cost, and quality.\n7. Response returns outputs and recommendation.\n## Setup Instructions\n1. Activate Webhook with authentication.\n2. Add API keys for all providers.\n3. Define models, tokens, and temperature.\n4. Adjust Router logic for selection.\n5. Tune Metrics scoring formulas.\n## Prerequisites\n* n8n v1.0+ instance\n* API keys: OpenAI, Anthropic, Groq\n* HTTP client for testing\n## Customization\nAdd providers like Gemini or Azure OpenAI.\nEnable routing by cost or performance.\n## Benefits\nAuto-select efficient providers and compare model performance in real time.\n",
  "featuredImage": "/data/workflows/10287/10287.webp",
  "author": {
    "id": 101,
    "slug": "cschin",
    "name": "Cheng Siong Chin",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 159,
  "downloads": 15,
  "createdAt": "2025-10-29T15:56:03.241Z",
  "updatedAt": "2026-01-16T09:04:17.573Z",
  "publishedAt": "2025-10-29T15:56:03.241Z",
  "nodes": 18,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10287",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Multi-AI agent router: compare OpenAI, Anthropic & Groq responses with webhooks",
    "workflowName": "Multi-AI agent router: compare OpenAI, Anthropic & Groq responses with webhooks",
    "description": "## Introduction\nThis workflow connects to OpenAI, Anthropic, and Groq, processing requests in parallel with automatic performance metrics. Ideal for testing speed, cost, and quality across models.\n## How It Works\nWebhooks trigger parameter extraction and routing. Three AI agents run simultaneously with memory and parsing. Responses merge with detailed metrics.\n## Workflow Template\nWebhook → Extract Parameters → Router\n├→ OpenAI Agent\n├→ Anthropic Agent\n├→ Groq Agent\n→ Merge → Metrics → Respond\n## Workflow Steps\n1. Webhook receives POST with prompt and settings.\n2. Parameters extracted and validated.\n3. Router directs by cost, latency, or type.\n4. AI agents run in parallel.\n5. Results merged with metadata.\n6. Metrics compute time, cost, and quality.\n7. Response returns outputs and recommendation.\n## Setup Instructions\n1. Activate Webhook with authentication.\n2. Add API keys for all providers.\n3. Define models, tokens, and temperature.\n4. Adjust Router logic for selection.\n5. Tune Metrics scoring formulas.\n## Prerequisites\n* n8n v1.0+ instance\n* API keys: OpenAI, Anthropic, Groq\n* HTTP client for testing\n## Customization\nAdd providers like Gemini or Azure OpenAI.\nEnable routing by cost or performance.\n## Benefits\nAuto-select efficient providers and compare model performance in real time.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Output Parser2",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2"
    },
    {
      "name": "Extract Input Parameters",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Dynamic LLM Router",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Route to Provider",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "OpenAI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Anthropic Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Groq Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Merge Results",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3"
    },
    {
      "name": "Calculate Performance Metrics",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.1"
    },
    {
      "name": "OpenAI Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Output Parser1",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Groq Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "role": "lmChatGroq",
      "configDescription": "Version 1"
    },
    {
      "name": "Anthropic Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "role": "lmChatAnthropic",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}