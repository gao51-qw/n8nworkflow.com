{
  "id": 7350,
  "slug": "7350",
  "title": "Extract and verify book titles from bookshelf photos using GPT-4o and Google Books",
  "description": "**Use Case: **\nAnalyze images with multiple subjects. In this use case I have a bookshelf and am extracting and verifying book titles/authors from a bookshelf photo.\n\n**How it works: **\n1) **Webhook** receives an image url from a front end in which a user can upload a picture. \n\t- In this use case, it is an image of a book shelf.  \n2) **Edit Field (Set)**: Saves image in a consistent location so AI can find it.\n3) **Analyze Image**: Image is analyzed. \n\t- Extracts titles from the book spines \n4) **Code**: Splits extracted subjects to single item to be able to validate each item separately. \n\t- Books are individualized to their own entity\n5) **HTTP Request **validates each subject. \n\t- Queries Google Books to validate books in case only partial titles were found. \n6) **Edit Field (Set)**: Tidies the result. \n7) **Code**: Aggregates and deduplicates \n\t- Titles and authors are aggregate into a list\n8) **Respond to Webhook** returns list to front end\n\n**How to use:** \nUse with a frontend that can capture images and receive back the result. For this use case Supabase was used to store images from which the image analyzer could reference.\n",
  "featuredImage": "/data/workflows/7350/7350.webp",
  "author": {
    "id": 101,
    "slug": "arlenemartin",
    "name": "Arlene Martin",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 241,
  "downloads": 24,
  "createdAt": "2025-08-14T03:37:05.778Z",
  "updatedAt": "2026-01-16T08:49:50.890Z",
  "publishedAt": "2025-08-14T03:37:05.778Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7350",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Extract and verify book titles from bookshelf photos using GPT-4o and Google Books",
    "workflowName": "Extract and verify book titles from bookshelf photos using GPT-4o and Google Books",
    "description": "**Use Case: **\nAnalyze images with multiple subjects. In this use case I have a bookshelf and am extracting and verifying book titles/authors from a bookshelf photo.\n\n**How it works: **\n1) **Webhook** receives an image url from a front end in which a user can upload a picture. \n\t- In this use case, it is an image of a book shelf.  \n2) **Edit Field (Set)**: Saves image in a consistent location so AI can find it.\n3) **Analyze Image**: Image is analyzed. \n\t- Extracts titles from the book spines \n4) **Code**: Splits extracted subjects to single item to be able to validate each item separately. \n\t- Books are individualized to their own entity\n5) **HTTP Request **validates each subject. \n\t- Queries Google Books to validate books in case only partial titles were found. \n6) **Edit Field (Set)**: Tidies the result. \n7) **Code**: Aggregates and deduplicates \n\t- Titles and authors are aggregate into a list\n8) **Respond to Webhook** returns list to front end\n\n**How to use:** \nUse with a frontend that can capture images and receive back the result. For this use case Supabase was used to store images from which the image analyzer could reference.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.4"
    },
    {
      "name": "Analyze image",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Input normalized",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Item list split",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Title validation",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Data normalized",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Reaggregates list",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    }
  ]
}