{
  "id": 1967,
  "slug": "1967",
  "title": "Prepare CSV files with GPT-4",
  "description": "This workflow generates CSV files containing a list of 10 random users with specific characteristics using OpenAI's GPT-4 model. It then splits this data into batches, converts it to CSV format, and saves it to disk for further use.\n\n1. The execution of the workflow begins from here when triggered manually.\n2. \"OpenAI\" Node. This uses the OpenAI API to generate random user data. The input to the OpenAI API is a fixed string, which asks for a list of 10 random users with some specific attributes. The attributes include a name and surname starting with the same letter, a subscription status, and a subscription date (if they are subscribed). There is also a short example of the JSON object structure. This technique is called one-shot prompting.\n3. \"Split In Batches\" Node. This node is used to handle the OpenAI responses one by one.\n4. \"Parse JSON\" Node. This node converts the content of the message received from the OpenAI node (which is in string format) into a JSON object.\n5. \"Make JSON Table\" Node. This node is used to convert the JSON data into a tabular format, which is easier to handle for further data processing.\n6. \"Convert to CSV\" Node. This node converts the table format data received from the \"Make JSON Table\" node into CSV format and assigns a file name.\n7. \"Save to Disk\" Node. This node is used to save the CSV generated in the previous node to disk in the \".n8n\" directory.\n\nThe workflow is designed in a circular manner. So, after saving the file to disk, it goes back to the \"Split In Batches\" node to process the OpenAI output, until all batches are processed.",
  "featuredImage": "/data/workflows/1967/1967.webp",
  "author": {
    "id": 101,
    "slug": "n8n-team",
    "name": "n8n Team",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "Multimodal AI"
  ],
  "complexityLevel": "beginner",
  "price": 0,
  "visitors": 7588,
  "downloads": 758,
  "createdAt": "2023-10-30T13:32:37.834Z",
  "updatedAt": "2026-01-16T08:22:26.688Z",
  "publishedAt": "2023-10-30T13:32:37.834Z",
  "nodes": 0,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/1967",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Prepare CSV files with GPT-4",
    "workflowName": "Prepare CSV files with GPT-4",
    "description": "This workflow generates CSV files containing a list of 10 random users with specific characteristics using OpenAI's GPT-4 model. It then splits this data into batches, converts it to CSV format, and saves it to disk for further use.\n\n1. The execution of the workflow begins from here when triggered manually.\n2. \"OpenAI\" Node. This uses the OpenAI API to generate random user data. The input to the OpenAI API is a fixed string, which asks for a list of 10 random users with some specific attributes. The attributes include a name and surname starting with the same letter, a subscription status, and a subscription date (if they are subscribed). There is also a short example of the JSON object structure. This technique is called one-shot prompting.\n3. \"Split In Batches\" Node. This node is used to handle the OpenAI responses one by one.\n4. \"Parse JSON\" Node. This node converts the content of the message received from the OpenAI node (which is in string format) into a JSON object.\n5. \"Make JSON Table\" Node. This node is used to convert the JSON data into a tabular format, which is easier to handle for further data processing.\n6. \"Convert to CSV\" Node. This node converts the table format data received from the \"Make JSON Table\" node into CSV format and assigns a file name.\n7. \"Save to Disk\" Node. This node is used to save the CSV generated in the previous node to disk in the \".n8n\" directory.\n\nThe workflow is designed in a circular manner. So, after saving the file to disk, it goes back to the \"Split In Batches\" node to process the OpenAI output, until all batches are processed.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking \"Execute Workflow\"",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenAI",
      "type": "n8n-nodes-base.openAi",
      "role": "openAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Split In Batches",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Parse JSON",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3"
    },
    {
      "name": "Make JSON Table",
      "type": "n8n-nodes-base.itemLists",
      "role": "itemLists",
      "configDescription": "Version 3"
    },
    {
      "name": "Convert to CSV",
      "type": "n8n-nodes-base.spreadsheetFile",
      "role": "spreadsheetFile",
      "configDescription": "Version 2"
    },
    {
      "name": "Save to Disk",
      "type": "n8n-nodes-base.writeBinaryFile",
      "role": "writeBinaryFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Strip UTF BOM bytes",
      "type": "n8n-nodes-base.moveBinaryData",
      "role": "moveBinaryData",
      "configDescription": "Version 1"
    },
    {
      "name": "Create valid binary",
      "type": "n8n-nodes-base.moveBinaryData",
      "role": "moveBinaryData",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}