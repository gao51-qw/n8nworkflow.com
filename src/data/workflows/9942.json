{
  "id": 9942,
  "slug": "9942",
  "title": "RAG-powered document chat with Google Drive, OpenAI, and Pinecone Assistant",
  "description": "## Try it out\n\nThis n8n workflow template lets you chat with your Google Drive documents (.docx, .json, .md, .txt, .pdf) using OpenAI and Pinecone Assistant. It retrieves relevant context from your files in real time so you can get accurate, context-aware answers about your proprietary data—without the need to train your own LLM.\n\n### What is Pinecone Assistant?\n\n[Pinecone Assistant](https://docs.pinecone.io/guides/assistant/overview) allows you to build production-grade chat and agent-based applications quickly. It abstracts the complexities of implementing retrieval-augmented (RAG) systems by managing the chunking, embedding, storage, query planning, vector search, model orchestration, reranking for you.\n\n### Prerequisites\n\n* A [Pinecone account](https://app.pinecone.io/) and [API key](https://app.pinecone.io/organizations/-/projects/-/keys)\n* A GCP project with [Google Drive API enabled and configured](https://docs.n8n.io/integrations/builtin/credentials/google/oauth-single-service/)\n  * Note: When setting up the OAuth consent screen, skip steps 8-10 if running on localhost\n* An [Open AI account](https://auth.openai.com/create-account) and [API key](https://platform.openai.com/settings/organization/api-keys)\n\n### Setup\n\n1. Create a Pinecone Assistant in the Pinecone Console [here](https://app.pinecone.io/organizations/-/projects/-/assistant) \n\t1. Name your Assistant `n8n-assistant` and create it in the `United States` region\n\t2. If you use a different name or region, update the related nodes to reflect these changes\n\t3. No need to configure a Chat model or Assistant instructions\n2. Setup your Google Drive OAuth2 API credential in n8n\n\t1. In the File added node -&gt; Credential to connect with, select Create new credential\n\t2. Set the Client ID and Client Secret from the values generated in the prerequisites\n\t3. Set the OAuth Redirect URL from the n8n credential in the Google Cloud Console ([instructions](https://docs.n8n.io/integrations/builtin/credentials/google/oauth-single-service/#create-your-google-oauth-client-credentials))\n\t4. Name this credential `Google Drive account` so that other nodes reference it\n3. Setup Pinecone API key credential in n8n\n\t1. In the Upload file to assistant node -&gt; PineconeApi section, select Create new credential\n\t2. Paste in your Pinecone API key in the API Key field\n4. Setup Pinecone MCP Bearer auth credential in n8n\n\t1. In the Pinecone Assistant node -&gt; Credential for Bearer Auth section, select Create new credential\n\t2. Set the Bearer Token field to your Pinecone API key used in the previous step\n5. Setup the Open AI credential in n8n\n\t1. In the OpenAI Chat Model node -&gt; Credential to connect with, select Create new credential\n\t2. Set the API Key field to your OpenAI API key\n6. Add your files to a Drive folder named `n8n-pinecone-demo` in the root of your My Drive\n\t1. If you use a different folder name, you'll need to update the Google Drive triggers to reflect that change\n7. Activate the workflow or test it with a manual execution to ingest the documents\n8. Chat with your docs!\n\n### Ideas for customizing this workflow\n\n- Customize the System Message on the AI Agent node to your use case to indicate what kind of knowledge is stored in Pinecone Assistant\n- Change the top_k value of results returned from Assistant by adding \"and should set a top_k of 3\" to the System Message to help manage token consumption\n- Configure the Context Window Length in the Conversation Memory node\n- Swap out the Conversation Memory node for one that is more persistent\n- Make the [chat node publicly available](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/#make-chat-publicly-available) or [create your own chat interface](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/#mode) that calls the chat webhook URL.\n\n### Need help?\n\nYou can find help by asking in the [Pinecone Discord community](https://discord.gg/tJ8V62S3sH), asking on the [Pinecone Forum](https://community.pinecone.io/), or [filing an issue](https://github.com/pinecone-io/n8n-templates/issues/new/choose) on this repo.",
  "featuredImage": "/data/workflows/9942/9942.webp",
  "author": {
    "id": 101,
    "slug": "pinecone",
    "name": "Pinecone",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1304,
  "downloads": 130,
  "createdAt": "2025-10-20T13:42:34.526Z",
  "updatedAt": "2026-01-16T09:02:41.649Z",
  "publishedAt": "2025-10-20T13:42:34.526Z",
  "nodes": 22,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9942",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "RAG-powered document chat with Google Drive, OpenAI, and Pinecone Assistant",
    "workflowName": "RAG-powered document chat with Google Drive, OpenAI, and Pinecone Assistant",
    "description": "## Try it out\n\nThis n8n workflow template lets you chat with your Google Drive documents (.docx, .json, .md, .txt, .pdf) using OpenAI and Pinecone Assistant. It retrieves relevant context from your files in real time so you can get accurate, context-aware answers about your proprietary data—without the need to train your own LLM.\n\n### What is Pinecone Assistant?\n\n[Pinecone Assistant](https://docs.pinecone.io/guides/assistant/overview) allows you to build production-grade chat and agent-based applications quickly. It abstracts the complexities of implementing retrieval-augmented (RAG) systems by managing the chunking, embedding, storage, query planning, vector search, model orchestration, reranking for you.\n\n### Prerequisites\n\n* A [Pinecone account](https://app.pinecone.io/) and [API key](https://app.pinecone.io/organizations/-/projects/-/keys)\n* A GCP project with [Google Drive API enabled and configured](https://docs.n8n.io/integrations/builtin/credentials/google/oauth-single-service/)\n  * Note: When setting up the OAuth consent screen, skip steps 8-10 if running on localhost\n* An [Open AI account](https://auth.openai.com/create-account) and [API key](https://platform.openai.com/settings/organization/api-keys)\n\n### Setup\n\n1. Create a Pinecone Assistant in the Pinecone Console [here](https://app.pinecone.io/organizations/-/projects/-/assistant) \n\t1. Name your Assistant `n8n-assistant` and create it in the `United States` region\n\t2. If you use a different name or region, update the related nodes to reflect these changes\n\t3. No need to configure a Chat model or Assistant instructions\n2. Setup your Google Drive OAuth2 API credential in n8n\n\t1. In the File added node -&gt; Credential to connect with, select Create new credential\n\t2. Set the Client ID and Client Secret from the values generated in the prerequisites\n\t3. Set the OAuth Redirect URL from the n8n credential in the Google Cloud Console ([instructions](https://docs.n8n.io/integrations/builtin/credentials/google/oauth-single-service/#create-your-google-oauth-client-credentials))\n\t4. Name this credential `Google Drive account` so that other nodes reference it\n3. Setup Pinecone API key credential in n8n\n\t1. In the Upload file to assistant node -&gt; PineconeApi section, select Create new credential\n\t2. Paste in your Pinecone API key in the API Key field\n4. Setup Pinecone MCP Bearer auth credential in n8n\n\t1. In the Pinecone Assistant node -&gt; Credential for Bearer Auth section, select Create new credential\n\t2. Set the Bearer Token field to your Pinecone API key used in the previous step\n5. Setup the Open AI credential in n8n\n\t1. In the OpenAI Chat Model node -&gt; Credential to connect with, select Create new credential\n\t2. Set the API Key field to your OpenAI API key\n6. Add your files to a Drive folder named `n8n-pinecone-demo` in the root of your My Drive\n\t1. If you use a different folder name, you'll need to update the Google Drive triggers to reflect that change\n7. Activate the workflow or test it with a manual execution to ingest the documents\n8. Chat with your docs!\n\n### Ideas for customizing this workflow\n\n- Customize the System Message on the AI Agent node to your use case to indicate what kind of knowledge is stored in Pinecone Assistant\n- Change the top_k value of results returned from Assistant by adding \"and should set a top_k of 3\" to the System Message to help manage token consumption\n- Configure the Context Window Length in the Conversation Memory node\n- Swap out the Conversation Memory node for one that is more persistent\n- Make the [chat node publicly available](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/#make-chat-publicly-available) or [create your own chat interface](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/#mode) that calls the chat webhook URL.\n\n### Need help?\n\nYou can find help by asking in the [Pinecone Discord community](https://discord.gg/tJ8V62S3sH), asking on the [Pinecone Forum](https://community.pinecone.io/), or [filing an issue](https://github.com/pinecone-io/n8n-templates/issues/new/choose) on this repo.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Upload file to assistant",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Download file",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Delete file from assistant",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "File updated",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "File added",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Get file to delete",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Set file data",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Chat input",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Pinecone Assistant",
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Check file status",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "End if status Available",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Conversation Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}