{
  "id": 6057,
  "slug": "6057",
  "title": "Generate SEO-optimized blog content with Gemini, Scrapeless and Pinecone RAG",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n## How it works\n\nThis advanced automation builds a **fully autonomous SEO blog writer** using **n8n**, **Scrapeless**, **LLMs**, and **Pinecone vector database**. Itâ€™s powered by a Retrieval-Augmented Generation (RAG) system that collects high-performing blog content, stores it in a vector store, and then generates new blog posts based on that knowledgeâ€”endlessly.\n\n## Part 1: Build a Knowledge Base from Popular Blogs\n\n- **Scrape existing articles** from a well-established writer (in this case, Mark Manson) using the Scrapeless node.\n- **Extract content from blog pages** and store it in **Pinecone**, a powerful vector database that supports similarity search.\n- **Use Gemini Embedding 001** or any other supported embedding model to encode blog content into vectors.\n- **Result**: Youâ€™ll have a searchable vector store of expert-level content, ready to be used for content generation and intelligent search.\n\n## Part 2: SERP Analysis & AI Blog Generation\n\n- Use **Scrapeless' SERP node** to fetch search results based on your keyword and search intent.\n- Send the results to an **LLM** (like Gemini, OpenRouter, or OpenAI) to generate a **keyword analysis report** in Markdown â†’ then converted to HTML.\n- Extract **long-tail keywords**, **search intent insights**, and **content angles** from this report.\n- Feed everything into another LLM with access to your **Pinecone-stored knowledge base**, and generate a **fully SEO-optimized blog post**.\n\n\n## Set up steps\n\n### Prerequisites\n- [**Scrapeless API key**](https://scrapeless.com/?utm_source=n8n&utm_campaign=ai-powered-blog-writer)\n\n![image.png](fileId:1757)\n- [Pinecone account and index setup](https://www.pinecone.io/)\n- An embedding model (Gemini, OpenAI, etc.)\n- n8n instance with **Community Node: `n8n-nodes-scrapeless`** installed\n\n### Credential Configuration\n- Add your Scrapeless and Pinecone credentials in n8n under the \"Credentials\" tab\n- Choose embedding dimensions according to the model you use (e.g., 768 for Gemini Embedding 001)\n\n\n## Key Highlights\n\n- **Clones a real content creator**: Replicates knowledge and writing style from top-performing blog authors.\n- **Auto-scrapes hundreds of blog posts** without being blocked.\n- **Stores expert content** in a vector DB to build a reusable knowledge base.\n- **Performs real-time SERP analysis** using Scrapeless to fetch and analyze search data.\n- **Generates SEO blog drafts** using RAG with detailed keyword intelligence.\n- **Output includes**: blog title, HTML summary report, long-tail keywords, and AI-written article body.\n\n\n## RAG + SEO: The Future of Content Creation\n\nThis template combines:\n- **AI reasoning** from large language models\n- **Reliable data scraping** from Scrapeless\n- **Scalable storage** via Pinecone vector DB\n- **Flexible orchestration** using n8n nodes\n\nThis is **not just an automation**â€”itâ€™s a **full-stack SEO content machine** that enables you to:\n- Build a domain-specific knowledge base\n- Run intelligent keyword research\n- Generate traffic-ready content on autopilot\n\n\n## ðŸ’¡ Use Cases\n\n- SaaS content teams cloning competitor success\n- Affiliate marketers scaling high-traffic blog production\n- Agencies offering automated SEO content services\n- AI researchers building personal knowledge bots\n- Writers automating first-draft generation with real-world tone\n\n",
  "featuredImage": "/data/workflows/6057/6057.webp",
  "author": {
    "id": 101,
    "slug": "scrapelessofficial",
    "name": "scrapeless official",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1145,
  "downloads": 114,
  "createdAt": "2025-07-16T09:58:48.207Z",
  "updatedAt": "2026-01-16T08:42:53.929Z",
  "publishedAt": "2025-07-16T09:58:48.207Z",
  "nodes": 28,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6057",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Generate SEO-optimized blog content with Gemini, Scrapeless and Pinecone RAG",
    "workflowName": "Generate SEO-optimized blog content with Gemini, Scrapeless and Pinecone RAG",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n## How it works\n\nThis advanced automation builds a **fully autonomous SEO blog writer** using **n8n**, **Scrapeless**, **LLMs**, and **Pinecone vector database**. Itâ€™s powered by a Retrieval-Augmented Generation (RAG) system that collects high-performing blog content, stores it in a vector store, and then generates new blog posts based on that knowledgeâ€”endlessly.\n\n## Part 1: Build a Knowledge Base from Popular Blogs\n\n- **Scrape existing articles** from a well-established writer (in this case, Mark Manson) using the Scrapeless node.\n- **Extract content from blog pages** and store it in **Pinecone**, a powerful vector database that supports similarity search.\n- **Use Gemini Embedding 001** or any other supported embedding model to encode blog content into vectors.\n- **Result**: Youâ€™ll have a searchable vector store of expert-level content, ready to be used for content generation and intelligent search.\n\n## Part 2: SERP Analysis & AI Blog Generation\n\n- Use **Scrapeless' SERP node** to fetch search results based on your keyword and search intent.\n- Send the results to an **LLM** (like Gemini, OpenRouter, or OpenAI) to generate a **keyword analysis report** in Markdown â†’ then converted to HTML.\n- Extract **long-tail keywords**, **search intent insights**, and **content angles** from this report.\n- Feed everything into another LLM with access to your **Pinecone-stored knowledge base**, and generate a **fully SEO-optimized blog post**.\n\n\n## Set up steps\n\n### Prerequisites\n- [**Scrapeless API key**](https://scrapeless.com/?utm_source=n8n&utm_campaign=ai-powered-blog-writer)\n\n![image.png](fileId:1757)\n- [Pinecone account and index setup](https://www.pinecone.io/)\n- An embedding model (Gemini, OpenAI, etc.)\n- n8n instance with **Community Node: `n8n-nodes-scrapeless`** installed\n\n### Credential Configuration\n- Add your Scrapeless and Pinecone credentials in n8n under the \"Credentials\" tab\n- Choose embedding dimensions according to the model you use (e.g., 768 for Gemini Embedding 001)\n\n\n## Key Highlights\n\n- **Clones a real content creator**: Replicates knowledge and writing style from top-performing blog authors.\n- **Auto-scrapes hundreds of blog posts** without being blocked.\n- **Stores expert content** in a vector DB to build a reusable knowledge base.\n- **Performs real-time SERP analysis** using Scrapeless to fetch and analyze search data.\n- **Generates SEO blog drafts** using RAG with detailed keyword intelligence.\n- **Output includes**: blog title, HTML summary report, long-tail keywords, and AI-written article body.\n\n\n## RAG + SEO: The Future of Content Creation\n\nThis template combines:\n- **AI reasoning** from large language models\n- **Reliable data scraping** from Scrapeless\n- **Scalable storage** via Pinecone vector DB\n- **Flexible orchestration** using n8n nodes\n\nThis is **not just an automation**â€”itâ€™s a **full-stack SEO content machine** that enables you to:\n- Build a domain-specific knowledge base\n- Run intelligent keyword research\n- Generate traffic-ready content on autopilot\n\n\n## ðŸ’¡ Use Cases\n\n- SaaS content teams cloning competitor success\n- Affiliate marketers scaling high-traffic blog production\n- Agencies offering automated SEO content services\n- AI researchers building personal knowledge bots\n- Writers automating first-draft generation with real-world tone",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking â€˜Execute workflowâ€™",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Pinecone Vector Store3",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings Google Gemini3",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model3",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Convert to File",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Edit Fields1",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Basic LLM Chain1",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Google Gemini Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Markdown",
      "type": "n8n-nodes-base.markdown",
      "role": "markdown",
      "configDescription": "Version 1"
    },
    {
      "name": "HTML",
      "type": "n8n-nodes-base.html",
      "role": "html",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Google Gemini",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Crawl all Blogs",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "Parse content and extract information",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Scrape detailed contents",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "Analyze target keywords on Google SERP",
      "type": "n8n-nodes-scrapeless.scrapeless",
      "role": "scrapeless",
      "configDescription": "Version 1"
    },
    {
      "name": "Split Out the url and text",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    }
  ]
}