{
  "id": 9507,
  "slug": "9507",
  "title": "Insurance news aggregation keyword analysis & database storage via Supabase",
  "description": "Automatically collect, analyze, and store industry news articles with intelligent filtering and dual-database storage\n\nüéØ What This Workflow Does\n\nThis comprehensive news scraping automation monitors multiple industry sources every 6 hours, intelligently extracts relevant content, analyzes it for keyword relevance, and stores high-quality articles in both a content library and knowledge base. Perfect for content marketers, researchers, industry analysts, and anyone building an AI-powered knowledge system.\n\n‚ú® Key Features\n\nMulti-Source Aggregation: Collects from RSS feeds, Google News, and direct website scraping\nSmart Content Extraction: Uses Cheerio to parse HTML and extract clean article content\nAI-Ready Keyword Analysis: Automatically identifies and tags industry-specific terms\nIntelligent Filtering: Only stores articles meeting your relevance threshold (default: 30%)\nDual Storage System: Saves to both content library (marketing) and knowledge base (AI training)\nRate Limiting: Includes polite delays to respect website resources\nFully Automated: Runs on schedule without manual intervention\n\nüîß Technical Highlights\n\nSchedule-based trigger (every 6 hours, customizable)\nHandles 3 content types: RSS feeds, Google News RSS, and web pages\nLimits to top 10 articles per source to manage volume\nTracks 17+ insurance-specific keywords (easily customizable for any industry)\nIncludes comprehensive error handling and timeout management\nSupabase integration (works with any REST API database)\n\nüìö Perfect For\n\nBuilding AI chatbot knowledge bases\nContent marketing research\nCompetitive intelligence gathering\nIndustry trend monitoring\nNews aggregation platforms\nSEO content research\nMarket analysis and reporting\n\nüöÄ Setup Requirements\n\nn8n instance (self-hosted or cloud)\nSupabase account (free tier works) or any REST API database\nBasic understanding of JSON and HTTP requests\nAll setup instructions included in sticky notes within the workflow!\n\nüì¶ What's Included\n\nComplete workflow JSON (ready to import)\n8 detailed sticky notes with beginner-friendly explanations\nSetup guide with step-by-step instructions\nCustomization tips for different industries\nExample sources for insurance industry (easily adaptable)\n\nüé® Customization Options\n\nModify schedule interval (hourly, daily, weekly)\nAdd your own RSS feeds and websites\nAdjust relevance threshold\nCustomize keyword lists for your industry\nChange article limits per source\nModify storage destinations\n\n‚ö†Ô∏è Important Notes\n\nRemember to update Supabase credentials before running\nTest with a single source before deploying all sources\nRespect website terms of service and robots.txt\nConsider API rate limits for your sources\nThe workflow includes rate limiting to be respectful to websites\n\nüè∑Ô∏è Tags\ncontent-scraping rss-feeds web-scraping automation knowledge-base supabase cheerio news-aggregation content-marketing ai-training-data\n\nVersion: 2.0\nLast Updated: January 2025\nDifficulty: Intermediate\nEstimated Setup Time: 30 minutes",
  "featuredImage": "/data/workflows/9507/9507.webp",
  "author": {
    "id": 101,
    "slug": "SheCodesFlow",
    "name": "Shelly-Ann Davy",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 34,
  "downloads": 3,
  "createdAt": "2025-10-12T11:27:10.451Z",
  "updatedAt": "2026-01-16T09:00:46.571Z",
  "publishedAt": "2025-10-12T11:27:10.451Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9507",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Insurance news aggregation keyword analysis & database storage via Supabase",
    "workflowName": "Insurance news aggregation keyword analysis & database storage via Supabase",
    "description": "Automatically collect, analyze, and store industry news articles with intelligent filtering and dual-database storage\n\nüéØ What This Workflow Does\n\nThis comprehensive news scraping automation monitors multiple industry sources every 6 hours, intelligently extracts relevant content, analyzes it for keyword relevance, and stores high-quality articles in both a content library and knowledge base. Perfect for content marketers, researchers, industry analysts, and anyone building an AI-powered knowledge system.\n\n‚ú® Key Features\n\nMulti-Source Aggregation: Collects from RSS feeds, Google News, and direct website scraping\nSmart Content Extraction: Uses Cheerio to parse HTML and extract clean article content\nAI-Ready Keyword Analysis: Automatically identifies and tags industry-specific terms\nIntelligent Filtering: Only stores articles meeting your relevance threshold (default: 30%)\nDual Storage System: Saves to both content library (marketing) and knowledge base (AI training)\nRate Limiting: Includes polite delays to respect website resources\nFully Automated: Runs on schedule without manual intervention\n\nüîß Technical Highlights\n\nSchedule-based trigger (every 6 hours, customizable)\nHandles 3 content types: RSS feeds, Google News RSS, and web pages\nLimits to top 10 articles per source to manage volume\nTracks 17+ insurance-specific keywords (easily customizable for any industry)\nIncludes comprehensive error handling and timeout management\nSupabase integration (works with any REST API database)\n\nüìö Perfect For\n\nBuilding AI chatbot knowledge bases\nContent marketing research\nCompetitive intelligence gathering\nIndustry trend monitoring\nNews aggregation platforms\nSEO content research\nMarket analysis and reporting\n\nüöÄ Setup Requirements\n\nn8n instance (self-hosted or cloud)\nSupabase account (free tier works) or any REST API database\nBasic understanding of JSON and HTTP requests\nAll setup instructions included in sticky notes within the workflow!\n\nüì¶ What's Included\n\nComplete workflow JSON (ready to import)\n8 detailed sticky notes with beginner-friendly explanations\nSetup guide with step-by-step instructions\nCustomization tips for different industries\nExample sources for insurance industry (easily adaptable)\n\nüé® Customization Options\n\nModify schedule interval (hourly, daily, weekly)\nAdd your own RSS feeds and websites\nAdjust relevance threshold\nCustomize keyword lists for your industry\nChange article limits per source\nModify storage destinations\n\n‚ö†Ô∏è Important Notes\n\nRemember to update Supabase credentials before running\nTest with a single source before deploying all sources\nRespect website terms of service and robots.txt\nConsider API rate limits for your sources\nThe workflow includes rate limiting to be respectful to websites\n\nüè∑Ô∏è Tags\ncontent-scraping rss-feeds web-scraping automation knowledge-base supabase cheerio news-aggregation content-marketing ai-training-data\n\nVersion: 2.0\nLast Updated: January 2025\nDifficulty: Intermediate\nEstimated Setup Time: 30 minutes",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Sticky Note - Overview",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Schedule Every 6 Hours",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Get News Sources",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    },
    {
      "name": "Is RSS Feed?",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 1"
    },
    {
      "name": "Fetch RSS Feed",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1"
    },
    {
      "name": "Fetch Google News RSS",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1"
    },
    {
      "name": "Scrape Web Page",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 3"
    },
    {
      "name": "Parse Articles",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    },
    {
      "name": "Fetch Full Article",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 3"
    },
    {
      "name": "Rate Limit Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract Content & Keywords",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 1"
    },
    {
      "name": "Is Relevant?",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 1"
    },
    {
      "name": "Store in Content Library",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 3"
    },
    {
      "name": "Store in Knowledge Base",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 3"
    },
    {
      "name": "Error Handler",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note - Setup",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}