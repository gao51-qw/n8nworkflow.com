{
  "id": 7717,
  "slug": "7717",
  "title": "Build a PDF Q&A system with LlamaIndex, OpenAI embeddings & Pinecone vector DB",
  "description": "## Parse, Normalize, Extract, and Store PDF Content for RAG in Pinecone\n\nThis workflow automates a full RAG pipeline for structured documents (like insurance policies).  \n\n### What it does\n- Watches a Google Drive folder for new PDFs  \n- Uploads to LlamaIndex Cloud for parsing → returns clean Markdown  \n- Normalizes text (removes headers, footers, page numbers, formatting artifacts)  \n- Splits text into chunks (~1200 chars with 150 overlap)  \n- Generates embeddings with OpenAI  \n- Stores vectors in Pinecone with metadata  \n- Connects a Chat Agent that retrieves answers from Pinecone  \n\n### Who’s it for\n- Developers building **chatbots or Q&A systems** for structured docs  \n- Teams working with **insurance, compliance, or legal PDFs**  \n- Anyone who needs to **normalize & store documents for semantic search**  \n\n### Requirements\n- Google Drive connected (for source PDFs)  \n- LlamaIndex Cloud account (parsing API key)  \n- Pinecone account (vector DB)  \n- OpenAI account (LLM and embeddings) \n\n### How to use and customize\n* Update the folder name in google drive trigger node. \n* Place a pdf file in the same folder in google drive.  \n* Customize the `Normalized Content` function node to adjust regex for headers/footers specific to your documents.  \n* Adjust chunk size or metadata namespace in the Pinecone node to fit your project needs.  \n\n---\n",
  "featuredImage": "/data/workflows/7717/7717.webp",
  "author": {
    "id": 101,
    "slug": "alokkumar",
    "name": "Alok Kumar",
    "avatar": ""
  },
  "categories": [
    "AI RAG",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 551,
  "downloads": 55,
  "createdAt": "2025-08-22T00:19:30.170Z",
  "updatedAt": "2026-01-16T08:51:59.618Z",
  "publishedAt": "2025-08-22T00:19:30.170Z",
  "nodes": 18,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7717",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build a PDF Q&A system with LlamaIndex, OpenAI embeddings & Pinecone vector DB",
    "workflowName": "Build a PDF Q&A system with LlamaIndex, OpenAI embeddings & Pinecone vector DB",
    "description": "## Parse, Normalize, Extract, and Store PDF Content for RAG in Pinecone\n\nThis workflow automates a full RAG pipeline for structured documents (like insurance policies).  \n\n### What it does\n- Watches a Google Drive folder for new PDFs  \n- Uploads to LlamaIndex Cloud for parsing → returns clean Markdown  \n- Normalizes text (removes headers, footers, page numbers, formatting artifacts)  \n- Splits text into chunks (~1200 chars with 150 overlap)  \n- Generates embeddings with OpenAI  \n- Stores vectors in Pinecone with metadata  \n- Connects a Chat Agent that retrieves answers from Pinecone  \n\n### Who’s it for\n- Developers building **chatbots or Q&A systems** for structured docs  \n- Teams working with **insurance, compliance, or legal PDFs**  \n- Anyone who needs to **normalize & store documents for semantic search**  \n\n### Requirements\n- Google Drive connected (for source PDFs)  \n- LlamaIndex Cloud account (parsing API key)  \n- Pinecone account (vector DB)  \n- OpenAI account (LLM and embeddings) \n\n### How to use and customize\n* Update the folder name in google drive trigger node. \n* Place a pdf file in the same folder in google drive.  \n* Customize the `Normalized Content` function node to adjust regex for headers/footers specific to your documents.  \n* Adjust chunk size or metadata namespace in the Pinecone node to fit your project needs.  \n\n---",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Google Drive Trigger",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Download file",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "If",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Wait2",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Upload to Llama Cloud",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Check Parsing Status",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Extract Markdown from Llama Cloud",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Normalize Text",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Chunk Text",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Generate Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Store in Pinecone",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}