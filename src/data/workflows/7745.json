{
  "id": 7745,
  "slug": "7745",
  "title": "Hr policy retrieval using Slack, S3, and GPT-4.1-mini with RAG",
  "description": "## HR Chatbot with RAG: Retrieve Company Policies via Slack, Amazon S3, and OpenAI\n \n## Overview\nAnswer HR and company policy questions via Slack, powered by a Knowledge Base of internal documents stored in S3. The assistant uses vector search and an OpenAI Chat Model to retrieve accurate answers.\n\nThe HR Assistant is an AI-powered Slack bot that allows employees to ask questions in natural language and get accurate answers from company documentation. Documents are managed through an ingestion workflow that retrieves files from S3, transforms them into embeddings, and stores them in a vector database.\nOn Slack, the assistant interprets questions, searches the Knowledge Base, and responds with concise and reliable answers, or clearly states when information isn’t available.\n\n## How it works\n**Normal interaction** \n- An employee asks a question in Slack (e.g., “How many vacation days do I have?”).\n- The assistant checks the Knowledge Base (vector store).\n- If relevant information is found, the assistant provides a clear answer.\n- If not, it responds with: “That answer doesn’t appear to be covered in the materials I have access to.”\n\n**Standardized process of Knowledge Base ingestion**\n1. Trigger – The ingestion workflow is manually executed.\n2. S3 Download – Files are pulled from the company’s S3 bucket.\n3. Data Loader – Documents are pre-processed and split into chunks.\n4. Embeddings – Each chunk is converted into an embedding via OpenAI.\n5. Vector Store – Embeddings are stored in the Knowledge Base (vector DB).\n6. Chatbot Workflow – When questions arrive via Slack, the assistant queries the vector store to find the most relevant context before generating a response.\n\n## Required Connections\nTo use the HR Assistant effectively, you need:\n- A Slack workspace, where the bot is installed and invited to relevant channels.\n- An S3 bucket containing company documents (e.g., HR policies, procedures).\n- Access to OpenAI API keys for both embeddings and chat models.\n- Proper permissions to fetch documents from S3 and write to the vector store.\n- A configured n8n instance with both ingestion and chatbot workflows.\n\n## Setup Time\n≈ 20–30 minutes (depending on number of documents and Slack integration).\n\n## Customising this workflow\n- Add more document sources (e.g., Google Drive, Confluence) in the ingestion pipeline.\n- Expand the Slack integration to allow commands like /askHR or to restrict the bot to only respond when @mentioned.\n- Add scheduled ingestion (instead of manual trigger) to automatically refresh the Knowledge Base from S3.\n- Connect analytics nodes to monitor which HR topics employees ask most often.",
  "featuredImage": "/data/workflows/7745/7745.webp",
  "author": {
    "id": 101,
    "slug": "humbleturtle",
    "name": "Humble Turtle",
    "avatar": ""
  },
  "categories": [
    "AI RAG",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 67,
  "downloads": 6,
  "createdAt": "2025-08-22T13:22:48.181Z",
  "updatedAt": "2026-01-16T08:52:09.697Z",
  "publishedAt": "2025-08-22T13:22:48.181Z",
  "nodes": 24,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7745",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Hr policy retrieval using Slack, S3, and GPT-4.1-mini with RAG",
    "workflowName": "Hr policy retrieval using Slack, S3, and GPT-4.1-mini with RAG",
    "description": "## HR Chatbot with RAG: Retrieve Company Policies via Slack, Amazon S3, and OpenAI\n \n## Overview\nAnswer HR and company policy questions via Slack, powered by a Knowledge Base of internal documents stored in S3. The assistant uses vector search and an OpenAI Chat Model to retrieve accurate answers.\n\nThe HR Assistant is an AI-powered Slack bot that allows employees to ask questions in natural language and get accurate answers from company documentation. Documents are managed through an ingestion workflow that retrieves files from S3, transforms them into embeddings, and stores them in a vector database.\nOn Slack, the assistant interprets questions, searches the Knowledge Base, and responds with concise and reliable answers, or clearly states when information isn’t available.\n\n## How it works\n**Normal interaction** \n- An employee asks a question in Slack (e.g., “How many vacation days do I have?”).\n- The assistant checks the Knowledge Base (vector store).\n- If relevant information is found, the assistant provides a clear answer.\n- If not, it responds with: “That answer doesn’t appear to be covered in the materials I have access to.”\n\n**Standardized process of Knowledge Base ingestion**\n1. Trigger – The ingestion workflow is manually executed.\n2. S3 Download – Files are pulled from the company’s S3 bucket.\n3. Data Loader – Documents are pre-processed and split into chunks.\n4. Embeddings – Each chunk is converted into an embedding via OpenAI.\n5. Vector Store – Embeddings are stored in the Knowledge Base (vector DB).\n6. Chatbot Workflow – When questions arrive via Slack, the assistant queries the vector store to find the most relevant context before generating a response.\n\n## Required Connections\nTo use the HR Assistant effectively, you need:\n- A Slack workspace, where the bot is installed and invited to relevant channels.\n- An S3 bucket containing company documents (e.g., HR policies, procedures).\n- Access to OpenAI API keys for both embeddings and chat models.\n- Proper permissions to fetch documents from S3 and write to the vector store.\n- A configured n8n instance with both ingestion and chatbot workflows.\n\n## Setup Time\n≈ 20–30 minutes (depending on number of documents and Slack integration).\n\n## Customising this workflow\n- Add more document sources (e.g., Google Drive, Confluence) in the ingestion pipeline.\n- Expand the Slack integration to allow commands like /askHR or to restrict the bot to only respond when @mentioned.\n- Add scheduled ingestion (instead of manual trigger) to automatically refresh the Knowledge Base from S3.\n- Connect analytics nodes to monitor which HR topics employees ask most often.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Slack Trigger",
      "type": "n8n-nodes-base.slackTrigger",
      "role": "slackTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Chatbot",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Knowledge Base Search",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "role": "toolVectorStore",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Knowledge Base",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Knowledge Base Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Conversation Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Knowledge Base Response Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "S3 Document Downloader",
      "type": "n8n-nodes-base.awsS3",
      "role": "awsS3",
      "configDescription": "Version 2"
    },
    {
      "name": "Knowledge Base storage",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Knowledge Base Embeddings Generator",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Document Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Try Again",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Send a message",
      "type": "n8n-nodes-base.slack",
      "role": "slack",
      "configDescription": "Version 2.3"
    }
  ]
}