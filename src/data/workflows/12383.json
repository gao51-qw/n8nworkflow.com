{
  "id": 12383,
  "slug": "12383",
  "title": "Create multilingual localized speech audio with GPT-4 and ElevenLabs",
  "description": "## How It Works\nThis workflow delivers intelligent multilingual audio content creation for global marketing teams, e-learning providers, and content production studios. It solves the complex challenge of generating culturally adapted, professionally voiced translations optimized for each target language. The system begins with AI-powered localization that adapts source content for cultural context, idioms, and regional preferences rather than literal translation. Specialized AI agents then optimize speech parameters (pace, tone, emphasis) and voice characteristics (pitch, timbre, style) specific to each language's phonetic requirements. The workflow prepares language arrays and loops through each target language, generating optimized audio via ElevenLabs with customized voice parameters. All audio files are processed, formatted with metadata, and aggregated into a complete deliverable package, transforming single-source content into publication-ready multilingual audio assets.\n\n## Setup Steps\n1. Configure OpenAI API credentials in all AI agent nodes  \n2. Set up ElevenLabs account, obtain API key \n3. Define target languages list in \"Workflow Configuration\" node using ISO language codes\n4. Customize localization prompts in AI agents to match brand voice and content type\n5. Adjust voice parameter ranges and optimization criteria based on audio requirements\n6. Configure output formatting in \"Aggregate Results\" node  \n\n## Prerequisites\nOpenAI API access with GPT-4 capabilities, active ElevenLabs subscription with multi-voice access. \n## Use Cases\nGlobal product launch campaigns, international e-learning course production\n## Customization\nModify AI prompts for industry-specific terminology, add quality validation checkpoints\n## Benefits\nAchieves native-quality audio across languages, reduces production time by 80%",
  "featuredImage": "/data/workflows/12383/12383.webp",
  "author": {
    "id": 101,
    "slug": "cschin",
    "name": "Cheng Siong Chin",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 89,
  "downloads": 8,
  "createdAt": "2026-01-02T05:15:01.722Z",
  "updatedAt": "2026-01-16T09:12:21.723Z",
  "publishedAt": "2026-01-02T05:15:01.722Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/12383",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Create multilingual localized speech audio with GPT-4 and ElevenLabs",
    "workflowName": "Create multilingual localized speech audio with GPT-4 and ElevenLabs",
    "description": "## How It Works\nThis workflow delivers intelligent multilingual audio content creation for global marketing teams, e-learning providers, and content production studios. It solves the complex challenge of generating culturally adapted, professionally voiced translations optimized for each target language. The system begins with AI-powered localization that adapts source content for cultural context, idioms, and regional preferences rather than literal translation. Specialized AI agents then optimize speech parameters (pace, tone, emphasis) and voice characteristics (pitch, timbre, style) specific to each language's phonetic requirements. The workflow prepares language arrays and loops through each target language, generating optimized audio via ElevenLabs with customized voice parameters. All audio files are processed, formatted with metadata, and aggregated into a complete deliverable package, transforming single-source content into publication-ready multilingual audio assets.\n\n## Setup Steps\n1. Configure OpenAI API credentials in all AI agent nodes  \n2. Set up ElevenLabs account, obtain API key \n3. Define target languages list in \"Workflow Configuration\" node using ISO language codes\n4. Customize localization prompts in AI agents to match brand voice and content type\n5. Adjust voice parameter ranges and optimization criteria based on audio requirements\n6. Configure output formatting in \"Aggregate Results\" node  \n\n## Prerequisites\nOpenAI API access with GPT-4 capabilities, active ElevenLabs subscription with multi-voice access. \n## Use Cases\nGlobal product launch campaigns, international e-learning course production\n## Customization\nModify AI prompts for industry-specific terminology, add quality validation checkpoints\n## Benefits\nAchieves native-quality audio across languages, reduces production time by 80%",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Start Workflow",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Workflow Configuration",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Localization Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "OpenAI Model - Localization",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Structured Output - Translations",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Prepare Languages Array",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Loop Over Languages",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Speech Optimization Agent Tool",
      "type": "@n8n/n8n-nodes-langchain.agentTool",
      "role": "agentTool",
      "configDescription": "Version 3"
    },
    {
      "name": "OpenAI Model - Speech Optimization",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Voice Parameter Agent Tool",
      "type": "@n8n/n8n-nodes-langchain.agentTool",
      "role": "agentTool",
      "configDescription": "Version 3"
    },
    {
      "name": "OpenAI Model - Voice Parameters",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Structured Output - Voice Params",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Generate Audio with ElevenLabs",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Process Audio Response",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Aggregate Results",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}