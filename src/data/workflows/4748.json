{
  "id": 4748,
  "slug": "4748",
  "title": "Ai email auto-responder system- AI RAG agent for email inbox",
  "description": "# AI Email Auto-Responder – Smart Client Reply Automation with RAG\n\nThis workflow is built for individuals, teams, and businesses that receive regular inquiries via email and want to automate responses in a way that’s intelligent, brand-aligned, and always up to date. Its core purpose is to generate high-quality, professional email replies using internal company data, brand voice, and semantic search — fully automated through Gmail, Pinecone, and OpenAI.\n\nThe system is divided into three steps. First, it allows you to index your internal knowledge base (Docs, Sheets, PDFs) with embeddings. Second, it injects a consistent brand brief into every interaction to ensure tone and positioning. Finally, the main flow listens for incoming emails, understands the user query, retrieves all needed data, and writes a full HTML reply — sending it directly to the original thread via Gmail.\n\nThis solution is ideal for support teams, solopreneurs, B2B service providers, or anyone looking to scale high-quality client communication without scaling manual work. It can be extended to handle multilingual queries, intent routing, or CRM logging.\n\n## How it works\n\nWhen a new email arrives in Gmail, the workflow checks whether it's a valid client inquiry. If so, it:\n- Extracts the subject and message content\n- Sends the message through OpenAI to understand the question\n- Queries a Pinecone vector database (populated via a separate embedding workflow) to find relevant internal knowledge\n- Loads a brand brief from a Google Doc or Notion block\n- Combines retrieved data and brand context to generate a clear, structured HTML reply using OpenAI\n- Sends the reply via Gmail and logs the message\n\nThis process ensures every reply is relevant, accurate, and consistent with your brand — and takes under 10 seconds.\n\n## Set up steps\n\nGetting started takes about 30–60 minutes.\n\n- Create three workflows: one for embedding documents (Step 1), one sub-workflow for the brand brief (Step 2), and one main responder flow (Step 3)\n- Connect the following APIs: Gmail (OAuth2), OpenAI, Pinecone, Google Drive, and optionally Notion\n- Replace all placeholders: folder ID in Google Drive, Pinecone index and namespace, your brand brief URL or doc ID, and Gmail credentials\n- Test your embedding workflow by uploading a document and verifying its presence in Pinecone\n- Trigger the responder by sending an email and reviewing the AI’s reply\n\nDetailed setup instructions are stored in sticky notes within each workflow to guide you through configuration.\n",
  "featuredImage": "/data/workflows/4748/4748.webp",
  "author": {
    "id": 101,
    "slug": "lukaszb",
    "name": "LukaszB",
    "avatar": ""
  },
  "categories": [
    "Ticket Management",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 857,
  "downloads": 85,
  "createdAt": "2025-06-06T19:16:47.224Z",
  "updatedAt": "2026-01-16T08:36:00.662Z",
  "publishedAt": "2025-06-06T19:16:47.224Z",
  "nodes": 34,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4748",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Ai email auto-responder system- AI RAG agent for email inbox",
    "workflowName": "Ai email auto-responder system- AI RAG agent for email inbox",
    "description": "# AI Email Auto-Responder – Smart Client Reply Automation with RAG\n\nThis workflow is built for individuals, teams, and businesses that receive regular inquiries via email and want to automate responses in a way that’s intelligent, brand-aligned, and always up to date. Its core purpose is to generate high-quality, professional email replies using internal company data, brand voice, and semantic search — fully automated through Gmail, Pinecone, and OpenAI.\n\nThe system is divided into three steps. First, it allows you to index your internal knowledge base (Docs, Sheets, PDFs) with embeddings. Second, it injects a consistent brand brief into every interaction to ensure tone and positioning. Finally, the main flow listens for incoming emails, understands the user query, retrieves all needed data, and writes a full HTML reply — sending it directly to the original thread via Gmail.\n\nThis solution is ideal for support teams, solopreneurs, B2B service providers, or anyone looking to scale high-quality client communication without scaling manual work. It can be extended to handle multilingual queries, intent routing, or CRM logging.\n\n## How it works\n\nWhen a new email arrives in Gmail, the workflow checks whether it's a valid client inquiry. If so, it:\n- Extracts the subject and message content\n- Sends the message through OpenAI to understand the question\n- Queries a Pinecone vector database (populated via a separate embedding workflow) to find relevant internal knowledge\n- Loads a brand brief from a Google Doc or Notion block\n- Combines retrieved data and brand context to generate a clear, structured HTML reply using OpenAI\n- Sends the reply via Gmail and logs the message\n\nThis process ensures every reply is relevant, accurate, and consistent with your brand — and takes under 10 seconds.\n\n## Set up steps\n\nGetting started takes about 30–60 minutes.\n\n- Create three workflows: one for embedding documents (Step 1), one sub-workflow for the brand brief (Step 2), and one main responder flow (Step 3)\n- Connect the following APIs: Gmail (OAuth2), OpenAI, Pinecone, Google Drive, and optionally Notion\n- Replace all placeholders: folder ID in Google Drive, Pinecone index and namespace, your brand brief URL or doc ID, and Gmail credentials\n- Test your embedding workflow by uploading a document and verifying its presence in Pinecone\n- Trigger the responder by sending an email and reviewing the AI’s reply\n\nDetailed setup instructions are stored in sticky notes within each workflow to guide you through configuration.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Answer questions with a vector store",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "role": "toolVectorStore",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Pinecone Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Get Brand brief",
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "role": "toolWorkflow",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Gmail Trigger",
      "type": "n8n-nodes-base.gmailTrigger",
      "role": "gmailTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "If",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "OpenAI Chat Model3",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Gmail",
      "type": "n8n-nodes-base.gmail",
      "role": "gmail",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Search Information",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.9"
    },
    {
      "name": "Response writer",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Set Data",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Google Drive Trigger",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Drive",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "When Executed by Another Workflow",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "role": "executeWorkflowTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Notion",
      "type": "n8n-nodes-base.notion",
      "role": "notion",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Edit Fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Docs",
      "type": "n8n-nodes-base.googleDocs",
      "role": "googleDocs",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Check if Question",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}