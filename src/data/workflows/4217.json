{
  "id": 4217,
  "slug": "4217",
  "title": "Create OpenAI-compatible API using GitHub models for free AI access",
  "description": "### This n8n template shows you how to connect [Github's Free Models](https://docs.github.com/en/github-models) to your existing n8n AI workflows.\n\nWhilst it is possible to use HTTP nodes to access Github Models, The aim of this template is to use it with existing n8n LLM nodes - saves the trouble of refactoring!\n\nPlease note, Github states their model APIs are not intended for production usage! If you need higher rate limits, you'll need to use a paid service.\n\n### How it works\n* The approach builds a custom OpenAI compatible API around the Github Models API - all done in n8n!\n* First, we attach an OpenAI subnode to our LLM node and configure a new OpenAI credential.\n* Within this new OpenAI credential, we change the \"Base URL\" to point at a n8n webhook we've prepared as part of this template.\n* Next, we create 2 webhooks which the LLM node will now attempt to connect with: \"models\" and \"chat completion\".\n* The \"models\" webhook simply calls the Github Model's \"list all models\" endpoint and remaps the response to be compatible with our LLM node.\n* The \"Chat Completion\" webhook does a similar task with Github's Chat Completion endpoint.\n\n### How to use\n* Once connected, just open chat and ask away!\n* Any LLM or AI agent node connected with this custom LLM subnode will send requests to the Github Models API. Allowing your to try out a range of SOTA models for free.\n\n### Requirements\n* Github account and credentials for access to Models. If you've used the Github node previously, you can reuse this credential for this template.\n\n### Customising this workflow\n* This template is just an example. Use the custom OpenAI credential for your other workflows to test Github models.\n\n### References\n* [https://docs.github.com/en/github-models/prototyping-with-ai-models](https://docs.github.com/en/github-models/prototyping-with-ai-models)\n* [https://docs.github.com/en/github-models](https://docs.github.com/en/github-models)\n",
  "featuredImage": "/data/workflows/4217/4217.webp",
  "author": {
    "id": 101,
    "slug": "jimleuk",
    "name": "Jimleuk",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 5428,
  "downloads": 542,
  "createdAt": "2025-05-19T07:46:28.781Z",
  "updatedAt": "2026-01-16T08:33:20.101Z",
  "publishedAt": "2025-05-19T07:46:28.781Z",
  "nodes": 17,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4217",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Create OpenAI-compatible API using GitHub models for free AI access",
    "workflowName": "Create OpenAI-compatible API using GitHub models for free AI access",
    "description": "### This n8n template shows you how to connect [Github's Free Models](https://docs.github.com/en/github-models) to your existing n8n AI workflows.\n\nWhilst it is possible to use HTTP nodes to access Github Models, The aim of this template is to use it with existing n8n LLM nodes - saves the trouble of refactoring!\n\nPlease note, Github states their model APIs are not intended for production usage! If you need higher rate limits, you'll need to use a paid service.\n\n### How it works\n* The approach builds a custom OpenAI compatible API around the Github Models API - all done in n8n!\n* First, we attach an OpenAI subnode to our LLM node and configure a new OpenAI credential.\n* Within this new OpenAI credential, we change the \"Base URL\" to point at a n8n webhook we've prepared as part of this template.\n* Next, we create 2 webhooks which the LLM node will now attempt to connect with: \"models\" and \"chat completion\".\n* The \"models\" webhook simply calls the Github Model's \"list all models\" endpoint and remaps the response to be compatible with our LLM node.\n* The \"Chat Completion\" webhook does a similar task with Github's Chat Completion endpoint.\n\n### How to use\n* Once connected, just open chat and ask away!\n* Any LLM or AI agent node connected with this custom LLM subnode will send requests to the Github Models API. Allowing your to try out a range of SOTA models for free.\n\n### Requirements\n* Github account and credentials for access to Models. If you've used the Github node previously, you can reuse this credential for this template.\n\n### Customising this workflow\n* This template is just an example. Use the custom OpenAI credential for your other workflows to test Github models.\n\n### References\n* [https://docs.github.com/en/github-models/prototyping-with-ai-models](https://docs.github.com/en/github-models/prototyping-with-ai-models)\n* [https://docs.github.com/en/github-models](https://docs.github.com/en/github-models)",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Github Models",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Github Chat Completions",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "n8n Webhooks",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Chat Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Models Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Powered By Github Models",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "GET models",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2"
    },
    {
      "name": "POST ChatCompletions",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Is Agent?",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Agent Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.2"
    }
  ]
}