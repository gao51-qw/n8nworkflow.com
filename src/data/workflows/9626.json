{
  "id": 9626,
  "slug": "9626",
  "title": "Build a knowledge base chatbot with Jotform, RAG Supabase, Together AI & Gemini",
  "description": "Youtube Video: [https://youtu.be/dEtV7OYuMFQ?si=fOAlZWz4aDuFFovH](https://youtu.be/dEtV7OYuMFQ?si=fOAlZWz4aDuFFovH)\n\n\n# Workflow Pre-requisites\n\n### **Step 1: Supabase Setup**\n\nFirst, replace the keys in the \"Save the embedding in DB\" & \"Search Embeddings\" nodes with your new Supabase keys. After that, run the following code snippets in your Supabase SQL editor:\n\n1.  Create the table to store chunks and embeddings:\n    ```sql\n    CREATE TABLE public.\"RAG\"\n    (\n        id bigserial PRIMARY KEY,\n        chunk text NULL,\n        embeddings vector(1024) NULL\n    )\n    TABLESPACE pg_default;\n    ```\n\n2.  Create a function to match embeddings:\n    ```sql\n    DROP FUNCTION IF EXISTS public.matchembeddings1(integer, vector);\n\n    CREATE OR REPLACE FUNCTION public.matchembeddings1(\n        match_count integer,\n        query_embedding vector\n    )\n    RETURNS TABLE (\n        chunk text,\n        similarity float\n    )\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        RETURN QUERY\n        SELECT\n            R.chunk,\n            1 - (R.embeddings &lt;=&gt; query_embedding) AS similarity\n        FROM public.\"RAG\" AS R\n        ORDER BY R.embeddings &lt;=&gt; query_embedding\n        LIMIT match_count;\n    END;\n    $$;\n    ```\n\n### **Step 2: Create Jotform with these fields**\n1. Your full name\n2. email address\n3. Upload PDF Document [field where you upload the knowledgebase in PDF]\n\n\n### **Step 3: Get Together AI API Key**\n\nGet a Together AI API key and paste it into the \"Embedding Uploaded document\" node and the \"Embed User Message\" node.\n\n\n\n\n### Here is a detailed, node-by-node explanation of the n8n workflow, which is divided into two main parts.\n\n***\n\n### Part 1: Ingesting Knowledge from a PDF\n\nThis first sequence of nodes runs when you submit a PDF through a Jotform. Its purpose is to read the document, process its content, and save it in a specialized database for the AI to use later.\n\n1.  **`JotForm Trigger`**\n    * **Type:** Trigger\n    * **What it does:** This node starts the entire workflow. It's configured to listen for new submissions on a **specific Jotform**. When someone uploads a file and submits the form, this node activates and passes the submission data to the next step.\n\n2.  **`Grab New knowledgebase`**\n    * **Type:** HTTP Request\n    * **What it does:** The initial trigger from Jotform only contains basic information. This node makes a follow-up call to the Jotform API using the `submissionID` to get the complete details of that submission, including the specific link to the uploaded file.\n\n3.  **`Grab the uploaded knowledgebase file link`**\n    * **Type:** HTTP Request\n    * **What it does:** Using the file link obtained from the previous node, this step downloads the actual PDF file. It's set to receive the response as a file, not as text.\n\n4.  **`Extract Text from PDF File`**\n    * **Type:** Extract From File\n    * **What it does:** This utility node takes the binary PDF file downloaded in the previous step and extracts all the readable text content from it. The output is a single block of plain text.\n\n5.  **`Splitting into Chunks`**\n    * **Type:** Code\n    * **What it does:** This node runs a small JavaScript snippet. It takes the large block of text from the PDF and chops it into smaller, more manageable pieces, or **\"chunks,\"** each of a **predefined length**. This is critical because AI models work more effectively with smaller, focused pieces of text.\n\n6.  **`Embedding Uploaded document`**\n    * **Type:** HTTP Request\n    * **What it does:** This is a key AI step. It sends each individual text chunk to an embeddings API. A **specified AI model** converts the semantic meaning of the chunk into a numerical list called an **embedding** or vector. This vector is like a mathematical fingerprint of the text's meaning.\n\n7.  **`Save the embedding in DB`**\n    * **Type:** Supabase\n    * **What it does:** This node connects to your Supabase database. For every chunk, it creates a new row in a **specified table** and stores two important pieces of information: the original text chunk and its corresponding numerical embedding (its \"fingerprint\") from the previous step.\n\n***\n\n### Part 2: Answering Questions via Chat\n\nThis second sequence starts when a user sends a message. It uses the knowledge stored in the database to find relevant information and generate an intelligent answer.\n\n1.  **`When chat message received`**\n    * **Type:** Chat Trigger\n    * **What it does:** This node starts the second part of the workflow. It listens for any incoming message from a user in a connected chat application.\n\n2.  **`Embend User Message`**\n    * **Type:** HTTP Request\n    * **What it does:** This node takes the user's question and sends it to the *exact same* embeddings API and model used in Part 1. This converts the question's meaning into the same kind of numerical vector or \"fingerprint.\"\n\n3.  **`Search Embeddings`**\n    * **Type:** HTTP Request\n    * **What it does:** This is the \"retrieval\" step. It calls a **custom database function** in Supabase. It sends the question's embedding to this function and asks it to search the knowledge base table to find a **specified number of top text chunks** whose embeddings are mathematically most similar to the question's embedding.\n\n4.  **`Aggregate`**\n    * **Type:** Aggregate\n    * **What it does:** The search from the previous step returns multiple separate items. This utility node simply bundles those items into a single, combined piece of data. This makes it easier to feed all the context into the final AI model at once.\n\n5.  **`AI Agent` & `Google Gemini Chat Model`**\n    * **Type:** LangChain Agent & AI Model\n    * **What it does:** This is the \"generation\" step where the final answer is created.\n        * The **`AI Agent`** node is given a detailed set of instructions (a prompt).\n        * The prompt tells the **`Google Gemini Chat Model`** to act as a professional support agent.\n        * Crucially, it provides the AI with the user's original question and the **aggregated text chunks** from the `Aggregate` node as its **only source of truth**.\n        * It then instructs the AI to formulate an answer based *only* on that provided context, format it for a **specific chat style**, and to say \"I don't know\" if the answer cannot be found in the chunks. This prevents the AI from making things up.",
  "featuredImage": "/data/workflows/9626/9626.webp",
  "author": {
    "id": 101,
    "slug": "iamvaar",
    "name": "iamvaar",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1058,
  "downloads": 105,
  "createdAt": "2025-10-14T12:34:58.992Z",
  "updatedAt": "2026-01-16T09:01:16.765Z",
  "publishedAt": "2025-10-14T12:34:58.992Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9626",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build a knowledge base chatbot with Jotform, RAG Supabase, Together AI & Gemini",
    "workflowName": "Build a knowledge base chatbot with Jotform, RAG Supabase, Together AI & Gemini",
    "description": "Youtube Video: [https://youtu.be/dEtV7OYuMFQ?si=fOAlZWz4aDuFFovH](https://youtu.be/dEtV7OYuMFQ?si=fOAlZWz4aDuFFovH)\n\n\n# Workflow Pre-requisites\n\n### **Step 1: Supabase Setup**\n\nFirst, replace the keys in the \"Save the embedding in DB\" & \"Search Embeddings\" nodes with your new Supabase keys. After that, run the following code snippets in your Supabase SQL editor:\n\n1.  Create the table to store chunks and embeddings:\n    ```sql\n    CREATE TABLE public.\"RAG\"\n    (\n        id bigserial PRIMARY KEY,\n        chunk text NULL,\n        embeddings vector(1024) NULL\n    )\n    TABLESPACE pg_default;\n    ```\n\n2.  Create a function to match embeddings:\n    ```sql\n    DROP FUNCTION IF EXISTS public.matchembeddings1(integer, vector);\n\n    CREATE OR REPLACE FUNCTION public.matchembeddings1(\n        match_count integer,\n        query_embedding vector\n    )\n    RETURNS TABLE (\n        chunk text,\n        similarity float\n    )\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        RETURN QUERY\n        SELECT\n            R.chunk,\n            1 - (R.embeddings &lt;=&gt; query_embedding) AS similarity\n        FROM public.\"RAG\" AS R\n        ORDER BY R.embeddings &lt;=&gt; query_embedding\n        LIMIT match_count;\n    END;\n    $$;\n    ```\n\n### **Step 2: Create Jotform with these fields**\n1. Your full name\n2. email address\n3. Upload PDF Document [field where you upload the knowledgebase in PDF]\n\n\n### **Step 3: Get Together AI API Key**\n\nGet a Together AI API key and paste it into the \"Embedding Uploaded document\" node and the \"Embed User Message\" node.\n\n\n\n\n### Here is a detailed, node-by-node explanation of the n8n workflow, which is divided into two main parts.\n\n***\n\n### Part 1: Ingesting Knowledge from a PDF\n\nThis first sequence of nodes runs when you submit a PDF through a Jotform. Its purpose is to read the document, process its content, and save it in a specialized database for the AI to use later.\n\n1.  **`JotForm Trigger`**\n    * **Type:** Trigger\n    * **What it does:** This node starts the entire workflow. It's configured to listen for new submissions on a **specific Jotform**. When someone uploads a file and submits the form, this node activates and passes the submission data to the next step.\n\n2.  **`Grab New knowledgebase`**\n    * **Type:** HTTP Request\n    * **What it does:** The initial trigger from Jotform only contains basic information. This node makes a follow-up call to the Jotform API using the `submissionID` to get the complete details of that submission, including the specific link to the uploaded file.\n\n3.  **`Grab the uploaded knowledgebase file link`**\n    * **Type:** HTTP Request\n    * **What it does:** Using the file link obtained from the previous node, this step downloads the actual PDF file. It's set to receive the response as a file, not as text.\n\n4.  **`Extract Text from PDF File`**\n    * **Type:** Extract From File\n    * **What it does:** This utility node takes the binary PDF file downloaded in the previous step and extracts all the readable text content from it. The output is a single block of plain text.\n\n5.  **`Splitting into Chunks`**\n    * **Type:** Code\n    * **What it does:** This node runs a small JavaScript snippet. It takes the large block of text from the PDF and chops it into smaller, more manageable pieces, or **\"chunks,\"** each of a **predefined length**. This is critical because AI models work more effectively with smaller, focused pieces of text.\n\n6.  **`Embedding Uploaded document`**\n    * **Type:** HTTP Request\n    * **What it does:** This is a key AI step. It sends each individual text chunk to an embeddings API. A **specified AI model** converts the semantic meaning of the chunk into a numerical list called an **embedding** or vector. This vector is like a mathematical fingerprint of the text's meaning.\n\n7.  **`Save the embedding in DB`**\n    * **Type:** Supabase\n    * **What it does:** This node connects to your Supabase database. For every chunk, it creates a new row in a **specified table** and stores two important pieces of information: the original text chunk and its corresponding numerical embedding (its \"fingerprint\") from the previous step.\n\n***\n\n### Part 2: Answering Questions via Chat\n\nThis second sequence starts when a user sends a message. It uses the knowledge stored in the database to find relevant information and generate an intelligent answer.\n\n1.  **`When chat message received`**\n    * **Type:** Chat Trigger\n    * **What it does:** This node starts the second part of the workflow. It listens for any incoming message from a user in a connected chat application.\n\n2.  **`Embend User Message`**\n    * **Type:** HTTP Request\n    * **What it does:** This node takes the user's question and sends it to the *exact same* embeddings API and model used in Part 1. This converts the question's meaning into the same kind of numerical vector or \"fingerprint.\"\n\n3.  **`Search Embeddings`**\n    * **Type:** HTTP Request\n    * **What it does:** This is the \"retrieval\" step. It calls a **custom database function** in Supabase. It sends the question's embedding to this function and asks it to search the knowledge base table to find a **specified number of top text chunks** whose embeddings are mathematically most similar to the question's embedding.\n\n4.  **`Aggregate`**\n    * **Type:** Aggregate\n    * **What it does:** The search from the previous step returns multiple separate items. This utility node simply bundles those items into a single, combined piece of data. This makes it easier to feed all the context into the final AI model at once.\n\n5.  **`AI Agent` & `Google Gemini Chat Model`**\n    * **Type:** LangChain Agent & AI Model\n    * **What it does:** This is the \"generation\" step where the final answer is created.\n        * The **`AI Agent`** node is given a detailed set of instructions (a prompt).\n        * The prompt tells the **`Google Gemini Chat Model`** to act as a professional support agent.\n        * Crucially, it provides the AI with the user's original question and the **aggregated text chunks** from the `Aggregate` node as its **only source of truth**.\n        * It then instructs the AI to formulate an answer based *only* on that provided context, format it for a **specific chat style**, and to say \"I don't know\" if the answer cannot be found in the chunks. This prevents the AI from making things up.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Splitting into Chunks",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Embedding Uploaded document",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Save the embedding in DB",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Search Embeddings",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Embend User Message",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Extract Text from PDF File",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "JotForm Trigger",
      "type": "n8n-nodes-base.jotFormTrigger",
      "role": "jotFormTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Grab New knowledgebase",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Grab the uploaded knowledgebase file link",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    }
  ]
}