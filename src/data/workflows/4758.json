{
  "id": 4758,
  "slug": "4758",
  "title": "Perplexity-style iterative research with Gemini and Google Search",
  "description": "# AI Comprehensive Research on User's Query with Gemini and Web Search\n\n## What is this?\nPerform comprehensive research on a user's query by dynamically generating search terms, querying the web using Google Search (by Gemini) , reflecting on the results to identify knowledge gaps, and iteratively refining its search until it can provide a well-supported answer with citations. (like Perplexity)\n\nThis workflow is a reproduction of `gemini-fullstack-langgraph-quickstart` in **N8N**.\n\nThe [`gemini‚Äëfullstack‚Äëlanggraph‚Äëquickstart`](https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart) is a demo by the Google‚ÄëGemini team that showcases how to build a powerful full‚Äëstack AI agent using Gemini and LangGraph\n\n\n## How It Works\n\n### Generate Query üí¨\n- generates one or more search queries tasks based on the User's question.\n- uses Gemini 2.0 Flash\n\n### Web Research üåê\n- execute web search tasks using the native Google Search API tool in combination with Gemini 2.0 Flash.\n\n### Reflection üìö\n- Identifies knowledge gaps and generates potential follow-up queries. \n\n\n## Setup\n\n1. **Configure API Credentials:**\n   - Create Google Gemini(PaLM) Api Credential using you own Gemini key\n   - Connect the credential with three nodes: `Google Gemini Chat Model` and `GeminiSearch` and `reflection`\n\n2. **Configure Redis Source:**\n   - prepare a Redis service that can be accessed by n8n\n   - Create Redis Crediential and connect it with all Redis node\n\n## Customize\n\n- Try using different Gemini models.\n- Try modifying the parameters `number_of_initial_queries` and `max_research_loops`.\n\n\n\n## Why use Redis?\n\nUse Redis as an external storage to maintain global variables (counter, search results, etc.)\n\nThis workflow contains a loop process, which need global variables (as `State` in LangGraph).\n\nIt is difficult to achieve global variables management without external storage in n8n.\n",
  "featuredImage": "/data/workflows/4758/4758.webp",
  "author": {
    "id": 101,
    "slug": "coze",
    "name": "slow-groovin@api2o.com",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1325,
  "downloads": 132,
  "createdAt": "2025-06-07T15:02:56.126Z",
  "updatedAt": "2026-01-16T08:36:03.689Z",
  "publishedAt": "2025-06-07T15:02:56.126Z",
  "nodes": 37,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4758",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Perplexity-style iterative research with Gemini and Google Search",
    "workflowName": "Perplexity-style iterative research with Gemini and Google Search",
    "description": "# AI Comprehensive Research on User's Query with Gemini and Web Search\n\n## What is this?\nPerform comprehensive research on a user's query by dynamically generating search terms, querying the web using Google Search (by Gemini) , reflecting on the results to identify knowledge gaps, and iteratively refining its search until it can provide a well-supported answer with citations. (like Perplexity)\n\nThis workflow is a reproduction of `gemini-fullstack-langgraph-quickstart` in **N8N**.\n\nThe [`gemini‚Äëfullstack‚Äëlanggraph‚Äëquickstart`](https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart) is a demo by the Google‚ÄëGemini team that showcases how to build a powerful full‚Äëstack AI agent using Gemini and LangGraph\n\n\n## How It Works\n\n### Generate Query üí¨\n- generates one or more search queries tasks based on the User's question.\n- uses Gemini 2.0 Flash\n\n### Web Research üåê\n- execute web search tasks using the native Google Search API tool in combination with Gemini 2.0 Flash.\n\n### Reflection üìö\n- Identifies knowledge gaps and generates potential follow-up queries. \n\n\n## Setup\n\n1. **Configure API Credentials:**\n   - Create Google Gemini(PaLM) Api Credential using you own Gemini key\n   - Connect the credential with three nodes: `Google Gemini Chat Model` and `GeminiSearch` and `reflection`\n\n2. **Configure Redis Source:**\n   - prepare a Redis service that can be accessed by n8n\n   - Create Redis Crediential and connect it with all Redis node\n\n## Customize\n\n- Try using different Gemini models.\n- Try modifying the parameters `number_of_initial_queries` and `max_research_loops`.\n\n\n\n## Why use Redis?\n\nUse Redis as an external storage to maintain global variables (counter, search results, etc.)\n\nThis workflow contains a loop process, which need global variables (as `State` in LangGraph).\n\nIt is difficult to achieve global variables management without external storage in n8n.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Configs",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "generate_query",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "attach index as id",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "web_search",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "merge web_search_result",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "history_web_research_result",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "history_web_research_result1",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "history_sources_gathered",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "research_loop_count",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "retrieve value",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "If finish",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "search_query",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "number_of_ran_queries",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "GeminiSearch",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Build reflection request body",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "reflection",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "reflection_output_parse",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "finalize_answer",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "get:history_sources_gathered",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "format answer",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "web_search step record",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "push web_search step record",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "push reflection step",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "get:steps",
      "type": "n8n-nodes-base.redis",
      "role": "redis",
      "configDescription": "Version 1"
    },
    {
      "name": "set search_query",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}