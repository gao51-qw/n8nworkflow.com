{
  "id": 8790,
  "slug": "8790",
  "title": "A/B test AI prompts with Supabase, Langchain Agent & OpenAI GPT-4o",
  "description": "\n![n8n.png](fileId:2666)\n## Split Test AI Prompts Using Supabase & Langchain Agent\n\nThis workflow allows you to A/B test different prompts for an AI chatbot powered by Langchain and OpenAI. It uses Supabase to persist session state and randomly assigns users to either a baseline or alternative prompt, ensuring consistent prompt usage across the conversation.\n\n### üß† Use Case\n\nPrompt optimization is crucial for maximizing the performance of AI assistants. This workflow helps you run controlled experiments on different prompt versions, giving you a reliable way to compare performance over time.\n\n### ‚öôÔ∏è How It Works\n\n1. When a message is received, the system checks whether the session already exists in the Supabase table.\n2. If not, it randomly assigns the session to either the baseline or alternative prompt.\n3. The selected prompt is passed into a Langchain Agent using the OpenAI Chat Model.\n4. Postgres is used as chat memory for multi-turn conversation support.\n\n### üß™ Features\n\n- Randomized A/B split test per session\n- Supabase database for session persistence\n- Langchain Agent + OpenAI GPT-4o integration\n- PostgreSQL memory for maintaining chat context\n- Fully documented with sticky notes\n\n### üõ†Ô∏è Setup Instructions\n\n1. Create a Supabase table named `split_test_sessions` with the following columns:\n   - `session_id` (text)\n   - `show_alternative` (boolean)\n2. Add credentials for:\n   - Supabase\n   - OpenAI\n   - PostgreSQL (for chat memory)\n3. Modify the **\"Define Path Values\"** node to set your baseline and alternative prompts.\n4. Activate the workflow.\n5. Send messages to test both prompt paths in action.\n\n### üîÑ Next Steps\n\n- Add tracking for conversions or feedback scores to compare outcomes.\n- Modify the prompt content or model settings (e.g. temperature, model version).\n- Expand to multi-variant tests beyond A/B.\n\n\n### üìö Learn More\n\n- [How This Workflow Uses Supabase + OpenAI for Prompt Testing](https://banana-ai.art/blog/ab-test-ai-prompts)",
  "featuredImage": "/data/workflows/8790/8790.webp",
  "author": {
    "id": 101,
    "slug": "vanhon",
    "name": "vanhon",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 179,
  "downloads": 17,
  "createdAt": "2025-09-21T04:38:21.415Z",
  "updatedAt": "2026-01-16T08:57:41.891Z",
  "publishedAt": "2025-09-21T04:38:21.415Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/8790",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "A/B test AI prompts with Supabase, Langchain Agent & OpenAI GPT-4o",
    "workflowName": "A/B test AI prompts with Supabase, Langchain Agent & OpenAI GPT-4o",
    "description": "![n8n.png](fileId:2666)\n## Split Test AI Prompts Using Supabase & Langchain Agent\n\nThis workflow allows you to A/B test different prompts for an AI chatbot powered by Langchain and OpenAI. It uses Supabase to persist session state and randomly assigns users to either a baseline or alternative prompt, ensuring consistent prompt usage across the conversation.\n\n### üß† Use Case\n\nPrompt optimization is crucial for maximizing the performance of AI assistants. This workflow helps you run controlled experiments on different prompt versions, giving you a reliable way to compare performance over time.\n\n### ‚öôÔ∏è How It Works\n\n1. When a message is received, the system checks whether the session already exists in the Supabase table.\n2. If not, it randomly assigns the session to either the baseline or alternative prompt.\n3. The selected prompt is passed into a Langchain Agent using the OpenAI Chat Model.\n4. Postgres is used as chat memory for multi-turn conversation support.\n\n### üß™ Features\n\n- Randomized A/B split test per session\n- Supabase database for session persistence\n- Langchain Agent + OpenAI GPT-4o integration\n- PostgreSQL memory for maintaining chat context\n- Fully documented with sticky notes\n\n### üõ†Ô∏è Setup Instructions\n\n1. Create a Supabase table named `split_test_sessions` with the following columns:\n   - `session_id` (text)\n   - `show_alternative` (boolean)\n2. Add credentials for:\n   - Supabase\n   - OpenAI\n   - PostgreSQL (for chat memory)\n3. Modify the **\"Define Path Values\"** node to set your baseline and alternative prompts.\n4. Activate the workflow.\n5. Send messages to test both prompt paths in action.\n\n### üîÑ Next Steps\n\n- Add tracking for conversions or feedback scores to compare outcomes.\n- Modify the prompt content or model settings (e.g. temperature, model version).\n- Expand to multi-variant tests beyond A/B.\n\n\n### üìö Learn More\n\n- [How This Workflow Uses Supabase + OpenAI for Prompt Testing](https://banana-ai.art/blog/ab-test-ai-prompts)",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Check If Session Exists",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "If Session Does Exist",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Assign Path To Session",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Define Path Values",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Postgres Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "role": "memoryPostgresChat",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Get Correct Prompt",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}