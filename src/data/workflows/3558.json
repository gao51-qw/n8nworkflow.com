{
  "id": 3558,
  "slug": "3558",
  "title": "Autonomous customizable support chatbot on Intercom + Discord thread reports",
  "description": "**[Click here to access this Workflow for free](https://www.bonzai.pro/auth?action=buyPrice%2Cpri_NdDM_5249)**.\n\n---\n\n# Connect your own LLM-boosted chatbot to Intercom (f*** their overly priced FlN Agent), and stay in touch on Discord\n![ic.png](fileId:1731)\n\nThis workflow connects your Intercom chat system with your own AI Agent and sends a complete log of each conversation to Discord using threads. It allows you to run a fully automated support system while maintaining full visibility of the bot's behavior in real time.\n\nFor every new conversation in Intercom, a thread is created in a specified Discord channel. Each message from the user, the AI, and even manual human responses is logged to the thread, offering full traceability and transparency.\n\nYou also have fine-grained control over the AI agent. By simply clicking the ⭐️ star in Intercom’s UI, support agents can instantly pause or resume AI responses for a specific chat — no coding or config changes needed.\n\n---\n\n## Requirements\n\n- A working n8n instance\n- An Intercom account with permission to set up webhooks\n- A Discord bot with the following permissions:\n  - `Send Messages`\n  - `Create Public/Private Threads`\n  - `Manage Threads`\n- API credentials for your preferred LLM (OpenAI is used by default)\n- Google Chrome or any browser to access Intercom’s UI\n\n---\n\n## Setup\n\n1. **Intercom:**\n   - Go to Intercom’s webhook settings.\n   - Add a webhook that listens to new incoming messages and points to the Webhook URL in this n8n workflow.\n   - Make sure to send full conversation data.\n\n2. **Discord:**\n   - Create a Discord bot and invite it to your server with the required permissions.\n   - In the Discord + Token node at the top of the workflow:\n     - Add your bot token\n     - Add the ID of the channel where threads should be created\n\n3. **LLM / AI Agent:**\n   - By default, the workflow uses OpenAI via HTTP Request.\n   - You can substitute it with any LLM provider of your choice.\n   - Make sure to set up your credentials in n8n and select them in the HTTP nodes.\n\n4. **HTTP Authentication Tips:**\n   - For both Intercom and Discord API calls, it's recommended to create credentials in n8n's Credential Manager.\n   - Then, assign those credentials inside each HTTP Request node for a cleaner setup.\n\n---\n\n## Usage\n\n- When a new conversation starts in Intercom, a Discord thread is created automatically.\n- Each message — user input, AI response, and human reply — is logged into the Discord thread in real time.\n- The AI replies automatically **unless the ⭐️ star is checked** in Intercom:\n  - ☆ **Unchecked** = AI replies **enabled**\n  - ⭐️ **Checked** = AI replies **disabled**, human takeover enabled\n\n![screenshot intercoms inbox.png](fileId:1116)\n\nThis gives you on-the-fly control of each conversation’s automation level directly from the Intercom inbox.\n\n---\n\n## Customization\n\n- You can replace OpenAI with any LLM that provides a compatible API.\n- Discord channel ID, thread naming, and message formatting can be customized to match your team’s preferences.\n- You can expand the workflow to handle events like conversation closure or satisfaction ratings for deeper analytics.\n\n---\n### If you need any help, or have any question, feel free to come discuss about it on **[Telegram](https://www.bonzai.pro/theo_marcadet/lp/7018)** \n",
  "featuredImage": "/data/workflows/3558/3558.webp",
  "author": {
    "id": 101,
    "slug": "theomarcadet",
    "name": "Theo Marcadet",
    "avatar": ""
  },
  "categories": [
    "Support Chatbot",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 569,
  "downloads": 56,
  "createdAt": "2025-04-15T09:29:57.081Z",
  "updatedAt": "2026-01-16T08:30:19.111Z",
  "publishedAt": "2025-04-15T09:29:57.081Z",
  "nodes": 58,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3558",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Autonomous customizable support chatbot on Intercom + Discord thread reports",
    "workflowName": "Autonomous customizable support chatbot on Intercom + Discord thread reports",
    "description": "**[Click here to access this Workflow for free](https://www.bonzai.pro/auth?action=buyPrice%2Cpri_NdDM_5249)**.\n\n---\n\n# Connect your own LLM-boosted chatbot to Intercom (f*** their overly priced FlN Agent), and stay in touch on Discord\n![ic.png](fileId:1731)\n\nThis workflow connects your Intercom chat system with your own AI Agent and sends a complete log of each conversation to Discord using threads. It allows you to run a fully automated support system while maintaining full visibility of the bot's behavior in real time.\n\nFor every new conversation in Intercom, a thread is created in a specified Discord channel. Each message from the user, the AI, and even manual human responses is logged to the thread, offering full traceability and transparency.\n\nYou also have fine-grained control over the AI agent. By simply clicking the ⭐️ star in Intercom’s UI, support agents can instantly pause or resume AI responses for a specific chat — no coding or config changes needed.\n\n---\n\n## Requirements\n\n- A working n8n instance\n- An Intercom account with permission to set up webhooks\n- A Discord bot with the following permissions:\n  - `Send Messages`\n  - `Create Public/Private Threads`\n  - `Manage Threads`\n- API credentials for your preferred LLM (OpenAI is used by default)\n- Google Chrome or any browser to access Intercom’s UI\n\n---\n\n## Setup\n\n1. **Intercom:**\n   - Go to Intercom’s webhook settings.\n   - Add a webhook that listens to new incoming messages and points to the Webhook URL in this n8n workflow.\n   - Make sure to send full conversation data.\n\n2. **Discord:**\n   - Create a Discord bot and invite it to your server with the required permissions.\n   - In the Discord + Token node at the top of the workflow:\n     - Add your bot token\n     - Add the ID of the channel where threads should be created\n\n3. **LLM / AI Agent:**\n   - By default, the workflow uses OpenAI via HTTP Request.\n   - You can substitute it with any LLM provider of your choice.\n   - Make sure to set up your credentials in n8n and select them in the HTTP nodes.\n\n4. **HTTP Authentication Tips:**\n   - For both Intercom and Discord API calls, it's recommended to create credentials in n8n's Credential Manager.\n   - Then, assign those credentials inside each HTTP Request node for a cleaner setup.\n\n---\n\n## Usage\n\n- When a new conversation starts in Intercom, a Discord thread is created automatically.\n- Each message — user input, AI response, and human reply — is logged into the Discord thread in real time.\n- The AI replies automatically **unless the ⭐️ star is checked** in Intercom:\n  - ☆ **Unchecked** = AI replies **enabled**\n  - ⭐️ **Checked** = AI replies **disabled**, human takeover enabled\n\n![screenshot intercoms inbox.png](fileId:1116)\n\nThis gives you on-the-fly control of each conversation’s automation level directly from the Intercom inbox.\n\n---\n\n## Customization\n\n- You can replace OpenAI with any LLM that provides a compatible API.\n- Discord channel ID, thread naming, and message formatting can be customized to match your team’s preferences.\n- You can expand the workflow to handle events like conversation closure or satisfaction ratings for deeper analytics.\n\n---\n### If you need any help, or have any question, feel free to come discuss about it on **[Telegram](https://www.bonzai.pro/theo_marcadet/lp/7018)**",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "If2",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Intercom Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2"
    },
    {
      "name": "Whether it is a new conversation or not",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "[Intercom] GET conversation",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Discord] Create Thread",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Discord] Type first message into the thread",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Intercom] Store the thread ID as a 'note'",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Isolating the 'note' to get the thread ID stored",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Isolating all textual messages contents",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "conversation -> JSON",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "conversation info -> JSON",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "not going through if bot deactivated",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "sorting data (cuz we join 2 different flows here)",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "preparing data for Agentic use",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "[Discord] Reply",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Intercom] Reply",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Discord] Notify bot re-activation notification",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Discord] Notify bot de-activation",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Discord] User message",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "[Discord] Human admin reply ",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Tokens and Ids",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note9",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Prevents from running when event is 'bot reply'",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note10",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note12",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note13",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "new conversation prepared data",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "conversation prepared data",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3"
    },
    {
      "name": "Sticky Note14",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note15",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note16",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note11",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note17",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note18",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note19",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note20",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note21",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate1",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note24",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Get a lead",
      "type": "n8n-nodes-base.intercom",
      "role": "intercom",
      "configDescription": "Version 1"
    },
    {
      "name": "Get a lead1",
      "type": "n8n-nodes-base.intercom",
      "role": "intercom",
      "configDescription": "Version 1"
    },
    {
      "name": "Get a lead2",
      "type": "n8n-nodes-base.intercom",
      "role": "intercom",
      "configDescription": "Version 1"
    },
    {
      "name": "Get a lead3",
      "type": "n8n-nodes-base.intercom",
      "role": "intercom",
      "configDescription": "Version 1"
    }
  ]
}