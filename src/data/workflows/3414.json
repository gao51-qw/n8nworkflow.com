{
  "id": 3414,
  "slug": "3414",
  "title": "Slack AI chatbot for business team with RAG, Claude 3.7 Sonnet and Google Drive",
  "description": "Imagine having an **AI chatbot on Slack** that seamlessly integrates with your company’s workflow, **automating repetitive requests**. No more digging through emails or documents to find answers about IT requests, company policies, or vacation days—just ask the bot, and it will instantly provide the right information.  \n\nWith its **24/7 availability**, the chatbot ensures that team members get immediate support without waiting for a colleague to be online, making assistance faster and more efficient.  \n\nMoreover, this AI-powered bot serves as a **central hub for internal communication**, allowing everyone to quickly access procedures, documents, and company knowledge without searching manually. A simple Slack message is all it takes to get the information you need, enhancing productivity and collaboration across teams.\n\n-----\n\n#### **How It Works**  \n1. **Slack Trigger**: The workflow starts when a user mentions the AI bot in a Slack channel. The trigger captures the message and forwards it to the AI Agent.  \n2. **AI Agent Processing**:  \n   - The AI Agent, powered by Anthropic's Claude 3.7 Sonnet model, processes the query.  \n   - It uses **Retrieval-Augmented Generation (RAG)** to fetch relevant information from the company’s internal knowledge base stored in Qdrant (a vector database).  \n   - A **Simple Memory** buffer retains recent conversation context (last 10 messages) for continuity.  \n3. **Knowledge Retrieval**:  \n   - The RAG tool searches Qdrant’s vector store using OpenAI embeddings to find the most relevant document chunks (top 10 matches).  \n4. **Response Generation**:  \n   - The AI synthesizes the retrieved data into a concise, structured response (1-2 sentences for the answer, 2-3 supporting details, and a source citation).  \n   - The response is formatted in Slack-friendly markdown (bullet points, blockquotes) and sent back to the user.  \n\n---  \n\n#### **Set Up Steps**  \n1. **Prepare Qdrant Vector Database**:  \n   - Create a Qdrant collection via HTTP request (`Create collection` node).  \n   - Optionally, refresh/clear the collection (`Refresh collection` node) before adding new documents.  \n2. **Load Company Documents**:  \n   - Fetch files from a Google Drive folder (`Get folder` → `Download Files`).  \n   - Process documents: Split text into chunks (`Token Splitter`) and generate embeddings (`Embeddings OpenAI2`).  \n   - Store embeddings in Qdrant (`Qdrant Vector Store1`).  \n3. **Configure Slack Bot**:  \n   - Create a Slack bot via Slack API with required permissions\n   - Add the bot to the desired Slack channel and note the `channelId` for the workflow.  \n4. **Deploy AI Components**:  \n   - Connect the AI Agent to Anthropic’s model, RAG tool, and memory buffer.  \n   - Ensure OpenAI embeddings are configured for both RAG and document processing.  \n5. **Test & Activate**:  \n   - Use the manual trigger (`When clicking ‘Test workflow’`) to validate document ingestion.  \n   - Activate the workflow to enable real-time Slack interactions.  \n\n----\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
  "featuredImage": "/data/workflows/3414/3414.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI Chatbot"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 9431,
  "downloads": 943,
  "createdAt": "2025-04-03T07:33:30.762Z",
  "updatedAt": "2026-01-16T08:29:38.327Z",
  "publishedAt": "2025-04-03T07:33:30.762Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3414",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Slack AI chatbot for business team with RAG, Claude 3.7 Sonnet and Google Drive",
    "workflowName": "Slack AI chatbot for business team with RAG, Claude 3.7 Sonnet and Google Drive",
    "description": "Imagine having an **AI chatbot on Slack** that seamlessly integrates with your company’s workflow, **automating repetitive requests**. No more digging through emails or documents to find answers about IT requests, company policies, or vacation days—just ask the bot, and it will instantly provide the right information.  \n\nWith its **24/7 availability**, the chatbot ensures that team members get immediate support without waiting for a colleague to be online, making assistance faster and more efficient.  \n\nMoreover, this AI-powered bot serves as a **central hub for internal communication**, allowing everyone to quickly access procedures, documents, and company knowledge without searching manually. A simple Slack message is all it takes to get the information you need, enhancing productivity and collaboration across teams.\n\n-----\n\n#### **How It Works**  \n1. **Slack Trigger**: The workflow starts when a user mentions the AI bot in a Slack channel. The trigger captures the message and forwards it to the AI Agent.  \n2. **AI Agent Processing**:  \n   - The AI Agent, powered by Anthropic's Claude 3.7 Sonnet model, processes the query.  \n   - It uses **Retrieval-Augmented Generation (RAG)** to fetch relevant information from the company’s internal knowledge base stored in Qdrant (a vector database).  \n   - A **Simple Memory** buffer retains recent conversation context (last 10 messages) for continuity.  \n3. **Knowledge Retrieval**:  \n   - The RAG tool searches Qdrant’s vector store using OpenAI embeddings to find the most relevant document chunks (top 10 matches).  \n4. **Response Generation**:  \n   - The AI synthesizes the retrieved data into a concise, structured response (1-2 sentences for the answer, 2-3 supporting details, and a source citation).  \n   - The response is formatted in Slack-friendly markdown (bullet points, blockquotes) and sent back to the user.  \n\n---  \n\n#### **Set Up Steps**  \n1. **Prepare Qdrant Vector Database**:  \n   - Create a Qdrant collection via HTTP request (`Create collection` node).  \n   - Optionally, refresh/clear the collection (`Refresh collection` node) before adding new documents.  \n2. **Load Company Documents**:  \n   - Fetch files from a Google Drive folder (`Get folder` → `Download Files`).  \n   - Process documents: Split text into chunks (`Token Splitter`) and generate embeddings (`Embeddings OpenAI2`).  \n   - Store embeddings in Qdrant (`Qdrant Vector Store1`).  \n3. **Configure Slack Bot**:  \n   - Create a Slack bot via Slack API with required permissions\n   - Add the bot to the desired Slack channel and note the `channelId` for the workflow.  \n4. **Deploy AI Components**:  \n   - Connect the AI Agent to Anthropic’s model, RAG tool, and memory buffer.  \n   - Ensure OpenAI embeddings are configured for both RAG and document processing.  \n5. **Test & Activate**:  \n   - Use the manual trigger (`When clicking ‘Test workflow’`) to validate document ingestion.  \n   - Activate the workflow to enable real-time Slack interactions.  \n\n----\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "RAG",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Calculator",
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "role": "toolCalculator",
      "configDescription": "Version 1"
    },
    {
      "name": "Get message",
      "type": "n8n-nodes-base.slackTrigger",
      "role": "slackTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Send message",
      "type": "n8n-nodes-base.slack",
      "role": "slack",
      "configDescription": "Version 2.3"
    },
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Create collection",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Refresh collection",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Get folder",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Download Files",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Token Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterTokenSplitter",
      "role": "textSplitterTokenSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Qdrant Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Anthropic Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "role": "lmChatAnthropic",
      "configDescription": "Version 1.3"
    }
  ]
}