{
  "id": 7413,
  "slug": "7413",
  "title": "IPL cricket rules Q&A chat bot using RAG and Google Gemini API",
  "description": "## This workflow has 2 Broad Steps\n## Step 1 - Vector store creation with set of ipl rules using Google Gemini Embedding. This will we used to drive RAG for model grouding    \n## Step 2 - Connecting the vector store with google gemini API model and enabling a chat interface to drive the chat bot\n\n## Step 1\n## Load the reference material (run once via the Manual Trigger)\n## 1.1 Manual Trigger → HTTP Request downloads the IPL “Match Playing Conditions” PDF. \n## 1.2 Default Data Loader extracts text from the PDF.\n   **Type of data is binary\n## 1.3 Recursive Character Text Splitter breaks the text into overlapping chunks.\n   **This step ensures that the data chunks that are created in vector store have some overlap and hence less chance of hallucination\n   **Chunk size and chunk overlap are 2 variables to manage this \n## 1.4 Embeddings Google Gemini (1) converts each chunk to a vector.\n   **Connect the model with google gemini model. You will need your own api key for this\n   **Make note of the embedding model also since the same embedding model has to be selected in Step 2\n## 1.5 Simple Vector Store 1 inserts those vectors into an in-memory store under key\n   **Make note of the vector store name since it is same vector store you will have to use in Step 2\n\n\n## Note: Google gemini API key credential needed\n##Using Vector store nodes provided by n8n is the best way to get started to test out the workflow before you switch to more enterprise grade vector store nodes\n\n## Step 2\n## 2.1 Chat Trigger to initiate n8n native chat interface\n## 2.2 Simple Memory keeps the last 20 chat turns for context. This value can be edited within the node\n## 2.3 Simple Vector Store (retrieve-as-tool mode) receives the user’s query embedding, \n## finds the top-10 most relevant chunks stored in step 1, and supplies them as tool output. This will drive RAG\n**The name of vector store should match from Step 1, the embedding rule should match step 1\n## 2.4 Google Gemini Chat Model is the language model that is used as the llm model\n## 2.5 AI Agent orchestrates everything:\n** Uses the system prompt (“You are a cricket expert… If info is missing, say ‘Sorry I don’t know’”). to prompt the model\n** Has access to the memory (2.2) and the RAG tool (2.3).\n** Generates the final response with Google Gemini, strictly limited to the retrieved IPL cricket rules data.\n\n\n\n\n\n\n## Note: Google gemini API key credential needed\n##Using simple memory store nodes provided by n8n is the best way to get started to test out the workflow before you switch to more enterprise grade vector store nodes",
  "featuredImage": "/data/workflows/7413/7413.webp",
  "author": {
    "id": 101,
    "slug": "p10siddarthap",
    "name": "Sidd",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 966,
  "downloads": 96,
  "createdAt": "2025-08-15T05:27:38.602Z",
  "updatedAt": "2026-01-16T08:50:14.536Z",
  "publishedAt": "2025-08-15T05:27:38.602Z",
  "nodes": 24,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7413",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "IPL cricket rules Q&A chat bot using RAG and Google Gemini API",
    "workflowName": "IPL cricket rules Q&A chat bot using RAG and Google Gemini API",
    "description": "## This workflow has 2 Broad Steps\n## Step 1 - Vector store creation with set of ipl rules using Google Gemini Embedding. This will we used to drive RAG for model grouding    \n## Step 2 - Connecting the vector store with google gemini API model and enabling a chat interface to drive the chat bot\n\n## Step 1\n## Load the reference material (run once via the Manual Trigger)\n## 1.1 Manual Trigger → HTTP Request downloads the IPL “Match Playing Conditions” PDF. \n## 1.2 Default Data Loader extracts text from the PDF.\n   **Type of data is binary\n## 1.3 Recursive Character Text Splitter breaks the text into overlapping chunks.\n   **This step ensures that the data chunks that are created in vector store have some overlap and hence less chance of hallucination\n   **Chunk size and chunk overlap are 2 variables to manage this \n## 1.4 Embeddings Google Gemini (1) converts each chunk to a vector.\n   **Connect the model with google gemini model. You will need your own api key for this\n   **Make note of the embedding model also since the same embedding model has to be selected in Step 2\n## 1.5 Simple Vector Store 1 inserts those vectors into an in-memory store under key\n   **Make note of the vector store name since it is same vector store you will have to use in Step 2\n\n\n## Note: Google gemini API key credential needed\n##Using Vector store nodes provided by n8n is the best way to get started to test out the workflow before you switch to more enterprise grade vector store nodes\n\n## Step 2\n## 2.1 Chat Trigger to initiate n8n native chat interface\n## 2.2 Simple Memory keeps the last 20 chat turns for context. This value can be edited within the node\n## 2.3 Simple Vector Store (retrieve-as-tool mode) receives the user’s query embedding, \n## finds the top-10 most relevant chunks stored in step 1, and supplies them as tool output. This will drive RAG\n**The name of vector store should match from Step 1, the embedding rule should match step 1\n## 2.4 Google Gemini Chat Model is the language model that is used as the llm model\n## 2.5 AI Agent orchestrates everything:\n** Uses the system prompt (“You are a cricket expert… If info is missing, say ‘Sorry I don’t know’”). to prompt the model\n** Has access to the memory (2.2) and the RAG tool (2.3).\n** Generates the final response with Google Gemini, strictly limited to the retrieved IPL cricket rules data.\n\n\n\n\n\n\n## Note: Google gemini API key credential needed\n##Using simple memory store nodes provided by n8n is the best way to get started to test out the workflow before you switch to more enterprise grade vector store nodes",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Simple Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings Google Gemini",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Simple Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings Google Gemini1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "role": "embeddingsGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note9",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note10",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note11",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}