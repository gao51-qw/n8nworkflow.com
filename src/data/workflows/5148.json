{
  "id": 5148,
  "slug": "5148",
  "title": "Local chatbot with retrieval augmented generation (RAG)",
  "description": "## Build a 100% local RAG with n8n, Ollama and Qdrant. This agent uses a semantic database (Qdrant) to answer questions about PDF files.\n\n## Tutorial\n![thumbnail.png](fileId:1589)\n[Click here to view the YouTube Tutorial](https://youtu.be/maZ_fF57yhE)\n\n## How it works\nBuild a chatbot that answers based on documents you provide it (Retrieval Augmented Generation). You can upload as many PDF files as you want to the Qdrant database. The chatbot will use its retrieval tool to fetch the chunks and use them to answer questions.\n\n## Installation\n1. Install n8n + Ollama + Qdrant using the [Self-hosted AI starter kit](https://github.com/n8n-io/self-hosted-ai-starter-kit)\n2. Make sure to install Llama 3.2 and mxbai-embed-large as embeddings model.\n\n## How to use it\n1. First run the \"Data Ingestion\" part and upload as many PDF files as you want\n2. Run the Chatbot and start asking questions about the documents you uploaded\n",
  "featuredImage": "/data/workflows/5148/5148.webp",
  "author": {
    "id": 101,
    "slug": "thomasjanssen-tech",
    "name": "Thomas Janssen",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 94542,
  "downloads": 9454,
  "createdAt": "2025-06-23T10:40:17.187Z",
  "updatedAt": "2026-01-16T08:37:55.721Z",
  "publishedAt": "2025-06-23T10:40:17.187Z",
  "nodes": 13,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5148",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Local chatbot with retrieval augmented generation (RAG)",
    "workflowName": "Local chatbot with retrieval augmented generation (RAG)",
    "description": "## Build a 100% local RAG with n8n, Ollama and Qdrant. This agent uses a semantic database (Qdrant) to answer questions about PDF files.\n\n## Tutorial\n![thumbnail.png](fileId:1589)\n[Click here to view the YouTube Tutorial](https://youtu.be/maZ_fF57yhE)\n\n## How it works\nBuild a chatbot that answers based on documents you provide it (Retrieval Augmented Generation). You can upload as many PDF files as you want to the Qdrant database. The chatbot will use its retrieval tool to fetch the chunks and use them to answer questions.\n\n## Installation\n1. Install n8n + Ollama + Qdrant using the [Self-hosted AI starter kit](https://github.com/n8n-io/self-hosted-ai-starter-kit)\n2. Make sure to install Llama 3.2 and mxbai-embed-large as embeddings model.\n\n## How to use it\n1. First run the \"Data Ingestion\" part and upload as many PDF files as you want\n2. Run the Chatbot and start asking questions about the documents you uploaded",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "On form submission",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings Ollama",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "role": "embeddingsOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Ollama Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "role": "lmChatOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Qdrant Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings Ollama1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "role": "embeddingsOllama",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}