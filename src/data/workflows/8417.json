{
  "id": 8417,
  "slug": "8417",
  "title": "Scrape targeted leads from Google Maps & LinkedIn to Supabase using Apify",
  "description": "![Screenshot 20250912 090637.png](fileId:2619)\n\n## Who's it for\nThis template is perfect for sales teams, marketing professionals, recruiters, and business development specialists who need to efficiently collect targeted lead data from multiple sources. Whether you're building prospect lists, conducting market research, or expanding your contact database, this automated solution saves hours of manual data collection.\n\n## How it works\nThe workflow uses an n8n built-in form to collect search parameters, then automatically scrapes targeted leads from Google Maps and/or LinkedIn within Apify Actors based on your criteria. All collected data is cleaned, structured using Edit field nodes, and stored in your Supabase database for easy access and analysis.\n\n## Key features:\n- Interactive form for easy lead targeting\n- Dual-source scraping (Google Maps + LinkedIn), you choose one or Both.\n- Automatic data collection and cleaning, and structuring from Apify actors.\n- Direct database storage in Supabase\n- Flexible result limits and location targeting.\n\n## How to set up\n\n**Step 1: Set Up Apify Account**\nCreate account at apify.com\nNavigate to Settings &gt; Integrations &gt; API tokens\nCreate new API token and copy it\nEnsure you have access to these actors:\n\nLinkedIn Profile Search Scraper (harvestapi/linkedin-profile-search)\nGoogle Maps Scraper (compass/crawler-google-places)\n\n**Step 2: Configure Supabase Database**\nCreate new project at supabase.com\nGo to SQL Editor in your Supabase dashboard\nRun the SQL scripts from the Requirements section to create tables\nNavigate to Settings &gt; API to copy:\n\nProject URL (starts with https://...)\nService role key (secret key, not anon public)\n\n**Step 3: Import and Configure Workflow**\nDownload the workflow JSON file\nIn n8n Cloud, go to Workflows &gt; Import from File\nSelect the downloaded JSON file\nConfigure credentials by clicking on each node that shows a warning:\n\n**For Apify nodes (linkedin_dataset & googlemaps_dataset):**\nClick \"Create New Credential\"\nName: \"Apify account\"\nAPI Token: [Paste your Apify token from Step 1]\nSave credential\n\nFor Supabase nodes (save_linkedin & save_googlemaps):\n\nClick \"Create New Credential\"\nName: \"Supabase account\"\nHost: [Your Supabase project URL from Step 2]\nService Role Secret: [Your service role key from Step 2]\nSave credential\n\n**Step 4: Test the Workflow**\nClick on the \"On form submission\" node\nCopy the Production URL (webhook link)\nOpen this URL in a new browser tab\nFill out the test form:\n\nTitle/Industry: \"restaurants\"\nLocation: \"San Francisco, CA\"\nSource: \"Google Maps\"\nNumber of results: \"3\"\n\n\nClick Submit and wait for processing\nCheck your Supabase tables to verify data was saved\n\nStep 5: Verify Setup Success\n\nIn Supabase, go to Table Editor\nCheck the googlemaps table for new entries\nVerify all fields are populated correctly\nTest with LinkedIn source to confirm both paths work\n\nThe workflow is designed to be plug-and-play once credentials are configured. Simply share the form URL with your team or bookmark it for regular lead generation tasks.\nHow to customize the workflow\n\n**Search Parameters:**\nModify Apify actor configurations in the dataset nodes\nAdjust search query formats for better targeting\nChange result limits based on your needs\n\n**Data Processing:**\nEdit the Set nodes to extract additional fields\nAdd data validation steps\nImplement duplicate detection logic\n\n**Storage Options:**\nReplace Supabase with other databases (Airtable, PostgreSQL)\nAdd data export to CSV/Excel\nImplement real-time notifications\n\n**Support:**\nCheck [n8n community forum](https://community.n8n.io/) for help\nReview [Apify actor documentation](https://docs.apify.com/platform/actors)\n\nThe workflow is designed to be plug-and-play once credentials are configured. Simply fill out the form with your target criteria and let the automation handle the rest.\n\n## Requirements\n**External Services:** Apify account with credits (for web scraping)\nSupabase account (for data storage)\n\nSupabase Table Schemas:\nLinkedIn Table (LinkedIn):\n```\npublicidentifier (text)\nlinkedinurl (text)\nname (text)\nheadline (text)\nabout (text)\npremium (boolean)\nverified (boolean)\nopenprofile (boolean)\ntopskills (text)\nconnectionscount (integer)\nfollowercount (integer)\nlatest_experience (text)\neducation (text)\n```\nGoogle Maps Table (googlemaps):\n```\ntitle (text)\ncategory_name (text)\naddress (text)\nneighborhood (text)\nstreet (text)\ncity (text)\npostal_code (text)\nstate (text)\ncountry_code (text)\nwebsite (text)\nphone (text)\nphone_unformatted (text)\nlocation (text)\ntotal_score (numeric)\n```\n**Node Requirements:**\n\n- Form Trigger (built-in), you may use others, or a webhook.\n- Switch (built-in)\n- Set (built-in)\n- Supabase (built-in)\n- Apify (community node), you'll have to install it first.\n\n## How to customize the workflow\n**Form Customisation:**\n- Modify form fields in the \"On form submission\" node to add additional search criteria if you want more.\n- You may adjust dropdown options for different lead sources.\n- Add validation rules for better data quality\n\n**Search Parameters:**\n- Customize Apify actor configurations for different scraping behaviours.\n- Modify the number of results per search.\n- Add additional location targeting options\n\n**Data Processing:**\n- Enhance the Set nodes to extract additional LinkedIn profile data\n- Add data validation and cleaning steps\n- Implement duplicate detection logic\n\n**Storage Options:**\n- You may replace Supabase with other databases (Airtable, Google Sheets, etc.)\n- Add data enrichment steps before storage\n- Implement data export functionality\n\n**Advanced Features:**\n- Add email notifications when scraping completes\n- Implement error handling and retry logic\n- Create data quality scoring mechanisms\n\nLet's connect: [TUMUSIME David](https://www.linkedin.com/in/tumusime-david/)",
  "featuredImage": "/data/workflows/8417/8417.webp",
  "author": {
    "id": 101,
    "slug": "tumusime",
    "name": "TUMUSIME David",
    "avatar": ""
  },
  "categories": [
    "Lead Generation"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 524,
  "downloads": 52,
  "createdAt": "2025-09-09T14:02:06.363Z",
  "updatedAt": "2026-01-16T08:55:42.907Z",
  "publishedAt": "2025-09-09T14:02:06.363Z",
  "nodes": 12,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/8417",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Scrape targeted leads from Google Maps & LinkedIn to Supabase using Apify",
    "workflowName": "Scrape targeted leads from Google Maps & LinkedIn to Supabase using Apify",
    "description": "![Screenshot 20250912 090637.png](fileId:2619)\n\n## Who's it for\nThis template is perfect for sales teams, marketing professionals, recruiters, and business development specialists who need to efficiently collect targeted lead data from multiple sources. Whether you're building prospect lists, conducting market research, or expanding your contact database, this automated solution saves hours of manual data collection.\n\n## How it works\nThe workflow uses an n8n built-in form to collect search parameters, then automatically scrapes targeted leads from Google Maps and/or LinkedIn within Apify Actors based on your criteria. All collected data is cleaned, structured using Edit field nodes, and stored in your Supabase database for easy access and analysis.\n\n## Key features:\n- Interactive form for easy lead targeting\n- Dual-source scraping (Google Maps + LinkedIn), you choose one or Both.\n- Automatic data collection and cleaning, and structuring from Apify actors.\n- Direct database storage in Supabase\n- Flexible result limits and location targeting.\n\n## How to set up\n\n**Step 1: Set Up Apify Account**\nCreate account at apify.com\nNavigate to Settings &gt; Integrations &gt; API tokens\nCreate new API token and copy it\nEnsure you have access to these actors:\n\nLinkedIn Profile Search Scraper (harvestapi/linkedin-profile-search)\nGoogle Maps Scraper (compass/crawler-google-places)\n\n**Step 2: Configure Supabase Database**\nCreate new project at supabase.com\nGo to SQL Editor in your Supabase dashboard\nRun the SQL scripts from the Requirements section to create tables\nNavigate to Settings &gt; API to copy:\n\nProject URL (starts with https://...)\nService role key (secret key, not anon public)\n\n**Step 3: Import and Configure Workflow**\nDownload the workflow JSON file\nIn n8n Cloud, go to Workflows &gt; Import from File\nSelect the downloaded JSON file\nConfigure credentials by clicking on each node that shows a warning:\n\n**For Apify nodes (linkedin_dataset & googlemaps_dataset):**\nClick \"Create New Credential\"\nName: \"Apify account\"\nAPI Token: [Paste your Apify token from Step 1]\nSave credential\n\nFor Supabase nodes (save_linkedin & save_googlemaps):\n\nClick \"Create New Credential\"\nName: \"Supabase account\"\nHost: [Your Supabase project URL from Step 2]\nService Role Secret: [Your service role key from Step 2]\nSave credential\n\n**Step 4: Test the Workflow**\nClick on the \"On form submission\" node\nCopy the Production URL (webhook link)\nOpen this URL in a new browser tab\nFill out the test form:\n\nTitle/Industry: \"restaurants\"\nLocation: \"San Francisco, CA\"\nSource: \"Google Maps\"\nNumber of results: \"3\"\n\n\nClick Submit and wait for processing\nCheck your Supabase tables to verify data was saved\n\nStep 5: Verify Setup Success\n\nIn Supabase, go to Table Editor\nCheck the googlemaps table for new entries\nVerify all fields are populated correctly\nTest with LinkedIn source to confirm both paths work\n\nThe workflow is designed to be plug-and-play once credentials are configured. Simply share the form URL with your team or bookmark it for regular lead generation tasks.\nHow to customize the workflow\n\n**Search Parameters:**\nModify Apify actor configurations in the dataset nodes\nAdjust search query formats for better targeting\nChange result limits based on your needs\n\n**Data Processing:**\nEdit the Set nodes to extract additional fields\nAdd data validation steps\nImplement duplicate detection logic\n\n**Storage Options:**\nReplace Supabase with other databases (Airtable, PostgreSQL)\nAdd data export to CSV/Excel\nImplement real-time notifications\n\n**Support:**\nCheck [n8n community forum](https://community.n8n.io/) for help\nReview [Apify actor documentation](https://docs.apify.com/platform/actors)\n\nThe workflow is designed to be plug-and-play once credentials are configured. Simply fill out the form with your target criteria and let the automation handle the rest.\n\n## Requirements\n**External Services:** Apify account with credits (for web scraping)\nSupabase account (for data storage)\n\nSupabase Table Schemas:\nLinkedIn Table (LinkedIn):\n```\npublicidentifier (text)\nlinkedinurl (text)\nname (text)\nheadline (text)\nabout (text)\npremium (boolean)\nverified (boolean)\nopenprofile (boolean)\ntopskills (text)\nconnectionscount (integer)\nfollowercount (integer)\nlatest_experience (text)\neducation (text)\n```\nGoogle Maps Table (googlemaps):\n```\ntitle (text)\ncategory_name (text)\naddress (text)\nneighborhood (text)\nstreet (text)\ncity (text)\npostal_code (text)\nstate (text)\ncountry_code (text)\nwebsite (text)\nphone (text)\nphone_unformatted (text)\nlocation (text)\ntotal_score (numeric)\n```\n**Node Requirements:**\n\n- Form Trigger (built-in), you may use others, or a webhook.\n- Switch (built-in)\n- Set (built-in)\n- Supabase (built-in)\n- Apify (community node), you'll have to install it first.\n\n## How to customize the workflow\n**Form Customisation:**\n- Modify form fields in the \"On form submission\" node to add additional search criteria if you want more.\n- You may adjust dropdown options for different lead sources.\n- Add validation rules for better data quality\n\n**Search Parameters:**\n- Customize Apify actor configurations for different scraping behaviours.\n- Modify the number of results per search.\n- Add additional location targeting options\n\n**Data Processing:**\n- Enhance the Set nodes to extract additional LinkedIn profile data\n- Add data validation and cleaning steps\n- Implement duplicate detection logic\n\n**Storage Options:**\n- You may replace Supabase with other databases (Airtable, Google Sheets, etc.)\n- Add data enrichment steps before storage\n- Implement data export functionality\n\n**Advanced Features:**\n- Add email notifications when scraping completes\n- Implement error handling and retry logic\n- Create data quality scoring mechanisms\n\nLet's connect: [TUMUSIME David](https://www.linkedin.com/in/tumusime-david/)",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "save_linkedin",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "save_googlemaps",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "get_linkedin",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "set_google_maps_column",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "linkedin_dataset",
      "type": "@apify/n8n-nodes-apify.apify",
      "role": "apify",
      "configDescription": "Version 1"
    },
    {
      "name": "googlemaps_dataset",
      "type": "@apify/n8n-nodes-apify.apify",
      "role": "apify",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Route source",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Input desired lead",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.3"
    }
  ]
}