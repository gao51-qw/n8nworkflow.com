{
  "id": 11227,
  "slug": "11227",
  "title": "Aggregate financial regulatory news with ScrapeGraphAI, Slack alerts & Google Sheets",
  "description": "# Daily Stock Regulatory News Aggregator with Compliance Alerts and Google Sheets Tracking\n\n## üéØ Target Audience\n- Compliance officers and regulatory teams\n- Financial services firms monitoring regulatory updates\n- Investment advisors tracking regulatory changes\n- Risk management professionals\n- Corporate legal departments\n- Stock traders and analysts monitoring regulatory news\n\n## üöÄ Problem Statement\nManually monitoring regulatory updates from multiple agencies (SEC, FINRA, ESMA) is time-consuming and error-prone. This template automates daily regulatory news monitoring, aggregates updates from major regulatory bodies, filters for recent announcements, and instantly alerts compliance teams to critical regulatory changes, enabling timely responses and maintaining regulatory compliance.\n\n## üîß How it Works\n\nThis workflow automatically monitors regulatory news daily, scrapes the latest updates from major regulatory agencies using AI-powered web scraping, filters for updates from the last 24 hours, and sends Slack alerts while logging all updates to Google Sheets for historical tracking.\n\n### Key Components\n\n1. **Daily Schedule Trigger** - Automatically runs the workflow every 24 hours to check for regulatory updates\n2. **Regulatory Sources Configuration** - Defines the list of regulatory agencies and their URLs to monitor (SEC, FINRA, ESMA)\n3. **Batch Processing** - Iterates through regulatory sources one at a time for reliable processing\n4. **AI-Powered Scraping** - Uses ScrapeGraphAI to intelligently extract regulatory updates including title, summary, date, agency, and source URL\n5. **Data Flattening** - Transforms scraped data structure into individual update records\n6. **Time Filtering** - Filters updates to keep only those from the last 24 hours\n7. **Historical Tracking** - Logs all filtered updates to Google Sheets for compliance records\n8. **Compliance Alerts** - Sends Slack notifications to compliance teams when new regulatory updates are detected\n\n## üí∞ Key Features\n\n### Automated Regulatory Monitoring\n- **Daily Execution**: Runs automatically every 24 hours without manual intervention\n- **Multi-Agency Support**: Monitors SEC, FINRA, and ESMA simultaneously\n- **Error Handling**: Gracefully handles scraping errors and continues processing other sources\n\n### Smart Filtering\n- **Time-Based Filtering**: Automatically filters updates to show only those from the last 24 hours\n- **Date Validation**: Discards updates with unreadable or invalid dates\n- **Recent Updates Focus**: Ensures compliance teams only receive actionable, timely information\n\n### Alert System\n- **Compliance Alerts**: Instant Slack notifications for new regulatory updates\n- **Structured Data**: Alerts include title, summary, date, agency, and source URL\n- **Dedicated Channel**: Posts to designated compliance alerts channel for team visibility\n\n## üìä Output Specifications\n\nThe workflow generates and stores structured data including:\n\n| Output Type | Format | Description | Example |\n|-------------|--------|-------------|---------|\n| **Regulatory Updates** | JSON Object | Extracted regulatory update information | `{\"title\": \"SEC Announces New Rule\", \"date\": \"2024-01-15\", \"agency\": \"SEC\"}` |\n| **Update History** | Google Sheets | Historical regulatory update records with timestamps | Columns: Title, Summary, Date, Agency, Source URL, Scraped At |\n| **Slack Alerts** | Messages | Compliance notifications for new updates | \"üì¢ New SEC update: [Title] - [Summary]\" |\n| **Error Logs** | System Logs | Scraping error notifications | \"‚ùå Error scraping FINRA updates\" |\n\n## üõ†Ô∏è Setup Instructions\n\n**Estimated setup time: 15-20 minutes**\n\n### Prerequisites\n- n8n instance with community nodes enabled\n- ScrapeGraphAI API account and credentials\n- Google Sheets API access (OAuth2)\n- Slack workspace with API access\n- Google Sheets spreadsheet for regulatory update tracking\n\n### Step-by-Step Configuration\n\n#### 1. Install Community Nodes\n```bash\n# Install ScrapeGraphAI community node\nnpm install n8n-nodes-scrapegraphai\n```\n\n#### 2. Configure ScrapeGraphAI Credentials\n- Navigate to Credentials in your n8n instance\n- Add new ScrapeGraphAI API credentials\n- Enter your API key from ScrapeGraphAI dashboard\n- Test the connection to ensure it's working\n\n#### 3. Set up Google Sheets Connection\n- Add Google Sheets OAuth2 credentials\n- Authorize access to your Google account\n- Create or identify the spreadsheet for regulatory update tracking\n- Note the spreadsheet ID and sheet name (default: \"RegUpdates\")\n\n#### 4. Configure Slack Integration\n- Add Slack API credentials to your n8n instance\n- Create or identify Slack channel: `#compliance-alerts`\n- Test Slack connection with a sample message\n- Ensure the bot has permission to post messages\n\n#### 5. Customize Regulatory Sources\n- Open the \"Regulatory Sources\" Code node\n- Update the urls array with additional regulatory sources if needed:\n  ```javascript\n  const urls = [\n    'https://www.sec.gov/news/pressreleases',\n    'https://www.finra.org/rules-guidance/notices',\n    'https://www.esma.europa.eu/press-news',\n    // Add more URLs as needed\n  ];\n  ```\n\n#### 6. Configure Google Sheets\n- Update `documentId` in \"Log to Google Sheets\" node with your spreadsheet ID\n- Update `sheetName` to match your sheet name (default: \"RegUpdates\")\n- Ensure the sheet has columns: Title, Summary, Date, Agency, Source URL, Scraped At\n- Create the sheet with proper column headers if starting fresh\n\n#### 7. Customize Slack Channel\n- Open \"Send Compliance Alert\" Slack node\n- Update the channel name (default: \"#compliance-alerts\")\n- Customize the message format if needed\n- Test with a sample message\n\n#### 8. Adjust Schedule\n- Open \"Daily Regulatory Poll\" Schedule Trigger\n- Modify `hoursInterval` to change frequency (default: 24 hours)\n- Set specific times if needed for daily execution\n\n#### 9. Customize Scraping Prompt\n- Open \"Scrape Regulatory Updates\" ScrapeGraphAI node\n- Adjust the `userPrompt` to extract different or additional fields\n- Modify the JSON schema in the prompt if needed\n- Change the number of updates extracted (default: 5 most recent)\n\n#### 10. Test and Validate\n- Run the workflow manually to verify all connections\n- Check Google Sheets for data structure and format\n- Verify Slack alerts are working correctly\n- Test error handling with invalid URLs\n- Validate date filtering is working properly\n\n## üîÑ Workflow Customization Options\n\n### Modify Monitoring Frequency\n- Change `hoursInterval` in Schedule Trigger for different frequencies\n- Switch to multiple times per day for critical monitoring\n- Add multiple schedule triggers for different agency checks\n\n### Extend Data Collection\n- Modify ScrapeGraphAI prompt to extract additional fields (documents, categories, impact level)\n- Add data enrichment nodes for risk assessment\n- Integrate with regulatory databases for more comprehensive tracking\n- Add sentiment analysis for regulatory updates\n\n### Enhance Alert System\n- Add email notifications alongside Slack alerts\n- Create different alert channels for different agencies\n- Add priority-based alerting based on update keywords\n- Integrate with SMS or push notification services\n- Add webhook integrations for other compliance tools\n\n### Advanced Analytics\n- Add data visualization nodes for regulatory trend analysis\n- Create automated compliance reports with summaries\n- Integrate with business intelligence tools\n- Add machine learning for update categorization\n- Track regulatory themes and topics over time\n\n### Multi-Source Support\n- Add support for additional regulatory agencies\n- Implement agency-specific scraping strategies\n- Add regional regulatory sources (FCA, BaFin, etc.)\n- Include state-level regulatory updates\n\n## üìà Use Cases\n\n- **Compliance Monitoring**: Automatically track regulatory updates to ensure timely compliance responses\n- **Risk Management**: Monitor regulatory changes that may impact business operations or investments\n- **Regulatory Intelligence**: Build historical databases of regulatory announcements for trend analysis\n- **Client Communication**: Stay informed to provide timely updates to clients about regulatory changes\n- **Legal Research**: Track regulatory developments for legal research and case preparation\n- **Investment Strategy**: Monitor regulatory changes that may affect investment decisions\n\n## üö® Important Notes\n\n- Respect website terms of service and rate limits when scraping regulatory sites\n- Monitor ScrapeGraphAI API usage to manage costs\n- Ensure Google Sheets has proper column structure before first run\n- Set up Slack channel before running the workflow\n- Consider implementing rate limiting for multiple regulatory sources\n- Keep credentials secure and rotate them regularly\n- Test with one regulatory source first before adding multiple sources\n- Verify date formats are consistent across different regulatory agencies\n- Be aware that some regulatory sites may have anti-scraping measures\n\n## üîß Troubleshooting\n\n**Common Issues:**\n- ScrapeGraphAI connection errors: Verify API key and account status\n- Google Sheets logging failures: Check spreadsheet ID, sheet name, and column structure\n- Slack notification failures: Verify channel name exists and bot has permissions\n- Date filtering issues: Ensure dates from scraped content are in a parseable format\n- Validation errors: Check that scraped data matches expected schema\n- Empty results: Verify regulatory sites are accessible and haven't changed structure\n\n**Optimization Tips:**\n- Start with one regulatory source to test the workflow\n- Monitor API usage and costs regularly\n- Use batch processing to avoid overwhelming scraping services\n- Implement retry logic for failed scraping attempts\n- Consider caching mechanisms for frequently checked sources\n- Adjust the number of updates extracted based on typical volume\n\n**Support Resources:**\n- ScrapeGraphAI documentation and API reference\n- Google Sheets API documentation\n- Slack API documentation for webhooks\n- n8n community forums for workflow assistance\n- n8n documentation for node configuration\n- SEC, FINRA, and ESMA official websites for source verification\n",
  "featuredImage": "/data/workflows/11227/11227.webp",
  "author": {
    "id": 101,
    "slug": "vinci-king-01",
    "name": "vinci-king-01",
    "avatar": ""
  },
  "categories": [
    "Crypto Trading",
    "AI Summarization"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 63,
  "downloads": 6,
  "createdAt": "2025-11-25T17:11:08.967Z",
  "updatedAt": "2026-01-16T09:08:01.266Z",
  "publishedAt": "2025-11-25T17:11:08.967Z",
  "nodes": 12,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11227",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Aggregate financial regulatory news with ScrapeGraphAI, Slack alerts & Google Sheets",
    "workflowName": "Aggregate financial regulatory news with ScrapeGraphAI, Slack alerts & Google Sheets",
    "description": "# Daily Stock Regulatory News Aggregator with Compliance Alerts and Google Sheets Tracking\n\n## üéØ Target Audience\n- Compliance officers and regulatory teams\n- Financial services firms monitoring regulatory updates\n- Investment advisors tracking regulatory changes\n- Risk management professionals\n- Corporate legal departments\n- Stock traders and analysts monitoring regulatory news\n\n## üöÄ Problem Statement\nManually monitoring regulatory updates from multiple agencies (SEC, FINRA, ESMA) is time-consuming and error-prone. This template automates daily regulatory news monitoring, aggregates updates from major regulatory bodies, filters for recent announcements, and instantly alerts compliance teams to critical regulatory changes, enabling timely responses and maintaining regulatory compliance.\n\n## üîß How it Works\n\nThis workflow automatically monitors regulatory news daily, scrapes the latest updates from major regulatory agencies using AI-powered web scraping, filters for updates from the last 24 hours, and sends Slack alerts while logging all updates to Google Sheets for historical tracking.\n\n### Key Components\n\n1. **Daily Schedule Trigger** - Automatically runs the workflow every 24 hours to check for regulatory updates\n2. **Regulatory Sources Configuration** - Defines the list of regulatory agencies and their URLs to monitor (SEC, FINRA, ESMA)\n3. **Batch Processing** - Iterates through regulatory sources one at a time for reliable processing\n4. **AI-Powered Scraping** - Uses ScrapeGraphAI to intelligently extract regulatory updates including title, summary, date, agency, and source URL\n5. **Data Flattening** - Transforms scraped data structure into individual update records\n6. **Time Filtering** - Filters updates to keep only those from the last 24 hours\n7. **Historical Tracking** - Logs all filtered updates to Google Sheets for compliance records\n8. **Compliance Alerts** - Sends Slack notifications to compliance teams when new regulatory updates are detected\n\n## üí∞ Key Features\n\n### Automated Regulatory Monitoring\n- **Daily Execution**: Runs automatically every 24 hours without manual intervention\n- **Multi-Agency Support**: Monitors SEC, FINRA, and ESMA simultaneously\n- **Error Handling**: Gracefully handles scraping errors and continues processing other sources\n\n### Smart Filtering\n- **Time-Based Filtering**: Automatically filters updates to show only those from the last 24 hours\n- **Date Validation**: Discards updates with unreadable or invalid dates\n- **Recent Updates Focus**: Ensures compliance teams only receive actionable, timely information\n\n### Alert System\n- **Compliance Alerts**: Instant Slack notifications for new regulatory updates\n- **Structured Data**: Alerts include title, summary, date, agency, and source URL\n- **Dedicated Channel**: Posts to designated compliance alerts channel for team visibility\n\n## üìä Output Specifications\n\nThe workflow generates and stores structured data including:\n\n| Output Type | Format | Description | Example |\n|-------------|--------|-------------|---------|\n| **Regulatory Updates** | JSON Object | Extracted regulatory update information | `{\"title\": \"SEC Announces New Rule\", \"date\": \"2024-01-15\", \"agency\": \"SEC\"}` |\n| **Update History** | Google Sheets | Historical regulatory update records with timestamps | Columns: Title, Summary, Date, Agency, Source URL, Scraped At |\n| **Slack Alerts** | Messages | Compliance notifications for new updates | \"üì¢ New SEC update: [Title] - [Summary]\" |\n| **Error Logs** | System Logs | Scraping error notifications | \"‚ùå Error scraping FINRA updates\" |\n\n## üõ†Ô∏è Setup Instructions\n\n**Estimated setup time: 15-20 minutes**\n\n### Prerequisites\n- n8n instance with community nodes enabled\n- ScrapeGraphAI API account and credentials\n- Google Sheets API access (OAuth2)\n- Slack workspace with API access\n- Google Sheets spreadsheet for regulatory update tracking\n\n### Step-by-Step Configuration\n\n#### 1. Install Community Nodes\n```bash\n# Install ScrapeGraphAI community node\nnpm install n8n-nodes-scrapegraphai\n```\n\n#### 2. Configure ScrapeGraphAI Credentials\n- Navigate to Credentials in your n8n instance\n- Add new ScrapeGraphAI API credentials\n- Enter your API key from ScrapeGraphAI dashboard\n- Test the connection to ensure it's working\n\n#### 3. Set up Google Sheets Connection\n- Add Google Sheets OAuth2 credentials\n- Authorize access to your Google account\n- Create or identify the spreadsheet for regulatory update tracking\n- Note the spreadsheet ID and sheet name (default: \"RegUpdates\")\n\n#### 4. Configure Slack Integration\n- Add Slack API credentials to your n8n instance\n- Create or identify Slack channel: `#compliance-alerts`\n- Test Slack connection with a sample message\n- Ensure the bot has permission to post messages\n\n#### 5. Customize Regulatory Sources\n- Open the \"Regulatory Sources\" Code node\n- Update the urls array with additional regulatory sources if needed:\n  ```javascript\n  const urls = [\n    'https://www.sec.gov/news/pressreleases',\n    'https://www.finra.org/rules-guidance/notices',\n    'https://www.esma.europa.eu/press-news',\n    // Add more URLs as needed\n  ];\n  ```\n\n#### 6. Configure Google Sheets\n- Update `documentId` in \"Log to Google Sheets\" node with your spreadsheet ID\n- Update `sheetName` to match your sheet name (default: \"RegUpdates\")\n- Ensure the sheet has columns: Title, Summary, Date, Agency, Source URL, Scraped At\n- Create the sheet with proper column headers if starting fresh\n\n#### 7. Customize Slack Channel\n- Open \"Send Compliance Alert\" Slack node\n- Update the channel name (default: \"#compliance-alerts\")\n- Customize the message format if needed\n- Test with a sample message\n\n#### 8. Adjust Schedule\n- Open \"Daily Regulatory Poll\" Schedule Trigger\n- Modify `hoursInterval` to change frequency (default: 24 hours)\n- Set specific times if needed for daily execution\n\n#### 9. Customize Scraping Prompt\n- Open \"Scrape Regulatory Updates\" ScrapeGraphAI node\n- Adjust the `userPrompt` to extract different or additional fields\n- Modify the JSON schema in the prompt if needed\n- Change the number of updates extracted (default: 5 most recent)\n\n#### 10. Test and Validate\n- Run the workflow manually to verify all connections\n- Check Google Sheets for data structure and format\n- Verify Slack alerts are working correctly\n- Test error handling with invalid URLs\n- Validate date filtering is working properly\n\n## üîÑ Workflow Customization Options\n\n### Modify Monitoring Frequency\n- Change `hoursInterval` in Schedule Trigger for different frequencies\n- Switch to multiple times per day for critical monitoring\n- Add multiple schedule triggers for different agency checks\n\n### Extend Data Collection\n- Modify ScrapeGraphAI prompt to extract additional fields (documents, categories, impact level)\n- Add data enrichment nodes for risk assessment\n- Integrate with regulatory databases for more comprehensive tracking\n- Add sentiment analysis for regulatory updates\n\n### Enhance Alert System\n- Add email notifications alongside Slack alerts\n- Create different alert channels for different agencies\n- Add priority-based alerting based on update keywords\n- Integrate with SMS or push notification services\n- Add webhook integrations for other compliance tools\n\n### Advanced Analytics\n- Add data visualization nodes for regulatory trend analysis\n- Create automated compliance reports with summaries\n- Integrate with business intelligence tools\n- Add machine learning for update categorization\n- Track regulatory themes and topics over time\n\n### Multi-Source Support\n- Add support for additional regulatory agencies\n- Implement agency-specific scraping strategies\n- Add regional regulatory sources (FCA, BaFin, etc.)\n- Include state-level regulatory updates\n\n## üìà Use Cases\n\n- **Compliance Monitoring**: Automatically track regulatory updates to ensure timely compliance responses\n- **Risk Management**: Monitor regulatory changes that may impact business operations or investments\n- **Regulatory Intelligence**: Build historical databases of regulatory announcements for trend analysis\n- **Client Communication**: Stay informed to provide timely updates to clients about regulatory changes\n- **Legal Research**: Track regulatory developments for legal research and case preparation\n- **Investment Strategy**: Monitor regulatory changes that may affect investment decisions\n\n## üö® Important Notes\n\n- Respect website terms of service and rate limits when scraping regulatory sites\n- Monitor ScrapeGraphAI API usage to manage costs\n- Ensure Google Sheets has proper column structure before first run\n- Set up Slack channel before running the workflow\n- Consider implementing rate limiting for multiple regulatory sources\n- Keep credentials secure and rotate them regularly\n- Test with one regulatory source first before adding multiple sources\n- Verify date formats are consistent across different regulatory agencies\n- Be aware that some regulatory sites may have anti-scraping measures\n\n## üîß Troubleshooting\n\n**Common Issues:**\n- ScrapeGraphAI connection errors: Verify API key and account status\n- Google Sheets logging failures: Check spreadsheet ID, sheet name, and column structure\n- Slack notification failures: Verify channel name exists and bot has permissions\n- Date filtering issues: Ensure dates from scraped content are in a parseable format\n- Validation errors: Check that scraped data matches expected schema\n- Empty results: Verify regulatory sites are accessible and haven't changed structure\n\n**Optimization Tips:**\n- Start with one regulatory source to test the workflow\n- Monitor API usage and costs regularly\n- Use batch processing to avoid overwhelming scraping services\n- Implement retry logic for failed scraping attempts\n- Consider caching mechanisms for frequently checked sources\n- Adjust the number of updates extracted based on typical volume\n\n**Support Resources:**\n- ScrapeGraphAI documentation and API reference\n- Google Sheets API documentation\n- Slack API documentation for webhooks\n- n8n community forums for workflow assistance\n- n8n documentation for node configuration\n- SEC, FINRA, and ESMA official websites for source verification",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Daily Regulatory Poll",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "üìù Overview",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Regulatory Sources",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Split URLs",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Source Intake Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Scrape Regulatory Updates",
      "type": "n8n-nodes-scrapegraphai.scrapegraphAi",
      "role": "scrapegraphAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Processing & Filter Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Flatten Updates",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Filter Recent Updates",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Log to Google Sheets",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4"
    },
    {
      "name": "Send Compliance Alert",
      "type": "n8n-nodes-base.slack",
      "role": "slack",
      "configDescription": "Version 2"
    },
    {
      "name": "Delivery Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}