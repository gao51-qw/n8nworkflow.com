{
  "id": 11634,
  "slug": "11634",
  "title": "Real-time public transport delay tracking with ScrapeGraphAI, Teams & Dropbox",
  "description": "# Public Transport Schedule & Delay Tracker with Microsoft Teams and Dropbox\n\n![Workflow Preview Image](https://via.placeholder.com/800x400/4CAF50/FFFFFF?text=Public+Transport+Schedule+%26+Delay+Tracker+Workflow+Preview)\n\n**‚ö†Ô∏è COMMUNITY TEMPLATE DISCLAIMER: This is a community-contributed template that uses ScrapeGraphAI (a community node). Please ensure you have the ScrapeGraphAI community node installed in your n8n instance before using this template.**\n\nThis workflow automatically scrapes public transport websites or apps for real-time schedules and service alerts, then pushes concise delay notifications to Microsoft Teams while archiving full-detail JSON snapshots in Dropbox. Ideal for commuters and travel coordinators, it keeps riders informed and maintains a historical log of disruptions.\n\n## Pre-conditions/Requirements\n\n### Prerequisites\n- n8n instance (self-hosted or n8n.cloud)\n- ScrapeGraphAI community node installed\n- Microsoft Teams incoming webhook configured\n- Dropbox account with an app token created\n- Public transit data source (website or API) that is legally scrapable or offers open data\n\n### Required Credentials\n- **ScrapeGraphAI API Key** ‚Äì enables web scraping\n- **Microsoft Teams Webhook URL** ‚Äì posts messages into a channel\n- **Dropbox Access Token** ‚Äì saves JSON files to Dropbox\n\n### Specific Setup Requirements\n| Item | Example | Notes |\n|------|---------|-------|\n| Transit URL(s) | https://mycitytransit.com/line/42 | Must return the schedule or service alert data you need |\n| Polling Interval | 5 min | Adjust via Cron node or external trigger |\n| Teams Channel | #commuter-updates | Create an incoming webhook in channel settings |\n\n## How it works\n\nThis workflow automatically scrapes public transport websites or apps for real-time schedules and service alerts, then pushes concise delay notifications to Microsoft Teams while archiving full-detail JSON snapshots in Dropbox. Ideal for commuters and travel coordinators, it keeps riders informed and maintains a historical log of disruptions.\n\n## Key Steps:\n- **Webhook Trigger**: Starts the workflow (can be replaced with Cron for polling).\n- **Set Node**: Stores target route IDs, URLs, or API endpoints.\n- **SplitInBatches**: Processes multiple routes one after another to avoid rate limits.\n- **ScrapeGraphAI**: Scrapes each route page/API and returns structured schedule & alert data.\n- **Code Node (Normalize)**: Cleans & normalizes scraped fields (e.g., converts times to ISO).\n- **If Node (Delay Detected?)**: Compares live data vs. expected timetable to detect delays.\n- **Merge Node**: Combines route metadata with delay information.\n- **Microsoft Teams Node**: Sends alert message and rich card to the selected Teams channel.\n- **Dropbox Node**: Saves the full JSON snapshot to a dated folder for historical reference.\n- **StickyNote**: Documents the mapping between scraped fields and final JSON structure.\n\n## Set up steps\n\n**Setup Time: 15-25 minutes**\n\n1. **Clone or Import** the JSON workflow into your n8n instance.\n2. **Install ScrapeGraphAI** community node if you haven‚Äôt already (`Settings ‚Üí Community Nodes`).\n3. **Open the Set node** and enter your target routes or API endpoints (array of URLs/IDs).\n4. **Configure ScrapeGraphAI**:\n   - Add your API key in the node‚Äôs credentials section.\n   - Define CSS selectors or API fields inside the node parameters.\n5. **Add Microsoft Teams credentials**:\n   - Paste your channel‚Äôs incoming webhook URL into the Microsoft Teams node.\n   - Customize the message template (e.g., include route name, delay minutes, reason).\n6. **Add Dropbox credentials**:\n   - Provide the access token and designate a folder path (e.g., `/TransitLogs/`).\n7. **Customize the If node** logic to match your delay threshold (e.g., ‚â•5 min).\n8. **Activate** the workflow and trigger via the webhook URL, or add a Cron node (every 5 min).\n\n## Node Descriptions\n\n### Core Workflow Nodes:\n- **Webhook** ‚Äì External trigger for on-demand checks or recurring scheduler.\n- **Set** ‚Äì Defines static or dynamic variables such as route list and thresholds.\n- **SplitInBatches** ‚Äì Iterates through each route to control request volume.\n- **ScrapeGraphAI** ‚Äì Extracts live schedule and alert data from transit websites/APIs.\n- **Code (Normalize)** ‚Äì Formats scraped data, merges dates, and calculates delay minutes.\n- **If (Delay Detected?)** ‚Äì Branches the flow based on presence of delays.\n- **Merge** ‚Äì Re-assembles metadata with computed delay results.\n- **Microsoft Teams** ‚Äì Sends formatted notifications to Teams channels.\n- **Dropbox** ‚Äì Archives complete JSON payloads for auditing and analytics.\n- **StickyNote** ‚Äì Provides inline documentation for maintainers.\n\n### Data Flow:\n1. **Webhook** ‚Üí **Set** ‚Üí **SplitInBatches** ‚Üí **ScrapeGraphAI** ‚Üí **Code (Normalize)** ‚Üí **If (Delay Detected?)**  \n   ‚îú‚îÄ true ‚Üí **Merge** ‚Üí **Microsoft Teams** ‚Üí **Dropbox**  \n   ‚îî‚îÄ false ‚Üí **Dropbox**\n\n## Customization Examples\n\n### Change to Slack instead of Teams\n```javascript\n// Replace Microsoft Teams node with Slack node\n{\n  \"text\": `üöä *${$json.route}* is delayed by *${$json.delay}* minutes.`,\n  \"channel\": \"#commuter-updates\"\n}\n```\n\n### Filter only major delays (&gt;10 min)\n```javascript\n// In If node, use:\nreturn $json.delay &gt;= 10;\n```\n\n## Data Output Format\n\nThe workflow outputs structured JSON data:\n\n```json\n{\n  \"route\": \"Line 42\",\n  \"expected_departure\": \"2024-04-22T14:05:00Z\",\n  \"actual_departure\": \"2024-04-22T14:17:00Z\",\n  \"delay\": 12,\n  \"status\": \"delayed\",\n  \"reason\": \"Signal failure at Main Station\",\n  \"scraped_at\": \"2024-04-22T13:58:22Z\",\n  \"source_url\": \"https://mycitytransit.com/line/42\"\n}\n```\n\n## Troubleshooting\n\n### Common Issues\n1. **ScrapeGraphAI returns empty data** ‚Äì Verify CSS selectors/API fields match the current website markup; update selectors after site redesigns.\n2. **Teams messages not arriving** ‚Äì Ensure the Teams webhook URL is correct and the incoming webhook is still enabled.\n3. **Dropbox writes fail** ‚Äì Check folder path, token scopes (`files.content.write`), and available storage quota.\n\n### Performance Tips\n- Limit `SplitInBatches` to 5-10 routes per run to avoid IP blocking.\n- Cache unchanged schedules locally and fetch only alert pages for faster runs.\n\n**Pro Tips:**\n- Use environment variables for API keys & webhook URLs to keep credentials secure.\n- Attach a Cron node set to off-peak hours (e.g., 4 AM) for daily full-schedule backups.\n- Add a Grafana dashboard that reads the Dropbox archive for long-term delay analytics.",
  "featuredImage": "/data/workflows/11634/11634.webp",
  "author": {
    "id": 101,
    "slug": "vinci-king-01",
    "name": "vinci-king-01",
    "avatar": ""
  },
  "categories": [
    "Miscellaneous",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 37,
  "downloads": 3,
  "createdAt": "2025-12-09T17:58:53.974Z",
  "updatedAt": "2026-01-16T09:09:27.189Z",
  "publishedAt": "2025-12-09T17:58:53.974Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11634",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Real-time public transport delay tracking with ScrapeGraphAI, Teams & Dropbox",
    "workflowName": "Real-time public transport delay tracking with ScrapeGraphAI, Teams & Dropbox",
    "description": "# Public Transport Schedule & Delay Tracker with Microsoft Teams and Dropbox\n\n![Workflow Preview Image](https://via.placeholder.com/800x400/4CAF50/FFFFFF?text=Public+Transport+Schedule+%26+Delay+Tracker+Workflow+Preview)\n\n**‚ö†Ô∏è COMMUNITY TEMPLATE DISCLAIMER: This is a community-contributed template that uses ScrapeGraphAI (a community node). Please ensure you have the ScrapeGraphAI community node installed in your n8n instance before using this template.**\n\nThis workflow automatically scrapes public transport websites or apps for real-time schedules and service alerts, then pushes concise delay notifications to Microsoft Teams while archiving full-detail JSON snapshots in Dropbox. Ideal for commuters and travel coordinators, it keeps riders informed and maintains a historical log of disruptions.\n\n## Pre-conditions/Requirements\n\n### Prerequisites\n- n8n instance (self-hosted or n8n.cloud)\n- ScrapeGraphAI community node installed\n- Microsoft Teams incoming webhook configured\n- Dropbox account with an app token created\n- Public transit data source (website or API) that is legally scrapable or offers open data\n\n### Required Credentials\n- **ScrapeGraphAI API Key** ‚Äì enables web scraping\n- **Microsoft Teams Webhook URL** ‚Äì posts messages into a channel\n- **Dropbox Access Token** ‚Äì saves JSON files to Dropbox\n\n### Specific Setup Requirements\n| Item | Example | Notes |\n|------|---------|-------|\n| Transit URL(s) | https://mycitytransit.com/line/42 | Must return the schedule or service alert data you need |\n| Polling Interval | 5 min | Adjust via Cron node or external trigger |\n| Teams Channel | #commuter-updates | Create an incoming webhook in channel settings |\n\n## How it works\n\nThis workflow automatically scrapes public transport websites or apps for real-time schedules and service alerts, then pushes concise delay notifications to Microsoft Teams while archiving full-detail JSON snapshots in Dropbox. Ideal for commuters and travel coordinators, it keeps riders informed and maintains a historical log of disruptions.\n\n## Key Steps:\n- **Webhook Trigger**: Starts the workflow (can be replaced with Cron for polling).\n- **Set Node**: Stores target route IDs, URLs, or API endpoints.\n- **SplitInBatches**: Processes multiple routes one after another to avoid rate limits.\n- **ScrapeGraphAI**: Scrapes each route page/API and returns structured schedule & alert data.\n- **Code Node (Normalize)**: Cleans & normalizes scraped fields (e.g., converts times to ISO).\n- **If Node (Delay Detected?)**: Compares live data vs. expected timetable to detect delays.\n- **Merge Node**: Combines route metadata with delay information.\n- **Microsoft Teams Node**: Sends alert message and rich card to the selected Teams channel.\n- **Dropbox Node**: Saves the full JSON snapshot to a dated folder for historical reference.\n- **StickyNote**: Documents the mapping between scraped fields and final JSON structure.\n\n## Set up steps\n\n**Setup Time: 15-25 minutes**\n\n1. **Clone or Import** the JSON workflow into your n8n instance.\n2. **Install ScrapeGraphAI** community node if you haven‚Äôt already (`Settings ‚Üí Community Nodes`).\n3. **Open the Set node** and enter your target routes or API endpoints (array of URLs/IDs).\n4. **Configure ScrapeGraphAI**:\n   - Add your API key in the node‚Äôs credentials section.\n   - Define CSS selectors or API fields inside the node parameters.\n5. **Add Microsoft Teams credentials**:\n   - Paste your channel‚Äôs incoming webhook URL into the Microsoft Teams node.\n   - Customize the message template (e.g., include route name, delay minutes, reason).\n6. **Add Dropbox credentials**:\n   - Provide the access token and designate a folder path (e.g., `/TransitLogs/`).\n7. **Customize the If node** logic to match your delay threshold (e.g., ‚â•5 min).\n8. **Activate** the workflow and trigger via the webhook URL, or add a Cron node (every 5 min).\n\n## Node Descriptions\n\n### Core Workflow Nodes:\n- **Webhook** ‚Äì External trigger for on-demand checks or recurring scheduler.\n- **Set** ‚Äì Defines static or dynamic variables such as route list and thresholds.\n- **SplitInBatches** ‚Äì Iterates through each route to control request volume.\n- **ScrapeGraphAI** ‚Äì Extracts live schedule and alert data from transit websites/APIs.\n- **Code (Normalize)** ‚Äì Formats scraped data, merges dates, and calculates delay minutes.\n- **If (Delay Detected?)** ‚Äì Branches the flow based on presence of delays.\n- **Merge** ‚Äì Re-assembles metadata with computed delay results.\n- **Microsoft Teams** ‚Äì Sends formatted notifications to Teams channels.\n- **Dropbox** ‚Äì Archives complete JSON payloads for auditing and analytics.\n- **StickyNote** ‚Äì Provides inline documentation for maintainers.\n\n### Data Flow:\n1. **Webhook** ‚Üí **Set** ‚Üí **SplitInBatches** ‚Üí **ScrapeGraphAI** ‚Üí **Code (Normalize)** ‚Üí **If (Delay Detected?)**  \n   ‚îú‚îÄ true ‚Üí **Merge** ‚Üí **Microsoft Teams** ‚Üí **Dropbox**  \n   ‚îî‚îÄ false ‚Üí **Dropbox**\n\n## Customization Examples\n\n### Change to Slack instead of Teams\n```javascript\n// Replace Microsoft Teams node with Slack node\n{\n  \"text\": `üöä *${$json.route}* is delayed by *${$json.delay}* minutes.`,\n  \"channel\": \"#commuter-updates\"\n}\n```\n\n### Filter only major delays (&gt;10 min)\n```javascript\n// In If node, use:\nreturn $json.delay &gt;= 10;\n```\n\n## Data Output Format\n\nThe workflow outputs structured JSON data:\n\n```json\n{\n  \"route\": \"Line 42\",\n  \"expected_departure\": \"2024-04-22T14:05:00Z\",\n  \"actual_departure\": \"2024-04-22T14:17:00Z\",\n  \"delay\": 12,\n  \"status\": \"delayed\",\n  \"reason\": \"Signal failure at Main Station\",\n  \"scraped_at\": \"2024-04-22T13:58:22Z\",\n  \"source_url\": \"https://mycitytransit.com/line/42\"\n}\n```\n\n## Troubleshooting\n\n### Common Issues\n1. **ScrapeGraphAI returns empty data** ‚Äì Verify CSS selectors/API fields match the current website markup; update selectors after site redesigns.\n2. **Teams messages not arriving** ‚Äì Ensure the Teams webhook URL is correct and the incoming webhook is still enabled.\n3. **Dropbox writes fail** ‚Äì Check folder path, token scopes (`files.content.write`), and available storage quota.\n\n### Performance Tips\n- Limit `SplitInBatches` to 5-10 routes per run to avoid IP blocking.\n- Cache unchanged schedules locally and fetch only alert pages for faster runs.\n\n**Pro Tips:**\n- Use environment variables for API keys & webhook URLs to keep credentials secure.\n- Attach a Cron node set to off-peak hours (e.g., 4 AM) for daily full-schedule backups.\n- Add a Grafana dashboard that reads the Dropbox archive for long-term delay analytics.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Webhook Listener",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 1"
    },
    {
      "name": "Prepare Source URLs",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Split URLs",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Scrape Transit Data",
      "type": "n8n-nodes-scrapegraphai.scrapegraphAi",
      "role": "scrapegraphAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Merge Results",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 2"
    },
    {
      "name": "Normalize & Deduplicate",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Significant Delay?",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2"
    },
    {
      "name": "Send Teams Alert",
      "type": "n8n-nodes-base.microsoftTeams",
      "role": "microsoftTeams",
      "configDescription": "Version 2"
    },
    {
      "name": "Prepare File for Dropbox",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3"
    },
    {
      "name": "Archive to Dropbox",
      "type": "n8n-nodes-base.dropbox",
      "role": "dropbox",
      "configDescription": "Version 1"
    },
    {
      "name": "Workflow Overview",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Section ‚Äì Trigger & URLs",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Section ‚Äì Scraping Layer",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Section ‚Äì Processing & Alerts",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Section ‚Äì Storage & Archiving",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}