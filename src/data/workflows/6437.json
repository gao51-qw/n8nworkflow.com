{
  "id": 6437,
  "slug": "6437",
  "title": "Automate deep research with ScrapeGraphAI, GPT-4 & Google Sheets",
  "description": "# Deep Research Agent with AI Analysis and Multi-Source Data Collection\n\n## üéØ Target Audience\n- Market researchers and analysts\n- Business intelligence teams\n- Academic researchers and students\n- Content creators and journalists\n- Product managers conducting market research\n- Consultants performing competitive analysis\n- Data scientists gathering research data\n- Marketing teams analyzing industry trends\n\n## üöÄ Problem Statement\nManual research processes are time-consuming, inconsistent, and often miss critical information from multiple sources. This template solves the challenge of automating comprehensive research across web, news, and academic sources while providing AI-powered analysis and actionable insights.\n\n## üîß How it Works\n\nThis workflow automatically conducts deep research on any topic using AI-powered web scraping, collects data from multiple source types, and provides comprehensive analysis with actionable insights.\n\n### Key Components\n\n1. **Webhook Trigger** - Receives research requests and initiates the automated research process\n2. **Research Configuration Processor** - Validates and processes research parameters, generates search queries\n3. **Multi-Source AI Scraping** - Uses ScrapeGraphAI to collect data from web, news, and academic sources\n4. **Data Processing Engine** - Combines and structures data from all sources for analysis\n5. **AI Research Analyst** - Uses GPT-4 to provide comprehensive analysis and insights\n6. **Data Storage** - Stores all research findings in Google Sheets for historical tracking\n7. **Response System** - Returns structured research results via webhook response\n\n## üìä Google Sheets Column Specifications\n\nThe template creates the following columns in your Google Sheets:\n\n| Column | Data Type | Description | Example |\n|--------|-----------|-------------|---------|\n| **sessionId** | String | Unique research session identifier | \"research_1703123456789\" |\n| **query** | String | Research query that was executed | \"artificial intelligence trends\" |\n| **timestamp** | DateTime | When the research was conducted | \"2024-01-15T10:30:00Z\" |\n| **analysis** | Text | AI-generated comprehensive analysis | \"Executive Summary: AI trends show...\" |\n| **totalSources** | Number | Total number of sources analyzed | 15 |\n\n## üõ†Ô∏è Setup Instructions\n\n**Estimated setup time: 20-25 minutes**\n\n### Prerequisites\n- n8n instance with community nodes enabled\n- ScrapeGraphAI API account and credentials\n- OpenAI API account and credentials\n- Google Sheets account with API access\n\n### Step-by-Step Configuration\n\n#### 1. Install Community Nodes\n```bash\n# Install required community nodes\nnpm install n8n-nodes-scrapegraphai\n```\n\n#### 2. Configure ScrapeGraphAI Credentials\n- Navigate to Credentials in your n8n instance\n- Add new ScrapeGraphAI API credentials\n- Enter your API key from ScrapeGraphAI dashboard\n- Test the connection to ensure it's working\n\n#### 3. Set up OpenAI Credentials\n- Add OpenAI API credentials\n- Enter your API key from OpenAI dashboard\n- Ensure you have access to GPT-4 model\n- Test the connection to verify API access\n\n#### 4. Set up Google Sheets Connection\n- Add Google Sheets OAuth2 credentials\n- Grant necessary permissions for spreadsheet access\n- Create a new spreadsheet for research data\n- Configure the sheet name (default: \"Research_Data\")\n\n#### 5. Configure Research Parameters\n- Update the webhook endpoint URL\n- Customize default research parameters in the configuration processor\n- Set appropriate search query generation logic\n- Configure research depth levels (basic, detailed, comprehensive)\n\n#### 6. Test the Workflow\n- Send a test webhook request with research parameters\n- Verify data collection from all source types\n- Check Google Sheets for proper data storage\n- Validate AI analysis output quality\n\n## üîÑ Workflow Customization Options\n\n### Modify Research Sources\n- Add or remove source types (web, news, academic)\n- Customize search queries for specific industries\n- Adjust source credibility scoring algorithms\n- Implement custom data extraction patterns\n\n### Extend Analysis Capabilities\n- Add industry-specific analysis frameworks\n- Implement comparative analysis between sources\n- Create custom insight generation rules\n- Add sentiment analysis for news sources\n\n### Customize Data Storage\n- Add more detailed metadata tracking\n- Implement research versioning and history\n- Create multiple sheet tabs for different research types\n- Add data export capabilities\n\n### Output Customization\n- Create custom response formats\n- Add research summary generation\n- Implement citation and source tracking\n- Create executive dashboard integration\n\n## üìà Use Cases\n\n- **Market Research**: Comprehensive industry and competitor analysis\n- **Academic Research**: Literature reviews and citation gathering\n- **Content Creation**: Research for articles, reports, and presentations\n- **Business Intelligence**: Strategic decision-making support\n- **Product Development**: Market validation and trend analysis\n- **Investment Research**: Due diligence and market analysis\n\n## üö® Important Notes\n\n- Respect website terms of service and robots.txt files\n- Implement appropriate delays between requests to avoid rate limiting\n- Monitor API usage to manage costs effectively\n- Keep your credentials secure and rotate them regularly\n- Consider data privacy and compliance requirements\n- Validate research findings from multiple sources\n\n## üîß Troubleshooting\n\n**Common Issues:**\n- ScrapeGraphAI connection errors: Verify API key and account status\n- OpenAI API errors: Check API key and model access permissions\n- Google Sheets permission errors: Check OAuth2 scope and permissions\n- Research data quality issues: Review search query generation logic\n- Rate limiting: Adjust request frequency and implement delays\n- Webhook response errors: Check response format and content\n\n**Support Resources:**\n- ScrapeGraphAI documentation and API reference\n- OpenAI API documentation and model specifications\n- n8n community forums for workflow assistance\n- Google Sheets API documentation for advanced configurations\n",
  "featuredImage": "/data/workflows/6437/6437.webp",
  "author": {
    "id": 101,
    "slug": "vinci-king-01",
    "name": "vinci-king-01",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 939,
  "downloads": 93,
  "createdAt": "2025-07-25T12:18:39.012Z",
  "updatedAt": "2026-01-16T08:45:00.482Z",
  "publishedAt": "2025-07-25T12:18:39.012Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6437",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Automate deep research with ScrapeGraphAI, GPT-4 & Google Sheets",
    "workflowName": "Automate deep research with ScrapeGraphAI, GPT-4 & Google Sheets",
    "description": "# Deep Research Agent with AI Analysis and Multi-Source Data Collection\n\n## üéØ Target Audience\n- Market researchers and analysts\n- Business intelligence teams\n- Academic researchers and students\n- Content creators and journalists\n- Product managers conducting market research\n- Consultants performing competitive analysis\n- Data scientists gathering research data\n- Marketing teams analyzing industry trends\n\n## üöÄ Problem Statement\nManual research processes are time-consuming, inconsistent, and often miss critical information from multiple sources. This template solves the challenge of automating comprehensive research across web, news, and academic sources while providing AI-powered analysis and actionable insights.\n\n## üîß How it Works\n\nThis workflow automatically conducts deep research on any topic using AI-powered web scraping, collects data from multiple source types, and provides comprehensive analysis with actionable insights.\n\n### Key Components\n\n1. **Webhook Trigger** - Receives research requests and initiates the automated research process\n2. **Research Configuration Processor** - Validates and processes research parameters, generates search queries\n3. **Multi-Source AI Scraping** - Uses ScrapeGraphAI to collect data from web, news, and academic sources\n4. **Data Processing Engine** - Combines and structures data from all sources for analysis\n5. **AI Research Analyst** - Uses GPT-4 to provide comprehensive analysis and insights\n6. **Data Storage** - Stores all research findings in Google Sheets for historical tracking\n7. **Response System** - Returns structured research results via webhook response\n\n## üìä Google Sheets Column Specifications\n\nThe template creates the following columns in your Google Sheets:\n\n| Column | Data Type | Description | Example |\n|--------|-----------|-------------|---------|\n| **sessionId** | String | Unique research session identifier | \"research_1703123456789\" |\n| **query** | String | Research query that was executed | \"artificial intelligence trends\" |\n| **timestamp** | DateTime | When the research was conducted | \"2024-01-15T10:30:00Z\" |\n| **analysis** | Text | AI-generated comprehensive analysis | \"Executive Summary: AI trends show...\" |\n| **totalSources** | Number | Total number of sources analyzed | 15 |\n\n## üõ†Ô∏è Setup Instructions\n\n**Estimated setup time: 20-25 minutes**\n\n### Prerequisites\n- n8n instance with community nodes enabled\n- ScrapeGraphAI API account and credentials\n- OpenAI API account and credentials\n- Google Sheets account with API access\n\n### Step-by-Step Configuration\n\n#### 1. Install Community Nodes\n```bash\n# Install required community nodes\nnpm install n8n-nodes-scrapegraphai\n```\n\n#### 2. Configure ScrapeGraphAI Credentials\n- Navigate to Credentials in your n8n instance\n- Add new ScrapeGraphAI API credentials\n- Enter your API key from ScrapeGraphAI dashboard\n- Test the connection to ensure it's working\n\n#### 3. Set up OpenAI Credentials\n- Add OpenAI API credentials\n- Enter your API key from OpenAI dashboard\n- Ensure you have access to GPT-4 model\n- Test the connection to verify API access\n\n#### 4. Set up Google Sheets Connection\n- Add Google Sheets OAuth2 credentials\n- Grant necessary permissions for spreadsheet access\n- Create a new spreadsheet for research data\n- Configure the sheet name (default: \"Research_Data\")\n\n#### 5. Configure Research Parameters\n- Update the webhook endpoint URL\n- Customize default research parameters in the configuration processor\n- Set appropriate search query generation logic\n- Configure research depth levels (basic, detailed, comprehensive)\n\n#### 6. Test the Workflow\n- Send a test webhook request with research parameters\n- Verify data collection from all source types\n- Check Google Sheets for proper data storage\n- Validate AI analysis output quality\n\n## üîÑ Workflow Customization Options\n\n### Modify Research Sources\n- Add or remove source types (web, news, academic)\n- Customize search queries for specific industries\n- Adjust source credibility scoring algorithms\n- Implement custom data extraction patterns\n\n### Extend Analysis Capabilities\n- Add industry-specific analysis frameworks\n- Implement comparative analysis between sources\n- Create custom insight generation rules\n- Add sentiment analysis for news sources\n\n### Customize Data Storage\n- Add more detailed metadata tracking\n- Implement research versioning and history\n- Create multiple sheet tabs for different research types\n- Add data export capabilities\n\n### Output Customization\n- Create custom response formats\n- Add research summary generation\n- Implement citation and source tracking\n- Create executive dashboard integration\n\n## üìà Use Cases\n\n- **Market Research**: Comprehensive industry and competitor analysis\n- **Academic Research**: Literature reviews and citation gathering\n- **Content Creation**: Research for articles, reports, and presentations\n- **Business Intelligence**: Strategic decision-making support\n- **Product Development**: Market validation and trend analysis\n- **Investment Research**: Due diligence and market analysis\n\n## üö® Important Notes\n\n- Respect website terms of service and robots.txt files\n- Implement appropriate delays between requests to avoid rate limiting\n- Monitor API usage to manage costs effectively\n- Keep your credentials secure and rotate them regularly\n- Consider data privacy and compliance requirements\n- Validate research findings from multiple sources\n\n## üîß Troubleshooting\n\n**Common Issues:**\n- ScrapeGraphAI connection errors: Verify API key and account status\n- OpenAI API errors: Check API key and model access permissions\n- Google Sheets permission errors: Check OAuth2 scope and permissions\n- Research data quality issues: Review search query generation logic\n- Rate limiting: Adjust request frequency and implement delays\n- Webhook response errors: Check response format and content\n\n**Support Resources:**\n- ScrapeGraphAI documentation and API reference\n- OpenAI API documentation and model specifications\n- n8n community forums for workflow assistance\n- Google Sheets API documentation for advanced configurations",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Research Request Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Research Configuration Processor",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Split Search Queries",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Query Selector",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "AI Research Scraper",
      "type": "n8n-nodes-scrapegraphai.scrapegraphAi",
      "role": "scrapegraphAi",
      "configDescription": "Version 1"
    },
    {
      "name": "News Sources Scraper",
      "type": "n8n-nodes-scrapegraphai.scrapegraphAi",
      "role": "scrapegraphAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Academic Sources Scraper",
      "type": "n8n-nodes-scrapegraphai.scrapegraphAi",
      "role": "scrapegraphAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Merge Research Sources",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Research Data Processor",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Research Data Storage",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.5"
    },
    {
      "name": "Research Complete Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Webhook Trigger Guide",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Configuration Guide",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Scraping Guide",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Processing & Analysis Guide",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Storage & Response Guide",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}