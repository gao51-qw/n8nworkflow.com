{
  "id": 5521,
  "slug": "5521",
  "title": "Process documents with recursive chunking using Google Drive, OpenAI & Gemini RAG",
  "description": "**1. Document Ingestion & Processing**\n\nGoogle Drive Trigger monitors for new files → Loop Over Items processes each file → File Info extracts metadata → Google Drive downloads the actual content → Switch routes to appropriate extractors (PDF or TEXT) based on file type\n\n**2. Content Transformation & Chunking**\n\nDocument Data node processes extracted text → Recursive Splitter breaks content into contextual chunks → Chunk Splitting applies intelligent segmentation while preserving document context and relationships between chunks\n\n**3. Embedding & Storage**\n\nBasic LLM Chain processes chunks → OpenAI Chat Model generates contextual understanding → Summarize creates document summaries → Supabase Vector Store saves embeddings with metadata → Embeddings OpenAI creates vector representations → Default Data Loader handles storage operations\n\n**4. Query Processing & Retrieval**\n\nWhen Clicking Execute triggers user queries → OpenAI processes and understands the question → AI Agent orchestrates hybrid search (combining vector similarity + keyword matching) → Google Gemini Chat Model generates final responses using retrieved context → HTTP Request handles additional external data sources",
  "featuredImage": "/data/workflows/5521/5521.webp",
  "author": {
    "id": 101,
    "slug": "binbakhsh",
    "name": "Mohsin Ali",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 2463,
  "downloads": 246,
  "createdAt": "2025-07-01T15:06:26.131Z",
  "updatedAt": "2026-01-16T08:40:07.308Z",
  "publishedAt": "2025-07-01T15:06:26.131Z",
  "nodes": 25,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5521",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Process documents with recursive chunking using Google Drive, OpenAI & Gemini RAG",
    "workflowName": "Process documents with recursive chunking using Google Drive, OpenAI & Gemini RAG",
    "description": "**1. Document Ingestion & Processing**\n\nGoogle Drive Trigger monitors for new files → Loop Over Items processes each file → File Info extracts metadata → Google Drive downloads the actual content → Switch routes to appropriate extractors (PDF or TEXT) based on file type\n\n**2. Content Transformation & Chunking**\n\nDocument Data node processes extracted text → Recursive Splitter breaks content into contextual chunks → Chunk Splitting applies intelligent segmentation while preserving document context and relationships between chunks\n\n**3. Embedding & Storage**\n\nBasic LLM Chain processes chunks → OpenAI Chat Model generates contextual understanding → Summarize creates document summaries → Supabase Vector Store saves embeddings with metadata → Embeddings OpenAI creates vector representations → Default Data Loader handles storage operations\n\n**4. Query Processing & Retrieval**\n\nWhen Clicking Execute triggers user queries → OpenAI processes and understands the question → AI Agent orchestrates hybrid search (combining vector similarity + keyword matching) → Google Gemini Chat Model generates final responses using retrieved context → HTTP Request handles additional external data sources",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Google Drive Trigger",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Google Drive",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Basic LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Summarize",
      "type": "n8n-nodes-base.summarize",
      "role": "summarize",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Supabase Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterCharacterTextSplitter",
      "role": "textSplitterCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenAI",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "File info",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Extract from PDF",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from TEXT",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "PDF to DATA",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Recursive Splitter",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Document Data",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Chunk Splitting",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "SupaBase Query",
      "type": "n8n-nodes-base.httpRequestTool",
      "role": "httpRequestTool",
      "configDescription": "Version 4.2"
    }
  ]
}