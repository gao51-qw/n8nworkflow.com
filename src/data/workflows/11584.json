{
  "id": 11584,
  "slug": "11584",
  "title": "Extract viral-worthy clips from YouTube videos with Gemini AI & FFmpeg editing",
  "description": "![Workflow Overview](https://raw.githubusercontent.com/Habeeb-MD-Faiz/n8n/main/images/cliping.jpg)\n\n## Who's it for\n\nThis workflow transforms hours of manual video editing into an automated AI-powered pipeline. Perfect for anyone looking to repurpose long-form content into viral short-form clips.\n\n**Ideal users include:**\n\n- **Content Creators** - YouTubers producing long-form videos who want to maximize reach by automatically generating TikTok, Reels, and Shorts from their content\n- **Social Media Managers** - Agencies and freelancers handling multiple clients who need to scale clip production without hiring additional editors\n- **Podcasters** - Audio and video podcast hosts wanting to create promotional clips highlighting the best moments from each episode\n- **Video Editors** - Professional editors looking to automate repetitive clipping tasks and focus on creative decisions rather than technical execution\n- **Marketing Teams** - B2B and B2C teams extracting key moments from webinars, product demos, tutorials, and educational content for social campaigns\n\nWhether you're a solo creator or managing content at scale, this workflow saves 5-10 hours per video while maintaining professional quality output.\n\n## How it works\n\nThis workflow combines AI analysis with professional video editing tools to automatically identify and produce viral-ready clips from any YouTube video.\n\n**The process flows through three main stages:**\n\n**Stage 1: Download and Analysis**\n- Submit a YouTube URL through the built-in form trigger\n- yt-dlp simultaneously downloads the video in highest quality and extracts subtitles or auto-generated transcripts\n- The transcript is intelligently chunked into 150-segment batches for optimal AI processing\n- Each batch is analyzed by Gemini AI using specialized prompts that evaluate viral potential based on hooks, pacing, emotional peaks, and engagement triggers\n- AI identifies 3-5 high-quality moments per batch and assigns virality scores to each potential clip\n\n**Stage 2: Clip Selection and Extraction**\n- All AI-identified clips are merged and sorted by their virality scores\n- The top 10 candidates are automatically selected for processing\n- FFmpeg extracts each clip segment from the original video at precise timestamps\n- Clips are processed sequentially to prevent system overload\n\n**Stage 3: Professional Editing Pipeline**\n- Each clip enters a multi-stage editing subworkflow with automated operations:\n- Smart 9:16 cropping that intelligently frames the subject for vertical platforms\n- Precise trimming to remove dead air and optimize pacing\n- Dynamic subtitle generation with sizing calculated based on video resolution\n- Professional subtitle styling including bold text, high-contrast colors, strategic positioning, and text wrapping\n- Subtitles are burned directly into the video as permanent overlays\n\n**Final Delivery:**\nThe workflow processes clips with configurable wait times to match your system's capabilities. When all clips complete processing, you receive an email notification and find your social-ready clips in the `/data/clips/` directory, ready for upload to any platform.\n\n## Requirements\n\n**⚠️ Self-hosted n8n only** - This workflow requires command-line access and cannot run on n8n Cloud due to its dependency on system-level tools.\n\n**System dependencies you must install:**\n- **FFmpeg** - Industry-standard video processing tool for trimming, cropping, and subtitle burning. Install on your n8n host system following [this comprehensive guide](https://docs.n8n.io/integrations/community-nodes/installation/gui-install/). Most Linux systems can install via package manager: `apt-get install ffmpeg` or `yum install ffmpeg`.\n- **yt-dlp** - Advanced YouTube downloader that handles video and subtitle extraction. Follow [official installation instructions](https://github.com/yt-dlp/yt-dlp#installation). Recommended: `pip install yt-dlp` or direct binary download.\n- **FFprobe** - Usually included with FFmpeg, used for detecting video dimensions for dynamic subtitle sizing.\n\n**Credentials needed:**\n- **Google Gemini API account** - Powers the AI analysis for clip identification and editing instructions. [Get your free API key](https://ai.google.dev/) with generous free tier limits.\n- **Gmail OAuth2 credentials** - Enables email notifications when clips are ready. Set up through n8n's credential system.\n\n**Storage requirements:**\n- Ensure `/data/clips/` directory exists with write permissions\n- Plan for 2-3x the original video size in temporary storage during processing\n- Final clips typically use 10-30% of original video size\n\n## How to set up\n\n**Step 1: Install system dependencies**\n\nSSH into your n8n host and install required tools. For Ubuntu/Debian systems, run:\n```\napt-get update\napt-get install ffmpeg\npip install yt-dlp\n```\n\nVerify installations by running `ffmpeg -version` and `yt-dlp --version`.\n\n**Step 2: Configure directory structure**\n\nCreate the clips output directory with proper permissions:\n```\nmkdir -p /data/clips\nchmod 755 /data/clips\n```\n\n**Step 3: Import the workflow**\n\nDownload the workflow JSON and import it into your n8n instance. You'll see several sticky notes color-coded by stage: yellow for description, blue for download/analysis, pink for editing operations, and green for clipping.\n\n**Step 4: Set up credentials**\n\nNavigate to the \"viral clips identification\" node and add your Google Gemini API credentials. The workflow uses the `gemini-2.5-flash` model for optimal speed and quality balance. Then configure Gmail OAuth2 in the \"Send a message\" node following n8n's authentication wizard.\n\n**Step 5: Update email notification**\n\nOpen the \"Send a message\" node and replace `habeebmohammedfaiz@gmail.com` with your email address.\n\n**Step 6: Create the editing subworkflow**\n\nThe workflow references a separate subworkflow for the editing pipeline. Create a new workflow in n8n, copy all nodes from the \"EDITING\" section (between the Execute Workflow Trigger and the final output), and save it. Note the workflow ID from the URL.\n\n**Step 7: Link the subworkflow**\n\nIn the main workflow, open the \"Call subworkflow\" node and update the workflow ID to match your newly created editing workflow.\n\n**Step 8: Test with a short video**\n\nStart with a 5-10 minute YouTube video for your first test. Use the manual trigger or form submission. Monitor the execution to ensure all nodes complete successfully and clips appear in `/data/clips/`.\n\n**Step 9: Adjust performance settings**\n\nBased on your system's performance during the test, modify the Wait node durations. Systems with 8GB+ RAM and modern CPUs can reduce wait times to 30 seconds. Limited systems should keep 60-second waits or increase them.\n\n## How to customize the workflow\n\n**Adjust clip quantity and quality thresholds**\n\nOpen the \"filter out top clips according to score\" node. The code currently uses `.slice(0, 10)` to select the top 10 clips. Change this number based on your needs: use `.slice(0, 5)` for only the best clips, or `.slice(0, 20)` for more options. You can also add score filtering by adding `results.filter(c =&gt; c.score &gt; 0.7)` before the slice operation to only include clips with virality scores above 70%.\n\n**Customize subtitle appearance**\n\nNavigate to the \"calculate relative subtitle size\" node. The JavaScript code defines several styling variables you can modify:\n- `fontSize` - Currently calculated dynamically, but you can hardcode it: `const fontSize = 48;`\n- `fontName` - Change from Arial to any system font: `const fontName = 'Impact';`\n- `primaryColor` - Modify text color using BGR hex format: `'&H00FF00&'` for green, `'&HFF0000&'` for red\n- `borderColor` - Adjust outline color for better contrast\n- `outlineWidth` - Increase from 1 to 2 or 3 for thicker borders\n- `marginV` - Control vertical position (higher values move text up from bottom)\n\n**Modify AI analysis prompts**\n\nIn the \"viral clips identification\" node, edit the Gemini prompt to target specific content types. For educational content, add \"Focus on key teaching moments and actionable tips.\" For entertainment, emphasize \"Identify funny moments, reactions, and unexpected events.\" For podcast clips, specify \"Extract controversial opinions, storytelling segments, and quotable statements.\"\n\n**Change aspect ratios**\n\nThe workflow defaults to 9:16 for vertical video. To create horizontal clips for YouTube or other platforms, open the \"Analyze the actual whole video\" node and change the aspect ratio in the JSON schema from `\"aspect_ratio\": \"9:16\"` to `\"aspect_ratio\": \"16:9\"`. The AI will automatically adjust cropping coordinates accordingly.\n\n**Enable audio normalization**\n\nBy default, audio normalization is disabled for faster processing. To enable it, open the \"extract all actionable operations\" node, find the audio_normalize task object, and change `enabled: false` to `enabled: true`. This ensures consistent volume levels across all clips but adds processing time.\n\n**Add custom editing operations**\n\nThe editing pipeline is modular. You can add new operations like:\n- Color grading by inserting FFmpeg color filters\n- Logo overlays by adding watermark commands\n- Intro/outro sequences by concatenating video files\n- Background music by mixing audio tracks\n\nAdd these as new task objects in the \"extract all actionable operations\" node following the existing pattern.\n\n**Customize notification content**\n\nOpen the \"Send a message\" node to modify the email subject, body text, or add clip details. You can include clip metadata like timestamps, scores, and descriptions using expressions like `{{ $json.hook }}` or `{{ $json.score }}`.\n\n**Integrate with cloud storage**\n\nAdd nodes after clip generation to automatically upload finished clips to Google Drive, Dropbox, AWS S3, or any n8n-supported storage service. Use the Loop Over Items1 output to access completed clip file paths.\n\n**Schedule automated processing**\n\nReplace the Form Trigger with a Schedule Trigger to automatically process videos from a spreadsheet or RSS feed. Combine with Google Sheets integration to maintain a queue of videos to process overnight.",
  "featuredImage": "/data/workflows/11584/11584.webp",
  "author": {
    "id": 101,
    "slug": "faiz",
    "name": "Habeeb Mohammed",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1523,
  "downloads": 152,
  "createdAt": "2025-12-07T19:03:28.753Z",
  "updatedAt": "2026-01-16T09:09:12.463Z",
  "publishedAt": "2025-12-07T19:03:28.753Z",
  "nodes": 42,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11584",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Extract viral-worthy clips from YouTube videos with Gemini AI & FFmpeg editing",
    "workflowName": "Extract viral-worthy clips from YouTube videos with Gemini AI & FFmpeg editing",
    "description": "![Workflow Overview](https://raw.githubusercontent.com/Habeeb-MD-Faiz/n8n/main/images/cliping.jpg)\n\n## Who's it for\n\nThis workflow transforms hours of manual video editing into an automated AI-powered pipeline. Perfect for anyone looking to repurpose long-form content into viral short-form clips.\n\n**Ideal users include:**\n\n- **Content Creators** - YouTubers producing long-form videos who want to maximize reach by automatically generating TikTok, Reels, and Shorts from their content\n- **Social Media Managers** - Agencies and freelancers handling multiple clients who need to scale clip production without hiring additional editors\n- **Podcasters** - Audio and video podcast hosts wanting to create promotional clips highlighting the best moments from each episode\n- **Video Editors** - Professional editors looking to automate repetitive clipping tasks and focus on creative decisions rather than technical execution\n- **Marketing Teams** - B2B and B2C teams extracting key moments from webinars, product demos, tutorials, and educational content for social campaigns\n\nWhether you're a solo creator or managing content at scale, this workflow saves 5-10 hours per video while maintaining professional quality output.\n\n## How it works\n\nThis workflow combines AI analysis with professional video editing tools to automatically identify and produce viral-ready clips from any YouTube video.\n\n**The process flows through three main stages:**\n\n**Stage 1: Download and Analysis**\n- Submit a YouTube URL through the built-in form trigger\n- yt-dlp simultaneously downloads the video in highest quality and extracts subtitles or auto-generated transcripts\n- The transcript is intelligently chunked into 150-segment batches for optimal AI processing\n- Each batch is analyzed by Gemini AI using specialized prompts that evaluate viral potential based on hooks, pacing, emotional peaks, and engagement triggers\n- AI identifies 3-5 high-quality moments per batch and assigns virality scores to each potential clip\n\n**Stage 2: Clip Selection and Extraction**\n- All AI-identified clips are merged and sorted by their virality scores\n- The top 10 candidates are automatically selected for processing\n- FFmpeg extracts each clip segment from the original video at precise timestamps\n- Clips are processed sequentially to prevent system overload\n\n**Stage 3: Professional Editing Pipeline**\n- Each clip enters a multi-stage editing subworkflow with automated operations:\n- Smart 9:16 cropping that intelligently frames the subject for vertical platforms\n- Precise trimming to remove dead air and optimize pacing\n- Dynamic subtitle generation with sizing calculated based on video resolution\n- Professional subtitle styling including bold text, high-contrast colors, strategic positioning, and text wrapping\n- Subtitles are burned directly into the video as permanent overlays\n\n**Final Delivery:**\nThe workflow processes clips with configurable wait times to match your system's capabilities. When all clips complete processing, you receive an email notification and find your social-ready clips in the `/data/clips/` directory, ready for upload to any platform.\n\n## Requirements\n\n**⚠️ Self-hosted n8n only** - This workflow requires command-line access and cannot run on n8n Cloud due to its dependency on system-level tools.\n\n**System dependencies you must install:**\n- **FFmpeg** - Industry-standard video processing tool for trimming, cropping, and subtitle burning. Install on your n8n host system following [this comprehensive guide](https://docs.n8n.io/integrations/community-nodes/installation/gui-install/). Most Linux systems can install via package manager: `apt-get install ffmpeg` or `yum install ffmpeg`.\n- **yt-dlp** - Advanced YouTube downloader that handles video and subtitle extraction. Follow [official installation instructions](https://github.com/yt-dlp/yt-dlp#installation). Recommended: `pip install yt-dlp` or direct binary download.\n- **FFprobe** - Usually included with FFmpeg, used for detecting video dimensions for dynamic subtitle sizing.\n\n**Credentials needed:**\n- **Google Gemini API account** - Powers the AI analysis for clip identification and editing instructions. [Get your free API key](https://ai.google.dev/) with generous free tier limits.\n- **Gmail OAuth2 credentials** - Enables email notifications when clips are ready. Set up through n8n's credential system.\n\n**Storage requirements:**\n- Ensure `/data/clips/` directory exists with write permissions\n- Plan for 2-3x the original video size in temporary storage during processing\n- Final clips typically use 10-30% of original video size\n\n## How to set up\n\n**Step 1: Install system dependencies**\n\nSSH into your n8n host and install required tools. For Ubuntu/Debian systems, run:\n```\napt-get update\napt-get install ffmpeg\npip install yt-dlp\n```\n\nVerify installations by running `ffmpeg -version` and `yt-dlp --version`.\n\n**Step 2: Configure directory structure**\n\nCreate the clips output directory with proper permissions:\n```\nmkdir -p /data/clips\nchmod 755 /data/clips\n```\n\n**Step 3: Import the workflow**\n\nDownload the workflow JSON and import it into your n8n instance. You'll see several sticky notes color-coded by stage: yellow for description, blue for download/analysis, pink for editing operations, and green for clipping.\n\n**Step 4: Set up credentials**\n\nNavigate to the \"viral clips identification\" node and add your Google Gemini API credentials. The workflow uses the `gemini-2.5-flash` model for optimal speed and quality balance. Then configure Gmail OAuth2 in the \"Send a message\" node following n8n's authentication wizard.\n\n**Step 5: Update email notification**\n\nOpen the \"Send a message\" node and replace `habeebmohammedfaiz@gmail.com` with your email address.\n\n**Step 6: Create the editing subworkflow**\n\nThe workflow references a separate subworkflow for the editing pipeline. Create a new workflow in n8n, copy all nodes from the \"EDITING\" section (between the Execute Workflow Trigger and the final output), and save it. Note the workflow ID from the URL.\n\n**Step 7: Link the subworkflow**\n\nIn the main workflow, open the \"Call subworkflow\" node and update the workflow ID to match your newly created editing workflow.\n\n**Step 8: Test with a short video**\n\nStart with a 5-10 minute YouTube video for your first test. Use the manual trigger or form submission. Monitor the execution to ensure all nodes complete successfully and clips appear in `/data/clips/`.\n\n**Step 9: Adjust performance settings**\n\nBased on your system's performance during the test, modify the Wait node durations. Systems with 8GB+ RAM and modern CPUs can reduce wait times to 30 seconds. Limited systems should keep 60-second waits or increase them.\n\n## How to customize the workflow\n\n**Adjust clip quantity and quality thresholds**\n\nOpen the \"filter out top clips according to score\" node. The code currently uses `.slice(0, 10)` to select the top 10 clips. Change this number based on your needs: use `.slice(0, 5)` for only the best clips, or `.slice(0, 20)` for more options. You can also add score filtering by adding `results.filter(c =&gt; c.score &gt; 0.7)` before the slice operation to only include clips with virality scores above 70%.\n\n**Customize subtitle appearance**\n\nNavigate to the \"calculate relative subtitle size\" node. The JavaScript code defines several styling variables you can modify:\n- `fontSize` - Currently calculated dynamically, but you can hardcode it: `const fontSize = 48;`\n- `fontName` - Change from Arial to any system font: `const fontName = 'Impact';`\n- `primaryColor` - Modify text color using BGR hex format: `'&H00FF00&'` for green, `'&HFF0000&'` for red\n- `borderColor` - Adjust outline color for better contrast\n- `outlineWidth` - Increase from 1 to 2 or 3 for thicker borders\n- `marginV` - Control vertical position (higher values move text up from bottom)\n\n**Modify AI analysis prompts**\n\nIn the \"viral clips identification\" node, edit the Gemini prompt to target specific content types. For educational content, add \"Focus on key teaching moments and actionable tips.\" For entertainment, emphasize \"Identify funny moments, reactions, and unexpected events.\" For podcast clips, specify \"Extract controversial opinions, storytelling segments, and quotable statements.\"\n\n**Change aspect ratios**\n\nThe workflow defaults to 9:16 for vertical video. To create horizontal clips for YouTube or other platforms, open the \"Analyze the actual whole video\" node and change the aspect ratio in the JSON schema from `\"aspect_ratio\": \"9:16\"` to `\"aspect_ratio\": \"16:9\"`. The AI will automatically adjust cropping coordinates accordingly.\n\n**Enable audio normalization**\n\nBy default, audio normalization is disabled for faster processing. To enable it, open the \"extract all actionable operations\" node, find the audio_normalize task object, and change `enabled: false` to `enabled: true`. This ensures consistent volume levels across all clips but adds processing time.\n\n**Add custom editing operations**\n\nThe editing pipeline is modular. You can add new operations like:\n- Color grading by inserting FFmpeg color filters\n- Logo overlays by adding watermark commands\n- Intro/outro sequences by concatenating video files\n- Background music by mixing audio tracks\n\nAdd these as new task objects in the \"extract all actionable operations\" node following the existing pattern.\n\n**Customize notification content**\n\nOpen the \"Send a message\" node to modify the email subject, body text, or add clip details. You can include clip metadata like timestamps, scores, and descriptions using expressions like `{{ $json.hook }}` or `{{ $json.score }}`.\n\n**Integrate with cloud storage**\n\nAdd nodes after clip generation to automatically upload finished clips to Google Drive, Dropbox, AWS S3, or any n8n-supported storage service. Use the Loop Over Items1 output to access completed clip file paths.\n\n**Schedule automated processing**\n\nReplace the Form Trigger with a Schedule Trigger to automatically process videos from a spreadsheet or RSS feed. Combine with Google Sheets integration to maintain a queue of videos to process overnight.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from File",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "On form submission",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.3"
    },
    {
      "name": "get the downloaded video location",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Loop Over Items1",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Loop Over Items2",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "EDITING",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "role": "executeWorkflowTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Send a message",
      "type": "n8n-nodes-base.gmail",
      "role": "gmail",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "video download with yt-dlp",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "get transcript from yt-dlp",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "extract filepath",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "read srt from disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "formating of data",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "some more formating",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "viral clips identification",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "role": "googleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "filter out top clips according to score",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "wait for both branches to complete and merge",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "seperate actionable data items",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "simple clipping (still in orignal aspect ratio)",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "extract all clips paths",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Read clips from disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "extract clip file in base64",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "convert base64 to actual binary file",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Analyze the actual whole video",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "role": "googleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "extract all actionable operations",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Filterout the not required operations",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Call subworkflow",
      "type": "n8n-nodes-base.executeWorkflow",
      "role": "executeWorkflow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "if operation is subtitles",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Execute operation on the clip",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "Wait (according to how powerful your system is and how much ram you have)",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "find height & width",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "calculate relative subtitle size",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "burn subtitles",
      "type": "n8n-nodes-base.executeCommand",
      "role": "executeCommand",
      "configDescription": "Version 1"
    },
    {
      "name": "Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}