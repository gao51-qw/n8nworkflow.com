{
  "id": 7017,
  "slug": "7017",
  "title": "Filter cybersecurity news for your tech stack (OpenAI + Pinecone RAG)",
  "description": "## What it does:\nCollects cybersecurity news from trusted RSS feeds and uses OpenAI’s Retrieval-Augmented Generation (RAG) capabilities with Pinecone to filter for content that is directly relevant to your organization’s tech stack. “Relevant” means the AI looks for news items that mention your specific tools, vendors, frameworks, cloud platforms, programming languages, operating systems, or security solutions — as described in your .txt scope documents. By training on these documents, the system understands the environment you operate in and can prioritize news that could affect your security posture, compliance, or operational stability. Once filtered, summaries of the most important items are sent to your work email every day.\n\n## How it works\n- **Pulls in news from multiple cybersecurity-focused RSS feeds:** The workflow automatically collects articles from trusted, high-signal security news sources. These feeds cover threat intelligence, vulnerability disclosures, vendor advisories, and industry updates.\n- **Filters articles for recency and direct connection to your documented tech stack:** Using the publish date, it removes stale or outdated content. Then, leveraging your .txt scope documents stored in Pinecone, it checks each article for references to your technologies, vendors, platforms, or security tools.\n- **Uses OpenAI to generate and review concise summaries:** For each relevant article, OpenAI creates a short, clear summary of the key points. The AI also evaluates whether the article provides actionable or critical information before passing it through.\n- **Trains on your scope using Pinecone Vector Store (free) for context-aware filtering:** Your scope documents are embedded into a vector store so the AI can “remember” your environment. This context ensures the filtering process understands indirect or non-obvious connections to your tech stack.\n- **Aggregates and sends only the most critical items to your work email:** The system compiles the highest-priority news items into one daily digest, so you can review key developments without wading through irrelevant stories.\n\n## What you need to do:\n1. Setup your OpenAI and Pinecone credentials in the workflow\n2. Create and configure a Pinecone index (dimension 1536 recommended)\n\t1. Pinecone is free to setup.\n\t2. Setup Pinecone with a single free index.\n\t3. Use a namespace like: scope.\n\t4. Make sure the embedding model is the same for all of your Pinecone references.\n3. Submit .txt scope documents listing your technologies, vendors, platforms, frameworks, and security products.\n\t1. .txt does not need to be structured.\n\t2. Add as much detail as possible.\n4. Update AI prompts to accurately describe your company’s environment and priorities.\n",
  "featuredImage": "/data/workflows/7017/7017.webp",
  "author": {
    "id": 101,
    "slug": "will-carlson",
    "name": "Will Carlson",
    "avatar": ""
  },
  "categories": [
    "SecOps",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1797,
  "downloads": 179,
  "createdAt": "2025-08-05T16:19:47.224Z",
  "updatedAt": "2026-01-16T08:48:11.476Z",
  "publishedAt": "2025-08-05T16:19:47.224Z",
  "nodes": 41,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/7017",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Filter cybersecurity news for your tech stack (OpenAI + Pinecone RAG)",
    "workflowName": "Filter cybersecurity news for your tech stack (OpenAI + Pinecone RAG)",
    "description": "## What it does:\nCollects cybersecurity news from trusted RSS feeds and uses OpenAI’s Retrieval-Augmented Generation (RAG) capabilities with Pinecone to filter for content that is directly relevant to your organization’s tech stack. “Relevant” means the AI looks for news items that mention your specific tools, vendors, frameworks, cloud platforms, programming languages, operating systems, or security solutions — as described in your .txt scope documents. By training on these documents, the system understands the environment you operate in and can prioritize news that could affect your security posture, compliance, or operational stability. Once filtered, summaries of the most important items are sent to your work email every day.\n\n## How it works\n- **Pulls in news from multiple cybersecurity-focused RSS feeds:** The workflow automatically collects articles from trusted, high-signal security news sources. These feeds cover threat intelligence, vulnerability disclosures, vendor advisories, and industry updates.\n- **Filters articles for recency and direct connection to your documented tech stack:** Using the publish date, it removes stale or outdated content. Then, leveraging your .txt scope documents stored in Pinecone, it checks each article for references to your technologies, vendors, platforms, or security tools.\n- **Uses OpenAI to generate and review concise summaries:** For each relevant article, OpenAI creates a short, clear summary of the key points. The AI also evaluates whether the article provides actionable or critical information before passing it through.\n- **Trains on your scope using Pinecone Vector Store (free) for context-aware filtering:** Your scope documents are embedded into a vector store so the AI can “remember” your environment. This context ensures the filtering process understands indirect or non-obvious connections to your tech stack.\n- **Aggregates and sends only the most critical items to your work email:** The system compiles the highest-priority news items into one daily digest, so you can review key developments without wading through irrelevant stories.\n\n## What you need to do:\n1. Setup your OpenAI and Pinecone credentials in the workflow\n2. Create and configure a Pinecone index (dimension 1536 recommended)\n\t1. Pinecone is free to setup.\n\t2. Setup Pinecone with a single free index.\n\t3. Use a namespace like: scope.\n\t4. Make sure the embedding model is the same for all of your Pinecone references.\n3. Submit .txt scope documents listing your technologies, vendors, platforms, frameworks, and security products.\n\t1. .txt does not need to be structured.\n\t2. Add as much detail as possible.\n4. Update AI prompts to accurately describe your company’s environment and priorities.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Schedule Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Bleeping Computer",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1.2"
    },
    {
      "name": "The Hacker News",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Security Week",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Nist.Gov",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Krebson Security",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Threat Intelligence Analyst AI",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Send message to work email",
      "type": "n8n-nodes-base.gmail",
      "role": "gmail",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "On form submission",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.2"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Pinecone RAG test",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "OpenAI Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Pinecone Vector Store2",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "CISA.gov",
      "type": "n8n-nodes-base.rssFeedRead",
      "role": "rssFeedRead",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Second Reviewer Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "o4-mini",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Newer than 24 hours",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Pinecone Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Pinecone Vector Store Submission",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Merge all RSS items",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "News older than 24 hours",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Limit Length of article",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "If AI Agent thinks article is relevant to you",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Do nothing - Article is irrelevant",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Wait 1 minute",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Wait 1 minute (rate-limits)",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Loop Over Items (Batch = 10)",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Loop Over Items (Batch = 4)",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "If second ai agent thinks article is relevant",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Do nothing - Ai Agent thinks article is irrelevant",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate articles into one email",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}