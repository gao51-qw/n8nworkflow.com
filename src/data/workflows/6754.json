{
  "id": 6754,
  "slug": "6754",
  "title": "Scrape and analyze websites with custom prompts using Gemini, Apify, and LangChain",
  "description": "\n# ğŸ” AI-Powered Website Prompt Executor (Apify + OpenRouter)\n\nThis workflow combines the power of [Apify](https://apify.com) and [OpenRouter](https://openrouter.ai) to **scrape website content** and **execute any custom prompt** using AI. You define what you want â€” whether itâ€™s extracting contact details, summarizing content, collecting job offers, or anything else â€” and the system intelligently processes the site to give you results.\n\n## ğŸš€ Overview\n\nThis workflow allows you to:\n1. Input a URL and define a prompt.\n2. Scrape the specified number of pages from the website.\n3. Process each pageâ€™s metadata and Markdown content.\n4. Use AI to interpret and respond to the prompt on each page.\n5. Aggregate and return structured output.\n\n## ğŸ§  How It Works\n\n### Input Example\n\n```json\n{\n  \"enqueue\": true,\n  \"maxPages\": 5,\n  \"url\": \"https://apify.com\",\n  \"method\": \"GET\",\n  \"prompt\": \"collect all contact informations available on this website\"\n}\n````\n\n### Workflow Steps\n\n| Step | Action                                                                                                                                                                         |\n| ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| 1    | Triggered by another workflow with JSON input.                                                                                                                                 |\n| 2    | Calls the Apify actor [`firescraper-ai-website-content-markdown-scraper`](https://apify.com/mohamedgb00714/firescraper-ai-website-content-markdown-scraper) to scrape content. |\n| 3    | Loops through the scraped pages.                                                                                                                                               |\n| 4    | AI analyzes each page based on the input prompt.                                                                                                                               |\n| 5    | Aggregates AI outputs across all pages.                                                                                                                                        |\n| 6    | Final AI processing step to return a clean structured result.                                                                                                                  |\n\n---\n\n## ğŸ›  Technologies Used\n\n* **Apify** â€“ Scrapes structured content and Markdown from websites.\n* **OpenRouter** â€“ Provides access to advanced AI models like Gemini.\n* **LangChain** â€“ Handles AI agent orchestration and prompt interpretation.\n\n---\n\n## ğŸ”§ Customization\n\nCustomize the workflow via the following input fields:\n\n* `url`: Starting point for scraping\n* `maxPages`: Limit the number of pages to crawl\n* `prompt`: Define any instruction (e.g., â€œsummarize this website,â€ â€œextract product data,â€ â€œlist all emails,â€ etc.)\n\nThis allows dynamic, flexible use across various use cases.\n\n---\n\n## ğŸ“¦ Output\n\nThe workflow returns a JSON result that includes:\n\n* Processed prompt responses from each page\n* Aggregated AI insights\n* Structured and machine-readable format\n\n---\n\n## ğŸ§ª Example Use Cases\n\n* ğŸ” Extracting contact information from websites\n* ğŸ“„ Summarizing articles or company profiles\n* ğŸ›ï¸ Collecting product information\n* ğŸ“‹ Extracting job listings or news\n* ğŸ“¬ Generating outreach lists from public data\n* ğŸ¤– **Used as a tool within other AI agents for real-time web analysis**\n* ğŸ§© **Integrated as an external tool in MCP (Multi-Component Prompt) servers to enhance AI capabilities**\n\n---\n\n## ğŸ” API Credentials Required\n\nYou will need:\n\n* **Apify API token** â€“ For running the scraper actor\n* **OpenRouter API key** â€“ For AI-powered prompt processing\n\nSet these credentials in your environment or n8n credential manager before running.\n\n\n\n\n",
  "featuredImage": "/data/workflows/6754/6754.webp",
  "author": {
    "id": 101,
    "slug": "mohamedgb00714",
    "name": "Msaid Mohamed el hadi",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 1573,
  "downloads": 157,
  "createdAt": "2025-07-31T23:40:37.594Z",
  "updatedAt": "2026-01-16T08:46:55.492Z",
  "publishedAt": "2025-07-31T23:40:37.594Z",
  "nodes": 9,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6754",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Scrape and analyze websites with custom prompts using Gemini, Apify, and LangChain",
    "workflowName": "Scrape and analyze websites with custom prompts using Gemini, Apify, and LangChain",
    "description": "# ğŸ” AI-Powered Website Prompt Executor (Apify + OpenRouter)\n\nThis workflow combines the power of [Apify](https://apify.com) and [OpenRouter](https://openrouter.ai) to **scrape website content** and **execute any custom prompt** using AI. You define what you want â€” whether itâ€™s extracting contact details, summarizing content, collecting job offers, or anything else â€” and the system intelligently processes the site to give you results.\n\n## ğŸš€ Overview\n\nThis workflow allows you to:\n1. Input a URL and define a prompt.\n2. Scrape the specified number of pages from the website.\n3. Process each pageâ€™s metadata and Markdown content.\n4. Use AI to interpret and respond to the prompt on each page.\n5. Aggregate and return structured output.\n\n## ğŸ§  How It Works\n\n### Input Example\n\n```json\n{\n  \"enqueue\": true,\n  \"maxPages\": 5,\n  \"url\": \"https://apify.com\",\n  \"method\": \"GET\",\n  \"prompt\": \"collect all contact informations available on this website\"\n}\n````\n\n### Workflow Steps\n\n| Step | Action                                                                                                                                                                         |\n| ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| 1    | Triggered by another workflow with JSON input.                                                                                                                                 |\n| 2    | Calls the Apify actor [`firescraper-ai-website-content-markdown-scraper`](https://apify.com/mohamedgb00714/firescraper-ai-website-content-markdown-scraper) to scrape content. |\n| 3    | Loops through the scraped pages.                                                                                                                                               |\n| 4    | AI analyzes each page based on the input prompt.                                                                                                                               |\n| 5    | Aggregates AI outputs across all pages.                                                                                                                                        |\n| 6    | Final AI processing step to return a clean structured result.                                                                                                                  |\n\n---\n\n## ğŸ›  Technologies Used\n\n* **Apify** â€“ Scrapes structured content and Markdown from websites.\n* **OpenRouter** â€“ Provides access to advanced AI models like Gemini.\n* **LangChain** â€“ Handles AI agent orchestration and prompt interpretation.\n\n---\n\n## ğŸ”§ Customization\n\nCustomize the workflow via the following input fields:\n\n* `url`: Starting point for scraping\n* `maxPages`: Limit the number of pages to crawl\n* `prompt`: Define any instruction (e.g., â€œsummarize this website,â€ â€œextract product data,â€ â€œlist all emails,â€ etc.)\n\nThis allows dynamic, flexible use across various use cases.\n\n---\n\n## ğŸ“¦ Output\n\nThe workflow returns a JSON result that includes:\n\n* Processed prompt responses from each page\n* Aggregated AI insights\n* Structured and machine-readable format\n\n---\n\n## ğŸ§ª Example Use Cases\n\n* ğŸ” Extracting contact information from websites\n* ğŸ“„ Summarizing articles or company profiles\n* ğŸ›ï¸ Collecting product information\n* ğŸ“‹ Extracting job listings or news\n* ğŸ“¬ Generating outreach lists from public data\n* ğŸ¤– **Used as a tool within other AI agents for real-time web analysis**\n* ğŸ§© **Integrated as an external tool in MCP (Multi-Component Prompt) servers to enhance AI capabilities**\n\n---\n\n## ğŸ” API Credentials Required\n\nYou will need:\n\n* **Apify API token** â€“ For running the scraper actor\n* **OpenRouter API key** â€“ For AI-powered prompt processing\n\nSet these credentials in your environment or n8n credential manager before running.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When Executed by Another Workflow",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "role": "executeWorkflowTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "OpenRouter Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "role": "lmChatOpenRouter",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenRouter Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "role": "lmChatOpenRouter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}