{
  "id": 5085,
  "slug": "5085",
  "title": "Convert tour PDFs to vector database using Google Drive, LangChain & OpenAI",
  "description": "# **üß© Workflow:** \nProcess Tour PDF from Google Drive to Pinecone Vector DB with OpenAI Embeddings\n\n## **Overview**\nThis workflow automates the process of extracting tour information from PDF files stored in a Google Drive folder, processes and vectorizes the extracted data, and stores it in a Pinecone vector database for efficient querying. This is especially useful for building AI-powered search or recommendation systems for travel packages.\n\n## **Setup:** \n\n### Prerequisites\nA folder in Google Drive with PDF tour package brochures.\n\nPinecone account + API key\n\nOpenAI API key\n\nn8n cloud or self-hosted instance\n\n## **Workflow Setup Steps**\n#### Trigger\nManual Trigger (When clicking 'Test workflow'): Used for manual testing and execution of the workflow.\n\n#### Google Drive Integration\n**Step 1: Store Tour Packages in PDF Format**\n\nUpload your curated tour packages containing the tours, activities and sight-seeings in PDF format into a designated Google Drive folder.\n\n**Step 2: Search Folder**\n\nNode: PDF Tour Package Folder (Google Drive)\n\nThis node searches the designated folder for files (filter by MIME type = application/pdf if needed).\n\n**Step 3: Download PDFs**\n\nNode: Download Package Files (Google Drive)\n\nDownloads each matching PDF file found in the previous step.\n\n#### Process Each PDF File\n**Step 4: Loop Through Files**\n\nNode: Loop Over each PDF file\n\nIterates through each downloaded PDF file to extract, clean, split, and embed.\n\n#### Data Preparation & Embedding\n**Step 5: Data Loader**\n\nNode: Data Loader\n\nReads each PDF‚Äôs content using a compatible loader. It passes clean raw text to the next node.\n\nOften integrated with document loaders like pdf-loader, Unstructured, or pdfplumber.\n\n**Step 6: Recursive Text Splitter**\n\nNode: Recursive Character Text Splitter\n\nSplits large chunks of text into manageable segments using overlapping window logic (e.g., 500 tokens with 50 token overlap).\n\nThis ensures contextual preservation for long documents during embedding.\n\n**Step 7: Generate Embeddings**\n\nNode: Embeddings OpenAI\n\nUses text-embedding-3-small model to vectorize the split chunks.\n\nOutputs vector representations for each content chunk.\n\n#### Store in Pinecone\n**Step 8: Pinecone Vector Store**\n\nNode: Pinecone Vector Store - Store...\n\nStores each embedding along with its metadata (source PDF name, chunk ID, etc.).\n\nThis becomes the basis for fast, semantic search via RAG workflows or agents.\n\n\n## **üõ†Ô∏è Tools & Nodes Used**\nGoogle Drive (Search & Download)\n\nSearches for all PDF files in a specified Google Drive folder.\nDownloads each file for processing.\nSplitInBatches (Loop Over Items)\n\nLoops through each file found in the folder, ensuring each is processed individually.\nDefault Data Loader (LangChain)\n\nReads and extracts text from the PDF files.\nRecursive Character Text Splitter (LangChain)\n\nSplits the extracted text into manageable chunks for embedding.\nOpenAI Embeddings (LangChain)\n\nConverts each text chunk into a vector using OpenAI‚Äôs embedding model.\nPinecone Vector Store (LangChain)\n\nStores the resulting vectors in a Pinecone index for fast similarity search and querying.\n\n## **üîó Workflow Steps Explained**\n### **Trigger:** \nThe workflow starts manually for testing or can be scheduled.\n### **Google Drive Search:** \nFinds all PDF files in the specified folder.\n\n### **Loop Over Files:** \nEach file is processed one at a time using the SplitInBatches node.\n\n### Download File: \nDownloads the current PDF file from Google Drive.\n\n### **Extract Text:** \nThe Default Data Loader node reads the PDF and extracts its text content.\n\n### **Text Splitting: **\nThe Recursive Character Text Splitter breaks the text into chunks (e.g., 1000 characters with 50 overlap) to optimize embedding quality.\n\n### **Vectorization: \n**Each chunk is sent to the OpenAI Embeddings node to generate vector representations.\n\n### **Store in Pinecone:** \nThe vectors are inserted into a Pinecone index, making them available for semantic search and recommendations.\n\n## **üöÄ What Can Be Improved in the Next Version?**\n\n#### **Error Handling: **\nAdd error handling nodes to manage failed downloads or extraction issues gracefully.\n#### **File Type Filtering:** \nEnsure only PDF files are processed by adding a filter node.\n#### **Metadata Storage:** \nStore additional metadata (e.g., file name, tour ID) alongside vectors in Pinecone for richer search results.\n#### **Parallel Processing: **\nOptimize for large folders by processing multiple files in parallel (with care for API rate limits).\n#### **Automated Triggers:** \nReplace manual trigger with a time-based or webhook trigger for full automation.\n#### **Data Validation:** \nAdd checks to ensure extracted text contains valid tour data before vectorization.\n#### **User Feedback:** \nIntegrate notifications (e.g., email or Slack) to inform when processing is complete or if issues arise.\n\n## **üí° Summary**\nThis workflow demonstrates how n8n can orchestrate a powerful AI data pipeline using Google Drive, LangChain, OpenAI, and Pinecone. It‚Äôs a great foundation for building intelligent search or recommendation features for travel and tour data.\n\nFeel free to ask for more details or share your improvements!\n\n\nLet me know if you want to see a specific part of the workflow or need help with a particular node!",
  "featuredImage": "/data/workflows/5085/5085.webp",
  "author": {
    "id": 101,
    "slug": "mohan",
    "name": "Mohan Gopal",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 1234,
  "downloads": 123,
  "createdAt": "2025-06-21T06:37:26.155Z",
  "updatedAt": "2026-01-16T08:37:34.481Z",
  "publishedAt": "2025-06-21T06:37:26.155Z",
  "nodes": 10,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5085",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Convert tour PDFs to vector database using Google Drive, LangChain & OpenAI",
    "workflowName": "Convert tour PDFs to vector database using Google Drive, LangChain & OpenAI",
    "description": "# **üß© Workflow:** \nProcess Tour PDF from Google Drive to Pinecone Vector DB with OpenAI Embeddings\n\n## **Overview**\nThis workflow automates the process of extracting tour information from PDF files stored in a Google Drive folder, processes and vectorizes the extracted data, and stores it in a Pinecone vector database for efficient querying. This is especially useful for building AI-powered search or recommendation systems for travel packages.\n\n## **Setup:** \n\n### Prerequisites\nA folder in Google Drive with PDF tour package brochures.\n\nPinecone account + API key\n\nOpenAI API key\n\nn8n cloud or self-hosted instance\n\n## **Workflow Setup Steps**\n#### Trigger\nManual Trigger (When clicking 'Test workflow'): Used for manual testing and execution of the workflow.\n\n#### Google Drive Integration\n**Step 1: Store Tour Packages in PDF Format**\n\nUpload your curated tour packages containing the tours, activities and sight-seeings in PDF format into a designated Google Drive folder.\n\n**Step 2: Search Folder**\n\nNode: PDF Tour Package Folder (Google Drive)\n\nThis node searches the designated folder for files (filter by MIME type = application/pdf if needed).\n\n**Step 3: Download PDFs**\n\nNode: Download Package Files (Google Drive)\n\nDownloads each matching PDF file found in the previous step.\n\n#### Process Each PDF File\n**Step 4: Loop Through Files**\n\nNode: Loop Over each PDF file\n\nIterates through each downloaded PDF file to extract, clean, split, and embed.\n\n#### Data Preparation & Embedding\n**Step 5: Data Loader**\n\nNode: Data Loader\n\nReads each PDF‚Äôs content using a compatible loader. It passes clean raw text to the next node.\n\nOften integrated with document loaders like pdf-loader, Unstructured, or pdfplumber.\n\n**Step 6: Recursive Text Splitter**\n\nNode: Recursive Character Text Splitter\n\nSplits large chunks of text into manageable segments using overlapping window logic (e.g., 500 tokens with 50 token overlap).\n\nThis ensures contextual preservation for long documents during embedding.\n\n**Step 7: Generate Embeddings**\n\nNode: Embeddings OpenAI\n\nUses text-embedding-3-small model to vectorize the split chunks.\n\nOutputs vector representations for each content chunk.\n\n#### Store in Pinecone\n**Step 8: Pinecone Vector Store**\n\nNode: Pinecone Vector Store - Store...\n\nStores each embedding along with its metadata (source PDF name, chunk ID, etc.).\n\nThis becomes the basis for fast, semantic search via RAG workflows or agents.\n\n\n## **üõ†Ô∏è Tools & Nodes Used**\nGoogle Drive (Search & Download)\n\nSearches for all PDF files in a specified Google Drive folder.\nDownloads each file for processing.\nSplitInBatches (Loop Over Items)\n\nLoops through each file found in the folder, ensuring each is processed individually.\nDefault Data Loader (LangChain)\n\nReads and extracts text from the PDF files.\nRecursive Character Text Splitter (LangChain)\n\nSplits the extracted text into manageable chunks for embedding.\nOpenAI Embeddings (LangChain)\n\nConverts each text chunk into a vector using OpenAI‚Äôs embedding model.\nPinecone Vector Store (LangChain)\n\nStores the resulting vectors in a Pinecone index for fast similarity search and querying.\n\n## **üîó Workflow Steps Explained**\n### **Trigger:** \nThe workflow starts manually for testing or can be scheduled.\n### **Google Drive Search:** \nFinds all PDF files in the specified folder.\n\n### **Loop Over Files:** \nEach file is processed one at a time using the SplitInBatches node.\n\n### Download File: \nDownloads the current PDF file from Google Drive.\n\n### **Extract Text:** \nThe Default Data Loader node reads the PDF and extracts its text content.\n\n### **Text Splitting: **\nThe Recursive Character Text Splitter breaks the text into chunks (e.g., 1000 characters with 50 overlap) to optimize embedding quality.\n\n### **Vectorization: \n**Each chunk is sent to the OpenAI Embeddings node to generate vector representations.\n\n### **Store in Pinecone:** \nThe vectors are inserted into a Pinecone index, making them available for semantic search and recommendations.\n\n## **üöÄ What Can Be Improved in the Next Version?**\n\n#### **Error Handling: **\nAdd error handling nodes to manage failed downloads or extraction issues gracefully.\n#### **File Type Filtering:** \nEnsure only PDF files are processed by adding a filter node.\n#### **Metadata Storage:** \nStore additional metadata (e.g., file name, tour ID) alongside vectors in Pinecone for richer search results.\n#### **Parallel Processing: **\nOptimize for large folders by processing multiple files in parallel (with care for API rate limits).\n#### **Automated Triggers:** \nReplace manual trigger with a time-based or webhook trigger for full automation.\n#### **Data Validation:** \nAdd checks to ensure extracted text contains valid tour data before vectorization.\n#### **User Feedback:** \nIntegrate notifications (e.g., email or Slack) to inform when processing is complete or if issues arise.\n\n## **üí° Summary**\nThis workflow demonstrates how n8n can orchestrate a powerful AI data pipeline using Google Drive, LangChain, OpenAI, and Pinecone. It‚Äôs a great foundation for building intelligent search or recommendation features for travel and tour data.\n\nFeel free to ask for more details or share your improvements!\n\n\nLet me know if you want to see a specific part of the workflow or need help with a particular node!",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‚ÄòTest workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "PDF Tour Package Folder",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Download Package Files",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Loop Over each PDF file",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Pinecone Vector Store - Store Vector Data",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}