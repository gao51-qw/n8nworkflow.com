{
  "id": 3858,
  "slug": "3858",
  "title": "OpenAI ImageGen1 via HTTP request (edit image)",
  "description": "# Edit an existing image with OpenAI ImageGen1 via API Request\n\nTransform your creative pipeline by letting **n8n** call **OpenAI ImageGen1‚Äôs _edit image_ endpoint**, automatically replacing or augmenting parts of any image you supply and returning a brand-new version in seconds. Designers, marketers, and product teams can eliminate repetitive manual edits and test more variations, faster.\n\n### Who is this for?\n- Content creators who need quick, on-brand image tweaks  \n- Marketers running A/B visual tests at scale  \n- Developers exploring the new ImageGen1 API inside low-code automations  \n\n### Use case / problem solved\nOpening design software to mask, fill, or swap objects is slow and error-prone. This workflow feeds an input image plus a prompt to **OpenAI ImageGen1**, receives the edited output, and passes it on to any service you like‚Äîperfect for bulk-editing product shots, social visuals, or UI mocks.\n\n### What this workflow does\n1. **Read or receive** the source image (Webhook ‚Üí Binary Data).  \n2. **Call OpenAI ImageGen1** with an **HTTP Request** node, sending the image and edit prompt.  \n3. **Parse** the JSON response to capture the returned image URL.  \n4. **Download & hand off** the edited file (e.g., upload to S3, post to Slack, or store in Drive).\n\n### Setup\n1. Add your **OpenAI API key** in the API KEY node.  \n2. Follow the notes on the workflow for more information. \n3. (Optional) Point the final node to your preferred storage or chat tool.  \n\n&gt; üìù A sticky note in the workflow summarizes these steps and links to the OpenAI documentation.\n\n### How to customize this workflow\n- **Trigger alternatives**: Replace the Chat with Google Drive, Airtable, etc.  \n- **Chained edits**: Loop the output back for successive prompts.  \n- **Conditional flows**: Add an If node to branch actions by image size or category.  \n\nWith renamed nodes, color-coded sticky notes, and a concise setup guide, you‚Äôll be editing images via **OpenAI ImageGen1** in under five minutes‚Äîno code, maximum creativity.\n",
  "featuredImage": "/data/workflows/3858/3858.webp",
  "author": {
    "id": 101,
    "slug": "techdennis",
    "name": "TechDennis",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 2117,
  "downloads": 211,
  "createdAt": "2025-05-04T13:35:07.714Z",
  "updatedAt": "2026-01-16T08:31:48.247Z",
  "publishedAt": "2025-05-04T13:35:07.714Z",
  "nodes": 6,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3858",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "OpenAI ImageGen1 via HTTP request (edit image)",
    "workflowName": "OpenAI ImageGen1 via HTTP request (edit image)",
    "description": "# Edit an existing image with OpenAI ImageGen1 via API Request\n\nTransform your creative pipeline by letting **n8n** call **OpenAI ImageGen1‚Äôs _edit image_ endpoint**, automatically replacing or augmenting parts of any image you supply and returning a brand-new version in seconds. Designers, marketers, and product teams can eliminate repetitive manual edits and test more variations, faster.\n\n### Who is this for?\n- Content creators who need quick, on-brand image tweaks  \n- Marketers running A/B visual tests at scale  \n- Developers exploring the new ImageGen1 API inside low-code automations  \n\n### Use case / problem solved\nOpening design software to mask, fill, or swap objects is slow and error-prone. This workflow feeds an input image plus a prompt to **OpenAI ImageGen1**, receives the edited output, and passes it on to any service you like‚Äîperfect for bulk-editing product shots, social visuals, or UI mocks.\n\n### What this workflow does\n1. **Read or receive** the source image (Webhook ‚Üí Binary Data).  \n2. **Call OpenAI ImageGen1** with an **HTTP Request** node, sending the image and edit prompt.  \n3. **Parse** the JSON response to capture the returned image URL.  \n4. **Download & hand off** the edited file (e.g., upload to S3, post to Slack, or store in Drive).\n\n### Setup\n1. Add your **OpenAI API key** in the API KEY node.  \n2. Follow the notes on the workflow for more information. \n3. (Optional) Point the final node to your preferred storage or chat tool.  \n\n&gt; üìù A sticky note in the workflow summarizes these steps and links to the OpenAI documentation.\n\n### How to customize this workflow\n- **Trigger alternatives**: Replace the Chat with Google Drive, Airtable, etc.  \n- **Chained edits**: Loop the output back for successive prompts.  \n- **Conditional flows**: Add an If node to branch actions by image size or category.  \n\nWith renamed nodes, color-coded sticky notes, and a concise setup guide, you‚Äôll be editing images via **OpenAI ImageGen1** in under five minutes‚Äîno code, maximum creativity.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Convert to File",
      "type": "n8n-nodes-base.convertToFile",
      "role": "convertToFile",
      "configDescription": "Version 1.1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "API KEY",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}