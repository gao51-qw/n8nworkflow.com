{
  "id": 4526,
  "slug": "4526",
  "title": "Build a knowledge base chatbot with OpenAI, RAG and MongoDB vector embeddings",
  "description": "### Who is this for?\n\nThis template is designed for internal support teams, product specialists, and knowledge managers in technology companies who want to automate ingestion of product documentation and enable AI-driven, retrieval-augmented question answering.\n\n### What problem is this workflow solving?\nSupport agents often spend too much time manually searching through lengthy documentation, leading to inconsistent or delayed answers. This solution automates importing, chunking, and indexing product manuals, then uses retrieval-augmented generation (RAG) to answer user queries accurately and quickly with AI.\n\n### What these workflows do\n**Workflow 1**: Document Ingestion & Indexing\nManually triggered to import product documentation from Google Docs.\n\nAutomatically splits large documents into chunks for efficient searching.\n\nGenerates vector embeddings for each chunk using OpenAI embeddings.\n\nInserts the embedded chunks and metadata into a MongoDB Atlas vector store, enabling fast semantic search.\n\n**Workflow 2**: AI-Powered Query & Response\nListens for incoming user questions (can be extended to webhook).\n\nConverts questions to vector embeddings and performs similarity search on MongoDB vector store.\n\nUses OpenAI’s GPT-4o-mini model with retrieval-augmented generation to produce direct, context-aware answers.\n\nMaintains short-term conversation context using a memory buffer node.\n\n### Setup\n**Setting up vector embeddings**\nAuthenticate Google Docs and connect your Google Docs URL containing the product documentation you want to index.\n\nAuthenticate MongoDB Atlas and connect the collection where you want to store the vector embeddings. Create a search index on this collection to support vector similarity queries.\n\nEnsure the index name matches the one configured in n8n (data_index).\n\nSee the example MongoDB search index template below for reference.\n\n**Setting up chat**\nConfigure the AI system prompt in the “Knowledge Base Agent” node to reflect your company’s tone, answering style, and any business rules.\n\nUpdate the workflow description and instructions to help users understand the chat’s purpose and capabilities.\n\nConnect the MongoDB collection used for vector search in the chat workflow and update the vector search index if needed to match your setup.\n\n### Make sure\nBoth MongoDB nodes (in ingestion and chat workflows) are connected to the same collection, with:\n\nAn embedding field storing vector data,\n\nRelevant metadata fields (e.g., document ID, source), and\n\nThe same vector index name configured (e.g., data_index).\n\n\n\n**Search Index Example:**\n{\n  \"mappings\": {\n    \"dynamic\": false,\n    \"fields\": {\n      \"_id\": {\n        \"type\": \"string\"\n      },\n      \"text\": {\n        \"type\": \"string\"\n      },\n      \"embedding\": {\n        \"type\": \"knnVector\",\n        \"dimensions\": 1536,\n        \"similarity\": \"cosine\"\n      },\n      \"source\": {\n        \"type\": \"string\"\n      },\n      \"doc_id\": {\n        \"type\": \"string\"\n      }\n    }\n  }\n}\n",
  "featuredImage": "/data/workflows/4526/4526.webp",
  "author": {
    "id": 101,
    "slug": "thomasgpt",
    "name": "NovaNode",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 13113,
  "downloads": 1311,
  "createdAt": "2025-05-30T23:12:00.516Z",
  "updatedAt": "2026-01-16T08:34:49.601Z",
  "publishedAt": "2025-05-30T23:12:00.516Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4526",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build a knowledge base chatbot with OpenAI, RAG and MongoDB vector embeddings",
    "workflowName": "Build a knowledge base chatbot with OpenAI, RAG and MongoDB vector embeddings",
    "description": "### Who is this for?\n\nThis template is designed for internal support teams, product specialists, and knowledge managers in technology companies who want to automate ingestion of product documentation and enable AI-driven, retrieval-augmented question answering.\n\n### What problem is this workflow solving?\nSupport agents often spend too much time manually searching through lengthy documentation, leading to inconsistent or delayed answers. This solution automates importing, chunking, and indexing product manuals, then uses retrieval-augmented generation (RAG) to answer user queries accurately and quickly with AI.\n\n### What these workflows do\n**Workflow 1**: Document Ingestion & Indexing\nManually triggered to import product documentation from Google Docs.\n\nAutomatically splits large documents into chunks for efficient searching.\n\nGenerates vector embeddings for each chunk using OpenAI embeddings.\n\nInserts the embedded chunks and metadata into a MongoDB Atlas vector store, enabling fast semantic search.\n\n**Workflow 2**: AI-Powered Query & Response\nListens for incoming user questions (can be extended to webhook).\n\nConverts questions to vector embeddings and performs similarity search on MongoDB vector store.\n\nUses OpenAI’s GPT-4o-mini model with retrieval-augmented generation to produce direct, context-aware answers.\n\nMaintains short-term conversation context using a memory buffer node.\n\n### Setup\n**Setting up vector embeddings**\nAuthenticate Google Docs and connect your Google Docs URL containing the product documentation you want to index.\n\nAuthenticate MongoDB Atlas and connect the collection where you want to store the vector embeddings. Create a search index on this collection to support vector similarity queries.\n\nEnsure the index name matches the one configured in n8n (data_index).\n\nSee the example MongoDB search index template below for reference.\n\n**Setting up chat**\nConfigure the AI system prompt in the “Knowledge Base Agent” node to reflect your company’s tone, answering style, and any business rules.\n\nUpdate the workflow description and instructions to help users understand the chat’s purpose and capabilities.\n\nConnect the MongoDB collection used for vector search in the chat workflow and update the vector search index if needed to match your setup.\n\n### Make sure\nBoth MongoDB nodes (in ingestion and chat workflows) are connected to the same collection, with:\n\nAn embedding field storing vector data,\n\nRelevant metadata fields (e.g., document ID, source), and\n\nThe same vector index name configured (e.g., data_index).\n\n\n\n**Search Index Example:**\n{\n  \"mappings\": {\n    \"dynamic\": false,\n    \"fields\": {\n      \"_id\": {\n        \"type\": \"string\"\n      },\n      \"text\": {\n        \"type\": \"string\"\n      },\n      \"embedding\": {\n        \"type\": \"knnVector\",\n        \"dimensions\": 1536,\n        \"similarity\": \"cosine\"\n      },\n      \"source\": {\n        \"type\": \"string\"\n      },\n      \"doc_id\": {\n        \"type\": \"string\"\n      }\n    }\n  }\n}",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Knowledge Base Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.9"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "When clicking \"Execute Workflow\"",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "MongoDB Vector Search",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreMongoDBAtlas",
      "role": "vectorStoreMongoDBAtlas",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Document Section Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Document Chunker",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "MongoDB Vector Store Inserter",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreMongoDBAtlas",
      "role": "vectorStoreMongoDBAtlas",
      "configDescription": "Version 1.1"
    },
    {
      "name": "OpenAI Embeddings Generator",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Google Docs Importer",
      "type": "n8n-nodes-base.googleDocs",
      "role": "googleDocs",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}