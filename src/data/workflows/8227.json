{
  "id": 8227,
  "slug": "8227",
  "title": "üéì Learn evaluate tool. Tutorial for beginners with Gemini and Google Sheets",
  "description": "\nThis workflow is a beginner-friendly tutorial demonstrating how to use the **Evaluation tool** to automatically score the AI‚Äôs output against a known correct answer (‚Äúground truth‚Äù) stored in a Google Sheet.\n\n\n---\n\n### **Advantages**\n\n* ‚úÖ **Beginner-friendly** ‚Äì Provides a simple and clear structure to understand AI evaluation.\n* ‚úÖ **Flexible input sources** ‚Äì Works with both Google Sheets datasets and manual test entries.\n* ‚úÖ **Integrated with Google Gemini** ‚Äì Leverages a powerful AI model for text-based tasks.\n* ‚úÖ **Tool usage** ‚Äì Demonstrates how an AI agent can call external tools (e.g., calculator) for accurate answers.\n* ‚úÖ **Automated evaluation** ‚Äì Outputs are automatically compared against ground truth data for factual correctness.\n* ‚úÖ **Scalable testing** ‚Äì Can handle multiple dataset rows, making it useful for structured AI model evaluation.\n* ‚úÖ **Result tracking** ‚Äì Saves both answers and correctness scores back to Google Sheets for easy monitoring.\n\n---\n\n### **How it Works**\n\nThe workflow operates in two distinct modes, determined by the trigger:\n1.  **Manual Test Mode:** Triggered by \"When clicking 'Execute workflow'\". It sends a fixed question (\"How much is 8 * 3?\") to the AI agent and returns the answer to the user. This mode is for quick, ad-hoc testing.\n2.  **Evaluation Mode:** Triggered by \"When fetching a dataset row\". This mode reads rows of data from a linked Google Sheet. Each row contains an `input` (a question) and an `expected_output` (the correct answer). It processes each row as follows:\n    *   The `input` question is sent to the **AI Agent** node.\n    *   The AI Agent, powered by a **Google Gemini** model and equipped with a **Calculator** tool, processes the question and generates an answer (`output`).\n    *   The workflow then checks if it's in evaluation mode.\n    *   Instead of just returning the answer, it passes the AI's `actual_output` and the sheet's `expected_output` to another **Evaluation node**.\n    *   This node uses a second **Google Gemini** model as a \"judge\" to evaluate the factual correctness of the AI's answer compared to the expected one, generating a `Correctness` score on a scale from 1 to 5.\n    *   Finally, both the AI's `actual_output` and the automated `correctness` score are written back to a new column in the same row of the Google Sheet.\n\n---\n\n### **Set up Steps**\n\nTo use this workflow, you need to complete the following setup steps:\n\n1.  **Credentials Configuration:**\n    *   Set up the **Google Sheets OAuth2 API** credentials (named \"Google Sheets account\"). This allows n8n to read from and write to your Google Sheet.\n    *   Set up the **Google Gemini (PaLM) API** credentials (named \"Google Gemini(PaLM) (Eure)\"). This provides the AI language model capabilities for both the agent and the evaluator.\n\n2.  **Prepare Your Google Sheet:**\n    *   The workflow is pre-configured to use a specific Google Sheet. You must **clone** the provided template sheet (the URL is in the Sticky Note) to your own Google Drive.\n    *   In your cloned sheet, ensure you have at least two columns: one for the input/question (e.g., `input`) and one for the expected correct answer (e.g., `expected_output`). You may need to update the node parameters that reference `$json.input` and `$json.expected_output` to match your column names exactly.\n\n3.  **Update Document IDs:**\n    *   After cloning the sheet, get its new Document ID from its URL and update the `documentId` field in **all three Evaluation nodes** (\"When fetching a dataset row\", \"Set output Evaluation\", and \"Set correctness\") to point to your new sheet instead of the original template.\n\n4.  **Activate the Workflow:**\n    *   Once the credentials and sheet are configured, toggle the workflow to **Active**. You can then trigger a manual test run or set the \"When fetching a dataset row\" node to poll your sheet automatically to evaluate all rows.\n----\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).\n",
  "featuredImage": "/data/workflows/8227/8227.webp",
  "author": {
    "id": 101,
    "slug": "n3witalia",
    "name": "Davide",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 484,
  "downloads": 48,
  "createdAt": "2025-09-03T17:10:56.887Z",
  "updatedAt": "2026-01-16T08:54:47.588Z",
  "publishedAt": "2025-09-03T17:10:56.887Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/8227",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "üéì Learn evaluate tool. Tutorial for beginners with Gemini and Google Sheets",
    "workflowName": "üéì Learn evaluate tool. Tutorial for beginners with Gemini and Google Sheets",
    "description": "This workflow is a beginner-friendly tutorial demonstrating how to use the **Evaluation tool** to automatically score the AI‚Äôs output against a known correct answer (‚Äúground truth‚Äù) stored in a Google Sheet.\n\n\n---\n\n### **Advantages**\n\n* ‚úÖ **Beginner-friendly** ‚Äì Provides a simple and clear structure to understand AI evaluation.\n* ‚úÖ **Flexible input sources** ‚Äì Works with both Google Sheets datasets and manual test entries.\n* ‚úÖ **Integrated with Google Gemini** ‚Äì Leverages a powerful AI model for text-based tasks.\n* ‚úÖ **Tool usage** ‚Äì Demonstrates how an AI agent can call external tools (e.g., calculator) for accurate answers.\n* ‚úÖ **Automated evaluation** ‚Äì Outputs are automatically compared against ground truth data for factual correctness.\n* ‚úÖ **Scalable testing** ‚Äì Can handle multiple dataset rows, making it useful for structured AI model evaluation.\n* ‚úÖ **Result tracking** ‚Äì Saves both answers and correctness scores back to Google Sheets for easy monitoring.\n\n---\n\n### **How it Works**\n\nThe workflow operates in two distinct modes, determined by the trigger:\n1.  **Manual Test Mode:** Triggered by \"When clicking 'Execute workflow'\". It sends a fixed question (\"How much is 8 * 3?\") to the AI agent and returns the answer to the user. This mode is for quick, ad-hoc testing.\n2.  **Evaluation Mode:** Triggered by \"When fetching a dataset row\". This mode reads rows of data from a linked Google Sheet. Each row contains an `input` (a question) and an `expected_output` (the correct answer). It processes each row as follows:\n    *   The `input` question is sent to the **AI Agent** node.\n    *   The AI Agent, powered by a **Google Gemini** model and equipped with a **Calculator** tool, processes the question and generates an answer (`output`).\n    *   The workflow then checks if it's in evaluation mode.\n    *   Instead of just returning the answer, it passes the AI's `actual_output` and the sheet's `expected_output` to another **Evaluation node**.\n    *   This node uses a second **Google Gemini** model as a \"judge\" to evaluate the factual correctness of the AI's answer compared to the expected one, generating a `Correctness` score on a scale from 1 to 5.\n    *   Finally, both the AI's `actual_output` and the automated `correctness` score are written back to a new column in the same row of the Google Sheet.\n\n---\n\n### **Set up Steps**\n\nTo use this workflow, you need to complete the following setup steps:\n\n1.  **Credentials Configuration:**\n    *   Set up the **Google Sheets OAuth2 API** credentials (named \"Google Sheets account\"). This allows n8n to read from and write to your Google Sheet.\n    *   Set up the **Google Gemini (PaLM) API** credentials (named \"Google Gemini(PaLM) (Eure)\"). This provides the AI language model capabilities for both the agent and the evaluator.\n\n2.  **Prepare Your Google Sheet:**\n    *   The workflow is pre-configured to use a specific Google Sheet. You must **clone** the provided template sheet (the URL is in the Sticky Note) to your own Google Drive.\n    *   In your cloned sheet, ensure you have at least two columns: one for the input/question (e.g., `input`) and one for the expected correct answer (e.g., `expected_output`). You may need to update the node parameters that reference `$json.input` and `$json.expected_output` to match your column names exactly.\n\n3.  **Update Document IDs:**\n    *   After cloning the sheet, get its new Document ID from its URL and update the `documentId` field in **all three Evaluation nodes** (\"When fetching a dataset row\", \"Set output Evaluation\", and \"Set correctness\") to point to your new sheet instead of the original template.\n\n4.  **Activate the Workflow:**\n    *   Once the credentials and sheet are configured, toggle the workflow to **Active**. You can then trigger a manual test run or set the \"When fetching a dataset row\" node to poll your sheet automatically to evaluate all rows.\n----\n\n### **Need help customizing?**  \n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When fetching a dataset row",
      "type": "n8n-nodes-base.evaluationTrigger",
      "role": "evaluationTrigger",
      "configDescription": "Version 4.6"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Calculator",
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "role": "toolCalculator",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking ‚ÄòExecute workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Evaluation?",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Return chat response",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Set output Evaluation",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Get output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Get input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Get manual input",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Corectness",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Set correctness",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.7"
    }
  ]
}