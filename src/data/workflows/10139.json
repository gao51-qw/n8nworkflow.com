{
  "id": 10139,
  "slug": "10139",
  "title": "Generate AI videos from text or images with Sora 2/Pro & GPT-5 enhancement",
  "description": "Harness OpenAI's Sora 2 for instant video creation from text or images using fal.ai's API‚Äîpowered by GPT-5 for refined prompts that ensure cinematic quality. This template processes form submissions, intelligently routes to text-to-video (with mandatory prompt enhancement) or image-to-video modes, and polls for completion before redirecting to your generated clip.\n\n## üìã What This Template Does\nUsers submit prompts, aspect ratios (9:16 or 16:9), models (sora-2 or pro), durations (4s, 8s, or 12s), and optional images via a web form. For text-to-video, GPT-5 automatically refines the prompt for optimal Sora 2 results; image mode uses the raw input. It calls one of four fal.ai endpoints (text-to-video, text-to-video/pro, image-to-video, image-to-video/pro), then loops every 60s to check status until the video is ready.\n- Handles dual modes: Text (with GPT-5 enhancement) or image-seeded generation\n- Supports pro upgrades for higher fidelity and longer clips\n- Auto-uploads images to a temp host and polls asynchronously for hands-free results\n- Redirects directly to the final video URL on completion\n\n## üîß Prerequisites\n- n8n instance with HTTP Request and LangChain nodes enabled\n- fal.ai account for Sora 2 API access\n- OpenAI account for GPT-5 prompt refinement\n\n## üîë Required Credentials\n\n### fal.ai API Setup\n1. Sign up at fal.ai and navigate to Dashboard ‚Üí API Keys\n2. Generate a new key with \"sora-2\" permissions (full access recommended)\n3. In n8n, create \"Header Auth\" credential: Name it \"fal.ai\", set Header Name to \"Authorization\", Value to \"Key [Your API Key]\"\n\n### OpenAI API Setup\n1. Log in at platform.openai.com ‚Üí API Keys (top-right profile menu)\n2. Click \"Create new secret key\" and copy it (store securely)\n3. In n8n, add \"OpenAI API\" credential: Paste key, select GPT-5 model in the LLM node\n\n## ‚öôÔ∏è Configuration Steps\n1. Import the workflow JSON into your n8n instance via Settings ‚Üí Import from File\n2. Assign fal.ai and OpenAI credentials to the relevant HTTP Request and LLM nodes\n3. Activate the workflow‚Äîthe form URL auto-generates in the trigger node\n4. Test by submitting a sample prompt (e.g., \"A cat chasing a laser\"); monitor executions for video output\n5. Adjust polling wait (60s node) for longer generations if needed\n\n## üéØ Use Cases\n- **Social Media Teams**: Generate 9:16 vertical Reels from text ideas, like quick product animations enhanced by GPT-5 for professional polish\n- **Content Marketers**: Animate uploaded images into 8s promo clips, e.g., turning a static ad graphic into a dynamic story for email campaigns\n- **Educators and Trainers**: Create 4s explainer videos from outlines, such as historical reenactments, using pro mode for detailed visuals\n- **App Developers**: Embed as a backend service to process user prompts into Sora 2 videos on-demand for creative tools\n\n## ‚ö†Ô∏è Troubleshooting\n- **API quota exceeded**: Check fal.ai dashboard for usage limits; upgrade to pro tier or extend polling waits\n- **Prompt refinement fails**: Ensure GPT-5 credential is set and output matches JSON schema‚Äîtest LLM node independently\n- **Image upload errors**: Confirm file is JPG/PNG under 10MB; verify tmpfiles.org endpoint with a manual curl test\n- **Endless polling loop**: Add an IF node after 10 checks to timeout; increase wait to 120s for 12s pro generations",
  "featuredImage": "/data/workflows/10139/10139.webp",
  "author": {
    "id": 101,
    "slug": "daniel-automates",
    "name": "Daniel Nkencho",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1700,
  "downloads": 170,
  "createdAt": "2025-10-25T00:30:00.564Z",
  "updatedAt": "2026-01-16T09:03:37.872Z",
  "publishedAt": "2025-10-25T00:30:00.564Z",
  "nodes": 22,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10139",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Generate AI videos from text or images with Sora 2/Pro & GPT-5 enhancement",
    "workflowName": "Generate AI videos from text or images with Sora 2/Pro & GPT-5 enhancement",
    "description": "Harness OpenAI's Sora 2 for instant video creation from text or images using fal.ai's API‚Äîpowered by GPT-5 for refined prompts that ensure cinematic quality. This template processes form submissions, intelligently routes to text-to-video (with mandatory prompt enhancement) or image-to-video modes, and polls for completion before redirecting to your generated clip.\n\n## üìã What This Template Does\nUsers submit prompts, aspect ratios (9:16 or 16:9), models (sora-2 or pro), durations (4s, 8s, or 12s), and optional images via a web form. For text-to-video, GPT-5 automatically refines the prompt for optimal Sora 2 results; image mode uses the raw input. It calls one of four fal.ai endpoints (text-to-video, text-to-video/pro, image-to-video, image-to-video/pro), then loops every 60s to check status until the video is ready.\n- Handles dual modes: Text (with GPT-5 enhancement) or image-seeded generation\n- Supports pro upgrades for higher fidelity and longer clips\n- Auto-uploads images to a temp host and polls asynchronously for hands-free results\n- Redirects directly to the final video URL on completion\n\n## üîß Prerequisites\n- n8n instance with HTTP Request and LangChain nodes enabled\n- fal.ai account for Sora 2 API access\n- OpenAI account for GPT-5 prompt refinement\n\n## üîë Required Credentials\n\n### fal.ai API Setup\n1. Sign up at fal.ai and navigate to Dashboard ‚Üí API Keys\n2. Generate a new key with \"sora-2\" permissions (full access recommended)\n3. In n8n, create \"Header Auth\" credential: Name it \"fal.ai\", set Header Name to \"Authorization\", Value to \"Key [Your API Key]\"\n\n### OpenAI API Setup\n1. Log in at platform.openai.com ‚Üí API Keys (top-right profile menu)\n2. Click \"Create new secret key\" and copy it (store securely)\n3. In n8n, add \"OpenAI API\" credential: Paste key, select GPT-5 model in the LLM node\n\n## ‚öôÔ∏è Configuration Steps\n1. Import the workflow JSON into your n8n instance via Settings ‚Üí Import from File\n2. Assign fal.ai and OpenAI credentials to the relevant HTTP Request and LLM nodes\n3. Activate the workflow‚Äîthe form URL auto-generates in the trigger node\n4. Test by submitting a sample prompt (e.g., \"A cat chasing a laser\"); monitor executions for video output\n5. Adjust polling wait (60s node) for longer generations if needed\n\n## üéØ Use Cases\n- **Social Media Teams**: Generate 9:16 vertical Reels from text ideas, like quick product animations enhanced by GPT-5 for professional polish\n- **Content Marketers**: Animate uploaded images into 8s promo clips, e.g., turning a static ad graphic into a dynamic story for email campaigns\n- **Educators and Trainers**: Create 4s explainer videos from outlines, such as historical reenactments, using pro mode for detailed visuals\n- **App Developers**: Embed as a backend service to process user prompts into Sora 2 videos on-demand for creative tools\n\n## ‚ö†Ô∏è Troubleshooting\n- **API quota exceeded**: Check fal.ai dashboard for usage limits; upgrade to pro tier or extend polling waits\n- **Prompt refinement fails**: Ensure GPT-5 credential is set and output matches JSON schema‚Äîtest LLM node independently\n- **Image upload errors**: Confirm file is JPG/PNG under 10MB; verify tmpfiles.org endpoint with a manual curl test\n- **Endless polling loop**: Add an IF node after 10 checks to timeout; increase wait to 120s for 12s pro generations",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Note: Mode Router",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Image Upload",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Prompt Refiner",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: JSON Parser",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Text-to-Video",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Image-to-Video",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Video Input Form",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Prompt Refiner",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "JSON Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Temp Image Upload",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Text-to-Video Call",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Input Mode Router",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.3"
    },
    {
      "name": "Image-to-Video Call",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Wait 60 Seconds",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Status Check",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Status Router",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Retrieve Video",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Video Redirect",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Overview Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Form Trigger1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Polling Loop1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Refiner Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    }
  ]
}