{
  "id": 4591,
  "slug": "4591",
  "title": "Recipe recommendation engine with Bright Data MCP & OpenAI 4o mini",
  "description": "![Recipe Recommendation Engine with Bright Data MCP  OpenAI.png](fileId:1427)\n### Notice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\n### Who this is for\n\nRecipe Recommendation Engine with Bright Data MCP & OpenAI is a powerful automated workflow combines Bright Data's MCP for scraping trending or regional recipe data with OpenAI 4o mini to generate personalized recipe recommendations. \n\nThis automated workflow is designed for:\n\n**Food Bloggers & Culinary Creators** : Who want to automate the extraction and curation of recipes from across the web to generate content, compile cookbooks, or publish newsletters.\n\n**Nutritionists & Health Coaches** : Who need structured recipe data to analyze ingredients, calories, and nutrition for personalized meal planning or dietary tracking.\n\n**AI/ML Engineers & Data Scientists** : Building models that classify cuisines, predict recipes from ingredients, or generate dynamic meal suggestions using clean, structured datasets.\n\n**Grocery & Meal Kit Platforms** : Who aim to extract recipes to power recommendation engines, ingredient lists, or personalized meal plans.\n\n**Recipe Aggregator Startups** : Looking to scale recipe data collection, filtering, and standardization across diverse cooking websites with minimal human intervention.\n\n**Developers Integrating Cooking Features** : Into apps or digital assistants that offer recipe recommendations, step-by-step cooking instructions, or nutritional insights.\n\n### What problem is this workflow solving?\n\nThis workflow solves:\n\n- Automated recipe data extraction from any public URL\n\n- AI-driven structured data extraction\n\n- Scalable looped crawling and processing\n\n- Real-time notifications and data persistence\n\n### What this workflow does\n\n**1. Set Recipe Extract URL**\n- Configure the recipe website URL in the input node\n\n- Set your Bright Data zone name and authentication\n\n**2. Paginated Data Extract**\n- Triggers a paginated extraction across multiple pages (recipe listing, index, or search pages)\n\n- Returns a list of recipe links for processing\n\n**3. Loop Over Items**\n- Loops through the array of recipe links\n\n- Each link is passed individually to the scraping engine\n\n**4. Bright Data MCP Client (Per Recipe)**\n- Scrapes each individual recipe page using scrape_as_html\n\n- Smartly bypasses common anti-bot protections via Bright Data Web Unlocker\n\n**5. Structured Recipe Data Extract (via OpenAI GPT-4o mini)**\n- Converts raw HTML to clean text using an LLM preprocessing node\n\n- Uses OpenAI GPT-4o mini to extract structured data\n\n**6. Webhook Notification**\n- Pushes the structured recipe data to your configured webhook endpoint\n\n- Format: JSON payload, ideal for Slack, internal APIs, or dashboards\n\n**7. Save Response to Disk**\n- Saves the structured recipe JSON information to local file system\n\n### Pre-conditions\n\n1. You need to have a [Bright Data](https://brightdata.com/) account and do the necessary setup as mentioned in the \"Setup\" section below.\n2. You need to have an OpenAI Account.\n\n### Setup\n- Sign up at [Bright Data](https://brightdata.com/).\n- Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n- In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n![MCPClientAccount.png](fileId:1426)\nThe Value field should be set with the\n**Bearer XXXXXXXXXXXXXX**. The XXXXXXXXXXXXXX should be replaced by the Web Unlocker Token.\n- In n8n, configure the OpenAi account credentials.\n- Make sure to set the fields as part of **Set the Recipe Extract URL**. Remember to set the webhook_url to send a webhook notification of recipe response.\n- Set the desired local path in the **Write the structured content to disk** node to save the recipe response.\n\n### How to customize this workflow to your needs\n\nYou can tailor the Recipe Recommendation Engine workflow to better fit your specific use case by modifying the following key components:\n\n**1. Input Fields Node**\n- Update the Recipe URL to target specific cuisine sites or recipe types (e.g., vegan, keto, regional dishes).\n\n**2. LLM Configuration**\n- Swap out the OpenAI GPT-4o mini model with another provider (like Google Gemini) if you prefer.\n\n- Modify the structured data prompt to extract custom fields that you wish.\n\n**3. Webhook Notification**\n-  Configure the Webhook Notification node to point to your preferred integration (e.g., Slack, Discord, internal APIs).\n\n**4. Storage Destination**\n\nChange the **Save to Disk** node to store the structured recipe data in:\n\n- A cloud bucket (S3, GCS, Azure Blob etc.)\n\n- A database (MongoDB, PostgreSQL, Firestore)\n\n- Google Sheets or Airtable for spreadsheet-style access.\n\n",
  "featuredImage": "/data/workflows/4591/4591.webp",
  "author": {
    "id": 101,
    "slug": "ranjancse",
    "name": "Ranjan Dailata",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 563,
  "downloads": 56,
  "createdAt": "2025-06-02T13:18:54.970Z",
  "updatedAt": "2026-01-16T08:35:10.986Z",
  "publishedAt": "2025-06-02T13:18:54.970Z",
  "nodes": 23,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4591",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Recipe recommendation engine with Bright Data MCP & OpenAI 4o mini",
    "workflowName": "Recipe recommendation engine with Bright Data MCP & OpenAI 4o mini",
    "description": "![Recipe Recommendation Engine with Bright Data MCP  OpenAI.png](fileId:1427)\n### Notice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\n### Who this is for\n\nRecipe Recommendation Engine with Bright Data MCP & OpenAI is a powerful automated workflow combines Bright Data's MCP for scraping trending or regional recipe data with OpenAI 4o mini to generate personalized recipe recommendations. \n\nThis automated workflow is designed for:\n\n**Food Bloggers & Culinary Creators** : Who want to automate the extraction and curation of recipes from across the web to generate content, compile cookbooks, or publish newsletters.\n\n**Nutritionists & Health Coaches** : Who need structured recipe data to analyze ingredients, calories, and nutrition for personalized meal planning or dietary tracking.\n\n**AI/ML Engineers & Data Scientists** : Building models that classify cuisines, predict recipes from ingredients, or generate dynamic meal suggestions using clean, structured datasets.\n\n**Grocery & Meal Kit Platforms** : Who aim to extract recipes to power recommendation engines, ingredient lists, or personalized meal plans.\n\n**Recipe Aggregator Startups** : Looking to scale recipe data collection, filtering, and standardization across diverse cooking websites with minimal human intervention.\n\n**Developers Integrating Cooking Features** : Into apps or digital assistants that offer recipe recommendations, step-by-step cooking instructions, or nutritional insights.\n\n### What problem is this workflow solving?\n\nThis workflow solves:\n\n- Automated recipe data extraction from any public URL\n\n- AI-driven structured data extraction\n\n- Scalable looped crawling and processing\n\n- Real-time notifications and data persistence\n\n### What this workflow does\n\n**1. Set Recipe Extract URL**\n- Configure the recipe website URL in the input node\n\n- Set your Bright Data zone name and authentication\n\n**2. Paginated Data Extract**\n- Triggers a paginated extraction across multiple pages (recipe listing, index, or search pages)\n\n- Returns a list of recipe links for processing\n\n**3. Loop Over Items**\n- Loops through the array of recipe links\n\n- Each link is passed individually to the scraping engine\n\n**4. Bright Data MCP Client (Per Recipe)**\n- Scrapes each individual recipe page using scrape_as_html\n\n- Smartly bypasses common anti-bot protections via Bright Data Web Unlocker\n\n**5. Structured Recipe Data Extract (via OpenAI GPT-4o mini)**\n- Converts raw HTML to clean text using an LLM preprocessing node\n\n- Uses OpenAI GPT-4o mini to extract structured data\n\n**6. Webhook Notification**\n- Pushes the structured recipe data to your configured webhook endpoint\n\n- Format: JSON payload, ideal for Slack, internal APIs, or dashboards\n\n**7. Save Response to Disk**\n- Saves the structured recipe JSON information to local file system\n\n### Pre-conditions\n\n1. You need to have a [Bright Data](https://brightdata.com/) account and do the necessary setup as mentioned in the \"Setup\" section below.\n2. You need to have an OpenAI Account.\n\n### Setup\n- Sign up at [Bright Data](https://brightdata.com/).\n- Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n- In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n![MCPClientAccount.png](fileId:1426)\nThe Value field should be set with the\n**Bearer XXXXXXXXXXXXXX**. The XXXXXXXXXXXXXX should be replaced by the Web Unlocker Token.\n- In n8n, configure the OpenAi account credentials.\n- Make sure to set the fields as part of **Set the Recipe Extract URL**. Remember to set the webhook_url to send a webhook notification of recipe response.\n- Set the desired local path in the **Write the structured content to disk** node to save the recipe response.\n\n### How to customize this workflow to your needs\n\nYou can tailor the Recipe Recommendation Engine workflow to better fit your specific use case by modifying the following key components:\n\n**1. Input Fields Node**\n- Update the Recipe URL to target specific cuisine sites or recipe types (e.g., vegan, keto, regional dishes).\n\n**2. LLM Configuration**\n- Swap out the OpenAI GPT-4o mini model with another provider (like Google Gemini) if you prefer.\n\n- Modify the structured data prompt to extract custom fields that you wish.\n\n**3. Webhook Notification**\n-  Configure the Webhook Notification node to point to your preferred integration (e.g., Slack, Discord, internal APIs).\n\n**4. Storage Destination**\n\nChange the **Save to Disk** node to store the structured recipe data in:\n\n- A cloud bucket (S3, GCS, Azure Blob etc.)\n\n- A database (MongoDB, PostgreSQL, Firestore)\n\n- Google Sheets or Airtable for spreadsheet-style access.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "List all tools for Bright Data",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "Set the Recipe Extract URL",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Paginated Data Extract",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Code to output the array of paginated info",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Structured Output Parser for Paginated Data",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Bright Data MCP Client For Recipe Extract",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "Bright Data MCP Client For Recipe Extract Within The Loop",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser for Recipe Data Extract",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Create a binary data",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    },
    {
      "name": "Webhook Notification for Data Extract Within the Loop",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Write the structured content to disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Recipe Data Extract",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenAI Chat Model for Paginated Data Extract",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model for Structured Data Extract",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    }
  ]
}