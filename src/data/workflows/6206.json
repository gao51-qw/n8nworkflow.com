{
  "id": 6206,
  "slug": "6206",
  "title": "Build a ServiceNow knowledge chatbot with OpenAI and Qdrant RAG",
  "description": "\n\n\n### **1. Data Ingestion Workflow (Left Panel – Pink Section)**\n\nThis part collects data from the ServiceNow Knowledge Article table, processes it into embeddings, and stores it in Qdrant.\n\n#### **Steps:**\n\n1. **Trigger: When clicking ‘Execute workflow’**\n\n   * The workflow starts manually when you click *Execute workflow* in n8n.\n\n2. **Get Many Table Records**\n\n   * Fetches multiple records from the ServiceNow Knowledge Article table.\n   * Each record typically contains knowledge article content that needs to be indexed.\n\n3. **Default Data Loader**\n\n   * Takes the fetched data and structures it into a format suitable for text splitting and embedding generation.\n\n4. **Recursive Character Text Splitter**\n\n   * Splits large text (e.g., long knowledge articles) into smaller, manageable chunks for embeddings.\n   * This step ensures that each text chunk can be properly processed by the embedding model.\n\n5. **Embeddings OpenAI**\n\n   * Uses OpenAI’s Embeddings API to convert each text chunk into a high-dimensional vector representation.\n   * These embeddings are essential for semantic search in the vector database.\n\n6. **Qdrant Vector Store**\n\n   * Stores the generated embeddings along with metadata (e.g., article ID, title) in the Qdrant vector database.\n   * This database will later be used for similarity searches during chatbot interactions.\n\n---\n\n### **2. RAG Chatbot Workflow (Right Panel – Green Section)**\n\nThis section powers the Retrieval-Augmented Generation (RAG) chatbot that retrieves relevant information from Qdrant and responds intelligently.\n\n#### **Steps:**\n\n1. **Trigger: When chat message received**\n\n   * Starts when a user sends a chat message to the system.\n\n2. **AI Agent**\n\n   * Acts as the orchestrator, combining memory, tools, and LLM reasoning.\n   * Connects to the OpenAI Chat Model and Qdrant Vector Store.\n\n3. **OpenAI Chat Model**\n\n   * Processes user messages and generates responses, enriched with context retrieved from Qdrant.\n\n4. **Simple Memory**\n\n   * Stores conversational history or context to ensure continuity in multi-turn conversations.\n\n5. **Qdrant Vector Store1**\n\n   * Performs a similarity search on stored embeddings using the user’s query.\n   * Retrieves the most relevant knowledge article chunks for the chatbot.\n\n6. **Embeddings OpenAI**\n\n   * Converts user query into embeddings for vector search in Qdrant.\n\n",
  "featuredImage": "/data/workflows/6206/6206.webp",
  "author": {
    "id": 101,
    "slug": "yajna",
    "name": "Tushar Mishra",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 824,
  "downloads": 82,
  "createdAt": "2025-07-20T17:59:22.729Z",
  "updatedAt": "2026-01-16T08:43:47.933Z",
  "publishedAt": "2025-07-20T17:59:22.729Z",
  "nodes": 14,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6206",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build a ServiceNow knowledge chatbot with OpenAI and Qdrant RAG",
    "workflowName": "Build a ServiceNow knowledge chatbot with OpenAI and Qdrant RAG",
    "description": "### **1. Data Ingestion Workflow (Left Panel – Pink Section)**\n\nThis part collects data from the ServiceNow Knowledge Article table, processes it into embeddings, and stores it in Qdrant.\n\n#### **Steps:**\n\n1. **Trigger: When clicking ‘Execute workflow’**\n\n   * The workflow starts manually when you click *Execute workflow* in n8n.\n\n2. **Get Many Table Records**\n\n   * Fetches multiple records from the ServiceNow Knowledge Article table.\n   * Each record typically contains knowledge article content that needs to be indexed.\n\n3. **Default Data Loader**\n\n   * Takes the fetched data and structures it into a format suitable for text splitting and embedding generation.\n\n4. **Recursive Character Text Splitter**\n\n   * Splits large text (e.g., long knowledge articles) into smaller, manageable chunks for embeddings.\n   * This step ensures that each text chunk can be properly processed by the embedding model.\n\n5. **Embeddings OpenAI**\n\n   * Uses OpenAI’s Embeddings API to convert each text chunk into a high-dimensional vector representation.\n   * These embeddings are essential for semantic search in the vector database.\n\n6. **Qdrant Vector Store**\n\n   * Stores the generated embeddings along with metadata (e.g., article ID, title) in the Qdrant vector database.\n   * This database will later be used for similarity searches during chatbot interactions.\n\n---\n\n### **2. RAG Chatbot Workflow (Right Panel – Green Section)**\n\nThis section powers the Retrieval-Augmented Generation (RAG) chatbot that retrieves relevant information from Qdrant and responds intelligently.\n\n#### **Steps:**\n\n1. **Trigger: When chat message received**\n\n   * Starts when a user sends a chat message to the system.\n\n2. **AI Agent**\n\n   * Acts as the orchestrator, combining memory, tools, and LLM reasoning.\n   * Connects to the OpenAI Chat Model and Qdrant Vector Store.\n\n3. **OpenAI Chat Model**\n\n   * Processes user messages and generates responses, enriched with context retrieved from Qdrant.\n\n4. **Simple Memory**\n\n   * Stores conversational history or context to ensure continuity in multi-turn conversations.\n\n5. **Qdrant Vector Store1**\n\n   * Performs a similarity search on stored embeddings using the user’s query.\n   * Retrieves the most relevant knowledge article chunks for the chatbot.\n\n6. **Embeddings OpenAI**\n\n   * Converts user query into embeddings for vector search in Qdrant.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Qdrant Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Get many table records",
      "type": "n8n-nodes-base.serviceNow",
      "role": "serviceNow",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    }
  ]
}