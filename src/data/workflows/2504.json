{
  "id": 2504,
  "slug": "2504",
  "title": "WordPress - AI chatbot to enhance user experience - with Supabase and OpenAI",
  "description": "This is the **first version of a template for a RAG/GenAI App** using **WordPress content**.\n\nAs **creating, sharing, and improving templates** brings me joy üòÑ, feel free to reach out on [LinkedIn](https://www.linkedin.com/in/nicolas-aknin/) if you have **any ideas to enhance this template**!\n\n# How It Works\n\nThis template includes three workflows:\n\n- **Workflow 1**: Generate embeddings for your WordPress posts and pages, then store them in the Supabase vector store.\n- **Workflow 2**: Handle upserts for WordPress content when edits are made.\n- **Workflow 3**: Enable chat functionality by performing Retrieval-Augmented Generation (RAG) on the embedded documents.\n\n## Why use this template?\n\nThis template can be applied to various use cases:\n\n- Build a **GenAI application** that requires embedded documents from your website's content.\n- Embed or create a **chatbot** page on your website to **enhance user experience** as visitors search for information.\n- Gain **insights** into the **types of questions** visitors are asking on your website.\n- Simplify **content management** by asking the AI for related content ideas or checking if **similar content already exists**. Useful for internal linking.\n\n## Prerequisites\n- Access to **Supabase** for storing embeddings.\n- Basic knowledge of **Postgres** and **pgvector**.\n- A **WordPress website** with content to be embedded.\n- An **OpenAI API key**\n- Ensure that your n8n workflow, Supabase instance, and WordPress website are set to the **same timezone** (or use GMT) for consistency.\n\n\n## Workflow 1 : Initial Embedding\n\nThis workflow retrieves your WordPress pages and posts, generates embeddings from the content, and stores them in Supabase using `pgvector`.\n\n### Step 0 : Create Supabase tables\n\n**Nodes :** \n- `Postgres - Create Documents Table`: This table is structured to support **OpenAI embedding** models with **1536 dimensions**\n- `Postgres - Create Workflow Execution History Table`\n\nThese two nodes create tables in Supabase:\n\n- The **documents** table, which stores embeddings of your website content.\n- The **n8n_website_embedding_histories** table, which logs workflow executions for efficient management of upserts. This table tracks the workflow execution ID and execution timestamp.\n\n### Step 1 : Retrieve and Merge WordPress Pages and Posts\n\n**Nodes :**\n- `WordPress - Get All Posts`\n- `WordPress - Get All Pages`\n- `Merge WordPress Posts and Pages`\n\nThese three nodes retrieve **all content and metadata from your posts and pages** and merge them. \n**Important: ** **Apply filters** to avoid generating embeddings for all site content.\n\n### Step 2 : Set Fields, Apply Filter, and Transform HTML to Markdown\n\n**Nodes :**\n- `Set Fields`\n- `Filter - Only Published & Unprotected Content`\n- `HTML to Markdown`\n\nThese three nodes prepare the content for embedding by:\n\n1. Setting up the necessary fields for content embeddings and document metadata.\n2. Filtering to include only **published** and **unprotected** content (`protected=false`), ensuring private or unpublished content is **excluded from your GenAI application**.\n3. Converting HTML to Markdown, which enhances **performance and relevance** in Retrieval-Augmented Generation (RAG) by optimizing document embeddings.\n\n### Step 3: Generate Embeddings, Store Documents in Supabase, and Log Workflow Execution\n\n**Nodes**:\n- `Supabase Vector Store`\n  - **Sub-nodes**:\n    - `Embeddings OpenAI`\n    - `Default Data Loader`\n    - `Token Splitter`\n    - `Aggregate`\n- `Supabase - Store Workflow Execution`\n\nThis step involves generating embeddings for the content and storing it in Supabase, followed by logging the workflow execution details.\n\n1. **Generate Embeddings**: The `Embeddings OpenAI` node generates vector embeddings for the content.\n2. **Load Data**: The `Default Data Loader` prepares the content for embedding storage. The metadata stored includes the content title, publication date, modification date, URL, and **ID**, which is **essential for managing upserts**. \n\n\n‚ö†Ô∏è **Important Note :** Be cautious **not to store any sensitive information in metadata** fields, as this information will be **accessible to the AI and may appear in user-facing answers**.\n\n3. **Token Management**: The `Token Splitter` ensures that content is segmented into manageable sizes to comply with token limits.\n4. **Aggregate**: Ensure the last node is run only for 1 item.\n5. **Store Execution Details**: The `Supabase - Store Workflow Execution` node saves the workflow execution ID and timestamp, enabling tracking of when each content update was processed.\n\nThis setup **ensures that content embeddings are stored in Supabase for use in downstream applications**, while workflow execution details are logged for consistency and version tracking.\n\nThis workflow should be **executed only once for the initial embedding**. \n**Workflow 2**, described below, will **handle all future upserts**, ensuring that new or updated content is embedded as needed.\n\n## Workflow 2: Handle document upserts\n\n**Content on a website follows a lifecycle**‚Äîit may be **updated**, **new content** might be added, or, at times, content may be **deleted**. \n\nIn this **first version of the template**, the upsert workflow manages:\n- **Newly added content**\n- **Updated content**\n\n### Step 1: Retrieve WordPress Content with Regular CRON\n\n**Nodes**:\n- `CRON - Every 30 Seconds`\n- `Postgres - Get Last Workflow Execution`\n- `WordPress - Get Posts Modified After Last Workflow Execution`\n- `WordPress - Get Pages Modified After Last Workflow Execution`\n- `Merge Retrieved WordPress Posts and Pages`\n\nA **CRON job** (set to run **every 30 seconds** in this template, but you can **adjust it** as needed) initiates the workflow. A **Postgres SQL** query on the `n8n_website_embedding_histories` table retrieves the **timestamp** of the **latest workflow execution**.\n\nNext, the HTTP nodes use the **WordPress API** (**update the example URL** in the template with your own website‚Äôs URL and add your **WordPress credentials**) to request **all posts and pages modified after the last workflow execution date**. This process captures both **newly added** and **recently updated content**. The retrieved content is then merged for further processing.\n\n### Step 2 : Set fields, use filter\n\n**Nodes :**\n- `Set fields2`\n- `Filter - Only published and unprotected content`\n\nThe same that Step 2 in **Workflow 1**, except that HTML To Makrdown is used in further Step.\n\n### Step 3: Loop Over Items to Identify and Route Updated vs. Newly Added Content\n\n\n**Here, I initially aimed to use 'update documents' instead of the delete + insert approach, but encountered challenges, especially with updating both content and metadata columns together. Any help or suggestions are welcome! :)**\n\n\n**Nodes**:\n- `Loop Over Items`\n- `Postgres - Filter on Existing Documents`\n- `Switch`\n\n  - **Route `existing_documents`** (if documents with matching IDs are found in metadata):\n    - `Supabase - Delete Row if Document Exists`: Removes any existing entry for the document, preparing for an update.\n    - `Aggregate2`: Used to aggregate documents on Supabase with ID to ensure that `Set Fields3` is executed only once for each WordPress content to **avoid duplicate execution**.\n    - `Set Fields3`: Sets fields required for embedding updates.\n    \n  - **Route `new_documents`** (if no matching documents are found with IDs in metadata):\n    - `Set Fields4`: Configures fields for embedding newly added content.\n\n\nIn this step, a loop processes **each item**, directing it based on **whether the document already exists**. The **`Aggregate2`** node acts as a control to ensure `Set Fields3` runs only once per WordPress content, effectively **avoiding duplicate execution** and optimizing the update process.\n\n\n### Step 4 : HTML to Markdown, Supabase Vector Store, Update Workflow Execution Table\n\nThe **HTML to Markdown** node mirrors **Workflow 1 - Step 2**. Refer to that section for a detailed explanation on how HTML content is converted to Markdown for improved embedding performance and relevance.\n\nFollowing this, the content is **stored in the Supabase vector store** to manage embeddings efficiently. Lastly, the **workflow execution table is updated. These nodes mirros the **Workflow 1 - Step 3 nodes**.\n\n## Workflow 3 : An example of GenAI App with Wordpress Content : Chatbot to be embed on your website\n\n### Step 1: Retrieve Supabase Documents, Aggregate, and Set Fields After a Chat Input\n\n**Nodes**:\n- `When Chat Message Received`\n- `Supabase - Retrieve Documents from Chat Input`\n- `Embeddings OpenAI1`\n- `Aggregate Documents`\n- `Set Fields`\n\n\nWhen a user sends a message to the chat, the prompt (user question) is sent to the Supabase vector store retriever. The RPC function `match_documents` (created in **Workflow 1 - Step 0**) retrieves documents relevant to the user‚Äôs question, enabling a more accurate and relevant response.\n\nIn this step:\n1. The **Supabase vector store retriever** fetches documents that match the user‚Äôs question, including metadata.\n2. The **Aggregate Documents** node consolidates the retrieved data.\n3. Finally, **Set Fields** organizes the data to create a more readable input for the AI agent.\n\n**Directly using the AI agent** without these nodes would prevent metadata from being sent to the language model (LLM), but **metadata is essential for enhancing the context** and accuracy of the AI‚Äôs response. By including metadata, the **AI‚Äôs answers can reference relevant document details, making the interaction more informative**.\n\n### Step 2: Call AI Agent, Respond to User, and Store Chat Conversation History\n\n**Nodes**:\n- **AI Agent**\n  - Sub-nodes:\n    - `OpenAI Chat Model`\n    - `Postgres Chat Memories`\n- **Respond to Webhook**\n\nThis step involves calling the AI agent to generate an answer, responding to the user, and storing the conversation history.  The model used is **gpt4-o-mini**, chosen for its cost-efficiency. ",
  "featuredImage": "/data/workflows/2504/2504.webp",
  "author": {
    "id": 101,
    "slug": "dataki",
    "name": "Dataki",
    "avatar": ""
  },
  "categories": [
    "Support Chatbot",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 12543,
  "downloads": 1254,
  "createdAt": "2024-10-28T12:11:32.191Z",
  "updatedAt": "2026-01-16T08:25:04.870Z",
  "publishedAt": "2024-10-28T12:11:32.191Z",
  "nodes": 53,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2504",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "WordPress - AI chatbot to enhance user experience - with Supabase and OpenAI",
    "workflowName": "WordPress - AI chatbot to enhance user experience - with Supabase and OpenAI",
    "description": "This is the **first version of a template for a RAG/GenAI App** using **WordPress content**.\n\nAs **creating, sharing, and improving templates** brings me joy üòÑ, feel free to reach out on [LinkedIn](https://www.linkedin.com/in/nicolas-aknin/) if you have **any ideas to enhance this template**!\n\n# How It Works\n\nThis template includes three workflows:\n\n- **Workflow 1**: Generate embeddings for your WordPress posts and pages, then store them in the Supabase vector store.\n- **Workflow 2**: Handle upserts for WordPress content when edits are made.\n- **Workflow 3**: Enable chat functionality by performing Retrieval-Augmented Generation (RAG) on the embedded documents.\n\n## Why use this template?\n\nThis template can be applied to various use cases:\n\n- Build a **GenAI application** that requires embedded documents from your website's content.\n- Embed or create a **chatbot** page on your website to **enhance user experience** as visitors search for information.\n- Gain **insights** into the **types of questions** visitors are asking on your website.\n- Simplify **content management** by asking the AI for related content ideas or checking if **similar content already exists**. Useful for internal linking.\n\n## Prerequisites\n- Access to **Supabase** for storing embeddings.\n- Basic knowledge of **Postgres** and **pgvector**.\n- A **WordPress website** with content to be embedded.\n- An **OpenAI API key**\n- Ensure that your n8n workflow, Supabase instance, and WordPress website are set to the **same timezone** (or use GMT) for consistency.\n\n\n## Workflow 1 : Initial Embedding\n\nThis workflow retrieves your WordPress pages and posts, generates embeddings from the content, and stores them in Supabase using `pgvector`.\n\n### Step 0 : Create Supabase tables\n\n**Nodes :** \n- `Postgres - Create Documents Table`: This table is structured to support **OpenAI embedding** models with **1536 dimensions**\n- `Postgres - Create Workflow Execution History Table`\n\nThese two nodes create tables in Supabase:\n\n- The **documents** table, which stores embeddings of your website content.\n- The **n8n_website_embedding_histories** table, which logs workflow executions for efficient management of upserts. This table tracks the workflow execution ID and execution timestamp.\n\n### Step 1 : Retrieve and Merge WordPress Pages and Posts\n\n**Nodes :**\n- `WordPress - Get All Posts`\n- `WordPress - Get All Pages`\n- `Merge WordPress Posts and Pages`\n\nThese three nodes retrieve **all content and metadata from your posts and pages** and merge them. \n**Important: ** **Apply filters** to avoid generating embeddings for all site content.\n\n### Step 2 : Set Fields, Apply Filter, and Transform HTML to Markdown\n\n**Nodes :**\n- `Set Fields`\n- `Filter - Only Published & Unprotected Content`\n- `HTML to Markdown`\n\nThese three nodes prepare the content for embedding by:\n\n1. Setting up the necessary fields for content embeddings and document metadata.\n2. Filtering to include only **published** and **unprotected** content (`protected=false`), ensuring private or unpublished content is **excluded from your GenAI application**.\n3. Converting HTML to Markdown, which enhances **performance and relevance** in Retrieval-Augmented Generation (RAG) by optimizing document embeddings.\n\n### Step 3: Generate Embeddings, Store Documents in Supabase, and Log Workflow Execution\n\n**Nodes**:\n- `Supabase Vector Store`\n  - **Sub-nodes**:\n    - `Embeddings OpenAI`\n    - `Default Data Loader`\n    - `Token Splitter`\n    - `Aggregate`\n- `Supabase - Store Workflow Execution`\n\nThis step involves generating embeddings for the content and storing it in Supabase, followed by logging the workflow execution details.\n\n1. **Generate Embeddings**: The `Embeddings OpenAI` node generates vector embeddings for the content.\n2. **Load Data**: The `Default Data Loader` prepares the content for embedding storage. The metadata stored includes the content title, publication date, modification date, URL, and **ID**, which is **essential for managing upserts**. \n\n\n‚ö†Ô∏è **Important Note :** Be cautious **not to store any sensitive information in metadata** fields, as this information will be **accessible to the AI and may appear in user-facing answers**.\n\n3. **Token Management**: The `Token Splitter` ensures that content is segmented into manageable sizes to comply with token limits.\n4. **Aggregate**: Ensure the last node is run only for 1 item.\n5. **Store Execution Details**: The `Supabase - Store Workflow Execution` node saves the workflow execution ID and timestamp, enabling tracking of when each content update was processed.\n\nThis setup **ensures that content embeddings are stored in Supabase for use in downstream applications**, while workflow execution details are logged for consistency and version tracking.\n\nThis workflow should be **executed only once for the initial embedding**. \n**Workflow 2**, described below, will **handle all future upserts**, ensuring that new or updated content is embedded as needed.\n\n## Workflow 2: Handle document upserts\n\n**Content on a website follows a lifecycle**‚Äîit may be **updated**, **new content** might be added, or, at times, content may be **deleted**. \n\nIn this **first version of the template**, the upsert workflow manages:\n- **Newly added content**\n- **Updated content**\n\n### Step 1: Retrieve WordPress Content with Regular CRON\n\n**Nodes**:\n- `CRON - Every 30 Seconds`\n- `Postgres - Get Last Workflow Execution`\n- `WordPress - Get Posts Modified After Last Workflow Execution`\n- `WordPress - Get Pages Modified After Last Workflow Execution`\n- `Merge Retrieved WordPress Posts and Pages`\n\nA **CRON job** (set to run **every 30 seconds** in this template, but you can **adjust it** as needed) initiates the workflow. A **Postgres SQL** query on the `n8n_website_embedding_histories` table retrieves the **timestamp** of the **latest workflow execution**.\n\nNext, the HTTP nodes use the **WordPress API** (**update the example URL** in the template with your own website‚Äôs URL and add your **WordPress credentials**) to request **all posts and pages modified after the last workflow execution date**. This process captures both **newly added** and **recently updated content**. The retrieved content is then merged for further processing.\n\n### Step 2 : Set fields, use filter\n\n**Nodes :**\n- `Set fields2`\n- `Filter - Only published and unprotected content`\n\nThe same that Step 2 in **Workflow 1**, except that HTML To Makrdown is used in further Step.\n\n### Step 3: Loop Over Items to Identify and Route Updated vs. Newly Added Content\n\n\n**Here, I initially aimed to use 'update documents' instead of the delete + insert approach, but encountered challenges, especially with updating both content and metadata columns together. Any help or suggestions are welcome! :)**\n\n\n**Nodes**:\n- `Loop Over Items`\n- `Postgres - Filter on Existing Documents`\n- `Switch`\n\n  - **Route `existing_documents`** (if documents with matching IDs are found in metadata):\n    - `Supabase - Delete Row if Document Exists`: Removes any existing entry for the document, preparing for an update.\n    - `Aggregate2`: Used to aggregate documents on Supabase with ID to ensure that `Set Fields3` is executed only once for each WordPress content to **avoid duplicate execution**.\n    - `Set Fields3`: Sets fields required for embedding updates.\n    \n  - **Route `new_documents`** (if no matching documents are found with IDs in metadata):\n    - `Set Fields4`: Configures fields for embedding newly added content.\n\n\nIn this step, a loop processes **each item**, directing it based on **whether the document already exists**. The **`Aggregate2`** node acts as a control to ensure `Set Fields3` runs only once per WordPress content, effectively **avoiding duplicate execution** and optimizing the update process.\n\n\n### Step 4 : HTML to Markdown, Supabase Vector Store, Update Workflow Execution Table\n\nThe **HTML to Markdown** node mirrors **Workflow 1 - Step 2**. Refer to that section for a detailed explanation on how HTML content is converted to Markdown for improved embedding performance and relevance.\n\nFollowing this, the content is **stored in the Supabase vector store** to manage embeddings efficiently. Lastly, the **workflow execution table is updated. These nodes mirros the **Workflow 1 - Step 3 nodes**.\n\n## Workflow 3 : An example of GenAI App with Wordpress Content : Chatbot to be embed on your website\n\n### Step 1: Retrieve Supabase Documents, Aggregate, and Set Fields After a Chat Input\n\n**Nodes**:\n- `When Chat Message Received`\n- `Supabase - Retrieve Documents from Chat Input`\n- `Embeddings OpenAI1`\n- `Aggregate Documents`\n- `Set Fields`\n\n\nWhen a user sends a message to the chat, the prompt (user question) is sent to the Supabase vector store retriever. The RPC function `match_documents` (created in **Workflow 1 - Step 0**) retrieves documents relevant to the user‚Äôs question, enabling a more accurate and relevant response.\n\nIn this step:\n1. The **Supabase vector store retriever** fetches documents that match the user‚Äôs question, including metadata.\n2. The **Aggregate Documents** node consolidates the retrieved data.\n3. Finally, **Set Fields** organizes the data to create a more readable input for the AI agent.\n\n**Directly using the AI agent** without these nodes would prevent metadata from being sent to the language model (LLM), but **metadata is essential for enhancing the context** and accuracy of the AI‚Äôs response. By including metadata, the **AI‚Äôs answers can reference relevant document details, making the interaction more informative**.\n\n### Step 2: Call AI Agent, Respond to User, and Store Chat Conversation History\n\n**Nodes**:\n- **AI Agent**\n  - Sub-nodes:\n    - `OpenAI Chat Model`\n    - `Postgres Chat Memories`\n- **Respond to Webhook**\n\nThis step involves calling the AI agent to generate an answer, responding to the user, and storing the conversation history.  The model used is **gpt4-o-mini**, chosen for its cost-efficiency.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‚ÄòTest workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Token Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterTokenSplitter",
      "role": "textSplitterTokenSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Postgres Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "role": "memoryPostgresChat",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "role": "respondToWebhook",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Set fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Embeddings OpenAI2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Default Data Loader1",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Token Splitter1",
      "type": "@n8n/n8n-nodes-langchain.textSplitterTokenSplitter",
      "role": "textSplitterTokenSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Markdown1",
      "type": "n8n-nodes-base.markdown",
      "role": "markdown",
      "configDescription": "Version 1"
    },
    {
      "name": "Postgres",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.5"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate1",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate2",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Wordpress - Get all posts",
      "type": "n8n-nodes-base.wordpress",
      "role": "wordpress",
      "configDescription": "Version 1"
    },
    {
      "name": "Wordpress - Get all pages",
      "type": "n8n-nodes-base.wordpress",
      "role": "wordpress",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Set fields1",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Filter - Only published &  unprotected content",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "HTML To Markdown",
      "type": "n8n-nodes-base.markdown",
      "role": "markdown",
      "configDescription": "Version 1"
    },
    {
      "name": "Supabase - Store workflow execution",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Every 30 seconds",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Wordpress - Get posts modified after last workflow execution",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Wordpress - Get posts modified after last workflow execution1",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Set fields2",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Filter - Only published and unprotected content",
      "type": "n8n-nodes-base.filter",
      "role": "filter",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Set fields3",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Set fields4",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Store documents on Supabase",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Store workflow execution id and timestamptz",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate documents",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Postgres - Create documents table",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.5"
    },
    {
      "name": "Postgres - Create workflow execution history table",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.5"
    },
    {
      "name": "Merge Wordpress Posts and Pages",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3"
    },
    {
      "name": "Merge retrieved WordPress posts and pages",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3"
    },
    {
      "name": "Postgres - Filter on existing documents",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.5"
    },
    {
      "name": "Supabase - Delete row if documents exists",
      "type": "n8n-nodes-base.supabase",
      "role": "supabase",
      "configDescription": "Version 1"
    },
    {
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Supabase - Retrieve documents from chatinput",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Supabase Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1"
    }
  ]
}