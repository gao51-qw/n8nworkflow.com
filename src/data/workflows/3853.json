{
  "id": 3853,
  "slug": "3853",
  "title": "Structured data extract & data mining with Bright Data & Google Gemini",
  "description": "### Who this is for?\nThe Structured Data Extract & Data Mining workflow is crafted for researchers, content analysts, SEO strategists, and AI developers who need to transform semi-structured web data (like markdown content or scraped HTML) into actionable structured datasets. \n\nIt is ideal for:\n\n- **Content Analysts** - Organizing and mining large volumes of markdown or HTML content.\n\n- **SEO & Trend Researchers** - Exploring topics by location and category.\n\n- **AI Engineers & NLP Developers** - Looking to automate insight extraction from unstructured inputs.\n\n- **Growth Marketers** - Tracking topic-level trends for strategic campaigns.\n\n- **Automation Specialists** - Streamlining workflows from scrape to storage.\n\n### What problem is this workflow solving?\n\nExtracting insights from markdown or HTML documents typically requires manual review, formatting, and parsing. This becomes unscalable when dealing with large datasets or when real-time response is needed. Additionally, trend and topic extraction usually involves external tools, custom scripts, and inconsistent formatting.\n\nThis workflow solves:\n\n- Automatic text extraction from markdown or structured content.\n\n- Location and category-based trend mining with semantic grouping.\n\n- AI-driven topic extraction and summarization\n\n- Real-time notification via webhook with rich structured payloads.\n\n- Persistent storage of mined data to disk for audits or further processing.\n\n### What this workflow does\n\n- Receives input: Sets the URL for the data extraction and analysis.\n\n- Uses Bright Data's Web Unlocker to extract content from relevant sites.\n\n- A Markdown/Text Extractor node parses the content into clean plaintext\n\n- The cleaned data is passed to Google Gemini to:\n\n\t- Identify trends by location and category\n\n\t- Extract key topics and themes\n\n\t- Format the response into structured JSON\n\n\t- The structured insights are sent via Webhook Notification to external systems (e.g., Slack, Web apps, Zapier)\n\n\t- The final output is saved to disk\n\n### Setup\n\n- Sign up at [Bright Data](https://brightdata.com/).\n- Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n- In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n![Header Authentication.png](fileId:1252)\nThe Value field should be set with the \n**Bearer XXXXXXXXXXXXXX**. The XXXXXXXXXXXXXX should be replaced by the Web Unlocker Token.\n- A Google Gemini API key (or access through Vertex AI or proxy).\n- Update the **Set URL and Bright Data Zone** for setting the brand content URL and the Bright Data Zone name.\n- Update the Webhook HTTP Request node with the Webhook endpoint of your choice.\n\n### How to customize this workflow to your needs\n\n- **Update Source** : Update the workflow input to read from Google Sheet or Airbase for dynamically tracking multiple brands or topics.\n- **Gemini Prompt Customization** : \n\t- Extract trends within a custom category (e.g., E-commerce design patterns in the US)\n\n\t- Output topics with popularity metrics\n\n\t- Structure the output as per your database schema (e.g., [{ topic, trend_score, location }])\n\n- **Webhook Output** : Send notifications to -\n\n\t- Slack – with AI summaries in rich blocks\n\t- Internal APIs – for use in dashboards\n\n\t- Zapier/Make – for multi-step automation\n\n- **Persistence**\n\t- Save output to:\n\n\t\t- Remote FTP or SFTP storage\n\t\t- Amazon S3, Google Cloud Storage etc.\n\n",
  "featuredImage": "/data/workflows/3853/3853.webp",
  "author": {
    "id": 101,
    "slug": "ranjancse",
    "name": "Ranjan Dailata",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 783,
  "downloads": 78,
  "createdAt": "2025-05-03T23:44:32.500Z",
  "updatedAt": "2026-01-16T08:31:46.830Z",
  "publishedAt": "2025-05-03T23:44:32.500Z",
  "nodes": 18,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3853",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Structured data extract & data mining with Bright Data & Google Gemini",
    "workflowName": "Structured data extract & data mining with Bright Data & Google Gemini",
    "description": "### Who this is for?\nThe Structured Data Extract & Data Mining workflow is crafted for researchers, content analysts, SEO strategists, and AI developers who need to transform semi-structured web data (like markdown content or scraped HTML) into actionable structured datasets. \n\nIt is ideal for:\n\n- **Content Analysts** - Organizing and mining large volumes of markdown or HTML content.\n\n- **SEO & Trend Researchers** - Exploring topics by location and category.\n\n- **AI Engineers & NLP Developers** - Looking to automate insight extraction from unstructured inputs.\n\n- **Growth Marketers** - Tracking topic-level trends for strategic campaigns.\n\n- **Automation Specialists** - Streamlining workflows from scrape to storage.\n\n### What problem is this workflow solving?\n\nExtracting insights from markdown or HTML documents typically requires manual review, formatting, and parsing. This becomes unscalable when dealing with large datasets or when real-time response is needed. Additionally, trend and topic extraction usually involves external tools, custom scripts, and inconsistent formatting.\n\nThis workflow solves:\n\n- Automatic text extraction from markdown or structured content.\n\n- Location and category-based trend mining with semantic grouping.\n\n- AI-driven topic extraction and summarization\n\n- Real-time notification via webhook with rich structured payloads.\n\n- Persistent storage of mined data to disk for audits or further processing.\n\n### What this workflow does\n\n- Receives input: Sets the URL for the data extraction and analysis.\n\n- Uses Bright Data's Web Unlocker to extract content from relevant sites.\n\n- A Markdown/Text Extractor node parses the content into clean plaintext\n\n- The cleaned data is passed to Google Gemini to:\n\n\t- Identify trends by location and category\n\n\t- Extract key topics and themes\n\n\t- Format the response into structured JSON\n\n\t- The structured insights are sent via Webhook Notification to external systems (e.g., Slack, Web apps, Zapier)\n\n\t- The final output is saved to disk\n\n### Setup\n\n- Sign up at [Bright Data](https://brightdata.com/).\n- Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n- In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n![Header Authentication.png](fileId:1252)\nThe Value field should be set with the \n**Bearer XXXXXXXXXXXXXX**. The XXXXXXXXXXXXXX should be replaced by the Web Unlocker Token.\n- A Google Gemini API key (or access through Vertex AI or proxy).\n- Update the **Set URL and Bright Data Zone** for setting the brand content URL and the Bright Data Zone name.\n- Update the Webhook HTTP Request node with the Webhook endpoint of your choice.\n\n### How to customize this workflow to your needs\n\n- **Update Source** : Update the workflow input to read from Google Sheet or Airbase for dynamically tracking multiple brands or topics.\n- **Gemini Prompt Customization** : \n\t- Extract trends within a custom category (e.g., E-commerce design patterns in the US)\n\n\t- Output topics with popularity metrics\n\n\t- Structure the output as per your database schema (e.g., [{ topic, trend_score, location }])\n\n- **Webhook Output** : Send notifications to -\n\n\t- Slack – with AI summaries in rich blocks\n\t- Internal APIs – for use in dashboards\n\n\t- Zapier/Make – for multi-step automation\n\n- **Persistence**\n\t- Save output to:\n\n\t\t- Remote FTP or SFTP storage\n\t\t- Amazon S3, Google Cloud Storage etc.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Markdown to Textual Data Extractor",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Set URL and Bright Data Zone",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Initiate a Webhook Notification for Markdown to Textual Data Extraction",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Initiate a Webhook Notification for AI Sentiment Analyzer",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Google Gemini Chat Model for Data Extract",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model for Sentiment Analyzer",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Perform Bright Data Web Request",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Topic Extractor with the structured response",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1"
    },
    {
      "name": "Trends by location and category with the structured response",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Initiate a Webhook Notification for trends by location and category",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Create a binary file for topics",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    },
    {
      "name": "Write the topics file to disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Write the trends file to disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Create a binary data for tends",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    }
  ]
}