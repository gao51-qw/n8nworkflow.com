{
  "id": 6395,
  "slug": "6395",
  "title": "Automate news article scraping with ScrapegraphAI and store in Google Sheets",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n## News Article Scraping and Analysis with AI and Google Sheets Integration\n\n\n### üéØ Target Audience\n- News aggregators and content curators\n- Media monitoring professionals\n- Market researchers tracking industry news\n- PR professionals monitoring brand mentions\n- Journalists and content creators\n- Business analysts tracking competitor news\n- Academic researchers collecting news data\n\n### üöÄ Problem Statement\nManual news monitoring is time-consuming and often misses important articles. This template solves the challenge of automatically collecting, structuring, and storing news articles from any website for comprehensive analysis and tracking.\n\n### üîß How it Works\n\nThis workflow automatically scrapes news articles from websites using AI-powered extraction and stores them in Google Sheets for analysis and tracking.\n\n#### Key Components\n\n- **Scheduled Trigger**: Runs automatically at specified intervals to collect fresh content\n- **AI-Powered Scraping**: Uses ScrapeGraphAI to intelligently extract article titles, URLs, and categories from any news website\n- **Data Processing**: Formats extracted data for optimal spreadsheet compatibility\n- **Automated Storage**: Saves all articles to Google Sheets with metadata for easy filtering and analysis\n\n### üìä Google Sheets Column Specifications\n\nThe template creates the following columns in your Google Sheets:\n\n| Column | Data Type | Description | Example |\n|--------|-----------|-------------|---------|\n| **title** | String | Article headline and title | \"'My friend died right in front of me' - Student describes moment air force jet crashed into school\" |\n| **url** | URL | Direct link to the article | \"https://www.bbc.com/news/articles/cglzw8y5wy5o\" |\n| **category** | String | Article category or section | \"Asia\" |\n\n### üõ†Ô∏è Setup Instructions\n\n**Estimated setup time: 10-15 minutes**\n\n#### Prerequisites\n- n8n instance with community nodes enabled\n- ScrapeGraphAI API account and credentials\n- Google Sheets account with API access\n\n#### Step-by-Step Configuration\n\n##### 1. Install Community Nodes\n```bash\n# Install ScrapeGraphAI community node\nnpm install n8n-nodes-scrapegraphai\n```\n\n##### 2. Configure ScrapeGraphAI Credentials\n- Navigate to Credentials in your n8n instance\n- Add new ScrapeGraphAI API credentials\n- Enter your API key from ScrapeGraphAI dashboard\n- Test the connection to ensure it's working\n\n##### 3. Set up Google Sheets Connection\n- Add Google Sheets OAuth2 credentials\n- Grant necessary permissions for spreadsheet access\n- Select or create a target spreadsheet for data storage\n- Configure the sheet name (default: \"Sheet1\")\n\n##### 4. Customize News Source Parameters\n- Update the `websiteUrl` parameter in the ScrapeGraphAI node\n- Modify the target news website URL as needed\n- Adjust the user prompt to extract additional fields if required\n- Test with a small website first before scaling to larger news sites\n\n##### 5. Configure Schedule Trigger\n- Set your preferred execution frequency (daily, hourly, etc.)\n- Choose appropriate time zones for your business hours\n- Consider the news website's update frequency when setting intervals\n\n##### 6. Test and Validate\n- Run the workflow manually to verify all connections\n- Check Google Sheets for proper data formatting\n- Validate that all required fields are being captured\n\n### üîÑ Workflow Customization Options\n\n#### Modify News Sources\n- Change the website URL to target different news sources\n- Add multiple news websites for comprehensive coverage\n- Implement filters for specific topics or categories\n\n#### Extend Data Collection\n- Modify the user prompt to extract additional fields (author, date, summary)\n- Add sentiment analysis for article content\n- Integrate with other data sources for comprehensive analysis\n\n#### Output Customization\n- Change Google Sheets operation from \"append\" to \"upsert\" for deduplication\n- Add data validation and cleaning steps\n- Implement error handling and retry logic\n\n### üìà Use Cases\n\n- **Media Monitoring**: Track mentions of your brand, competitors, or industry keywords\n- **Content Curation**: Automatically collect articles for newsletters or content aggregation\n- **Market Research**: Monitor industry trends and competitor activities\n- **News Aggregation**: Build custom news feeds for specific topics or sources\n- **Academic Research**: Collect news data for research projects and analysis\n- **Crisis Management**: Monitor breaking news and emerging stories\n\n### ÔøΩÔøΩ Important Notes\n\n- Respect the target website's terms of service and robots.txt\n- Consider implementing delays between requests for large datasets\n- Regularly review and update your scraping parameters\n- Monitor API usage to manage costs effectively\n- Keep your credentials secure and rotate them regularly\n\n### üîß Troubleshooting\n\n**Common Issues:**\n- ScrapeGraphAI connection errors: Verify API key and account status\n- Google Sheets permission errors: Check OAuth2 scope and permissions\n- Data formatting issues: Review the Code node's JavaScript logic\n- Rate limiting: Adjust schedule frequency and implement delays\n\n**Pro Tips:**\n- Keep detailed configuration notes in the sticky notes within the workflow\n- Test with a small website first before scaling to larger news sites\n- Consider adding filters in the Code node to exclude certain article types or categories\n- Monitor execution logs for any issues and adjust parameters accordingly\n\n**Support Resources:**\n- ScrapeGraphAI documentation and API reference\n- n8n community forums for workflow assistance\n- Google Sheets API documentation for advanced configurations\n",
  "featuredImage": "/data/workflows/6395/6395.webp",
  "author": {
    "id": 101,
    "slug": "vinci-king-01",
    "name": "vinci-king-01",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 1441,
  "downloads": 144,
  "createdAt": "2025-07-24T18:43:56.533Z",
  "updatedAt": "2026-01-16T08:44:46.624Z",
  "publishedAt": "2025-07-24T18:43:56.533Z",
  "nodes": 8,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6395",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Automate news article scraping with ScrapegraphAI and store in Google Sheets",
    "workflowName": "Automate news article scraping with ScrapegraphAI and store in Google Sheets",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\n## News Article Scraping and Analysis with AI and Google Sheets Integration\n\n\n### üéØ Target Audience\n- News aggregators and content curators\n- Media monitoring professionals\n- Market researchers tracking industry news\n- PR professionals monitoring brand mentions\n- Journalists and content creators\n- Business analysts tracking competitor news\n- Academic researchers collecting news data\n\n### üöÄ Problem Statement\nManual news monitoring is time-consuming and often misses important articles. This template solves the challenge of automatically collecting, structuring, and storing news articles from any website for comprehensive analysis and tracking.\n\n### üîß How it Works\n\nThis workflow automatically scrapes news articles from websites using AI-powered extraction and stores them in Google Sheets for analysis and tracking.\n\n#### Key Components\n\n- **Scheduled Trigger**: Runs automatically at specified intervals to collect fresh content\n- **AI-Powered Scraping**: Uses ScrapeGraphAI to intelligently extract article titles, URLs, and categories from any news website\n- **Data Processing**: Formats extracted data for optimal spreadsheet compatibility\n- **Automated Storage**: Saves all articles to Google Sheets with metadata for easy filtering and analysis\n\n### üìä Google Sheets Column Specifications\n\nThe template creates the following columns in your Google Sheets:\n\n| Column | Data Type | Description | Example |\n|--------|-----------|-------------|---------|\n| **title** | String | Article headline and title | \"'My friend died right in front of me' - Student describes moment air force jet crashed into school\" |\n| **url** | URL | Direct link to the article | \"https://www.bbc.com/news/articles/cglzw8y5wy5o\" |\n| **category** | String | Article category or section | \"Asia\" |\n\n### üõ†Ô∏è Setup Instructions\n\n**Estimated setup time: 10-15 minutes**\n\n#### Prerequisites\n- n8n instance with community nodes enabled\n- ScrapeGraphAI API account and credentials\n- Google Sheets account with API access\n\n#### Step-by-Step Configuration\n\n##### 1. Install Community Nodes\n```bash\n# Install ScrapeGraphAI community node\nnpm install n8n-nodes-scrapegraphai\n```\n\n##### 2. Configure ScrapeGraphAI Credentials\n- Navigate to Credentials in your n8n instance\n- Add new ScrapeGraphAI API credentials\n- Enter your API key from ScrapeGraphAI dashboard\n- Test the connection to ensure it's working\n\n##### 3. Set up Google Sheets Connection\n- Add Google Sheets OAuth2 credentials\n- Grant necessary permissions for spreadsheet access\n- Select or create a target spreadsheet for data storage\n- Configure the sheet name (default: \"Sheet1\")\n\n##### 4. Customize News Source Parameters\n- Update the `websiteUrl` parameter in the ScrapeGraphAI node\n- Modify the target news website URL as needed\n- Adjust the user prompt to extract additional fields if required\n- Test with a small website first before scaling to larger news sites\n\n##### 5. Configure Schedule Trigger\n- Set your preferred execution frequency (daily, hourly, etc.)\n- Choose appropriate time zones for your business hours\n- Consider the news website's update frequency when setting intervals\n\n##### 6. Test and Validate\n- Run the workflow manually to verify all connections\n- Check Google Sheets for proper data formatting\n- Validate that all required fields are being captured\n\n### üîÑ Workflow Customization Options\n\n#### Modify News Sources\n- Change the website URL to target different news sources\n- Add multiple news websites for comprehensive coverage\n- Implement filters for specific topics or categories\n\n#### Extend Data Collection\n- Modify the user prompt to extract additional fields (author, date, summary)\n- Add sentiment analysis for article content\n- Integrate with other data sources for comprehensive analysis\n\n#### Output Customization\n- Change Google Sheets operation from \"append\" to \"upsert\" for deduplication\n- Add data validation and cleaning steps\n- Implement error handling and retry logic\n\n### üìà Use Cases\n\n- **Media Monitoring**: Track mentions of your brand, competitors, or industry keywords\n- **Content Curation**: Automatically collect articles for newsletters or content aggregation\n- **Market Research**: Monitor industry trends and competitor activities\n- **News Aggregation**: Build custom news feeds for specific topics or sources\n- **Academic Research**: Collect news data for research projects and analysis\n- **Crisis Management**: Monitor breaking news and emerging stories\n\n### ÔøΩÔøΩ Important Notes\n\n- Respect the target website's terms of service and robots.txt\n- Consider implementing delays between requests for large datasets\n- Regularly review and update your scraping parameters\n- Monitor API usage to manage costs effectively\n- Keep your credentials secure and rotate them regularly\n\n### üîß Troubleshooting\n\n**Common Issues:**\n- ScrapeGraphAI connection errors: Verify API key and account status\n- Google Sheets permission errors: Check OAuth2 scope and permissions\n- Data formatting issues: Review the Code node's JavaScript logic\n- Rate limiting: Adjust schedule frequency and implement delays\n\n**Pro Tips:**\n- Keep detailed configuration notes in the sticky notes within the workflow\n- Test with a small website first before scaling to larger news sites\n- Consider adding filters in the Code node to exclude certain article types or categories\n- Monitor execution logs for any issues and adjust parameters accordingly\n\n**Support Resources:**\n- ScrapeGraphAI documentation and API reference\n- n8n community forums for workflow assistance\n- Google Sheets API documentation for advanced configurations",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Automated News Collection Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "AI-Powered News Article Scraper",
      "type": "n8n-nodes-scrapegraphai.scrapegraphAi",
      "role": "scrapegraphAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Sheets News Storage",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.5"
    },
    {
      "name": "News Data Formatting and Processing",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}