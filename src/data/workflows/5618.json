{
  "id": 5618,
  "slug": "5618",
  "title": "Scrape LinkedIn profiles & save to Google Sheets with Apify",
  "description": "This n8n workflow automates the process of scraping LinkedIn profiles using the Apify platform and organizing the extracted data into Google Sheets for easy analysis and follow-up.\n\n## Use Cases\n- **Lead Generation**: Extract contact information and professional details from LinkedIn profiles\n- **Recruitment**: Gather candidate information for talent acquisition\n- **Market Research**: Analyze professional networks and industry connections\n- **Sales Prospecting**: Build targeted prospect lists with detailed professional information\n\n## How It Works\n\n### 1. **Workflow Initialization & Input**\n- **Webhook Start Scraper**: Triggers the entire scraping workflow\n- **Read LinkedIn URLs**: Retrieves LinkedIn profile URLs from Google Sheets\n- **Schedule Scraper Trigger**: Sets up automated scheduling for regular scraping\n\n### 2. **Data Processing & Extraction**\n- **Data Formatting**: Prepares and structures the LinkedIn URLs for processing\n- **Fetch Profile Data**: Makes HTTP requests to Apify API with profile URLs\n- **Run Scraper Actor**: Executes the Apify LinkedIn scraper actor\n- **Get Scraped Results**: Retrieves the extracted profile data from Apify\n\n### 3. **Data Storage & Completion**\n- **Save to Google Sheets**: Stores the scraped profile data in organized spreadsheet format\n- **Update Progress Tracker**: Updates workflow status and progress tracking\n- **Process Complete Wait**: Ensures all operations finish before final steps\n- **Send Success Notification**: Alerts users when scraping is successfully completed\n\n## Requirements\n\n### **Apify Account**\n- Active Apify account with sufficient credits\n- API token for authentication\n- Access to LinkedIn Profile Scraper actor\n\n### **Google Sheets**\n- Google account with Sheets access\n- Properly formatted input sheet with LinkedIn URLs\n- Credentials configured in n8n\n\n### **n8n Setup**\n- HTTP Request node credentials for Apify\n- Google Sheets node credentials\n- Webhook endpoint configured\n\n## How to Use\n\n### **Step 1: Prepare Your Data**\n1. Create a Google Sheet with LinkedIn profile URLs\n2. Ensure the sheet has a column named 'linkedin_url'\n3. Add any additional columns for metadata (name, company, etc.)\n\n### **Step 2: Configure Credentials**\n1. Set up Apify API credentials in n8n\n2. Configure Google Sheets authentication\n3. Update webhook endpoint URL\n\n### **Step 3: Customize Settings**\n1. Adjust scraping parameters in the Apify node\n2. Modify data fields to extract based on your needs\n3. Set up notification preferences\n\n### **Step 4: Execute Workflow**\n1. Trigger via webhook or manual execution\n2. Monitor progress through the workflow\n3. Check Google Sheets for scraped data\n4. Review completion notifications\n\n## Good to Know\n\n- **Rate Limits**: LinkedIn scraping is subject to rate limits. The workflow includes delays to respect these limits.\n- **Data Quality**: Results depend on profile visibility and LinkedIn's anti-scraping measures.\n- **Costs**: Apify charges based on compute units used. Monitor your usage to control costs.\n- **Compliance**: Ensure your scraping activities comply with LinkedIn's Terms of Service and applicable laws.\n\n## Customizing This Workflow\n\n### **Enhanced Data Processing**\n- Add data enrichment steps to append additional information\n- Implement duplicate detection and merge logic\n- Create data validation rules for quality control\n\n### **Advanced Notifications**\n- Set up Slack or email alerts for different scenarios\n- Create detailed reports with scraping statistics\n- Implement error recovery mechanisms\n\n### **Integration Options**\n- Connect to CRM systems for automatic lead creation\n- Integrate with marketing automation platforms\n- Export data to analytics tools for further analysis\n\n## Troubleshooting\n\n### **Common Issues**\n- **Apify Actor Failures**: Check API limits and actor status\n- **Google Sheets Errors**: Verify permissions and sheet structure\n- **Rate Limiting**: Implement longer delays between requests\n- **Data Quality Issues**: Review scraping parameters and target profiles\n\n### **Best Practices**\n- Test with small batches before scaling up\n- Monitor Apify credit usage regularly\n- Keep backup copies of your data\n- Regular validation of scraped information accuracy",
  "featuredImage": "/data/workflows/5618/5618.webp",
  "author": {
    "id": 101,
    "slug": "oneclick-ai",
    "name": "Oneclick AI Squad",
    "avatar": ""
  },
  "categories": [
    "Lead Generation"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 8215,
  "downloads": 821,
  "createdAt": "2025-07-03T03:57:18.386Z",
  "updatedAt": "2026-01-16T08:40:34.248Z",
  "publishedAt": "2025-07-03T03:57:18.386Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5618",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Scrape LinkedIn profiles & save to Google Sheets with Apify",
    "workflowName": "Scrape LinkedIn profiles & save to Google Sheets with Apify",
    "description": "This n8n workflow automates the process of scraping LinkedIn profiles using the Apify platform and organizing the extracted data into Google Sheets for easy analysis and follow-up.\n\n## Use Cases\n- **Lead Generation**: Extract contact information and professional details from LinkedIn profiles\n- **Recruitment**: Gather candidate information for talent acquisition\n- **Market Research**: Analyze professional networks and industry connections\n- **Sales Prospecting**: Build targeted prospect lists with detailed professional information\n\n## How It Works\n\n### 1. **Workflow Initialization & Input**\n- **Webhook Start Scraper**: Triggers the entire scraping workflow\n- **Read LinkedIn URLs**: Retrieves LinkedIn profile URLs from Google Sheets\n- **Schedule Scraper Trigger**: Sets up automated scheduling for regular scraping\n\n### 2. **Data Processing & Extraction**\n- **Data Formatting**: Prepares and structures the LinkedIn URLs for processing\n- **Fetch Profile Data**: Makes HTTP requests to Apify API with profile URLs\n- **Run Scraper Actor**: Executes the Apify LinkedIn scraper actor\n- **Get Scraped Results**: Retrieves the extracted profile data from Apify\n\n### 3. **Data Storage & Completion**\n- **Save to Google Sheets**: Stores the scraped profile data in organized spreadsheet format\n- **Update Progress Tracker**: Updates workflow status and progress tracking\n- **Process Complete Wait**: Ensures all operations finish before final steps\n- **Send Success Notification**: Alerts users when scraping is successfully completed\n\n## Requirements\n\n### **Apify Account**\n- Active Apify account with sufficient credits\n- API token for authentication\n- Access to LinkedIn Profile Scraper actor\n\n### **Google Sheets**\n- Google account with Sheets access\n- Properly formatted input sheet with LinkedIn URLs\n- Credentials configured in n8n\n\n### **n8n Setup**\n- HTTP Request node credentials for Apify\n- Google Sheets node credentials\n- Webhook endpoint configured\n\n## How to Use\n\n### **Step 1: Prepare Your Data**\n1. Create a Google Sheet with LinkedIn profile URLs\n2. Ensure the sheet has a column named 'linkedin_url'\n3. Add any additional columns for metadata (name, company, etc.)\n\n### **Step 2: Configure Credentials**\n1. Set up Apify API credentials in n8n\n2. Configure Google Sheets authentication\n3. Update webhook endpoint URL\n\n### **Step 3: Customize Settings**\n1. Adjust scraping parameters in the Apify node\n2. Modify data fields to extract based on your needs\n3. Set up notification preferences\n\n### **Step 4: Execute Workflow**\n1. Trigger via webhook or manual execution\n2. Monitor progress through the workflow\n3. Check Google Sheets for scraped data\n4. Review completion notifications\n\n## Good to Know\n\n- **Rate Limits**: LinkedIn scraping is subject to rate limits. The workflow includes delays to respect these limits.\n- **Data Quality**: Results depend on profile visibility and LinkedIn's anti-scraping measures.\n- **Costs**: Apify charges based on compute units used. Monitor your usage to control costs.\n- **Compliance**: Ensure your scraping activities comply with LinkedIn's Terms of Service and applicable laws.\n\n## Customizing This Workflow\n\n### **Enhanced Data Processing**\n- Add data enrichment steps to append additional information\n- Implement duplicate detection and merge logic\n- Create data validation rules for quality control\n\n### **Advanced Notifications**\n- Set up Slack or email alerts for different scenarios\n- Create detailed reports with scraping statistics\n- Implement error recovery mechanisms\n\n### **Integration Options**\n- Connect to CRM systems for automatic lead creation\n- Integrate with marketing automation platforms\n- Export data to analytics tools for further analysis\n\n## Troubleshooting\n\n### **Common Issues**\n- **Apify Actor Failures**: Check API limits and actor status\n- **Google Sheets Errors**: Verify permissions and sheet structure\n- **Rate Limiting**: Implement longer delays between requests\n- **Data Quality Issues**: Review scraping parameters and target profiles\n\n### **Best Practices**\n- Test with small batches before scaling up\n- Monitor Apify credit usage regularly\n- Keep backup copies of your data\n- Regular validation of scraped information accuracy",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Read LinkedIn URLs1",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Schedule Scraper Trigger 1",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Execute Apify LinkedIn Scraper1",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Fetch Profile Data1",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Run Scraper Actor1",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Get Scraped Results1",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Save to Google Sheets1",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Update Progress Tracker1",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Process Complete Wait 1",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Send Success Notification1",
      "type": "n8n-nodes-base.gmail",
      "role": "gmail",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Data Formatting1",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}