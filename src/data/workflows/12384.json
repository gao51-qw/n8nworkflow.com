{
  "id": 12384,
  "slug": "12384",
  "title": "Convert Japanese scripts to multilingual speech with GPT-4 and ElevenLabs",
  "description": "## How It Works\nThis workflow provides enterprise-grade translation and text-to-speech automation for international communication teams, content publishers, and localization services. It addresses producing high-quality multilingual audio content with consistent accuracy and natural delivery at scale. An AI orchestrator analyzes source content to determine optimal translation strategy, selecting specialized agents based on content type, complexity, and target languages. The translation agent processes text with contextual awareness, generating structured output that feeds into ElevenLabs' neural text-to-speech engine. Each audio file undergoes automated quality validation checking pronunciation accuracy, natural flow, and technical specifications. High-quality outputs proceed to standardized formatting for delivery, while failures trigger dedicated error handling with diagnostic reporting, ensuring reliable production of professional multilingual audio assets.\n\n## Setup Steps\n1. Configure OpenAI API key in \"Translation Orchestrator\" \n2. Set up ElevenLabs credentials in \"Text-to-Speech\" \n3. Define source and target languages in \"Workflow Configuration\" \n4. Customize orchestration logic based on content types and complexity\n5. Set quality thresholds in \"Audio Quality Validation\" matching output \n\n## Prerequisites\nOpenAI API access with GPT-4 capabilities, active ElevenLabs subscription.\n## Use Cases\nEnterprise content localization, multilingual customer communications\n## Customization\nAdd language-specific translation agents, modify orchestration routing logic\n## Benefits\nDelivers consistent translation quality through intelligent routing",
  "featuredImage": "/data/workflows/12384/12384.webp",
  "author": {
    "id": 101,
    "slug": "cschin",
    "name": "Cheng Siong Chin",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 30,
  "downloads": 3,
  "createdAt": "2026-01-02T05:25:44.707Z",
  "updatedAt": "2026-01-16T09:12:22.904Z",
  "publishedAt": "2026-01-02T05:25:44.707Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/12384",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Convert Japanese scripts to multilingual speech with GPT-4 and ElevenLabs",
    "workflowName": "Convert Japanese scripts to multilingual speech with GPT-4 and ElevenLabs",
    "description": "## How It Works\nThis workflow provides enterprise-grade translation and text-to-speech automation for international communication teams, content publishers, and localization services. It addresses producing high-quality multilingual audio content with consistent accuracy and natural delivery at scale. An AI orchestrator analyzes source content to determine optimal translation strategy, selecting specialized agents based on content type, complexity, and target languages. The translation agent processes text with contextual awareness, generating structured output that feeds into ElevenLabs' neural text-to-speech engine. Each audio file undergoes automated quality validation checking pronunciation accuracy, natural flow, and technical specifications. High-quality outputs proceed to standardized formatting for delivery, while failures trigger dedicated error handling with diagnostic reporting, ensuring reliable production of professional multilingual audio assets.\n\n## Setup Steps\n1. Configure OpenAI API key in \"Translation Orchestrator\" \n2. Set up ElevenLabs credentials in \"Text-to-Speech\" \n3. Define source and target languages in \"Workflow Configuration\" \n4. Customize orchestration logic based on content types and complexity\n5. Set quality thresholds in \"Audio Quality Validation\" matching output \n\n## Prerequisites\nOpenAI API access with GPT-4 capabilities, active ElevenLabs subscription.\n## Use Cases\nEnterprise content localization, multilingual customer communications\n## Customization\nAdd language-specific translation agents, modify orchestration routing logic\n## Benefits\nDelivers consistent translation quality through intelligent routing",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Workflow Configuration",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Translation Orchestrator Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "Translation Agent Tool",
      "type": "@n8n/n8n-nodes-langchain.agentTool",
      "role": "agentTool",
      "configDescription": "Version 3"
    },
    {
      "name": "OpenAI Chat Model - Orchestrator",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "OpenAI Chat Model - Translation",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Structured Output Parser - Orchestrator",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Structured Output Parser - Translation",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Prepare Translation Request",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "ElevenLabs Text-to-Speech",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Audio Quality Validation",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Check Audio Quality",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Standardize Audio Output",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Handle Quality Failure",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}