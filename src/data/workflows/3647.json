{
  "id": 3647,
  "slug": "3647",
  "title": "üì• Transform Google Drive documents into vector embeddings",
  "description": "Automatically convert documents from Google Drive into vector embeddings using OpenAI, LangChain, and PGVector ‚Äî fully automated through n8n.\n\n---\n\n### ‚öôÔ∏è What It Does\n\nThis workflow monitors a Google Drive folder for new files, supports multiple file types (PDF, TXT, JSON), and processes them into vector embeddings using OpenAI‚Äôs `text-embedding-3-small` model. These embeddings are stored in a Postgres database using the PGVector extension, making them query-ready for semantic search or RAG-based AI agents.\n\nAfter successful processing, files are moved to a separate ‚Äúvectorized‚Äù folder to avoid duplication.\n\n---\n\n### üí° Use Cases\n\n- Powering Retrieval-Augmented Generation (RAG) AI agents  \n- Semantic search across private documents  \n- AI assistant knowledge ingestion  \n- Automated document pipelines for indexing or classification  \n\n---\n\n### üß† Workflow Highlights\n\n- **Trigger Options:** Manual or Scheduled (3 AM daily by default)  \n- **Supported File Types:** PDF, TXT, JSON  \n- **Embedding Stack:** LangChain Text Splitter, OpenAI Embeddings, PGVector  \n- **Deduplication:** Files are moved after processing  \n- **License:** CC BY-SA 4.0  \n- **Author:** [AlexK1919](https://www.alexk1919.com)\n\n---\n\n### üõ† What You‚Äôll Need\n\n- **Google Drive OAuth2** credentials (connected to `Search Folder`, `Download File`, and `Move File` nodes)  \n- **OpenAI API Key** (used in the `Embeddings OpenAI` node)  \n- **Postgres + PGVector** database (connected in the `Postgres PGVector Store` node)\n\n---\n\n### üîß Step-by-Step Setup Instructions\n\n1. **Create Google OAuth2 credentials** in n8n and connect them to all Google Drive nodes.\n2. **Set your source folder** ID in the `Search Folder` node ‚Äî this is where incoming files are placed.\n3. **Set your processed folder** ID in the `Move File` node ‚Äî files will be moved here after vectorization.\n4. **Ensure you have a PGVector-enabled Postgres instance** and input the table name and collection in the `Postgres PGVector Store` node.\n5. **Add your OpenAI credentials** to the `Embeddings OpenAI` node and select `text-embedding-3-small`.\n6. **Optional:** Activate the `Schedule Trigger` node to run daily or configure your own schedule.\n7. **Run manually** by triggering `When clicking ‚ÄòTest workflow‚Äô` for on-demand ingestion.\n\n---\n\n### üß© Customization Tips\n\nWant to support more file types or enhance the pipeline?\n\n- **Add new extractors**: Use `Extract from File` with other formats like DOCX, Markdown, or HTML.\n- **Refine logic by file type**: The `Switch` node routes files to the correct extraction method based on MIME type (`application/pdf`, `text/plain`, `application/json`).\n- **Pre-process with OCR**: Add an OCR step before extraction to handle scanned PDFs or images.\n- **Add filters**: Enhance the `Search Folder` or `Switch` node logic to skip specific files or folders.\n\n---\n\n### üìÑ License\n\nThis workflow is available under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license. You are free to use, adapt, and share this workflow for non-commercial purposes under the terms of this license.\n\nFull license details: https://creativecommons.org/licenses/by-nc-sa/4.0/",
  "featuredImage": "/data/workflows/3647/3647.webp",
  "author": {
    "id": 101,
    "slug": "alexk1919",
    "name": "Alex Kim",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 7928,
  "downloads": 792,
  "createdAt": "2025-04-21T18:34:36.809Z",
  "updatedAt": "2026-01-16T08:30:49.301Z",
  "publishedAt": "2025-04-21T18:34:36.809Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3647",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "üì• Transform Google Drive documents into vector embeddings",
    "workflowName": "üì• Transform Google Drive documents into vector embeddings",
    "description": "Automatically convert documents from Google Drive into vector embeddings using OpenAI, LangChain, and PGVector ‚Äî fully automated through n8n.\n\n---\n\n### ‚öôÔ∏è What It Does\n\nThis workflow monitors a Google Drive folder for new files, supports multiple file types (PDF, TXT, JSON), and processes them into vector embeddings using OpenAI‚Äôs `text-embedding-3-small` model. These embeddings are stored in a Postgres database using the PGVector extension, making them query-ready for semantic search or RAG-based AI agents.\n\nAfter successful processing, files are moved to a separate ‚Äúvectorized‚Äù folder to avoid duplication.\n\n---\n\n### üí° Use Cases\n\n- Powering Retrieval-Augmented Generation (RAG) AI agents  \n- Semantic search across private documents  \n- AI assistant knowledge ingestion  \n- Automated document pipelines for indexing or classification  \n\n---\n\n### üß† Workflow Highlights\n\n- **Trigger Options:** Manual or Scheduled (3 AM daily by default)  \n- **Supported File Types:** PDF, TXT, JSON  \n- **Embedding Stack:** LangChain Text Splitter, OpenAI Embeddings, PGVector  \n- **Deduplication:** Files are moved after processing  \n- **License:** CC BY-SA 4.0  \n- **Author:** [AlexK1919](https://www.alexk1919.com)\n\n---\n\n### üõ† What You‚Äôll Need\n\n- **Google Drive OAuth2** credentials (connected to `Search Folder`, `Download File`, and `Move File` nodes)  \n- **OpenAI API Key** (used in the `Embeddings OpenAI` node)  \n- **Postgres + PGVector** database (connected in the `Postgres PGVector Store` node)\n\n---\n\n### üîß Step-by-Step Setup Instructions\n\n1. **Create Google OAuth2 credentials** in n8n and connect them to all Google Drive nodes.\n2. **Set your source folder** ID in the `Search Folder` node ‚Äî this is where incoming files are placed.\n3. **Set your processed folder** ID in the `Move File` node ‚Äî files will be moved here after vectorization.\n4. **Ensure you have a PGVector-enabled Postgres instance** and input the table name and collection in the `Postgres PGVector Store` node.\n5. **Add your OpenAI credentials** to the `Embeddings OpenAI` node and select `text-embedding-3-small`.\n6. **Optional:** Activate the `Schedule Trigger` node to run daily or configure your own schedule.\n7. **Run manually** by triggering `When clicking ‚ÄòTest workflow‚Äô` for on-demand ingestion.\n\n---\n\n### üß© Customization Tips\n\nWant to support more file types or enhance the pipeline?\n\n- **Add new extractors**: Use `Extract from File` with other formats like DOCX, Markdown, or HTML.\n- **Refine logic by file type**: The `Switch` node routes files to the correct extraction method based on MIME type (`application/pdf`, `text/plain`, `application/json`).\n- **Pre-process with OCR**: Add an OCR step before extraction to handle scanned PDFs or images.\n- **Add filters**: Enhance the `Search Folder` or `Switch` node logic to skip specific files or folders.\n\n---\n\n### üìÑ License\n\nThis workflow is available under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license. You are free to use, adapt, and share this workflow for non-commercial purposes under the terms of this license.\n\nFull license details: https://creativecommons.org/licenses/by-nc-sa/4.0/",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Postgres PGVector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "role": "vectorStorePGVector",
      "configDescription": "Version 1.1"
    },
    {
      "name": "When clicking ‚ÄòTest workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Move File",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Download File",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Search Folder",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Schedule Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Extract from PDF",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from Text",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from JSON",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    }
  ]
}