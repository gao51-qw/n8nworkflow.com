{
  "id": 3573,
  "slug": "3573",
  "title": "Create a RAG system with Paul Essays, Milvus, and OpenAI for cited answers",
  "description": "### Create a RAG System with Paul Essays, Milvus, and OpenAI for Cited Answers\n\nThis workflow automates the process of creating a document-based AI retrieval system using [Milvus](https://milvus.io/), an open-source vector database. It consists of two main steps:\n\n1. Data collection/processing\n2. Retrieval/response generation\n\nThe system scrapes [Paul Graham essays](https://paulgraham.com/articles.html), processes them, and loads them into a Milvus vector store. When users ask questions, it retrieves relevant information and generates responses with citations.\n\n### Step 1: Data Collection and Processing\n\n1. Set up a Milvus server using the [official guide](https://milvus.io/docs/install_standalone-docker.md)\n2. Create a collection named \"my_collection\"\n3. Execute the workflow to scrape Paul Graham essays:\n   - Fetch essay lists\n   - Extract names\n   - Split content into manageable items\n   - Limit results (if needed)\n   - Fetch texts\n   - Extract content\n   - Load everything into Milvus Vector Store\n\nThis step uses [OpenAI embeddings](https://platform.openai.com/docs/guides/embeddings) for vectorization.\n\n### Step 2: Retrieval and Response Generation\n\nWhen a chat message is received, the system:\n\n* Sets chunks to send to the model\n* Retrieves relevant information from the Milvus Vector Store\n* Prepares chunks\n* Answers the query based on those chunks\n* Composes citations\n* Generates a comprehensive response\n\nThis process uses OpenAI embeddings and models to ensure accurate and relevant answers with proper citations.\n\nFor more information on vector databases and similarity search, visit [Milvus documentation](https://milvus.io/docs).\n",
  "featuredImage": "/data/workflows/3573/3573.webp",
  "author": {
    "id": 101,
    "slug": "zc277584121",
    "name": "Cheney Zhang",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 2171,
  "downloads": 217,
  "createdAt": "2025-04-16T12:54:47.941Z",
  "updatedAt": "2026-01-16T08:30:24.330Z",
  "publishedAt": "2025-04-16T12:54:47.941Z",
  "nodes": 25,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/3573",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Create a RAG system with Paul Essays, Milvus, and OpenAI for cited answers",
    "workflowName": "Create a RAG system with Paul Essays, Milvus, and OpenAI for cited answers",
    "description": "### Create a RAG System with Paul Essays, Milvus, and OpenAI for Cited Answers\n\nThis workflow automates the process of creating a document-based AI retrieval system using [Milvus](https://milvus.io/), an open-source vector database. It consists of two main steps:\n\n1. Data collection/processing\n2. Retrieval/response generation\n\nThe system scrapes [Paul Graham essays](https://paulgraham.com/articles.html), processes them, and loads them into a Milvus vector store. When users ask questions, it retrieves relevant information and generates responses with citations.\n\n### Step 1: Data Collection and Processing\n\n1. Set up a Milvus server using the [official guide](https://milvus.io/docs/install_standalone-docker.md)\n2. Create a collection named \"my_collection\"\n3. Execute the workflow to scrape Paul Graham essays:\n   - Fetch essay lists\n   - Extract names\n   - Split content into manageable items\n   - Limit results (if needed)\n   - Fetch texts\n   - Extract content\n   - Load everything into Milvus Vector Store\n\nThis step uses [OpenAI embeddings](https://platform.openai.com/docs/guides/embeddings) for vectorization.\n\n### Step 2: Retrieval and Response Generation\n\nWhen a chat message is received, the system:\n\n* Sets chunks to send to the model\n* Retrieves relevant information from the Milvus Vector Store\n* Prepares chunks\n* Answers the query based on those chunks\n* Composes citations\n* Generates a comprehensive response\n\nThis process uses OpenAI embeddings and models to ensure accurate and relevant answers with proper citations.\n\nFor more information on vector databases and similarity search, visit [Milvus documentation](https://milvus.io/docs).",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking \"Execute Workflow\"",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Fetch Essay List",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Extract essay names",
      "type": "n8n-nodes-base.html",
      "role": "html",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Split out into items",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Fetch essay texts",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Limit to first 3",
      "type": "n8n-nodes-base.limit",
      "role": "limit",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract Text Only",
      "type": "n8n-nodes-base.html",
      "role": "html",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter1",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Generate response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Compose citations",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Answer the query based on chunks",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1"
    },
    {
      "name": "Prepare chunks",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Set max chunks to send to model",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Embeddings OpenAI2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Milvus Vector Store in retrieval",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreMilvus",
      "role": "vectorStoreMilvus",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Milvus Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreMilvus",
      "role": "vectorStoreMilvus",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    }
  ]
}