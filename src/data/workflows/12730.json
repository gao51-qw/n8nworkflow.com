{
  "id": 12730,
  "slug": "12730",
  "title": "Draft and manage academic research papers with GPT-4 and Pinecone",
  "description": "## How It Works\nThis workflow automates academic research processing by routing queries through specialized AI models while maintaining contextual memory. Designed for researchers, faculty, and graduate students, it solves the challenge of managing multiple AI models for different research tasks while preserving conversation context across sessions. The system accepts research queries via webhook, stores them in vector databases for semantic search, and intelligently routes requests to appropriate AI models (OpenAI, Anthropic Claude, or NVIDIA NIM). Results are consolidated, formatted, and delivered via email with full citation tracking. The workflow maintains conversation history using Pinecone vector storage, enabling follow-up queries that reference previous interactions. This eliminates manual model switching, context loss, and repetitive credential management—streamlining research workflows from literature review to hypothesis generation.\n\n## Setup Steps\n1. Configure Pinecone credentials  \n2. Add OpenAI API key for GPT-4 access and embeddings\n3. Set up Anthropic Claude API credentials for advanced reasoning\n4. Configure NVIDIA NIM API key for specialized academic models\n5. Connect Google Sheets for query logging and result tracking\n6. Set Gmail OAuth credentials for automated result delivery\n7. Configure webhook URL for query submission endpoint\n \n## Prerequisites\nActive accounts and API keys for Pinecone, OpenAI \n## Use Cases\nLiterature review automation with semantic paper discovery. \n## Customization\nModify AI model selection logic for domain-specific optimization.\n## Benefits\nReduces research processing time by 60% through automated routing.",
  "featuredImage": "/data/workflows/12730/12730.webp",
  "author": {
    "id": 101,
    "slug": "cschin",
    "name": "Cheng Siong Chin",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 0,
  "downloads": 0,
  "createdAt": "2026-01-15T14:58:27.265Z",
  "updatedAt": "2026-01-16T09:12:54.168Z",
  "publishedAt": "2026-01-15T14:58:27.265Z",
  "nodes": 40,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/12730",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Draft and manage academic research papers with GPT-4 and Pinecone",
    "workflowName": "Draft and manage academic research papers with GPT-4 and Pinecone",
    "description": "## How It Works\nThis workflow automates academic research processing by routing queries through specialized AI models while maintaining contextual memory. Designed for researchers, faculty, and graduate students, it solves the challenge of managing multiple AI models for different research tasks while preserving conversation context across sessions. The system accepts research queries via webhook, stores them in vector databases for semantic search, and intelligently routes requests to appropriate AI models (OpenAI, Anthropic Claude, or NVIDIA NIM). Results are consolidated, formatted, and delivered via email with full citation tracking. The workflow maintains conversation history using Pinecone vector storage, enabling follow-up queries that reference previous interactions. This eliminates manual model switching, context loss, and repetitive credential management—streamlining research workflows from literature review to hypothesis generation.\n\n## Setup Steps\n1. Configure Pinecone credentials  \n2. Add OpenAI API key for GPT-4 access and embeddings\n3. Set up Anthropic Claude API credentials for advanced reasoning\n4. Configure NVIDIA NIM API key for specialized academic models\n5. Connect Google Sheets for query logging and result tracking\n6. Set Gmail OAuth credentials for automated result delivery\n7. Configure webhook URL for query submission endpoint\n \n## Prerequisites\nActive accounts and API keys for Pinecone, OpenAI \n## Use Cases\nLiterature review automation with semantic paper discovery. \n## Customization\nModify AI model selection logic for domain-specific optimization.\n## Benefits\nReduces research processing time by 60% through automated routing.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Schedule Research Monitoring",
      "type": "n8n-nodes-base.scheduleTrigger",
      "role": "scheduleTrigger",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Workflow Configuration",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Fetch Academic Papers",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Fetch Patents",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Fetch Datasets",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Fetch Technical Blogs",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Combine All Sources",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Rate Limit Delay",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Research Analysis Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "OpenAI GPT-4 Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Analysis Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Research Context Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Knowledge Base Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "OpenAI Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Document Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Manuscript Drafting Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "OpenAI GPT-4 Drafting Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Manuscript Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Citation Reference Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreInMemory",
      "role": "vectorStoreInMemory",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Citation Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Validate References API",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Plagiarism Check API",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Check Validation Results",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Save to Research Database",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Track Submission Deadlines",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Log Reviewer Feedback",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Format Adaptation Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "OpenAI Format Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Format Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Learning Optimization Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3.1"
    },
    {
      "name": "OpenAI Learning Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Learning Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Store Learning Insights",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.7"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}