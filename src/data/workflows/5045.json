{
  "id": 5045,
  "slug": "5045",
  "title": "Ai prompt generator workflow",
  "description": "# ðŸ§  AI Prompt Generator Workflow â€“ n8n Documentation\n\n## Who is this for?\n\nThis workflow is for **AI builders, prompt engineers, developers, marketers, and no-code creators** who want to convert rough user input into structured, high-quality prompts for LLMs. Itâ€™s especially useful for tools that rely on precision prompting and want to automate the discovery of intent and constraints.\n\n---\n\n## What problem is this workflow solving? / Use case\n\nMany users struggle to write effective prompts due to vague ideas or unclear formatting needs. This workflow:\n- Collects structured user input.\n- Dynamically generates clarifying questions.\n- Returns a well-formatted AI prompt based on the user's intent and context.\n\nThis ensures the generated prompt is useful for downstream AI agents without requiring technical understanding from the end user.\n\n---\n\n## What this workflow does\n\n1. **Start with a branded form UI**  \n   The user is shown a styled form with questions like:\n   - What do you want to build?\n   - What tools can you access?\n   - What input can be expected?\n   - What output do you expect?\n\n2. **Analyze and generate relevant follow-up questions**  \n   The workflow sends the user's answers to **Google Gemini (via LangChain)** which outputs 1â€“3 clarifying questions. These questions are parsed into a dynamic form.\n\n3. **Loop through and collect follow-up answers**  \n   Each follow-up question is shown in a form one at a time to capture additional context.\n\n4. **Merge all inputs**  \n   The base intent and follow-up responses are merged into a single context block.\n\n5. **Generate a final AI-ready prompt**  \n   The prompt generator node formats everything into a clean, six-section structure:\n   - &lt;constraints&gt;\n   - &lt;role&gt;\n   - &lt;inputs&gt;\n   - &lt;tools&gt;\n   - &lt;instructions&gt;\n   - &lt;conclusions&gt;\n\n6. **Display the final result**  \n   The finished prompt is shown in a clean UI where users can easily copy and reuse it.\n\n---\n\n## Setup\n\n1. **Credentials Required**\n   - Google Gemini (PaLM) API credentials (already integrated as `Google Gemini(PaLM) Api account 2`).\n\n2. **Form Trigger**\n   - Ensure the `On form submission` trigger is exposed via a webhook or public endpoint (e.g. using [ngrok](https://ngrok.com/) or deployed server).\n\n3. **Styling**\n   - Custom CSS is included in all form nodes for a beautiful UI. You can modify this to match your branding.\n\n4. **Environment**\n   - This workflow is compatible with **self-hosted n8n** or **n8n.cloud**.\n   - Webhooks must be accessible to users who will fill out the form.\n\n---\n\n## How to customize this workflow to your needs\n\n- **Change the base questions**  \n  Update the `BaseQuestions` form node to add or remove fields depending on your use case.\n\n- **Modify Gemini prompts**  \n  You can edit the system prompt inside `PromptGenerator` to change tone, output structure, or AI instructions.\n\n- **Change prompt formatting**  \n  If you use a different AI agent (like GPT, Claude, or Mistral), adjust the section labels and formatting to suit that agentâ€™s expected input.\n\n- **Send results elsewhere**  \n  Add integration nodes after `PromptGenerator`, such as:\n  - Google Docs / Notion (to log prompts)\n  - Gmail / Slack (to notify your team)\n  - Zapier / Make (to push to other automation flows)\n\n- **Skip follow-up questions (optional)**  \n  If your base form collects all needed info, you can bypass the `RelevantQuestions` form section by modifying conditional logic.\n\n---\n\n## Example Output Prompt (Structure)\n\n&lt;role&gt; You are an AI assistant that converts videos into LinkedIn posts with a witty tone. &lt;/role&gt; &lt;inputs&gt; - A short video (max 5 minutes) - Desired tone: witty - Style: both summary and quotes - Audience: general network &lt;/inputs&gt; &lt;tools&gt; You do not have access to APIs or web search. &lt;/tools&gt; &lt;instructions&gt; 1. Parse transcript. 2. Extract insights and quotes. 3. Write an engaging, witty LinkedIn post under 3000 characters. &lt;/instructions&gt; &lt;constraints&gt; Avoid technical jargon. No generic intros. Make it platform-native. &lt;/constraints&gt; &lt;conclusions&gt; Return a LinkedIn-ready post that starts with a hook and ends with hashtags.",
  "featuredImage": "/data/workflows/5045/5045.webp",
  "author": {
    "id": 101,
    "slug": "anuragmerndev",
    "name": "Anurag Srivastava",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 47160,
  "downloads": 4716,
  "createdAt": "2025-06-19T13:11:05.033Z",
  "updatedAt": "2026-01-16T08:37:22.131Z",
  "publishedAt": "2025-06-19T13:11:05.033Z",
  "nodes": 21,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5045",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Ai prompt generator workflow",
    "workflowName": "Ai prompt generator workflow",
    "description": "# ðŸ§  AI Prompt Generator Workflow â€“ n8n Documentation\n\n## Who is this for?\n\nThis workflow is for **AI builders, prompt engineers, developers, marketers, and no-code creators** who want to convert rough user input into structured, high-quality prompts for LLMs. Itâ€™s especially useful for tools that rely on precision prompting and want to automate the discovery of intent and constraints.\n\n---\n\n## What problem is this workflow solving? / Use case\n\nMany users struggle to write effective prompts due to vague ideas or unclear formatting needs. This workflow:\n- Collects structured user input.\n- Dynamically generates clarifying questions.\n- Returns a well-formatted AI prompt based on the user's intent and context.\n\nThis ensures the generated prompt is useful for downstream AI agents without requiring technical understanding from the end user.\n\n---\n\n## What this workflow does\n\n1. **Start with a branded form UI**  \n   The user is shown a styled form with questions like:\n   - What do you want to build?\n   - What tools can you access?\n   - What input can be expected?\n   - What output do you expect?\n\n2. **Analyze and generate relevant follow-up questions**  \n   The workflow sends the user's answers to **Google Gemini (via LangChain)** which outputs 1â€“3 clarifying questions. These questions are parsed into a dynamic form.\n\n3. **Loop through and collect follow-up answers**  \n   Each follow-up question is shown in a form one at a time to capture additional context.\n\n4. **Merge all inputs**  \n   The base intent and follow-up responses are merged into a single context block.\n\n5. **Generate a final AI-ready prompt**  \n   The prompt generator node formats everything into a clean, six-section structure:\n   - &lt;constraints&gt;\n   - &lt;role&gt;\n   - &lt;inputs&gt;\n   - &lt;tools&gt;\n   - &lt;instructions&gt;\n   - &lt;conclusions&gt;\n\n6. **Display the final result**  \n   The finished prompt is shown in a clean UI where users can easily copy and reuse it.\n\n---\n\n## Setup\n\n1. **Credentials Required**\n   - Google Gemini (PaLM) API credentials (already integrated as `Google Gemini(PaLM) Api account 2`).\n\n2. **Form Trigger**\n   - Ensure the `On form submission` trigger is exposed via a webhook or public endpoint (e.g. using [ngrok](https://ngrok.com/) or deployed server).\n\n3. **Styling**\n   - Custom CSS is included in all form nodes for a beautiful UI. You can modify this to match your branding.\n\n4. **Environment**\n   - This workflow is compatible with **self-hosted n8n** or **n8n.cloud**.\n   - Webhooks must be accessible to users who will fill out the form.\n\n---\n\n## How to customize this workflow to your needs\n\n- **Change the base questions**  \n  Update the `BaseQuestions` form node to add or remove fields depending on your use case.\n\n- **Modify Gemini prompts**  \n  You can edit the system prompt inside `PromptGenerator` to change tone, output structure, or AI instructions.\n\n- **Change prompt formatting**  \n  If you use a different AI agent (like GPT, Claude, or Mistral), adjust the section labels and formatting to suit that agentâ€™s expected input.\n\n- **Send results elsewhere**  \n  Add integration nodes after `PromptGenerator`, such as:\n  - Google Docs / Notion (to log prompts)\n  - Gmail / Slack (to notify your team)\n  - Zapier / Make (to push to other automation flows)\n\n- **Skip follow-up questions (optional)**  \n  If your base form collects all needed info, you can bypass the `RelevantQuestions` form section by modifying conditional logic.\n\n---\n\n## Example Output Prompt (Structure)\n\n&lt;role&gt; You are an AI assistant that converts videos into LinkedIn posts with a witty tone. &lt;/role&gt; &lt;inputs&gt; - A short video (max 5 minutes) - Desired tone: witty - Style: both summary and quotes - Audience: general network &lt;/inputs&gt; &lt;tools&gt; You do not have access to APIs or web search. &lt;/tools&gt; &lt;instructions&gt; 1. Parse transcript. 2. Extract insights and quotes. 3. Write an engaging, witty LinkedIn post under 3000 characters. &lt;/instructions&gt; &lt;constraints&gt; Avoid technical jargon. No generic intros. Make it platform-native. &lt;/constraints&gt; &lt;conclusions&gt; Return a LinkedIn-ready post that starts with a hook and ends with hashtags.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "On form submission",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "BaseQuestions",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 1"
    },
    {
      "name": "LoopQuestions",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "RelevantQuestions",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 1"
    },
    {
      "name": "MergeUserIntent",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.1"
    },
    {
      "name": "PromptGenerator",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "Google Gemini Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "RelatedQuestionAI",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.6"
    },
    {
      "name": "SplitQuestions",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Auto-fixing Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "role": "outputParserAutofixing",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser1",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "SendingPrompt",
      "type": "n8n-nodes-base.form",
      "role": "form",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}