{
  "id": 4268,
  "slug": "4268",
  "title": "Evaluation metric example: Check if tool was called",
  "description": "## AI evaluation in n8n\n\nThis is a template for n8n's [evaluation feature](https://docs.n8n.io/advanced-ai/evaluations/overview). \n\nEvaluation is a technique for getting confidence that your AI workflow performs reliably, by running a test dataset containing different inputs through the workflow.\n\nBy calculating a metric (score) for each input, you can see where the workflow is performing well and where it isn't.\n\n## How it works\n\nThis template shows how to calculate a workflow evaluation metric: **whether a specific tool was called** by an agent.\n\n- We use an evaluation trigger to read in our dataset \n- It is wired up in parallel with the regular trigger so that the workflow can be started from either one. [More info](https://docs.n8n.io/advanced-ai/evaluations/tips-and-common-issues/#combining-multiple-triggers)\n- We make sure that the agent outputs the list of tools that it used\n- We then check whether the expected tool (from the dataset) is in that list\n- Finally we pass this information back to n8n as a metric\n",
  "featuredImage": "/data/workflows/4268/4268.webp",
  "author": {
    "id": 101,
    "slug": "davidn8n",
    "name": "David Roberts",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1100,
  "downloads": 110,
  "createdAt": "2025-05-21T08:06:35.412Z",
  "updatedAt": "2026-01-16T08:33:38.337Z",
  "publishedAt": "2025-05-21T08:06:35.412Z",
  "nodes": 15,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4268",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Evaluation metric example: Check if tool was called",
    "workflowName": "Evaluation metric example: Check if tool was called",
    "description": "## AI evaluation in n8n\n\nThis is a template for n8n's [evaluation feature](https://docs.n8n.io/advanced-ai/evaluations/overview). \n\nEvaluation is a technique for getting confidence that your AI workflow performs reliably, by running a test dataset containing different inputs through the workflow.\n\nBy calculating a metric (score) for each input, you can see where the workflow is performing well and where it isn't.\n\n## How it works\n\nThis template shows how to calculate a workflow evaluation metric: **whether a specific tool was called** by an agent.\n\n- We use an evaluation trigger to read in our dataset \n- It is wired up in parallel with the regular trigger so that the workflow can be started from either one. [More info](https://docs.n8n.io/advanced-ai/evaluations/tips-and-common-issues/#combining-multiple-triggers)\n- We make sure that the agent outputs the list of tools that it used\n- We then check whether the expected tool (from the dataset) is in that list\n- Finally we pass this information back to n8n as a metric",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.9"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Calculator",
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "role": "toolCalculator",
      "configDescription": "Version 1"
    },
    {
      "name": "Check if tool called",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Fetch a webpage",
      "type": "n8n-nodes-base.httpRequestTool",
      "role": "httpRequestTool",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Match chat format",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Return chat response",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When fetching a dataset row",
      "type": "n8n-nodes-base.evaluationTrigger",
      "role": "evaluationTrigger",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Evaluation",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.6"
    },
    {
      "name": "Evaluating?",
      "type": "n8n-nodes-base.evaluation",
      "role": "evaluation",
      "configDescription": "Version 4.6"
    }
  ]
}