{
  "id": 6542,
  "slug": "6542",
  "title": "Build an All-Source Knowledge Assistant with Claude, RAG, Perplexity, and Drive",
  "description": "# ðŸ“œ Detailed n8n Workflow Description\n\n## Main Flow\n\nThe workflow operates through a three-step process that handles incoming chat messages with intelligent tool orchestration:\n\n1. **Message Trigger**: The `When chat message received` node triggers whenever a user message arrives and passes it directly to the `Knowledge Agent` for processing.\n\n2. **Agent Orchestration**: The `Knowledge Agent` serves as the central orchestrator, registering a comprehensive toolkit of capabilities:\n   - **LLM Processing**: Uses `Anthropic Chat Model` with the *claude-sonnet-4-20250514* model to craft final responses\n   - **Memory Management**: Implements `Postgres Chat Memory` to save and recall conversation context across sessions\n   - **Reasoning Engine**: Incorporates a `Think` tool to force internal chain-of-thought processing before taking any action\n   - **Semantic Search**: Leverages `General knowledge` vector store with OpenAI embeddings (1536-dimensional) and Cohere reranking for intelligent content retrieval\n   - **Structured Queries**: Provides `structured data` Postgres tool for executing queries on relational database tables\n   - **Drive Integration**: Includes `search about any doc in google drive` functionality to locate specific file IDs\n   - **File Processing**: Connects to `Read File From GDrive` sub-workflow for fetching and processing various file formats\n   - **External Intelligence**: Offers `Message a model in Perplexity` for accessing up-to-the-minute web information when internal knowledge proves insufficient\n\n3. **Response Generation**: After invoking the `Think` process, the agent intelligently selects appropriate tools based on the query, integrates results from multiple sources, and returns a comprehensive Markdown-formatted answer to the user.\n\n## Persistent Context Management\n\nThe workflow maintains conversation continuity through `Postgres Chat Memory`, which automatically logs every user-agent exchange. This ensures long-term context retention without requiring manual intervention, allowing for sophisticated multi-turn conversations that build upon previous interactions.\n\n## Semantic Retrieval Pipeline\n\nThe semantic search system operates through a sophisticated two-stage process:\n\n- **Embedding Generation**: `Embeddings OpenAI` converts textual content into high-dimensional vector representations\n- **Relevance Reranking**: `Reranker Cohere` reorders search hits to prioritize the most contextually relevant results\n- **Knowledge Integration**: Processed results feed into the `General knowledge` vector store, providing the agent with relevant internal knowledge snippets for enhanced response accuracy\n\n## Google Drive File Processing\n\nThe file reading capability handles multiple formats through a structured sub-workflow:\n\n1. **Workflow Initiation**: The agent calls `Read File From GDrive` with the selected `fileId` parameter\n2. **Sub-workflow Activation**: `When Executed by Another Workflow` node activates the dedicated file processing sub-workflow\n3. **Operation Validation**: `Operation` node confirms the request type is `readFile`\n4. **File Retrieval**: `Download File1` node retrieves the binary file data from Google Drive\n5. **Format-Specific Processing**: `FileType` node branches processing based on MIME type:\n   - **PDF Files**: Route through `Extract from PDF` â†’ `Get PDF Response` to extract plain text content\n   - **CSV Files**: Process via `Extract from CSV` â†’ `Get CSV Response` to obtain comma-delimited text data\n   - **Image Files**: Analyze using `Analyse Image` with GPT-4o-mini to generate visual descriptions\n   - **Audio/Video Files**: Transcribe using `Transcribe Audio` with Whisper for text transcript generation\n6. **Content Integration**: The extracted text content returns to `Knowledge Agent`, which seamlessly weaves it into the final response\n\n## External Search Capability\n\nWhen internal knowledge sources prove insufficient, the workflow can access current public information through `Message a model in Perplexity`, ensuring responses remain accurate and up-to-date with the latest available information.\n\n## Design Highlights\n\nThe workflow architecture incorporates several key design principles that enhance reliability and reusability:\n\n- **Forced Reasoning**: The mandatory `Think` step significantly reduces hallucinations and prevents tool misuse by requiring deliberate consideration before action\n- **Template Flexibility**: The design is intentionally genericâ€”organizations can replace **[your company]** placeholders with their specific company name and integrate their own credentials for immediate deployment\n- **Documentation Integration**: Sticky notes throughout the canvas serve as inline documentation for workflow creators and maintainers, providing context without affecting runtime performance\n\n## System Benefits\n\nWith this comprehensive architecture, the assistant delivers powerful capabilities including long-term memory retention, semantic knowledge retrieval, multi-format file processing, and contextually rich responses tailored specifically for users at **[your company]**. The system balances sophisticated AI capabilities with practical business requirements, creating a robust foundation for enterprise-grade conversational AI deployment.",
  "featuredImage": "/data/workflows/6542/6542.webp",
  "author": {
    "id": 101,
    "slug": "diagopl",
    "name": "Paul",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 6828,
  "downloads": 682,
  "createdAt": "2025-07-27T21:17:51.143Z",
  "updatedAt": "2026-01-16T08:45:34.703Z",
  "publishedAt": "2025-07-27T21:17:51.143Z",
  "nodes": 40,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6542",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build an All-Source Knowledge Assistant with Claude, RAG, Perplexity, and Drive",
    "workflowName": "Build an All-Source Knowledge Assistant with Claude, RAG, Perplexity, and Drive",
    "description": "# ðŸ“œ Detailed n8n Workflow Description\n\n## Main Flow\n\nThe workflow operates through a three-step process that handles incoming chat messages with intelligent tool orchestration:\n\n1. **Message Trigger**: The `When chat message received` node triggers whenever a user message arrives and passes it directly to the `Knowledge Agent` for processing.\n\n2. **Agent Orchestration**: The `Knowledge Agent` serves as the central orchestrator, registering a comprehensive toolkit of capabilities:\n   - **LLM Processing**: Uses `Anthropic Chat Model` with the *claude-sonnet-4-20250514* model to craft final responses\n   - **Memory Management**: Implements `Postgres Chat Memory` to save and recall conversation context across sessions\n   - **Reasoning Engine**: Incorporates a `Think` tool to force internal chain-of-thought processing before taking any action\n   - **Semantic Search**: Leverages `General knowledge` vector store with OpenAI embeddings (1536-dimensional) and Cohere reranking for intelligent content retrieval\n   - **Structured Queries**: Provides `structured data` Postgres tool for executing queries on relational database tables\n   - **Drive Integration**: Includes `search about any doc in google drive` functionality to locate specific file IDs\n   - **File Processing**: Connects to `Read File From GDrive` sub-workflow for fetching and processing various file formats\n   - **External Intelligence**: Offers `Message a model in Perplexity` for accessing up-to-the-minute web information when internal knowledge proves insufficient\n\n3. **Response Generation**: After invoking the `Think` process, the agent intelligently selects appropriate tools based on the query, integrates results from multiple sources, and returns a comprehensive Markdown-formatted answer to the user.\n\n## Persistent Context Management\n\nThe workflow maintains conversation continuity through `Postgres Chat Memory`, which automatically logs every user-agent exchange. This ensures long-term context retention without requiring manual intervention, allowing for sophisticated multi-turn conversations that build upon previous interactions.\n\n## Semantic Retrieval Pipeline\n\nThe semantic search system operates through a sophisticated two-stage process:\n\n- **Embedding Generation**: `Embeddings OpenAI` converts textual content into high-dimensional vector representations\n- **Relevance Reranking**: `Reranker Cohere` reorders search hits to prioritize the most contextually relevant results\n- **Knowledge Integration**: Processed results feed into the `General knowledge` vector store, providing the agent with relevant internal knowledge snippets for enhanced response accuracy\n\n## Google Drive File Processing\n\nThe file reading capability handles multiple formats through a structured sub-workflow:\n\n1. **Workflow Initiation**: The agent calls `Read File From GDrive` with the selected `fileId` parameter\n2. **Sub-workflow Activation**: `When Executed by Another Workflow` node activates the dedicated file processing sub-workflow\n3. **Operation Validation**: `Operation` node confirms the request type is `readFile`\n4. **File Retrieval**: `Download File1` node retrieves the binary file data from Google Drive\n5. **Format-Specific Processing**: `FileType` node branches processing based on MIME type:\n   - **PDF Files**: Route through `Extract from PDF` â†’ `Get PDF Response` to extract plain text content\n   - **CSV Files**: Process via `Extract from CSV` â†’ `Get CSV Response` to obtain comma-delimited text data\n   - **Image Files**: Analyze using `Analyse Image` with GPT-4o-mini to generate visual descriptions\n   - **Audio/Video Files**: Transcribe using `Transcribe Audio` with Whisper for text transcript generation\n6. **Content Integration**: The extracted text content returns to `Knowledge Agent`, which seamlessly weaves it into the final response\n\n## External Search Capability\n\nWhen internal knowledge sources prove insufficient, the workflow can access current public information through `Message a model in Perplexity`, ensuring responses remain accurate and up-to-date with the latest available information.\n\n## Design Highlights\n\nThe workflow architecture incorporates several key design principles that enhance reliability and reusability:\n\n- **Forced Reasoning**: The mandatory `Think` step significantly reduces hallucinations and prevents tool misuse by requiring deliberate consideration before action\n- **Template Flexibility**: The design is intentionally genericâ€”organizations can replace **[your company]** placeholders with their specific company name and integrate their own credentials for immediate deployment\n- **Documentation Integration**: Sticky notes throughout the canvas serve as inline documentation for workflow creators and maintainers, providing context without affecting runtime performance\n\n## System Benefits\n\nWith this comprehensive architecture, the assistant delivers powerful capabilities including long-term memory retention, semantic knowledge retrieval, multi-format file processing, and contextually rich responses tailored specifically for users at **[your company]**. The system balances sophisticated AI capabilities with practical business requirements, creating a robust foundation for enterprise-grade conversational AI deployment.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Postgres Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "role": "memoryPostgresChat",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Reranker Cohere",
      "type": "@n8n/n8n-nodes-langchain.rerankerCohere",
      "role": "rerankerCohere",
      "configDescription": "Version 1"
    },
    {
      "name": "Anthropic Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "role": "lmChatAnthropic",
      "configDescription": "Version 1.3"
    },
    {
      "name": "structured data",
      "type": "n8n-nodes-base.postgresTool",
      "role": "postgresTool",
      "configDescription": "Version 2.6"
    },
    {
      "name": "General knowledge",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1.3"
    },
    {
      "name": "When clicking â€˜Execute workflowâ€™",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Download file",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Default Data Loader1",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Recursive Character Text Splitter1",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Add to Supabase Vector DB",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Think",
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "role": "toolThink",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When Executed by Another Workflow",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "role": "executeWorkflowTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Google Drive MCP Server",
      "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
      "role": "mcpTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Download File1",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "FileType",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Operation",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Extract from PDF",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Extract from CSV",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Get PDF Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Get CSV Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Read File From GDrive",
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "role": "toolWorkflow",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Search Files from Gdrive",
      "type": "n8n-nodes-base.googleDriveTool",
      "role": "googleDriveTool",
      "configDescription": "Version 3"
    },
    {
      "name": "Analyse Image",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Transcribe Audio",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "role": "openAi",
      "configDescription": "Version 1.8"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "search  about any doc in google drive",
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "role": "mcpClientTool",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Knowledge Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Message a model in Perplexity",
      "type": "n8n-nodes-base.perplexityTool",
      "role": "perplexityTool",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note9",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}