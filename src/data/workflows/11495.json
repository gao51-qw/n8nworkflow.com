{
  "id": 11495,
  "slug": "11495",
  "title": "Automatically optimize AI prompts with OpenAI using OPRO & DSPy methodology",
  "description": "This workflow implements cutting-edge concepts from **Google DeepMind's OPRO** (Optimization by PROmpting) and **Stanford's DSPy** to automatically refine AI prompts. It iteratively generates, evaluates, and optimizes responses against a ground truth, allowing you to \"compile\" your prompts for maximum accuracy.\n\n## Why this is powerful\n\nInstead of manually tweaking prompts (trial and error), this workflow treats prompt engineering as an **optimization problem**:\n- **OPRO-style Optimization**: The \"Optimizer\" LLM analyzes past performance scores and reasons to mathematically deduce a better prompt.\n- **DSPy-style Logic**: It separates the \"Logic\" (Workflow) from the \"Parameters\" (Prompts), allowing the system to self-correct until it matches the Ground Truth.\n\n## How it works\n\n- **Define**: Set your initial prompt and a test case with the expected answer (Ground Truth).\n- **Generate**: The workflow generates a response using the current prompt.\n- **Evaluate**: An AI Evaluator scores the response (0-100) based on accuracy and format.\n- **Optimize**: If the score is low, the Optimizer AI analyzes the failure and rewrites the prompt.\n- **Loop**: The process repeats until the score reaches 95/100 or the loop limit is hit.\n\n## Setup steps\n\n1. **Configure OpenAI**: Ensure you have an OpenAI credential set up in the `OpenAI Chat Model` node.\n2. **Customize**: Open the `Define Initial Prompt & Test Data` node and set your `initial_prompt`, `test_input`, and `ground_truth`.\n3. **Run**: Execute the workflow and check the `Manage Loop & State` node output for the optimized prompt.\n",
  "featuredImage": "/data/workflows/11495/11495.webp",
  "author": {
    "id": 101,
    "slug": "nakayama",
    "name": "Shun Nakayama",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 247,
  "downloads": 24,
  "createdAt": "2025-12-04T15:01:58.494Z",
  "updatedAt": "2026-01-16T09:08:57.081Z",
  "publishedAt": "2025-12-04T15:01:58.494Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/11495",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Automatically optimize AI prompts with OpenAI using OPRO & DSPy methodology",
    "workflowName": "Automatically optimize AI prompts with OpenAI using OPRO & DSPy methodology",
    "description": "This workflow implements cutting-edge concepts from **Google DeepMind's OPRO** (Optimization by PROmpting) and **Stanford's DSPy** to automatically refine AI prompts. It iteratively generates, evaluates, and optimizes responses against a ground truth, allowing you to \"compile\" your prompts for maximum accuracy.\n\n## Why this is powerful\n\nInstead of manually tweaking prompts (trial and error), this workflow treats prompt engineering as an **optimization problem**:\n- **OPRO-style Optimization**: The \"Optimizer\" LLM analyzes past performance scores and reasons to mathematically deduce a better prompt.\n- **DSPy-style Logic**: It separates the \"Logic\" (Workflow) from the \"Parameters\" (Prompts), allowing the system to self-correct until it matches the Ground Truth.\n\n## How it works\n\n- **Define**: Set your initial prompt and a test case with the expected answer (Ground Truth).\n- **Generate**: The workflow generates a response using the current prompt.\n- **Evaluate**: An AI Evaluator scores the response (0-100) based on accuracy and format.\n- **Optimize**: If the score is low, the Optimizer AI analyzes the failure and rewrites the prompt.\n- **Loop**: The process repeats until the score reaches 95/100 or the loop limit is hit.\n\n## Setup steps\n\n1. **Configure OpenAI**: Ensure you have an OpenAI credential set up in the `OpenAI Chat Model` node.\n2. **Customize**: Open the `Define Initial Prompt & Test Data` node and set your `initial_prompt`, `test_input`, and `ground_truth`.\n3. **Run**: Execute the workflow and check the `Manage Loop & State` node output for the optimized prompt.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Sticky Note Main",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note Init",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note Gen Eval",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note Opt",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Define Initial Prompt & Test Data",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "AI Prompt Optimizer",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3"
    },
    {
      "name": "AI Response Evaluator",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3"
    },
    {
      "name": "Manage Loop & State",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "AI Response Generator",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 3"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Check Loop Condition",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "End Loop",
      "type": "n8n-nodes-base.noOp",
      "role": "noOp",
      "configDescription": "Version 1"
    },
    {
      "name": "Evaluator Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Optimizer Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Update Prompt & Loop Count",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    }
  ]
}