{
  "id": 10096,
  "slug": "10096",
  "title": "Document RAG & chat agent: Google Drive to Qdrant with Mistral OCR",
  "description": "# **Knowledge RAG & AI Chat Agent: Google Drive to Qdrant**\n\n## **Description**\n\nThis workflow transforms a Google Drive folder into an intelligent, searchable knowledge base and provides a chat agent to query it.  \nIt’s composed of two distinct flows:  \n- An **ingestion pipeline** to process documents.  \n- A **live chat agent** that uses **RAG (Retrieval-Augmented Generation)** and optional **web search** to answer user questions.  \n\nThis system fully automates the creation of a “Chat with your docs” solution and enhances it with external web-searching capabilities.\n\n---\n\n## **Quick Implementation Steps**\n\n1. Import the workflow JSON into your **n8n** instance.  \n2. Set up credentials for **Google Drive**, **Mistral AI**, **OpenAI**, and **Qdrant**.  \n3. Open the **Web Search** node and add your **Tavily AI API key** to the Authorization header.  \n4. In the **Google Drive (List Files)** node, set the Folder ID you want to ingest.  \n5. Run the workflow manually once to populate your **Qdrant database (Flow 1)**.  \n6. Activate the workflow to enable the **chat trigger (Flow 2)**.  \n7. Copy the **public webhook URL** from the *When chat message received* node and open it in a new tab to start chatting.\n\n---\n\n## **What It Does**\n\nThe workflow is divided into two primary functions:\n\n### **1. Knowledge Base Ingestion (Manual Trigger)**  \nThis flow populates your vector database.  \n\n- **Scans Google Drive:** Lists all files from a specified folder.  \n- **Processes Files Individually:** Downloads each file.  \n- **Extracts Text via OCR:** Uses **Mistral AI OCR API** for text extraction from PDFs, images, etc.  \n- **Generates Smart Metadata:** A Mistral LLM assigns metadata like `document_type`, `project`, and `assigned_to`.  \n- **Chunks & Embeds:** Text is cleaned, chunked, and embedded via **OpenAI’s text-embedding-3-small** model.  \n- **Stores in Qdrant:** Text chunks, embeddings, and metadata are stored in a Qdrant collection (`docaiauto`).  \n\n### **2. AI Chat Agent (Chat Trigger)**  \nThis flow powers the conversational interface.  \n\n- **Handles User Queries:** Triggered when a user sends a chat message.  \n- **Internal RAG Retrieval:** Searches **Qdrant Vector Store** first for answers.  \n- **Web Search Fallback:** If unavailable internally, the agent offers to perform a **Tavily AI web search**.  \n- **Contextual Responses:** Combines internal and external info for comprehensive answers.\n\n---\n\n## **Who's It For**\n\nIdeal for:\n\n- Teams building internal AI knowledge bases from Google Drive.  \n- Developers creating **AI-powered support**, **research**, or **onboarding** bots.  \n- Organizations implementing **RAG pipelines**.  \n- Anyone making **unstructured Google Drive documents searchable** via chat.\n\n---\n\n## **Requirements**\n\n- **n8n instance** (self-hosted or cloud).  \n- **Google Drive Credentials** (to list and download files).  \n- **Mistral AI API Key** (for OCR & metadata extraction).  \n- **OpenAI API Key** (for embeddings and chat LLM).  \n- **Qdrant instance** (cloud or self-hosted).  \n- **Tavily AI API Key** (for web search).\n\n---\n\n## **How It Works**\n\nThe workflow runs two independent flows in parallel:\n\n### **Flow 1: Ingestion Pipeline (Manual Trigger)**\n\n1. **List Files:** Fetch files from Google Drive using the Folder ID.  \n2. **Loop & Download:** Each file is processed one by one.  \n3. **OCR Processing:**  \n   - Upload file to Mistral  \n   - Retrieve signed URL  \n   - Extract text using **Mistral DOC OCR**  \n4. **Metadata Extraction:** Analyze text using a **Mistral LLM**.  \n5. **Text Cleaning & Chunking:** Split into 1000-character chunks.  \n6. **Embeddings Creation:** Use **OpenAI embeddings**.  \n7. **Vector Insertion:** Push chunks + metadata into **Qdrant**.  \n\n### **Flow 2: AI Chat Agent (Chat Trigger)**\n\n1. **Chat Trigger:** Starts when a chat message is received.  \n2. **AI Agent:** Uses OpenAI + Simple Memory to process context.  \n3. **RAG Retrieval:** Queries Qdrant for related data.  \n4. **Decision Logic:**  \n   - Found → Form answer.  \n   - Not found → Ask if user wants web search.  \n5. **Web Search:** Performs Tavily web lookup.  \n6. **Final Response:** Synthesizes internal + external info.\n\n---\n\n## **How To Set Up**\n\n### **1. Import the Workflow**\nUpload the provided JSON into your **n8n** instance.\n\n### **2. Configure Credentials**\nCreate and assign:\n\n- **Google Drive** → Google Drive nodes  \n- **Mistral AI** → Upload, Signed URL, DOC OCR, Cloud Chat Model  \n- **OpenAI** → Embeddings + Chat Model nodes  \n- **Qdrant** → Vector Store nodes  \n\n### **3. Add Tavily API Key**\n- Open **Web Search node → Parameters → Headers**  \n- Add your key under **Authorization** (e.g., `tvly-xxxx`).  \n\n### **4. Node Configuration**\n- **Google Drive (List Files):** Set Folder ID.  \n- **Qdrant Nodes:** Ensure same collection name (`docaiauto`).  \n\n### **5. Run Ingestion (Flow 1)**\nClick **Test workflow** to populate Qdrant with your Drive documents.  \n\n### **6. Activate Chat (Flow 2)**\nToggle the workflow ON to enable real-time chat.  \n\n### **7. Test**\nOpen the webhook URL and start chatting!\n\n---\n\n## **How To Customize**\n\n- **Change LLMs:** Swap models in OpenAI or Mistral nodes (e.g., GPT-4o, Claude 3).  \n- **Modify Prompts:** Edit the system message in `ai chat agent` to alter tone or logic.  \n- **Chunking Strategy:** Adjust `chunkSize` and `chunkOverlap` in the Code node.  \n- **Different Sources:** Replace Google Drive with AWS S3, Local Folder, etc.  \n- **Automate Updates:** Add a **Cron** node for scheduled ingestion.  \n- **Validation:** Add post-processing steps after metadata extraction.  \n- **Expand Tools:** Add more functional nodes like Google Calendar or Calculator.\n\n---\n\n## **Use Case Examples**\n\n- **Internal HR Bot:** Answer HR-related queries from stored policy docs.  \n- **Tech Support Assistant:** Retrieve troubleshooting steps for products.  \n- **Research Assistant:** Summarize and compare market reports.  \n- **Project Management Bot:** Query document ownership or project status.\n\n---\n\n## **Troubleshooting Guide**\n\n| **Issue** | **Possible Solution** |\n|------------|------------------------|\n| Chat agent doesn’t respond | Check OpenAI API key and model availability (e.g., `gpt-4.1-mini`). |\n| Known documents not found | Ensure ingestion flow ran and both Qdrant nodes use same collection name. |\n| OCR node fails | Verify Mistral API key and input file integrity. |\n| Web search not triggered | Re-check Tavily API key in Web Search node headers. |\n| Incorrect metadata | Tune Information Extractor prompt or use a stronger Mistral model. |\n\n---\n\n###  **Need Help or More Workflows?**\nWant to customize this workflow for your business or integrate it with your existing tools?  \nOur team at **Digital Biz Tech** can tailor it precisely to your use case  from automation logic to AI-powered enhancements.  \n\n We can help you set it up for free — from connecting credentials to deploying it live.\n\nContact: [shilpa.raju@digitalbiz.tech](mailto:shilpa.raju@digitalbiz.tech)  \nWebsite: [https://www.digitalbiz.tech](https://www.digitalbiz.tech)  \nLinkedIn: [https://www.linkedin.com/company/digital-biz-tech/](https://www.linkedin.com/company/digital-biz-tech/)  \nYou can also DM us on LinkedIn for any help.\n\n---\n",
  "featuredImage": "/data/workflows/10096/10096.webp",
  "author": {
    "id": 101,
    "slug": "dbt",
    "name": "DIGITAL BIZ TECH",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1394,
  "downloads": 139,
  "createdAt": "2025-10-24T01:10:25.155Z",
  "updatedAt": "2026-01-16T09:03:22.689Z",
  "publishedAt": "2025-10-24T01:10:25.155Z",
  "nodes": 39,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/10096",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Document RAG & chat agent: Google Drive to Qdrant with Mistral OCR",
    "workflowName": "Document RAG & chat agent: Google Drive to Qdrant with Mistral OCR",
    "description": "# **Knowledge RAG & AI Chat Agent: Google Drive to Qdrant**\n\n## **Description**\n\nThis workflow transforms a Google Drive folder into an intelligent, searchable knowledge base and provides a chat agent to query it.  \nIt’s composed of two distinct flows:  \n- An **ingestion pipeline** to process documents.  \n- A **live chat agent** that uses **RAG (Retrieval-Augmented Generation)** and optional **web search** to answer user questions.  \n\nThis system fully automates the creation of a “Chat with your docs” solution and enhances it with external web-searching capabilities.\n\n---\n\n## **Quick Implementation Steps**\n\n1. Import the workflow JSON into your **n8n** instance.  \n2. Set up credentials for **Google Drive**, **Mistral AI**, **OpenAI**, and **Qdrant**.  \n3. Open the **Web Search** node and add your **Tavily AI API key** to the Authorization header.  \n4. In the **Google Drive (List Files)** node, set the Folder ID you want to ingest.  \n5. Run the workflow manually once to populate your **Qdrant database (Flow 1)**.  \n6. Activate the workflow to enable the **chat trigger (Flow 2)**.  \n7. Copy the **public webhook URL** from the *When chat message received* node and open it in a new tab to start chatting.\n\n---\n\n## **What It Does**\n\nThe workflow is divided into two primary functions:\n\n### **1. Knowledge Base Ingestion (Manual Trigger)**  \nThis flow populates your vector database.  \n\n- **Scans Google Drive:** Lists all files from a specified folder.  \n- **Processes Files Individually:** Downloads each file.  \n- **Extracts Text via OCR:** Uses **Mistral AI OCR API** for text extraction from PDFs, images, etc.  \n- **Generates Smart Metadata:** A Mistral LLM assigns metadata like `document_type`, `project`, and `assigned_to`.  \n- **Chunks & Embeds:** Text is cleaned, chunked, and embedded via **OpenAI’s text-embedding-3-small** model.  \n- **Stores in Qdrant:** Text chunks, embeddings, and metadata are stored in a Qdrant collection (`docaiauto`).  \n\n### **2. AI Chat Agent (Chat Trigger)**  \nThis flow powers the conversational interface.  \n\n- **Handles User Queries:** Triggered when a user sends a chat message.  \n- **Internal RAG Retrieval:** Searches **Qdrant Vector Store** first for answers.  \n- **Web Search Fallback:** If unavailable internally, the agent offers to perform a **Tavily AI web search**.  \n- **Contextual Responses:** Combines internal and external info for comprehensive answers.\n\n---\n\n## **Who's It For**\n\nIdeal for:\n\n- Teams building internal AI knowledge bases from Google Drive.  \n- Developers creating **AI-powered support**, **research**, or **onboarding** bots.  \n- Organizations implementing **RAG pipelines**.  \n- Anyone making **unstructured Google Drive documents searchable** via chat.\n\n---\n\n## **Requirements**\n\n- **n8n instance** (self-hosted or cloud).  \n- **Google Drive Credentials** (to list and download files).  \n- **Mistral AI API Key** (for OCR & metadata extraction).  \n- **OpenAI API Key** (for embeddings and chat LLM).  \n- **Qdrant instance** (cloud or self-hosted).  \n- **Tavily AI API Key** (for web search).\n\n---\n\n## **How It Works**\n\nThe workflow runs two independent flows in parallel:\n\n### **Flow 1: Ingestion Pipeline (Manual Trigger)**\n\n1. **List Files:** Fetch files from Google Drive using the Folder ID.  \n2. **Loop & Download:** Each file is processed one by one.  \n3. **OCR Processing:**  \n   - Upload file to Mistral  \n   - Retrieve signed URL  \n   - Extract text using **Mistral DOC OCR**  \n4. **Metadata Extraction:** Analyze text using a **Mistral LLM**.  \n5. **Text Cleaning & Chunking:** Split into 1000-character chunks.  \n6. **Embeddings Creation:** Use **OpenAI embeddings**.  \n7. **Vector Insertion:** Push chunks + metadata into **Qdrant**.  \n\n### **Flow 2: AI Chat Agent (Chat Trigger)**\n\n1. **Chat Trigger:** Starts when a chat message is received.  \n2. **AI Agent:** Uses OpenAI + Simple Memory to process context.  \n3. **RAG Retrieval:** Queries Qdrant for related data.  \n4. **Decision Logic:**  \n   - Found → Form answer.  \n   - Not found → Ask if user wants web search.  \n5. **Web Search:** Performs Tavily web lookup.  \n6. **Final Response:** Synthesizes internal + external info.\n\n---\n\n## **How To Set Up**\n\n### **1. Import the Workflow**\nUpload the provided JSON into your **n8n** instance.\n\n### **2. Configure Credentials**\nCreate and assign:\n\n- **Google Drive** → Google Drive nodes  \n- **Mistral AI** → Upload, Signed URL, DOC OCR, Cloud Chat Model  \n- **OpenAI** → Embeddings + Chat Model nodes  \n- **Qdrant** → Vector Store nodes  \n\n### **3. Add Tavily API Key**\n- Open **Web Search node → Parameters → Headers**  \n- Add your key under **Authorization** (e.g., `tvly-xxxx`).  \n\n### **4. Node Configuration**\n- **Google Drive (List Files):** Set Folder ID.  \n- **Qdrant Nodes:** Ensure same collection name (`docaiauto`).  \n\n### **5. Run Ingestion (Flow 1)**\nClick **Test workflow** to populate Qdrant with your Drive documents.  \n\n### **6. Activate Chat (Flow 2)**\nToggle the workflow ON to enable real-time chat.  \n\n### **7. Test**\nOpen the webhook URL and start chatting!\n\n---\n\n## **How To Customize**\n\n- **Change LLMs:** Swap models in OpenAI or Mistral nodes (e.g., GPT-4o, Claude 3).  \n- **Modify Prompts:** Edit the system message in `ai chat agent` to alter tone or logic.  \n- **Chunking Strategy:** Adjust `chunkSize` and `chunkOverlap` in the Code node.  \n- **Different Sources:** Replace Google Drive with AWS S3, Local Folder, etc.  \n- **Automate Updates:** Add a **Cron** node for scheduled ingestion.  \n- **Validation:** Add post-processing steps after metadata extraction.  \n- **Expand Tools:** Add more functional nodes like Google Calendar or Calculator.\n\n---\n\n## **Use Case Examples**\n\n- **Internal HR Bot:** Answer HR-related queries from stored policy docs.  \n- **Tech Support Assistant:** Retrieve troubleshooting steps for products.  \n- **Research Assistant:** Summarize and compare market reports.  \n- **Project Management Bot:** Query document ownership or project status.\n\n---\n\n## **Troubleshooting Guide**\n\n| **Issue** | **Possible Solution** |\n|------------|------------------------|\n| Chat agent doesn’t respond | Check OpenAI API key and model availability (e.g., `gpt-4.1-mini`). |\n| Known documents not found | Ensure ingestion flow ran and both Qdrant nodes use same collection name. |\n| OCR node fails | Verify Mistral API key and input file integrity. |\n| Web search not triggered | Re-check Tavily API key in Web Search node headers. |\n| Incorrect metadata | Tune Information Extractor prompt or use a stronger Mistral model. |\n\n---\n\n###  **Need Help or More Workflows?**\nWant to customize this workflow for your business or integrate it with your existing tools?  \nOur team at **Digital Biz Tech** can tailor it precisely to your use case  from automation logic to AI-powered enhancements.  \n\n We can help you set it up for free — from connecting credentials to deploying it live.\n\nContact: [shilpa.raju@digitalbiz.tech](mailto:shilpa.raju@digitalbiz.tech)  \nWebsite: [https://www.digitalbiz.tech](https://www.digitalbiz.tech)  \nLinkedIn: [https://www.linkedin.com/company/digital-biz-tech/](https://www.linkedin.com/company/digital-biz-tech/)  \nYou can also DM us on LinkedIn for any help.\n\n---",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Web Search ",
      "type": "@n8n/n8n-nodes-langchain.toolHttpRequest",
      "role": "toolHttpRequest",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Simple Memory1",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "role": "memoryBufferWindow",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.1"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterCharacterTextSplitter",
      "role": "textSplitterCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Drive",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Google Drive1",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Mistral Upload",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Mistral Signed URL",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Mistral DOC OCR",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1"
    },
    {
      "name": "Qdrant Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "role": "vectorStoreQdrant",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Mistral Cloud Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "role": "lmChatMistralCloud",
      "configDescription": "Version 1"
    },
    {
      "name": "ai chat agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note10",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note11",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note12",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note9",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over each file in gdrive folder",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "add metadata",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "If NODE",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "based file name it assign differ metadata",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1"
    },
    {
      "name": "set all metadata",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "clean output",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "convert data into smaller chunks",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note14",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}