{
  "id": 2418,
  "slug": "2418",
  "title": "Easy image captioning with Gemini 1.5 Pro",
  "description": "This n8n workflow demonstrates how to automate image captioning tasks using Gemini 1.5 Pro - a multimodal LLM which can accept and analyse images. This is a really simple example of how easy it is to build and leverage powerful AI models in your repetitive tasks.\n\n## How it works\n* For this demo, we'll import a public image from a popular stock photography website, Pexel.com, into our workflow using the HTTP request node.\n* With multimodal LLMs, there is little do preprocess other than ensuring the image dimensions fit within the LLMs accepted limits. Though not essential, we'll resize the image using the Edit image node to achieve fast processing.\n* The image is used as an input to the basic LLM node by defining a \"user message\" entry with the binary (data) type.\n* The LLM node has the Gemini 1.5 Pro language model attached and we'll prompt it to generate a caption title and text appropriate for the image it sees.\n* Once generated, the generated caption text is positioning over the original image to complete the task. We can calculate the positioning relative to the amount of characters produced using the code node.\n\nAn example of the combined image and caption can be found here: [https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc](https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc)\n\n## Requirements\n* Google Gemini API Key.\n* Access to Google Drive.\n\n## Customising the workflow\n\n* Not using Google Gemini? n8n's basic LLM node supports the standard syntax for image content for models that support it - try using GPT4o, Claude or LLava (via Ollama).\n\n* Google Drive is only used for demonstration purposes. Feel free to swap this out for other triggers such as webhooks to fit your use case.\n\n",
  "featuredImage": "/data/workflows/2418/2418.webp",
  "author": {
    "id": 101,
    "slug": "jimleuk",
    "name": "Jimleuk",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 13836,
  "downloads": 1383,
  "createdAt": "2024-09-18T10:17:10.042Z",
  "updatedAt": "2026-01-16T08:24:39.548Z",
  "publishedAt": "2024-09-18T10:17:10.042Z",
  "nodes": 16,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/2418",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Easy image captioning with Gemini 1.5 Pro",
    "workflowName": "Easy image captioning with Gemini 1.5 Pro",
    "description": "This n8n workflow demonstrates how to automate image captioning tasks using Gemini 1.5 Pro - a multimodal LLM which can accept and analyse images. This is a really simple example of how easy it is to build and leverage powerful AI models in your repetitive tasks.\n\n## How it works\n* For this demo, we'll import a public image from a popular stock photography website, Pexel.com, into our workflow using the HTTP request node.\n* With multimodal LLMs, there is little do preprocess other than ensuring the image dimensions fit within the LLMs accepted limits. Though not essential, we'll resize the image using the Edit image node to achieve fast processing.\n* The image is used as an input to the basic LLM node by defining a \"user message\" entry with the binary (data) type.\n* The LLM node has the Gemini 1.5 Pro language model attached and we'll prompt it to generate a caption title and text appropriate for the image it sees.\n* Once generated, the generated caption text is positioning over the original image to complete the task. We can calculate the positioning relative to the amount of characters produced using the code node.\n\nAn example of the combined image and caption can be found here: [https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc](https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc)\n\n## Requirements\n* Google Gemini API Key.\n* Access to Google Drive.\n\n## Customising the workflow\n\n* Not using Google Gemini? n8n's basic LLM node supports the standard syntax for image content for models that support it - try using GPT4o, Claude or LLava (via Ollama).\n\n* Google Drive is only used for demonstration purposes. Feel free to swap this out for other triggers such as webhooks to fit your use case.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Get Info",
      "type": "n8n-nodes-base.editImage",
      "role": "editImage",
      "configDescription": "Version 1"
    },
    {
      "name": "Resize For AI",
      "type": "n8n-nodes-base.editImage",
      "role": "editImage",
      "configDescription": "Version 1"
    },
    {
      "name": "Calculate Positioning",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Apply Caption to Image",
      "type": "n8n-nodes-base.editImage",
      "role": "editImage",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Merge Image & Caption",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3"
    },
    {
      "name": "Merge Caption & Positions",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3"
    },
    {
      "name": "Get Image",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Image Captioning Agent",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.4"
    }
  ]
}