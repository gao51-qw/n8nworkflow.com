{
  "id": 4821,
  "slug": "4821",
  "title": "DNB company search & extract with Bright Data and OpenAI 4o mini",
  "description": "![DNB Company Search  Extract with Bright Data and Open AI 4o mini.png](fileId:1468)\n\n### Notice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\n### Who this is for\n\nThe DNB Company Search & Extract workflow is designed for professionals who need to gather structured business intelligence from Dun & Bradstreet (DNB). \n\nIt is ideal for:\n\n- Market Researchers\n\n- B2B Sales & Lead Generation Experts\n\n- Business Analysts\n\n- Investment Analysts\n\n- AI Developers Building Financial Knowledge Graphs\n\n### What problem is this workflow solving?\n\nGathering business information from the DNB website usually involves manual browsing, copying company details, and organizing them in spreadsheets. \n\nThis workflow automates the entire data collection pipeline — from searching DNB via Google, scraping relevant pages, to structuring the data and saving it in usable formats.\n\n### What this workflow does\nThis workflow performs automated search, scraping, and structured extraction of DNB company profiles using Bright Data’s MCP search agents and OpenAI’s 4o mini model. \n\nHere's what it includes:\n\n**Set Input Fields**: \nProvide search_query and webhook_notification_url.\n\n**Bright Data MCP Client (Search)**: \nPerforms Google search for the DNB company URL.\n\n**Markdown Scrape from DNB**: \nScrapes the company page using Bright Data and returns it as markdown.\n\n**OpenAI LLM Extraction**:\n\nTransforms markdown into clean structured data.\n\nExtracts business information (company name, size, address, industry, etc.)\n\n**Webhook Notification**: \nSends structured response to your provided webhook.\n\n**Save to Disk**: \nPersists the structured data locally for logging or auditing.\n\n### Pre-conditions\n\n1. Knowledge of Model Context Protocol (MCP) is highly essential. Please read this blog post - [model-context-protocol](https://www.anthropic.com/news/model-context-protocol)\n2. You need to have the [Bright Data](https://brightdata.com/) account and do the necessary setup as mentioned in the **Setup** section below.\n3. You need to have the Google Gemini API Key. Visit [Google AI Studio](https://aistudio.google.com/)\n3. You need to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)\n4. You need to install the [n8n-nodes-mcp](https://github.com/nerding-io/n8n-nodes-mcp)\n\n### Setup\n\n1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://github.com/nerding-io/n8n-nodes-mcp)\n2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)  on your local machine.\n2. Sign up at [Bright Data](https://brightdata.com/).\n3. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n4. Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\n5. In n8n, configure the OpenAi account credentials.\n6. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\n![MCPClientAccount.png](fileId:1467)\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above as API_TOKEN=&lt;your-token&gt;.\n7. Update the Set input fields for search_query and webhook_notification_url.\n8. Update the file name and path to persist on disk.\n\n\n### How to customize this workflow to your needs\n\n- **Search Engine**: \nDefault is Google, but you can change the MCP client engine to Bing, or Yandex if needed.\n\n- **Company Scope**: \nModify search query logic for niche filtering, e.g., \"biotech startups site:dnb.com\".\n\n- **Structured Fields**: \nCustomize the LLM prompt to extract additional fields like CEO name, revenue, or ratings.\n\n- **Integrations**: \nPush output to Notion, Airtable, or CRMs like HubSpot using additional n8n nodes.\n\n- **Formatting**: \nConvert output to PDF or CSV using built-in File and Spreadsheet nodes.",
  "featuredImage": "/data/workflows/4821/4821.webp",
  "author": {
    "id": 101,
    "slug": "ranjancse",
    "name": "Ranjan Dailata",
    "avatar": ""
  },
  "categories": [
    "Lead Generation",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 380,
  "downloads": 38,
  "createdAt": "2025-06-09T14:48:49.096Z",
  "updatedAt": "2026-01-16T08:36:22.719Z",
  "publishedAt": "2025-06-09T14:48:49.096Z",
  "nodes": 18,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4821",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "DNB company search & extract with Bright Data and OpenAI 4o mini",
    "workflowName": "DNB company search & extract with Bright Data and OpenAI 4o mini",
    "description": "![DNB Company Search  Extract with Bright Data and Open AI 4o mini.png](fileId:1468)\n\n### Notice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\n### Who this is for\n\nThe DNB Company Search & Extract workflow is designed for professionals who need to gather structured business intelligence from Dun & Bradstreet (DNB). \n\nIt is ideal for:\n\n- Market Researchers\n\n- B2B Sales & Lead Generation Experts\n\n- Business Analysts\n\n- Investment Analysts\n\n- AI Developers Building Financial Knowledge Graphs\n\n### What problem is this workflow solving?\n\nGathering business information from the DNB website usually involves manual browsing, copying company details, and organizing them in spreadsheets. \n\nThis workflow automates the entire data collection pipeline — from searching DNB via Google, scraping relevant pages, to structuring the data and saving it in usable formats.\n\n### What this workflow does\nThis workflow performs automated search, scraping, and structured extraction of DNB company profiles using Bright Data’s MCP search agents and OpenAI’s 4o mini model. \n\nHere's what it includes:\n\n**Set Input Fields**: \nProvide search_query and webhook_notification_url.\n\n**Bright Data MCP Client (Search)**: \nPerforms Google search for the DNB company URL.\n\n**Markdown Scrape from DNB**: \nScrapes the company page using Bright Data and returns it as markdown.\n\n**OpenAI LLM Extraction**:\n\nTransforms markdown into clean structured data.\n\nExtracts business information (company name, size, address, industry, etc.)\n\n**Webhook Notification**: \nSends structured response to your provided webhook.\n\n**Save to Disk**: \nPersists the structured data locally for logging or auditing.\n\n### Pre-conditions\n\n1. Knowledge of Model Context Protocol (MCP) is highly essential. Please read this blog post - [model-context-protocol](https://www.anthropic.com/news/model-context-protocol)\n2. You need to have the [Bright Data](https://brightdata.com/) account and do the necessary setup as mentioned in the **Setup** section below.\n3. You need to have the Google Gemini API Key. Visit [Google AI Studio](https://aistudio.google.com/)\n3. You need to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)\n4. You need to install the [n8n-nodes-mcp](https://github.com/nerding-io/n8n-nodes-mcp)\n\n### Setup\n\n1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://github.com/nerding-io/n8n-nodes-mcp)\n2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)  on your local machine.\n2. Sign up at [Bright Data](https://brightdata.com/).\n3. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n4. Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\n5. In n8n, configure the OpenAi account credentials.\n6. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\n![MCPClientAccount.png](fileId:1467)\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above as API_TOKEN=&lt;your-token&gt;.\n7. Update the Set input fields for search_query and webhook_notification_url.\n8. Update the file name and path to persist on disk.\n\n\n### How to customize this workflow to your needs\n\n- **Search Engine**: \nDefault is Google, but you can change the MCP client engine to Bing, or Yandex if needed.\n\n- **Company Scope**: \nModify search query logic for niche filtering, e.g., \"biotech startups site:dnb.com\".\n\n- **Structured Fields**: \nCustomize the LLM prompt to extract additional fields like CEO name, revenue, or ratings.\n\n- **Integrations**: \nPush output to Notion, Airtable, or CRMs like HubSpot using additional n8n nodes.\n\n- **Formatting**: \nConvert output to PDF or CSV using built-in File and Spreadsheet nodes.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Set input fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "List all tools for Bright Data",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "MCP Client for Search Engine",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "Bright Data MCP Client For DNB",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "DNB URL Data Extract Using LLM",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "DNB Structured Data Extract Using LLM",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "Create a binary data for Structured Data Extract",
      "type": "n8n-nodes-base.function",
      "role": "function",
      "configDescription": "Version 1"
    },
    {
      "name": "Write the structured content to disk",
      "type": "n8n-nodes-base.readWriteFile",
      "role": "readWriteFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Initiate a Webhook Notification for Structured Data",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser for URL",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Structured Output Parser for Structured Extract",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model for URL Data Extract",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "OpenAI Chat Model for DNB Structured Data Extract",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    }
  ]
}