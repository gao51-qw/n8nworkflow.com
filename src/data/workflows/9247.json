{
  "id": 9247,
  "slug": "9247",
  "title": "Smart chat routing between Gemini and GPT models based on query complexity",
  "description": "# Adaptive LLM Router for Optimized AI Chat Responses\n\nElevate your AI chatbots with intelligent model selection: automatically route simple queries to cost-effective LLMs and complex ones to powerful ones, balancing performance and expenses seamlessly.\n\n## What It Does\n\nThis workflow listens for chat messages, uses a lightweight Gemini model to classify query complexity, then selects and routes to the optimal LLM (Gemini 2.5 Pro for complex, OpenAI GPT-4.1 Nano for simple) to generate responses—ensuring efficient resource use.\n\n## Key Features\n\n- **Complexity Classifier** - Quick assessment using Gemini 2.0 Flash\n- **Dynamic Model Switching** - Routes to premium or budget models based on needs\n- **Chat Trigger** - Webhook-based for real-time conversations\n- **Current Date Awareness** - Injects $now into system prompt\n- **Modular Design** - Easy to add more models or adjust rules\n- **Cost Optimization** - Reserves heavy models for demanding tasks only\n\n## Perfect For\n\n- **Chatbot Developers**: Build responsive, cost-aware AI assistants\n- **Customer Support**: Handle routine vs. technical queries efficiently\n- **Educational Tools**: Simple facts vs. in-depth explanations\n- **Content Creators**: Quick ideas vs. detailed writing assistance\n- **Researchers**: Basic lookups vs. complex analysis\n- **Business Apps**: Optimize API costs in production environments\n\n## Technical Highlights\n\nHarnessing n8n's LangChain nodes, this workflow demonstrates:\n- Webhook triggers for instant chat handling\n- Agent-based classification with strict output rules\n- Conditional model selection for AI chains\n- Integration of multiple LLM providers (Google Gemini, OpenAI)\n- Scalable architecture for expanding model options\n\nIdeal for minimizing AI costs while maximizing response quality. No coding required—import, configure credentials, and deploy!",
  "featuredImage": "/data/workflows/9247/9247.webp",
  "author": {
    "id": 101,
    "slug": "daniel-automates",
    "name": "Daniel Nkencho",
    "avatar": ""
  },
  "categories": [
    "Engineering",
    "AI Chatbot"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 302,
  "downloads": 30,
  "createdAt": "2025-10-03T15:47:59.069Z",
  "updatedAt": "2026-01-16T08:59:38.640Z",
  "publishedAt": "2025-10-03T15:47:59.069Z",
  "nodes": 11,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/9247",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Smart chat routing between Gemini and GPT models based on query complexity",
    "workflowName": "Smart chat routing between Gemini and GPT models based on query complexity",
    "description": "# Adaptive LLM Router for Optimized AI Chat Responses\n\nElevate your AI chatbots with intelligent model selection: automatically route simple queries to cost-effective LLMs and complex ones to powerful ones, balancing performance and expenses seamlessly.\n\n## What It Does\n\nThis workflow listens for chat messages, uses a lightweight Gemini model to classify query complexity, then selects and routes to the optimal LLM (Gemini 2.5 Pro for complex, OpenAI GPT-4.1 Nano for simple) to generate responses—ensuring efficient resource use.\n\n## Key Features\n\n- **Complexity Classifier** - Quick assessment using Gemini 2.0 Flash\n- **Dynamic Model Switching** - Routes to premium or budget models based on needs\n- **Chat Trigger** - Webhook-based for real-time conversations\n- **Current Date Awareness** - Injects $now into system prompt\n- **Modular Design** - Easy to add more models or adjust rules\n- **Cost Optimization** - Reserves heavy models for demanding tasks only\n\n## Perfect For\n\n- **Chatbot Developers**: Build responsive, cost-aware AI assistants\n- **Customer Support**: Handle routine vs. technical queries efficiently\n- **Educational Tools**: Simple facts vs. in-depth explanations\n- **Content Creators**: Quick ideas vs. detailed writing assistance\n- **Researchers**: Basic lookups vs. complex analysis\n- **Business Apps**: Optimize API costs in production environments\n\n## Technical Highlights\n\nHarnessing n8n's LangChain nodes, this workflow demonstrates:\n- Webhook triggers for instant chat handling\n- Agent-based classification with strict output rules\n- Conditional model selection for AI chains\n- Integration of multiple LLM providers (Google Gemini, OpenAI)\n- Scalable architecture for expanding model options\n\nIdeal for minimizing AI costs while maximizing response quality. No coding required—import, configure credentials, and deploy!",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Model Selector",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 1.9"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Model selector",
      "type": "@n8n/n8n-nodes-langchain.modelSelector",
      "role": "modelSelector",
      "configDescription": "Version 1"
    },
    {
      "name": "Main Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2.2"
    },
    {
      "name": "4.1 nano",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "2.5 pro",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "2.0 flash",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Overview Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Trigger",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Classifier",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Note: Main Agent",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}