{
  "id": 5597,
  "slug": "5597",
  "title": "Iterative content refinement with GPT-4 multi-agent feedback system",
  "description": "## **Who's it for**\nThis workflow is designed for users who want to implement iterative AI-powered content improvement processes. It's ideal for content creators, marketers, product managers, and anyone who needs to refine ideas through multiple rounds of critique and enhancement until they meet quality standards.\n\n## **How it works**\nThe workflow creates a sophisticated feedback loop using three specialized AI agents that work together to continuously improve content. Starting with an initial input (like a product description), the system generates ideas and then enters a reasoning loop where:\n\nA **Critic Agent** analyzes the current output and identifies flaws or areas for improvement\nA **Refiner Agent** takes the original input plus the critic's feedback to create enhanced versions\nAn **Evaluator Agent** assesses the refined output and determines if it meets the quality threshold\n\nThe loop continues until either the evaluator determines the output is satisfactory or a maximum number of iterations is reached (configurable, default is 5 turns).\n\n## How to set up\n\n1. Configure the initial AI agent to generate your starting content\n2. Set up the loop structure with \"Reset Loop\" enabled in the loop node options\n3. Configure three AI agents within the loop:\n\n- Critic: Provide detailed analysis prompts for identifying improvements\n- Refiner: Create prompts that incorporate feedback to enhance content\n- Evaluator: Define quality criteria and decision-making logic\n\n\n4. Add Edit Fields nodes at the beginning and end of the loop to maintain data structure\n5. Include a Code node to track iteration count and loop control\n6. Set up the IF node to check exit conditions (max turns or completion status)\n\n## Requirements\n\n**n8n workflow environment**\nAccess to AI/LLM nodes (OpenAI, Anthropic, etc.)\nBasic understanding of JSON data structures\nConfigured AI model credentials\n\n**How to customize the workflow**\nCustomize the system prompts for each agent based on your specific use case. The critic should focus on your quality criteria, the refiner should understand your improvement goals, and the evaluator should have clear success metrics. Adjust the maximum iteration count in the code node and IF condition based on your complexity needs and token budget considerations.",
  "featuredImage": "/data/workflows/5597/5597.webp",
  "author": {
    "id": 101,
    "slug": "lewxiangang",
    "name": "Sebastian/OptiLever",
    "avatar": ""
  },
  "categories": [
    "Content Creation",
    "Multimodal AI"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 23443,
  "downloads": 2344,
  "createdAt": "2025-07-02T15:00:40.640Z",
  "updatedAt": "2026-01-16T08:40:29.865Z",
  "publishedAt": "2025-07-02T15:00:40.640Z",
  "nodes": 13,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5597",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Iterative content refinement with GPT-4 multi-agent feedback system",
    "workflowName": "Iterative content refinement with GPT-4 multi-agent feedback system",
    "description": "## **Who's it for**\nThis workflow is designed for users who want to implement iterative AI-powered content improvement processes. It's ideal for content creators, marketers, product managers, and anyone who needs to refine ideas through multiple rounds of critique and enhancement until they meet quality standards.\n\n## **How it works**\nThe workflow creates a sophisticated feedback loop using three specialized AI agents that work together to continuously improve content. Starting with an initial input (like a product description), the system generates ideas and then enters a reasoning loop where:\n\nA **Critic Agent** analyzes the current output and identifies flaws or areas for improvement\nA **Refiner Agent** takes the original input plus the critic's feedback to create enhanced versions\nAn **Evaluator Agent** assesses the refined output and determines if it meets the quality threshold\n\nThe loop continues until either the evaluator determines the output is satisfactory or a maximum number of iterations is reached (configurable, default is 5 turns).\n\n## How to set up\n\n1. Configure the initial AI agent to generate your starting content\n2. Set up the loop structure with \"Reset Loop\" enabled in the loop node options\n3. Configure three AI agents within the loop:\n\n- Critic: Provide detailed analysis prompts for identifying improvements\n- Refiner: Create prompts that incorporate feedback to enhance content\n- Evaluator: Define quality criteria and decision-making logic\n\n\n4. Add Edit Fields nodes at the beginning and end of the loop to maintain data structure\n5. Include a Code node to track iteration count and loop control\n6. Set up the IF node to check exit conditions (max turns or completion status)\n\n## Requirements\n\n**n8n workflow environment**\nAccess to AI/LLM nodes (OpenAI, Anthropic, etc.)\nBasic understanding of JSON data structures\nConfigured AI model credentials\n\n**How to customize the workflow**\nCustomize the system prompts for each agent based on your specific use case. The critic should focus on your quality criteria, the refiner should understand your improvement goals, and the evaluator should have clear success metrics. Adjust the maximum iteration count in the code node and IF condition based on your complexity needs and token budget considerations.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "If",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "Critic Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Refiner Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Edit Fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Edit Fields1",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Evaluation agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    }
  ]
}