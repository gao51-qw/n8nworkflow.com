{
  "id": 5786,
  "slug": "5786",
  "title": "Scrape public email addresses from any website using Firecrawl",
  "description": "## Who's it for\n\nThis template is perfect for sales professionals, marketers, and business developers who need to quickly gather contact information from company websites. Whether you're building prospect lists, researching potential partners, or collecting leads for outreach campaigns, this automation saves hours of manual email hunting.\n\n## What it does\n\nThis workflow automatically discovers and extracts email addresses from any website by:\n\n- Taking a website URL as input through a simple form\n- Using Firecrawl's mapping API to find relevant pages (about, contact, team pages)\n- Batch scraping those pages to extract email addresses\n- Intelligently handling common email obfuscations like \"(at)\" and \"(dot)\"\n- Returning a clean, deduplicated list of valid email addresses\n\nThe automation handles rate limiting, retries failed requests, and filters out invalid or hidden email addresses to ensure you get quality results.\n\n## How to set up\n\n1. **Get Firecrawl API access**: Sign up at [firecrawl.dev](https://firecrawl.dev) and obtain your API key\n2. **Configure credentials**: In n8n, create a new HTTP Header Auth credential named \"Firecrawl\" with:\n   - Header Name: `Authorization`\n   - Header Value: `Bearer YOUR_API_KEY`\n3. **Import the workflow**: Copy the workflow JSON into your n8n instance\n4. **Test the form**: Activate the workflow and test with a sample website URL\n\n## How to customize the workflow\n\n**Search parameters**: Modify the `search` parameter in the map_website node to target different page types (currently searches for \"about contact company authors team\")\n\n**Extraction limits**: Adjust the `limit` parameter to scrape more or fewer pages per website\n\n**Retry logic**: The workflow includes retry logic with a 12-attempt limit - modify the `check_retry_count` node to change this\n\n**Output format**: The `set_result` node formats the final output - customize this to match your preferred data structure\n\n**Email validation**: The JSON schema in `start_batch_scrape` defines how emails are extracted - modify the prompt or schema for different extraction rules\n\nThe workflow is designed to be reliable and handle common edge cases like rate limiting and failed requests, making it production-ready for regular use.",
  "featuredImage": "/data/workflows/5786/5786.webp",
  "author": {
    "id": 101,
    "slug": "lucaswalter",
    "name": "Lucas Walter",
    "avatar": ""
  },
  "categories": [
    "Lead Generation"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 3331,
  "downloads": 333,
  "createdAt": "2025-07-08T16:14:47.162Z",
  "updatedAt": "2026-01-16T08:41:24.347Z",
  "publishedAt": "2025-07-08T16:14:47.162Z",
  "nodes": 10,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/5786",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Scrape public email addresses from any website using Firecrawl",
    "workflowName": "Scrape public email addresses from any website using Firecrawl",
    "description": "## Who's it for\n\nThis template is perfect for sales professionals, marketers, and business developers who need to quickly gather contact information from company websites. Whether you're building prospect lists, researching potential partners, or collecting leads for outreach campaigns, this automation saves hours of manual email hunting.\n\n## What it does\n\nThis workflow automatically discovers and extracts email addresses from any website by:\n\n- Taking a website URL as input through a simple form\n- Using Firecrawl's mapping API to find relevant pages (about, contact, team pages)\n- Batch scraping those pages to extract email addresses\n- Intelligently handling common email obfuscations like \"(at)\" and \"(dot)\"\n- Returning a clean, deduplicated list of valid email addresses\n\nThe automation handles rate limiting, retries failed requests, and filters out invalid or hidden email addresses to ensure you get quality results.\n\n## How to set up\n\n1. **Get Firecrawl API access**: Sign up at [firecrawl.dev](https://firecrawl.dev) and obtain your API key\n2. **Configure credentials**: In n8n, create a new HTTP Header Auth credential named \"Firecrawl\" with:\n   - Header Name: `Authorization`\n   - Header Value: `Bearer YOUR_API_KEY`\n3. **Import the workflow**: Copy the workflow JSON into your n8n instance\n4. **Test the form**: Activate the workflow and test with a sample website URL\n\n## How to customize the workflow\n\n**Search parameters**: Modify the `search` parameter in the map_website node to target different page types (currently searches for \"about contact company authors team\")\n\n**Extraction limits**: Adjust the `limit` parameter to scrape more or fewer pages per website\n\n**Retry logic**: The workflow includes retry logic with a 12-attempt limit - modify the `check_retry_count` node to change this\n\n**Output format**: The `set_result` node formats the final output - customize this to match your preferred data structure\n\n**Email validation**: The JSON schema in `start_batch_scrape` defines how emails are extracted - modify the prompt or schema for different extraction rules\n\nThe workflow is designed to be reliable and handle common edge cases like rate limiting and failed requests, making it production-ready for regular use.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "form_trigger",
      "type": "n8n-nodes-base.formTrigger",
      "role": "formTrigger",
      "configDescription": "Version 2.2"
    },
    {
      "name": "map_website",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "start_batch_scrape",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "check_retry_count",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "too_many_attempts_error",
      "type": "n8n-nodes-base.stopAndError",
      "role": "stopAndError",
      "configDescription": "Version 1"
    },
    {
      "name": "rate_limit_wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "set_result",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "check_scrape_completed",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.2"
    },
    {
      "name": "fetch_scrape_results",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}