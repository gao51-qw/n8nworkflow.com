{
  "id": 12537,
  "slug": "12537",
  "title": "Run multi-model research analysis and email reports with GPT-4, Claude and NVIDIA NIM",
  "description": "## How It Works\nThis workflow automates end-to-end research analysis by coordinating multiple AI models—including NVIDIA NIM (Llama), OpenAI GPT-4, and Claude to analyze uploaded documents, extract insights, and generate polished reports delivered via email. Built for researchers, academics, and business analysts, it enables fast, accurate synthesis of information from multiple sources. The workflow eliminates the manual burden of document review, cross-referencing, and report compilation by running parallel AI analyses, aggregating and validating model outputs, and producing structured, publication-ready documents in minutes instead of hours. Data flows from Google Sheets (user input) through document extraction, parallel AI processing, response aggregation, quality validation, structured storage in Google Sheets, automated report formatting, and final delivery via Gmail with attachments.\n\n## Setup Steps\n1. Configure API credentials \n2. Add OpenAI API key with GPT-4 access enabled\n3. Connect Anthropic Claude API credentials\n4. Set up Google Sheets integration with read/write permissions\n5. Configure Gmail credentials with OAuth2 authentication for automated email\n6. Customize email templates and report formatting preferences \n\n## Prerequisites\nNVIDIA NIM API access, OpenAI API key (GPT-4 enabled), Anthropic Claude API key\n## Use Cases\nAcademic literature reviews, competitive intelligence reports\n## Customization\nAdjust AI model parameters (temperature, tokens) per analysis depth needs\n## Benefits\nReduces research analysis time by 80%, eliminates single-source bias through multi-model consensus",
  "featuredImage": "/data/workflows/12537/12537.webp",
  "author": {
    "id": 101,
    "slug": "cschin",
    "name": "Cheng Siong Chin",
    "avatar": ""
  },
  "categories": [
    "Document Extraction",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 82,
  "downloads": 8,
  "createdAt": "2026-01-07T09:54:53.094Z",
  "updatedAt": "2026-01-16T09:12:38.525Z",
  "publishedAt": "2026-01-07T09:54:53.094Z",
  "nodes": 46,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/12537",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Run multi-model research analysis and email reports with GPT-4, Claude and NVIDIA NIM",
    "workflowName": "Run multi-model research analysis and email reports with GPT-4, Claude and NVIDIA NIM",
    "description": "## How It Works\nThis workflow automates end-to-end research analysis by coordinating multiple AI models—including NVIDIA NIM (Llama), OpenAI GPT-4, and Claude to analyze uploaded documents, extract insights, and generate polished reports delivered via email. Built for researchers, academics, and business analysts, it enables fast, accurate synthesis of information from multiple sources. The workflow eliminates the manual burden of document review, cross-referencing, and report compilation by running parallel AI analyses, aggregating and validating model outputs, and producing structured, publication-ready documents in minutes instead of hours. Data flows from Google Sheets (user input) through document extraction, parallel AI processing, response aggregation, quality validation, structured storage in Google Sheets, automated report formatting, and final delivery via Gmail with attachments.\n\n## Setup Steps\n1. Configure API credentials \n2. Add OpenAI API key with GPT-4 access enabled\n3. Connect Anthropic Claude API credentials\n4. Set up Google Sheets integration with read/write permissions\n5. Configure Gmail credentials with OAuth2 authentication for automated email\n6. Customize email templates and report formatting preferences \n\n## Prerequisites\nNVIDIA NIM API access, OpenAI API key (GPT-4 enabled), Anthropic Claude API key\n## Use Cases\nAcademic literature reviews, competitive intelligence reports\n## Customization\nAdjust AI model parameters (temperature, tokens) per analysis depth needs\n## Benefits\nReduces research analysis time by 80%, eliminates single-source bias through multi-model consensus",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "LLM Request Webhook",
      "type": "n8n-nodes-base.webhook",
      "role": "webhook",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Workflow Configuration",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Parse Request & Validate",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Analyze Prompt Complexity",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Check Azure OpenAI Health",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Check AWS Bedrock Health",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Merge Health Checks",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Score & Rank Models",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Check Policy Constraints",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Apply Policy Routing",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Route to Selected Model",
      "type": "n8n-nodes-base.switch",
      "role": "switch",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Rewrite Prompt for Azure",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Rewrite Prompt for AWS",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Rewrite Prompt for Google",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Rewrite Prompt for Local",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Call Azure OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Call AWS Bedrock",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Call Google Vertex AI",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Call Local Model",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.3"
    },
    {
      "name": "Handle Circuit Breaker",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Check Retry Needed",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Adaptive Retry Delay",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Merge Model Responses",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Normalize Output",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Calculate Telemetry Metrics",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Assess Hallucination Risk",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Calculate Confidence Score",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Log Telemetry to Database",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.6"
    },
    {
      "name": "Store Result in Datastore",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.6"
    },
    {
      "name": "Detect Anomalies",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Check Anomaly Threshold",
      "type": "n8n-nodes-base.if",
      "role": "if",
      "configDescription": "Version 2.3"
    },
    {
      "name": "Send Anomaly Alert",
      "type": "n8n-nodes-base.slack",
      "role": "slack",
      "configDescription": "Version 2.4"
    },
    {
      "name": "Generate Cost Report Data",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.6"
    },
    {
      "name": "Generate Performance Report Data",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.6"
    },
    {
      "name": "Generate Governance Report Data",
      "type": "n8n-nodes-base.postgres",
      "role": "postgres",
      "configDescription": "Version 2.6"
    },
    {
      "name": "Merge Report Data",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.2"
    },
    {
      "name": "Format Report",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "Email Report",
      "type": "n8n-nodes-base.emailSend",
      "role": "emailSend",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Prepare Response",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}