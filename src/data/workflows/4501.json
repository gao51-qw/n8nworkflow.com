{
  "id": 4501,
  "slug": "4501",
  "title": "Build & query RAG system with Google Drive, OpenAI GPT-4o-mini, and Pinecone",
  "description": "üîç What This Workflow Does\n\nThis RAG Pipeline in n8n automates document ingestion from Google Drive, vectorizes it using OpenAI embeddings, stores it in Pinecone, and enables chat-based retrieval using LangChain agents.\n\nMain Functions:\n\nüìÇ Auto-detects new files uploaded to a specific Google Drive folder.\nüß† Converts the file into embeddings using OpenAI.\nüì¶ Stores them in a Pinecone vector database.\nüí¨ Allows a user to query the knowledge base through a chat interface.\nü§ñ Uses a GPT-4o-mini model with LangChain to generate intelligent responses using retrieved context.\n‚öôÔ∏è Setup Instructions\n\n1. Connect Accounts\nEnsure these services are connected in n8n:\n\n‚úÖ Google Drive (OAuth2)\n‚úÖ OpenAI\n‚úÖ Pinecone\nYou can do this in n8n &gt; Credentials &gt; New and use the matching names from the file:\n\nGoogle Drive: \"Google Drive account 2\"\nOpenAI: \"OpenAi success\"\nPinecone: \"PineconeApi account 2\"\n2. Folder Setup\nUpload your documents to this folder in Google Drive:\n\nüìÅ Power Folder\n\nThe workflow is triggered every minute when a new file is uploaded.\n\n3. Workflow Overview\nA. File Ingestion Path\n\nGoogle Drive Trigger ‚Äî detects new file.\nGoogle Drive (Download) ‚Äî downloads the new file.\nRecursive Text Splitter ‚Äî splits text into chunks.\nDefault Data Loader ‚Äî loads content as LangChain documents.\nOpenAI Embeddings ‚Äî converts text chunks into embeddings.\nPinecone Vector Store ‚Äî stores them in \"ragfile\" index.\nB. Chat Retrieval Path\n\nWhen chat message received ‚Äî \nAI Agent ‚Äî LangChain agent managing tools.\nOpenAI Chat Model (GPT-4o-mini) ‚Äî generates replies.\nPinecone Vector Store (retrieval) ‚Äî retrieves matching content.\nEmbeddings OpenAI1 ‚Äî helps match queries to document chunks.\n\n",
  "featuredImage": "/data/workflows/4501/4501.webp",
  "author": {
    "id": 101,
    "slug": "dae221",
    "name": "David Olusola",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "intermediate",
  "price": 0,
  "visitors": 4831,
  "downloads": 483,
  "createdAt": "2025-05-30T01:35:59.082Z",
  "updatedAt": "2026-01-16T08:34:40.880Z",
  "publishedAt": "2025-05-30T01:35:59.082Z",
  "nodes": 12,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4501",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Build & query RAG system with Google Drive, OpenAI GPT-4o-mini, and Pinecone",
    "workflowName": "Build & query RAG system with Google Drive, OpenAI GPT-4o-mini, and Pinecone",
    "description": "üîç What This Workflow Does\n\nThis RAG Pipeline in n8n automates document ingestion from Google Drive, vectorizes it using OpenAI embeddings, stores it in Pinecone, and enables chat-based retrieval using LangChain agents.\n\nMain Functions:\n\nüìÇ Auto-detects new files uploaded to a specific Google Drive folder.\nüß† Converts the file into embeddings using OpenAI.\nüì¶ Stores them in a Pinecone vector database.\nüí¨ Allows a user to query the knowledge base through a chat interface.\nü§ñ Uses a GPT-4o-mini model with LangChain to generate intelligent responses using retrieved context.\n‚öôÔ∏è Setup Instructions\n\n1. Connect Accounts\nEnsure these services are connected in n8n:\n\n‚úÖ Google Drive (OAuth2)\n‚úÖ OpenAI\n‚úÖ Pinecone\nYou can do this in n8n &gt; Credentials &gt; New and use the matching names from the file:\n\nGoogle Drive: \"Google Drive account 2\"\nOpenAI: \"OpenAi success\"\nPinecone: \"PineconeApi account 2\"\n2. Folder Setup\nUpload your documents to this folder in Google Drive:\n\nüìÅ Power Folder\n\nThe workflow is triggered every minute when a new file is uploaded.\n\n3. Workflow Overview\nA. File Ingestion Path\n\nGoogle Drive Trigger ‚Äî detects new file.\nGoogle Drive (Download) ‚Äî downloads the new file.\nRecursive Text Splitter ‚Äî splits text into chunks.\nDefault Data Loader ‚Äî loads content as LangChain documents.\nOpenAI Embeddings ‚Äî converts text chunks into embeddings.\nPinecone Vector Store ‚Äî stores them in \"ragfile\" index.\nB. Chat Retrieval Path\n\nWhen chat message received ‚Äî \nAI Agent ‚Äî LangChain agent managing tools.\nOpenAI Chat Model (GPT-4o-mini) ‚Äî generates replies.\nPinecone Vector Store (retrieval) ‚Äî retrieves matching content.\nEmbeddings OpenAI1 ‚Äî helps match queries to document chunks.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Google Drive Trigger",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "role": "googleDriveTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Drive",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "role": "lmChatOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Pinecone Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "role": "vectorStorePinecone",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}