{
  "id": 6345,
  "slug": "6345",
  "title": "Answer questions from documents with RAG using Supabase, OpenAI & Cohere reranker",
  "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\nThis comprehensive RAG workflow enables your AI agents to answer user questions with contextual knowledge pulled from your own documents â€” using metadata-rich embeddings stored in Supabase.\n\nðŸ”§ Key Features:\nRAG Agents powered by GPT-4.5 or GPT-3.5 via OpenRouter or OpenAI.\n\nSupabase Vector Store to store and retrieve document embeddings.\n\nCohere Reranker to improve response relevance and quality.\n\nMetadata Agent to enrich vectorized data before ingestion.\n\nPDF Extraction Flow to automatically parse and upload documents with metadata.\n\nâœ… Setup Steps:\nConnect your Supabase Vector Store.\n\nUse OpenAI Embeddings (e.g. text-embedding-3-small).\n\nAdd API keys for OpenAI and/or OpenRouter.\n\nConnect a reranker like Cohere.\n\nProcess documents with metadata before embedding.\n\nStart chatting â€” your AI agent now returns context-rich answers from your own knowledge base!\n\nPerfect for building AI assistants that can reason, search and answer based on internal company data, academic papers, support docs, or personal notes.",
  "featuredImage": "/data/workflows/6345/6345.webp",
  "author": {
    "id": 101,
    "slug": "luanstartflow",
    "name": "Luan Correia",
    "avatar": ""
  },
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 1254,
  "downloads": 125,
  "createdAt": "2025-07-23T21:38:30.005Z",
  "updatedAt": "2026-01-16T08:44:34.221Z",
  "publishedAt": "2025-07-23T21:38:30.005Z",
  "nodes": 26,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/6345",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Answer questions from documents with RAG using Supabase, OpenAI & Cohere reranker",
    "workflowName": "Answer questions from documents with RAG using Supabase, OpenAI & Cohere reranker",
    "description": "*This workflow contains community nodes that are only compatible with the self-hosted version of n8n.*\n\nThis comprehensive RAG workflow enables your AI agents to answer user questions with contextual knowledge pulled from your own documents â€” using metadata-rich embeddings stored in Supabase.\n\nðŸ”§ Key Features:\nRAG Agents powered by GPT-4.5 or GPT-3.5 via OpenRouter or OpenAI.\n\nSupabase Vector Store to store and retrieve document embeddings.\n\nCohere Reranker to improve response relevance and quality.\n\nMetadata Agent to enrich vectorized data before ingestion.\n\nPDF Extraction Flow to automatically parse and upload documents with metadata.\n\nâœ… Setup Steps:\nConnect your Supabase Vector Store.\n\nUse OpenAI Embeddings (e.g. text-embedding-3-small).\n\nAdd API keys for OpenAI and/or OpenRouter.\n\nConnect a reranker like Cohere.\n\nProcess documents with metadata before embedding.\n\nStart chatting â€” your AI agent now returns context-rich answers from your own knowledge base!\n\nPerfect for building AI assistants that can reason, search and answer based on internal company data, academic papers, support docs, or personal notes.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "Download File",
      "type": "n8n-nodes-base.googleDrive",
      "role": "googleDrive",
      "configDescription": "Version 3"
    },
    {
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "role": "documentDefaultDataLoader",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Extract from File",
      "type": "n8n-nodes-base.extractFromFile",
      "role": "extractFromFile",
      "configDescription": "Version 1"
    },
    {
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "role": "code",
      "configDescription": "Version 2"
    },
    {
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "role": "chatTrigger",
      "configDescription": "Version 1.1"
    },
    {
      "name": "GPT 4.1-mini",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "role": "lmChatOpenRouter",
      "configDescription": "Version 1"
    },
    {
      "name": "Reranker Cohere",
      "type": "@n8n/n8n-nodes-langchain.rerankerCohere",
      "role": "rerankerCohere",
      "configDescription": "Version 1"
    },
    {
      "name": "Upload to Supabase",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Supabase Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1.3"
    },
    {
      "name": "GPT 4.1-mini1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "role": "lmChatOpenRouter",
      "configDescription": "Version 1"
    },
    {
      "name": "Reranker Cohere1",
      "type": "@n8n/n8n-nodes-langchain.rerankerCohere",
      "role": "rerankerCohere",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Supabase Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "role": "vectorStoreSupabase",
      "configDescription": "Version 1.3"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "role": "embeddingsOpenAi",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Metadata Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "RAG Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "RAG Agent 2",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "role": "agent",
      "configDescription": "Version 2"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}