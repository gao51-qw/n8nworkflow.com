{
  "id": 4611,
  "slug": "4611",
  "title": "Extract, summarize & analyze Amazon price drops with Bright Data & Google Gemini",
  "description": "![Extract, Summarize, Sentiment Analysis of Price Drops for Amazon Products via Bright Data.png](fileId:1435)\n\n### Notice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\n### Who this is for\nThis n8n-powered automation uses Bright Data's MCP Client to extract real-time data from a price drop site listing the amazon products, including price changes and related product details. \n\nThe extracted data is enriched with structured data transformation, content summarization, and sentiment analysis using Google Gemini LLM.\n\nThe Amazon Price Drop Intelligence Engine is designed for:\n\n- **Ecommerce Analysts** who need timely updates on competitor pricing trends\n\n- **Brand Managers** seeking to understand consumer sentiment around pricing\n\n- **Data Scientists** building pricing models or enrichment pipelines\n\n- **Affiliate Marketers** looking to optimize campaigns based on dynamic pricing\n\n- **AI Developers** automating product intelligence pipelines\n\n\n### What problem is this workflow solving?\n\nThis workflow solves several key pain points:\n\n**Reliable Scraping**: Uses Bright Data MCP, a managed crawling platform that handles proxies, captchas, and site structure changes automatically.\n\n**Insight Generation**: Transforms unstructured HTML into structured data and then into human-readable summaries using Google Gemini LLM.\n\n**Sentiment Context**: Goes beyond raw pricing data to reveal how customers feel about the price change, helping businesses and researchers measure consumer reaction.\n\n**Automated Reporting**: Aggregates and stores data for easy access and downstream automation (e.g., dashboards, notifications, pricing models).\n\n### What this workflow does\n\n**Scrape price drop site with Bright Data MCP**\n\nThe workflow begins by scraping targeted price drop site for Amazon listings using Bright Data's Model Context Protocol (MCP). \n\nYou can configure this to target:\n\n**Structured Data Extraction**\n\nOnce the HTML content is retrieved, Google Gemini is employed to:\n\n- Parse and structure the product information (title, price, discount, brand, ratings)\n\n**Summarization & Sentiment Analysis**\n\nThe extracted data is passed through an LLM chain to:\n\n- Generate a concise summary of the product and its recent price movement\n\n- Perform sentiment analysis on user reviews and public perception\n\n**Store the Results**\n\n- Save to disk for archiving or bulk processing\n\n- Updated in a Google Sheet, making it instantly shareable with your team or integrated into a BI dashboard\n\n\n### Pre-conditions\n\n1. Knowledge of Model Context Protocol (MCP) is highly essential. Please read this blog post - [model-context-protocol](https://www.anthropic.com/news/model-context-protocol)\n2. You need to have the [Bright Data](https://brightdata.com/) account and do the necessary setup as mentioned in the **Setup** section below.\n3. You need to have the Google Gemini API Key. Visit [Google AI Studio](https://aistudio.google.com/)\n3. You need to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)\n4. You need to install the [n8n-nodes-mcp](https://github.com/nerding-io/n8n-nodes-mcp)\n\n### Setup\n1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://www.youtube.com/watch?v=NUb73ErUCsA)\n2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)  on your local machine.\n3. Sign up at [Bright Data](https://brightdata.com/).\n4. Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\n5. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n6. In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).\n7. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\n![MCPClientAccount.png](fileId:1434)\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above as API_TOKEN=&lt;your-token&gt;\n\n### How to customize this workflow to your needs\n\n- **Target different platforms**: Switch Amazon for Walmart, eBay, or any ecommerce source using Bright Data’s flexible scraping infrastructure.\n\n- **Enrich with more LLM tasks**: Add brand tone analysis, category classification, or competitive benchmarking using Gemini prompts.\n\n- **Visualize output**: Pipe the Google Sheet to Looker Studio, Tableau, or Power BI.\n\n- **Notification integrations**: Add Slack, Discord, or email notifications for price drop alerts.",
  "featuredImage": "/data/workflows/4611/4611.webp",
  "author": {
    "id": 101,
    "slug": "ranjancse",
    "name": "Ranjan Dailata",
    "avatar": ""
  },
  "categories": [
    "Market Research",
    "AI Summarization"
  ],
  "complexityLevel": "advanced",
  "price": 0,
  "visitors": 984,
  "downloads": 98,
  "createdAt": "2025-06-02T23:56:04.415Z",
  "updatedAt": "2026-01-16T08:35:20.997Z",
  "publishedAt": "2025-06-02T23:56:04.415Z",
  "nodes": 26,
  "version": "1.0.0",
  "sourceUrl": "https://n8n.io/workflows/4611",
  "disclaimer": "This workflow is provided as-is. Please review and test before using in production.",
  "overview": {
    "title": "Extract, summarize & analyze Amazon price drops with Bright Data & Google Gemini",
    "workflowName": "Extract, summarize & analyze Amazon price drops with Bright Data & Google Gemini",
    "description": "![Extract, Summarize, Sentiment Analysis of Price Drops for Amazon Products via Bright Data.png](fileId:1435)\n\n### Notice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\n### Who this is for\nThis n8n-powered automation uses Bright Data's MCP Client to extract real-time data from a price drop site listing the amazon products, including price changes and related product details. \n\nThe extracted data is enriched with structured data transformation, content summarization, and sentiment analysis using Google Gemini LLM.\n\nThe Amazon Price Drop Intelligence Engine is designed for:\n\n- **Ecommerce Analysts** who need timely updates on competitor pricing trends\n\n- **Brand Managers** seeking to understand consumer sentiment around pricing\n\n- **Data Scientists** building pricing models or enrichment pipelines\n\n- **Affiliate Marketers** looking to optimize campaigns based on dynamic pricing\n\n- **AI Developers** automating product intelligence pipelines\n\n\n### What problem is this workflow solving?\n\nThis workflow solves several key pain points:\n\n**Reliable Scraping**: Uses Bright Data MCP, a managed crawling platform that handles proxies, captchas, and site structure changes automatically.\n\n**Insight Generation**: Transforms unstructured HTML into structured data and then into human-readable summaries using Google Gemini LLM.\n\n**Sentiment Context**: Goes beyond raw pricing data to reveal how customers feel about the price change, helping businesses and researchers measure consumer reaction.\n\n**Automated Reporting**: Aggregates and stores data for easy access and downstream automation (e.g., dashboards, notifications, pricing models).\n\n### What this workflow does\n\n**Scrape price drop site with Bright Data MCP**\n\nThe workflow begins by scraping targeted price drop site for Amazon listings using Bright Data's Model Context Protocol (MCP). \n\nYou can configure this to target:\n\n**Structured Data Extraction**\n\nOnce the HTML content is retrieved, Google Gemini is employed to:\n\n- Parse and structure the product information (title, price, discount, brand, ratings)\n\n**Summarization & Sentiment Analysis**\n\nThe extracted data is passed through an LLM chain to:\n\n- Generate a concise summary of the product and its recent price movement\n\n- Perform sentiment analysis on user reviews and public perception\n\n**Store the Results**\n\n- Save to disk for archiving or bulk processing\n\n- Updated in a Google Sheet, making it instantly shareable with your team or integrated into a BI dashboard\n\n\n### Pre-conditions\n\n1. Knowledge of Model Context Protocol (MCP) is highly essential. Please read this blog post - [model-context-protocol](https://www.anthropic.com/news/model-context-protocol)\n2. You need to have the [Bright Data](https://brightdata.com/) account and do the necessary setup as mentioned in the **Setup** section below.\n3. You need to have the Google Gemini API Key. Visit [Google AI Studio](https://aistudio.google.com/)\n3. You need to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)\n4. You need to install the [n8n-nodes-mcp](https://github.com/nerding-io/n8n-nodes-mcp)\n\n### Setup\n1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://www.youtube.com/watch?v=NUb73ErUCsA)\n2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp)  on your local machine.\n3. Sign up at [Bright Data](https://brightdata.com/).\n4. Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\n5. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n6. In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).\n7. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\n![MCPClientAccount.png](fileId:1434)\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above as API_TOKEN=&lt;your-token&gt;\n\n### How to customize this workflow to your needs\n\n- **Target different platforms**: Switch Amazon for Walmart, eBay, or any ecommerce source using Bright Data’s flexible scraping infrastructure.\n\n- **Enrich with more LLM tasks**: Add brand tone analysis, category classification, or competitive benchmarking using Gemini prompts.\n\n- **Visualize output**: Pipe the Google Sheet to Looker Studio, Tableau, or Power BI.\n\n- **Notification integrations**: Add Slack, Discord, or email notifications for price drop alerts.",
    "features": [],
    "useCases": []
  },
  "logicalBlocks": [],
  "nodeDetails": [
    {
      "name": "When clicking ‘Test workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "role": "manualTrigger",
      "configDescription": "Version 1"
    },
    {
      "name": "Bright Data MCP Client List Tools",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "Set input fields",
      "type": "n8n-nodes-base.set",
      "role": "set",
      "configDescription": "Version 3.4"
    },
    {
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "role": "splitOut",
      "configDescription": "Version 1"
    },
    {
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "role": "splitInBatches",
      "configDescription": "Version 3"
    },
    {
      "name": "Wait",
      "type": "n8n-nodes-base.wait",
      "role": "wait",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Summarize Content",
      "type": "@n8n/n8n-nodes-langchain.chainSummarization",
      "role": "chainSummarization",
      "configDescription": "Version 2.1"
    },
    {
      "name": "Sentiment Analysis",
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "role": "informationExtractor",
      "configDescription": "Version 1.1"
    },
    {
      "name": "Google Gemini Chat Model for Summarize Content",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Google Gemini Chat Model for Sentiment Analysis",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "role": "merge",
      "configDescription": "Version 3.1"
    },
    {
      "name": "Update Google Sheets",
      "type": "n8n-nodes-base.googleSheets",
      "role": "googleSheets",
      "configDescription": "Version 4.5"
    },
    {
      "name": "Webhook Notification for Price Drop Info",
      "type": "n8n-nodes-base.httpRequest",
      "role": "httpRequest",
      "configDescription": "Version 4.2"
    },
    {
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "role": "lmChatGoogleGemini",
      "configDescription": "Version 1"
    },
    {
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "role": "outputParserStructured",
      "configDescription": "Version 1.2"
    },
    {
      "name": "Structure Data Extract Using LLM",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "role": "chainLlm",
      "configDescription": "Version 1.7"
    },
    {
      "name": "MCP Client for Price Drop Data Extract",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "MCP Client for Price Drop Data Extract Within a Loop",
      "type": "n8n-nodes-mcp.mcpClient",
      "role": "mcpClient",
      "configDescription": "Version 1"
    },
    {
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "role": "aggregate",
      "configDescription": "Version 1"
    },
    {
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "role": "textSplitterRecursiveCharacterTextSplitter",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    },
    {
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "role": "stickyNote",
      "configDescription": "Version 1"
    }
  ]
}